#include "tt-decomp_init.h"

__attribute__((alias("__imp____restvmx_26"))) PPC_WEAK_FUNC(__restvmx_26);
PPC_FUNC_IMPL(__imp____restvmx_26) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx v26,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v26.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx v27,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v27.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx v28,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v28.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx v29,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v29.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx v30,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v30.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx v31,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v31.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_27"))) PPC_WEAK_FUNC(__restvmx_27);
PPC_FUNC_IMPL(__imp____restvmx_27) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx v27,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v27.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx v28,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v28.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx v29,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v29.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx v30,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v30.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx v31,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v31.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_28"))) PPC_WEAK_FUNC(__restvmx_28);
PPC_FUNC_IMPL(__imp____restvmx_28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx v28,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v28.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx v29,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v29.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx v30,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v30.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx v31,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v31.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_29"))) PPC_WEAK_FUNC(__restvmx_29);
PPC_FUNC_IMPL(__imp____restvmx_29) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx v29,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v29.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx v30,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v30.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx v31,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v31.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_30"))) PPC_WEAK_FUNC(__restvmx_30);
PPC_FUNC_IMPL(__imp____restvmx_30) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx v30,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v30.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx v31,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v31.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_31"))) PPC_WEAK_FUNC(__restvmx_31);
PPC_FUNC_IMPL(__imp____restvmx_31) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx v31,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v31.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_64"))) PPC_WEAK_FUNC(__restvmx_64);
PPC_FUNC_IMPL(__imp____restvmx_64) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-1024
	ctx.r11.s64 = -1024;
	// lvx128 v64,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v64.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-1008
	ctx.r11.s64 = -1008;
	// lvx128 v65,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v65.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-992
	ctx.r11.s64 = -992;
	// lvx128 v66,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v66.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-976
	ctx.r11.s64 = -976;
	// lvx128 v67,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v67.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-960
	ctx.r11.s64 = -960;
	// lvx128 v68,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v68.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-944
	ctx.r11.s64 = -944;
	// lvx128 v69,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v69.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-928
	ctx.r11.s64 = -928;
	// lvx128 v70,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v70.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-912
	ctx.r11.s64 = -912;
	// lvx128 v71,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v71.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_65"))) PPC_WEAK_FUNC(__restvmx_65);
PPC_FUNC_IMPL(__imp____restvmx_65) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-1008
	ctx.r11.s64 = -1008;
	// lvx128 v65,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v65.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-992
	ctx.r11.s64 = -992;
	// lvx128 v66,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v66.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-976
	ctx.r11.s64 = -976;
	// lvx128 v67,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v67.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-960
	ctx.r11.s64 = -960;
	// lvx128 v68,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v68.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-944
	ctx.r11.s64 = -944;
	// lvx128 v69,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v69.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-928
	ctx.r11.s64 = -928;
	// lvx128 v70,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v70.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-912
	ctx.r11.s64 = -912;
	// lvx128 v71,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v71.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_66"))) PPC_WEAK_FUNC(__restvmx_66);
PPC_FUNC_IMPL(__imp____restvmx_66) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-992
	ctx.r11.s64 = -992;
	// lvx128 v66,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v66.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-976
	ctx.r11.s64 = -976;
	// lvx128 v67,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v67.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-960
	ctx.r11.s64 = -960;
	// lvx128 v68,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v68.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-944
	ctx.r11.s64 = -944;
	// lvx128 v69,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v69.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-928
	ctx.r11.s64 = -928;
	// lvx128 v70,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v70.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-912
	ctx.r11.s64 = -912;
	// lvx128 v71,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v71.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_67"))) PPC_WEAK_FUNC(__restvmx_67);
PPC_FUNC_IMPL(__imp____restvmx_67) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-976
	ctx.r11.s64 = -976;
	// lvx128 v67,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v67.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-960
	ctx.r11.s64 = -960;
	// lvx128 v68,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v68.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-944
	ctx.r11.s64 = -944;
	// lvx128 v69,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v69.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-928
	ctx.r11.s64 = -928;
	// lvx128 v70,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v70.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-912
	ctx.r11.s64 = -912;
	// lvx128 v71,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v71.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_68"))) PPC_WEAK_FUNC(__restvmx_68);
PPC_FUNC_IMPL(__imp____restvmx_68) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-960
	ctx.r11.s64 = -960;
	// lvx128 v68,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v68.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-944
	ctx.r11.s64 = -944;
	// lvx128 v69,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v69.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-928
	ctx.r11.s64 = -928;
	// lvx128 v70,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v70.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-912
	ctx.r11.s64 = -912;
	// lvx128 v71,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v71.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_69"))) PPC_WEAK_FUNC(__restvmx_69);
PPC_FUNC_IMPL(__imp____restvmx_69) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-944
	ctx.r11.s64 = -944;
	// lvx128 v69,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v69.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-928
	ctx.r11.s64 = -928;
	// lvx128 v70,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v70.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-912
	ctx.r11.s64 = -912;
	// lvx128 v71,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v71.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_70"))) PPC_WEAK_FUNC(__restvmx_70);
PPC_FUNC_IMPL(__imp____restvmx_70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-928
	ctx.r11.s64 = -928;
	// lvx128 v70,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v70.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-912
	ctx.r11.s64 = -912;
	// lvx128 v71,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v71.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_71"))) PPC_WEAK_FUNC(__restvmx_71);
PPC_FUNC_IMPL(__imp____restvmx_71) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-912
	ctx.r11.s64 = -912;
	// lvx128 v71,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v71.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_72"))) PPC_WEAK_FUNC(__restvmx_72);
PPC_FUNC_IMPL(__imp____restvmx_72) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-896
	ctx.r11.s64 = -896;
	// lvx128 v72,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v72.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_73"))) PPC_WEAK_FUNC(__restvmx_73);
PPC_FUNC_IMPL(__imp____restvmx_73) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-880
	ctx.r11.s64 = -880;
	// lvx128 v73,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v73.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_74"))) PPC_WEAK_FUNC(__restvmx_74);
PPC_FUNC_IMPL(__imp____restvmx_74) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-864
	ctx.r11.s64 = -864;
	// lvx128 v74,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v74.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_75"))) PPC_WEAK_FUNC(__restvmx_75);
PPC_FUNC_IMPL(__imp____restvmx_75) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-848
	ctx.r11.s64 = -848;
	// lvx128 v75,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v75.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_76"))) PPC_WEAK_FUNC(__restvmx_76);
PPC_FUNC_IMPL(__imp____restvmx_76) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-832
	ctx.r11.s64 = -832;
	// lvx128 v76,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v76.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_77"))) PPC_WEAK_FUNC(__restvmx_77);
PPC_FUNC_IMPL(__imp____restvmx_77) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-816
	ctx.r11.s64 = -816;
	// lvx128 v77,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v77.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_78"))) PPC_WEAK_FUNC(__restvmx_78);
PPC_FUNC_IMPL(__imp____restvmx_78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-800
	ctx.r11.s64 = -800;
	// lvx128 v78,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v78.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_79"))) PPC_WEAK_FUNC(__restvmx_79);
PPC_FUNC_IMPL(__imp____restvmx_79) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-784
	ctx.r11.s64 = -784;
	// lvx128 v79,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v79.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_80"))) PPC_WEAK_FUNC(__restvmx_80);
PPC_FUNC_IMPL(__imp____restvmx_80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-768
	ctx.r11.s64 = -768;
	// lvx128 v80,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v80.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_81"))) PPC_WEAK_FUNC(__restvmx_81);
PPC_FUNC_IMPL(__imp____restvmx_81) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-752
	ctx.r11.s64 = -752;
	// lvx128 v81,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v81.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_82"))) PPC_WEAK_FUNC(__restvmx_82);
PPC_FUNC_IMPL(__imp____restvmx_82) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-736
	ctx.r11.s64 = -736;
	// lvx128 v82,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v82.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_83"))) PPC_WEAK_FUNC(__restvmx_83);
PPC_FUNC_IMPL(__imp____restvmx_83) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-720
	ctx.r11.s64 = -720;
	// lvx128 v83,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v83.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_84"))) PPC_WEAK_FUNC(__restvmx_84);
PPC_FUNC_IMPL(__imp____restvmx_84) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-704
	ctx.r11.s64 = -704;
	// lvx128 v84,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v84.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_85"))) PPC_WEAK_FUNC(__restvmx_85);
PPC_FUNC_IMPL(__imp____restvmx_85) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-688
	ctx.r11.s64 = -688;
	// lvx128 v85,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v85.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_86"))) PPC_WEAK_FUNC(__restvmx_86);
PPC_FUNC_IMPL(__imp____restvmx_86) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-672
	ctx.r11.s64 = -672;
	// lvx128 v86,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v86.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_87"))) PPC_WEAK_FUNC(__restvmx_87);
PPC_FUNC_IMPL(__imp____restvmx_87) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-656
	ctx.r11.s64 = -656;
	// lvx128 v87,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v87.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_88"))) PPC_WEAK_FUNC(__restvmx_88);
PPC_FUNC_IMPL(__imp____restvmx_88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-640
	ctx.r11.s64 = -640;
	// lvx128 v88,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v88.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_89"))) PPC_WEAK_FUNC(__restvmx_89);
PPC_FUNC_IMPL(__imp____restvmx_89) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-624
	ctx.r11.s64 = -624;
	// lvx128 v89,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v89.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_90"))) PPC_WEAK_FUNC(__restvmx_90);
PPC_FUNC_IMPL(__imp____restvmx_90) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-608
	ctx.r11.s64 = -608;
	// lvx128 v90,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v90.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_91"))) PPC_WEAK_FUNC(__restvmx_91);
PPC_FUNC_IMPL(__imp____restvmx_91) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-592
	ctx.r11.s64 = -592;
	// lvx128 v91,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v91.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_92"))) PPC_WEAK_FUNC(__restvmx_92);
PPC_FUNC_IMPL(__imp____restvmx_92) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-576
	ctx.r11.s64 = -576;
	// lvx128 v92,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v92.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_93"))) PPC_WEAK_FUNC(__restvmx_93);
PPC_FUNC_IMPL(__imp____restvmx_93) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-560
	ctx.r11.s64 = -560;
	// lvx128 v93,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v93.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_94"))) PPC_WEAK_FUNC(__restvmx_94);
PPC_FUNC_IMPL(__imp____restvmx_94) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-544
	ctx.r11.s64 = -544;
	// lvx128 v94,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v94.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_95"))) PPC_WEAK_FUNC(__restvmx_95);
PPC_FUNC_IMPL(__imp____restvmx_95) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-528
	ctx.r11.s64 = -528;
	// lvx128 v95,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v95.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_96"))) PPC_WEAK_FUNC(__restvmx_96);
PPC_FUNC_IMPL(__imp____restvmx_96) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-512
	ctx.r11.s64 = -512;
	// lvx128 v96,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v96.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_97"))) PPC_WEAK_FUNC(__restvmx_97);
PPC_FUNC_IMPL(__imp____restvmx_97) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-496
	ctx.r11.s64 = -496;
	// lvx128 v97,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v97.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_98"))) PPC_WEAK_FUNC(__restvmx_98);
PPC_FUNC_IMPL(__imp____restvmx_98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-480
	ctx.r11.s64 = -480;
	// lvx128 v98,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v98.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_99"))) PPC_WEAK_FUNC(__restvmx_99);
PPC_FUNC_IMPL(__imp____restvmx_99) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-464
	ctx.r11.s64 = -464;
	// lvx128 v99,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v99.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_100"))) PPC_WEAK_FUNC(__restvmx_100);
PPC_FUNC_IMPL(__imp____restvmx_100) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-448
	ctx.r11.s64 = -448;
	// lvx128 v100,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v100.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_101"))) PPC_WEAK_FUNC(__restvmx_101);
PPC_FUNC_IMPL(__imp____restvmx_101) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-432
	ctx.r11.s64 = -432;
	// lvx128 v101,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v101.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_102"))) PPC_WEAK_FUNC(__restvmx_102);
PPC_FUNC_IMPL(__imp____restvmx_102) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-416
	ctx.r11.s64 = -416;
	// lvx128 v102,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v102.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_103"))) PPC_WEAK_FUNC(__restvmx_103);
PPC_FUNC_IMPL(__imp____restvmx_103) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-400
	ctx.r11.s64 = -400;
	// lvx128 v103,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v103.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_104"))) PPC_WEAK_FUNC(__restvmx_104);
PPC_FUNC_IMPL(__imp____restvmx_104) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-384
	ctx.r11.s64 = -384;
	// lvx128 v104,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v104.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_105"))) PPC_WEAK_FUNC(__restvmx_105);
PPC_FUNC_IMPL(__imp____restvmx_105) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-368
	ctx.r11.s64 = -368;
	// lvx128 v105,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v105.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_106"))) PPC_WEAK_FUNC(__restvmx_106);
PPC_FUNC_IMPL(__imp____restvmx_106) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-352
	ctx.r11.s64 = -352;
	// lvx128 v106,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v106.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_107"))) PPC_WEAK_FUNC(__restvmx_107);
PPC_FUNC_IMPL(__imp____restvmx_107) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-336
	ctx.r11.s64 = -336;
	// lvx128 v107,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v107.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_108"))) PPC_WEAK_FUNC(__restvmx_108);
PPC_FUNC_IMPL(__imp____restvmx_108) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-320
	ctx.r11.s64 = -320;
	// lvx128 v108,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v108.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_109"))) PPC_WEAK_FUNC(__restvmx_109);
PPC_FUNC_IMPL(__imp____restvmx_109) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-304
	ctx.r11.s64 = -304;
	// lvx128 v109,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v109.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_110"))) PPC_WEAK_FUNC(__restvmx_110);
PPC_FUNC_IMPL(__imp____restvmx_110) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-288
	ctx.r11.s64 = -288;
	// lvx128 v110,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v110.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_111"))) PPC_WEAK_FUNC(__restvmx_111);
PPC_FUNC_IMPL(__imp____restvmx_111) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-272
	ctx.r11.s64 = -272;
	// lvx128 v111,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v111.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_112"))) PPC_WEAK_FUNC(__restvmx_112);
PPC_FUNC_IMPL(__imp____restvmx_112) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-256
	ctx.r11.s64 = -256;
	// lvx128 v112,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v112.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_113"))) PPC_WEAK_FUNC(__restvmx_113);
PPC_FUNC_IMPL(__imp____restvmx_113) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-240
	ctx.r11.s64 = -240;
	// lvx128 v113,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v113.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_114"))) PPC_WEAK_FUNC(__restvmx_114);
PPC_FUNC_IMPL(__imp____restvmx_114) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-224
	ctx.r11.s64 = -224;
	// lvx128 v114,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v114.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_115"))) PPC_WEAK_FUNC(__restvmx_115);
PPC_FUNC_IMPL(__imp____restvmx_115) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-208
	ctx.r11.s64 = -208;
	// lvx128 v115,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v115.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_116"))) PPC_WEAK_FUNC(__restvmx_116);
PPC_FUNC_IMPL(__imp____restvmx_116) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-192
	ctx.r11.s64 = -192;
	// lvx128 v116,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v116.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_117"))) PPC_WEAK_FUNC(__restvmx_117);
PPC_FUNC_IMPL(__imp____restvmx_117) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-176
	ctx.r11.s64 = -176;
	// lvx128 v117,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v117.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_118"))) PPC_WEAK_FUNC(__restvmx_118);
PPC_FUNC_IMPL(__imp____restvmx_118) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-160
	ctx.r11.s64 = -160;
	// lvx128 v118,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v118.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_119"))) PPC_WEAK_FUNC(__restvmx_119);
PPC_FUNC_IMPL(__imp____restvmx_119) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-144
	ctx.r11.s64 = -144;
	// lvx128 v119,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v119.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_120"))) PPC_WEAK_FUNC(__restvmx_120);
PPC_FUNC_IMPL(__imp____restvmx_120) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-128
	ctx.r11.s64 = -128;
	// lvx128 v120,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v120.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_121"))) PPC_WEAK_FUNC(__restvmx_121);
PPC_FUNC_IMPL(__imp____restvmx_121) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-112
	ctx.r11.s64 = -112;
	// lvx128 v121,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v121.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_122"))) PPC_WEAK_FUNC(__restvmx_122);
PPC_FUNC_IMPL(__imp____restvmx_122) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-96
	ctx.r11.s64 = -96;
	// lvx128 v122,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v122.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_123"))) PPC_WEAK_FUNC(__restvmx_123);
PPC_FUNC_IMPL(__imp____restvmx_123) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-80
	ctx.r11.s64 = -80;
	// lvx128 v123,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v123.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_124"))) PPC_WEAK_FUNC(__restvmx_124);
PPC_FUNC_IMPL(__imp____restvmx_124) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-64
	ctx.r11.s64 = -64;
	// lvx128 v124,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v124.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_125"))) PPC_WEAK_FUNC(__restvmx_125);
PPC_FUNC_IMPL(__imp____restvmx_125) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-48
	ctx.r11.s64 = -48;
	// lvx128 v125,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v125.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_126"))) PPC_WEAK_FUNC(__restvmx_126);
PPC_FUNC_IMPL(__imp____restvmx_126) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-32
	ctx.r11.s64 = -32;
	// lvx128 v126,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v126.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp____restvmx_127"))) PPC_WEAK_FUNC(__restvmx_127);
PPC_FUNC_IMPL(__imp____restvmx_127) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// li r11,-16
	ctx.r11.s64 = -16;
	// lvx128 v127,r11,r12
	ea = (ctx.r11.u32 + ctx.r12.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v127.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_9980_2h"))) PPC_WEAK_FUNC(atSingleton_9980_2h);
PPC_FUNC_IMPL(__imp__atSingleton_9980_2h) {
	PPC_FUNC_PROLOGUE();
	// cmpwi cr6,r3,0
	// bgelr cr6
	if (ctx.r3.s32 >= 0) return;
	// neg r3,r3
	ctx.r3.s64 = static_cast<int64_t>(-ctx.r3.u64);
	// blr
	return;
}

__attribute__((alias("__imp__RtlUnwind_9990_fw"))) PPC_WEAK_FUNC(RtlUnwind_9990_fw);
PPC_FUNC_IMPL(__imp__RtlUnwind_9990_fw) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t ea{};
	// std r31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, var_r31);
	// mflr r31
	var_r31 = (uint32_t)(ctx.lr);
	// stwu r1,-80(r1)
	ea = -80 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x8258629c
	__imp__RtlUnwind(ctx, base);
	// mtlr r31
	ctx.lr = var_r31;
	// ld r31,8(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + 8));
	// addi r1,r1,80
	ctx.r1.s64 = ctx.r1.s64 + 80;
	// blr
	return;
}

__attribute__((alias("__imp__game_99B8_h"))) PPC_WEAK_FUNC(game_99B8_h);
PPC_FUNC_IMPL(__imp__game_99B8_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// bl 0x8242fc68
	fiAsciiTokenizer_FC68_g(ctx, base);
	// stw r31,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, var_r31);
	// blr
	return;
}

__attribute__((alias("__imp__game_99E8_w"))) PPC_WEAK_FUNC(game_99E8_w);
PPC_FUNC_IMPL(__imp__game_99E8_w) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// bl 0x8242fc68
	fiAsciiTokenizer_FC68_g(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r10,3
	ctx.r10.s64 = 196608;
	// ori r10,r10,17405
	ctx.r10.u64 = ctx.r10.u64 | 17405;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mullw r10,r9,r10
	ctx.r10.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// addis r10,r10,39
	ctx.r10.s64 = ctx.r10.s64 + 2555904;
	// addi r10,r10,-24893
	ctx.r10.s64 = ctx.r10.s64 + -24893;
	// rlwinm r3,r10,16,17,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x7FFF;
	// stw r10,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r10.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_9A30"))) PPC_WEAK_FUNC(xam_9A30);
PPC_FUNC_IMPL(__imp__xam_9A30) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r9,4
	ctx.r9.s64 = 4;
	// extsw r8,r4
	ctx.r8.s64 = ctx.r4.s32;
	// lwz r10,512(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 512);
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// std r8,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r8.u64);
	// lwz r3,512(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 512);
	// addi r10,r3,1
	ctx.r10.s64 = ctx.r3.s64 + 1;
	// stw r10,512(r11)
	PPC_STORE_U32(ctx.r11.u32 + 512, ctx.r10.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_9A60"))) PPC_WEAK_FUNC(xam_9A60);
PPC_FUNC_IMPL(__imp__xam_9A60) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=720, savegprlr_28
	// li r30,0
	var_r30 = 0;
	// stw r3,740(r1)
	PPC_STORE_U32(ctx.r1.u32 + 740, ctx.r3.u32);
	// stw r4,748(r1)
	PPC_STORE_U32(ctx.r1.u32 + 748, ctx.r4.u32);
	// li r3,518
	ctx.r3.s64 = 518;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// stw r5,756(r1)
	PPC_STORE_U32(ctx.r1.u32 + 756, ctx.r5.u32);
	// mr r29,r6
	var_r29 = ctx.r6.u32;
	// mr r28,r7
	var_r28 = ctx.r7.u32;
	// stw r30,672(r1)
	PPC_STORE_U32(ctx.r1.u32 + 672, var_r30);
	// stw r30,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, var_r30);
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, var_r30);
	// bl 0x8256a730
	xam_A730(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// blt 0x82569b8c
	if ((int32_t)var_r31 >= 0) {
		// li r9,0
		ctx.r9.s64 = 0;
		// lwz r3,136(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
		// li r8,0
		ctx.r8.s64 = 0;
		// addi r7,r1,132
		ctx.r7.s64 = ctx.r1.s64 + 132;
		// li r6,0
		ctx.r6.s64 = 0;
		// li r5,0
		ctx.r5.s64 = 0;
		// li r4,0
		ctx.r4.s64 = 0;
		// bl 0x8256a7a8
		xam_A7A8(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// blt 0x82569b8c
		if ((int32_t)var_r31 < 0) goto loc_82569B8C;
		// addi r5,r1,128
		ctx.r5.s64 = ctx.r1.s64 + 128;
		// lwz r4,132(r1)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
		// li r3,0
		ctx.r3.s64 = 0;
		// bl 0x8258676c
		__imp__XamAlloc(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// blt 0x82569b8c
		if ((int32_t)var_r31 < 0) goto loc_82569B8C;
		// addi r6,r1,144
		ctx.r6.s64 = ctx.r1.s64 + 144;
		// lwz r8,132(r1)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
		// addi r7,r1,148
		ctx.r7.s64 = ctx.r1.s64 + 148;
		// lwz r4,136(r1)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
		// addi r11,r1,140
		ctx.r11.s64 = ctx.r1.s64 + 140;
		// stw r30,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, var_r30);
		// li r10,0
		ctx.r10.s64 = 0;
		// stw r30,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, var_r30);
		// li r9,0
		ctx.r9.s64 = 0;
		// stw r6,92(r1)
		PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
		// li r5,0
		ctx.r5.s64 = 0;
		// li r6,0
		ctx.r6.s64 = 0;
		// stw r7,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
		// li r3,518
		ctx.r3.s64 = 518;
		// lwz r7,128(r1)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
		// stw r11,116(r1)
		PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
		// bl 0x8256a848
		xam_A848(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// blt 0x82569b8c
		if ((int32_t)var_r31 < 0) goto loc_82569B8C;
		// addi r4,r1,740
		ctx.r4.s64 = ctx.r1.s64 + 740;
		// addi r3,r1,160
		ctx.r3.s64 = ctx.r1.s64 + 160;
		// bl 0x82569a30
		xam_9A30(ctx, base);
		// addi r4,r1,748
		ctx.r4.s64 = ctx.r1.s64 + 748;
		// addi r3,r1,160
		ctx.r3.s64 = ctx.r1.s64 + 160;
		// bl 0x82569a30
		xam_9A30(ctx, base);
		// addi r4,r1,756
		ctx.r4.s64 = ctx.r1.s64 + 756;
		// addi r3,r1,160
		ctx.r3.s64 = ctx.r1.s64 + 160;
		// bl 0x82569a30
		xam_9A30(ctx, base);
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// addi r3,r1,160
		ctx.r3.s64 = ctx.r1.s64 + 160;
		// bl 0x82569a30
		xam_9A30(ctx, base);
		// mr r4,r28
		ctx.r4.u64 = var_r28;
		// addi r3,r1,160
		ctx.r3.s64 = ctx.r1.s64 + 160;
		// bl 0x82569a30
		xam_9A30(ctx, base);
		// lis r4,5
		ctx.r4.s64 = 327680;
		// addi r6,r1,160
		ctx.r6.s64 = ctx.r1.s64 + 160;
		// lwz r5,140(r1)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
		// ori r4,r4,32800
		ctx.r4.u64 = ctx.r4.u64 | 32800;
		// li r3,252
		ctx.r3.s64 = 252;
		// bl 0x825860dc
		__imp__XMsgInProcessCall(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// bge 0x82569bac
		if ((int32_t)var_r31 >= 0) goto loc_82569BAC;
	}
loc_82569B8C:
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r3,0
	// beq cr6,0x82569b9c
	if (ctx.r3.u32 != 0) {
		// bl 0x8258675c
		__imp__XamFree(ctx, base);
	}
loc_82569B9C:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8242c388
	thunk_game_C318(ctx, base);
	// li r30,1627
	var_r30 = 1627;
	// b 0x82569bb4
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	return;
loc_82569BAC:
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// bl 0x8258675c
	__imp__XamFree(ctx, base);
loc_82569BB4:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	return;
}

__attribute__((alias("__imp__xam_9BC0"))) PPC_WEAK_FUNC(xam_9BC0);
PPC_FUNC_IMPL(__imp__xam_9BC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=720, savegprlr_29
	// li r30,0
	var_r30 = 0;
	// stw r3,740(r1)
	PPC_STORE_U32(ctx.r1.u32 + 740, ctx.r3.u32);
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// li r3,1414
	ctx.r3.s64 = 1414;
	// stw r30,672(r1)
	PPC_STORE_U32(ctx.r1.u32 + 672, var_r30);
	// stw r30,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, var_r30);
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, var_r30);
	// bl 0x8256a730
	xam_A730(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// blt 0x82569cbc
	if ((int32_t)var_r31 >= 0) {
		// li r9,0
		ctx.r9.s64 = 0;
		// lwz r3,136(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
		// li r8,0
		ctx.r8.s64 = 0;
		// addi r7,r1,132
		ctx.r7.s64 = ctx.r1.s64 + 132;
		// li r6,0
		ctx.r6.s64 = 0;
		// li r5,0
		ctx.r5.s64 = 0;
		// li r4,0
		ctx.r4.s64 = 0;
		// bl 0x8256a7a8
		xam_A7A8(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// blt 0x82569cbc
		if ((int32_t)var_r31 < 0) goto loc_82569CBC;
		// addi r5,r1,128
		ctx.r5.s64 = ctx.r1.s64 + 128;
		// lwz r4,132(r1)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
		// li r3,0
		ctx.r3.s64 = 0;
		// bl 0x8258676c
		__imp__XamAlloc(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// blt 0x82569cbc
		if ((int32_t)var_r31 < 0) goto loc_82569CBC;
		// addi r6,r1,144
		ctx.r6.s64 = ctx.r1.s64 + 144;
		// lwz r8,132(r1)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
		// addi r7,r1,148
		ctx.r7.s64 = ctx.r1.s64 + 148;
		// lwz r4,136(r1)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
		// addi r11,r1,140
		ctx.r11.s64 = ctx.r1.s64 + 140;
		// stw r30,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, var_r30);
		// li r10,0
		ctx.r10.s64 = 0;
		// stw r30,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, var_r30);
		// li r9,0
		ctx.r9.s64 = 0;
		// stw r6,92(r1)
		PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
		// li r5,0
		ctx.r5.s64 = 0;
		// li r6,0
		ctx.r6.s64 = 0;
		// stw r7,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
		// li r3,1414
		ctx.r3.s64 = 1414;
		// lwz r7,128(r1)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
		// stw r11,116(r1)
		PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
		// bl 0x8256a848
		xam_A848(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// blt 0x82569cbc
		if ((int32_t)var_r31 < 0) goto loc_82569CBC;
		// addi r4,r1,740
		ctx.r4.s64 = ctx.r1.s64 + 740;
		// addi r3,r1,160
		ctx.r3.s64 = ctx.r1.s64 + 160;
		// bl 0x82569a30
		xam_9A30(ctx, base);
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// addi r3,r1,160
		ctx.r3.s64 = ctx.r1.s64 + 160;
		// bl 0x82569a30
		xam_9A30(ctx, base);
		// lis r4,5
		ctx.r4.s64 = 327680;
		// addi r6,r1,160
		ctx.r6.s64 = ctx.r1.s64 + 160;
		// lwz r5,140(r1)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
		// ori r4,r4,32803
		ctx.r4.u64 = ctx.r4.u64 | 32803;
		// li r3,252
		ctx.r3.s64 = 252;
		// bl 0x825860dc
		__imp__XMsgInProcessCall(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// bge 0x82569cdc
		if ((int32_t)var_r31 >= 0) goto loc_82569CDC;
	}
loc_82569CBC:
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplwi cr6,r3,0
	// beq cr6,0x82569ccc
	if (ctx.r3.u32 != 0) {
		// bl 0x8258675c
		__imp__XamFree(ctx, base);
	}
loc_82569CCC:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8242c388
	thunk_game_C318(ctx, base);
	// li r30,1627
	var_r30 = 1627;
	// b 0x82569ce4
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	return;
loc_82569CDC:
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// bl 0x8258675c
	__imp__XamFree(ctx, base);
loc_82569CE4:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	return;
}

__attribute__((alias("__imp__SinglesNetworkClient_9CF0_g"))) PPC_WEAK_FUNC(SinglesNetworkClient_9CF0_g);
PPC_FUNC_IMPL(__imp__SinglesNetworkClient_9CF0_g) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=112, manual
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// lis r4,5
	ctx.r4.s64 = 327680;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// ori r4,r4,32782
	ctx.r4.u64 = ctx.r4.u64 | 32782;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// li r3,252
	ctx.r3.s64 = 252;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// bl 0x825860dc
	__imp__XMsgInProcessCall(ctx, base);
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// blr
	return;
}

__attribute__((alias("__imp__xam_9D40"))) PPC_WEAK_FUNC(xam_9D40);
PPC_FUNC_IMPL(__imp__xam_9D40) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r23 = 0;
	PPCRegister temp{};
	// FRAME: size=224, savegprlr_22
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr r25,r5
	var_r25 = ctx.r5.u32;
	// mr r24,r6
	var_r24 = ctx.r6.u32;
	// mr r28,r7
	var_r28 = ctx.r7.u32;
	// mr r27,r8
	var_r27 = ctx.r8.u32;
	// mr r26,r9
	var_r26 = ctx.r9.u32;
	// mr r22,r10
	var_r22 = ctx.r10.u32;
	// cmplwi cr6,r29,4
	// bge cr6,0x82569ebc
	if (var_r29 < 4) {
		// cmplwi cr6,r27,0
		// beq cr6,0x82569ebc
		if (var_r27 == 0) goto loc_82569EBC;
		// cmplwi cr6,r28,0
		// beq cr6,0x82569ebc
		if (var_r28 == 0) goto loc_82569EBC;
		// cmplwi cr6,r22,0
		// beq cr6,0x82569ebc
		if (var_r22 == 0) goto loc_82569EBC;
		// li r12,-5952
		// li r11,-1
		ctx.r11.s64 = -1;
		// stw r11,0(r22)
		PPC_STORE_U32(var_r22 + 0, ctx.r11.u32);
		// and. r10,r30,r12
		ctx.r10.u64 = var_r30 & ctx.r12.u64;
		// bne 0x82569ebc
		if (ctx.r10.s32 != 0) goto loc_82569EBC;
		// rlwinm. r10,r30,0,28,28
		ctx.r10.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 0) & 0x8;
		// beq 0x82569db0
		if (ctx.r10.s32 != 0) {
			// rlwinm. r11,r30,0,26,26
			ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 0) & 0x20;
			// beq 0x82569ebc
			if (ctx.r11.s32 == 0) goto loc_82569EBC;
		}
	loc_82569DB0:
		// rlwinm. r11,r30,0,27,27
		ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 0) & 0x10;
		// beq 0x82569dc0
		if (ctx.r11.s32 != 0) {
			// rlwinm. r11,r30,0,29,29
			ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 0) & 0x4;
			// beq 0x82569ebc
			if (ctx.r11.s32 == 0) goto loc_82569EBC;
		}
	loc_82569DC0:
		// clrlwi. r11,r30,31
		ctx.r11.u64 = var_r30 & 0x1;
		// beq 0x82569dd4
		if (ctx.r11.s32 != 0) {
			// andi. r11,r30,44
			ctx.r11.u64 = var_r30 & 44;
			ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
			// cmplwi r11,0
			// beq 0x82569ebc
			if (ctx.r11.u32 == 0) goto loc_82569EBC;
		}
	loc_82569DD4:
		// rlwinm. r11,r30,0,21,23
		ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 0) & 0x700;
		// beq 0x82569e04
		if (ctx.r11.s32 != 0) {
			// andi. r9,r30,10
			ctx.r9.u64 = var_r30 & 10;
			ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
			// cmplwi r9,0
			// beq 0x82569ebc
			if (ctx.r9.u32 == 0) goto loc_82569EBC;
			// rlwinm. r9,r30,0,30,30
			ctx.r9.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 0) & 0x2;
			// bne 0x82569e04
			if (ctx.r9.s32 != 0) goto loc_82569E04;
			// cmplwi cr6,r10,0
			// beq cr6,0x82569e04
			if (ctx.r10.u32 == 0) goto loc_82569E04;
			// rlwinm r10,r30,0,21,21
			ctx.r10.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 0) & 0x400;
			// cmplw cr6,r11,r10
			// bne cr6,0x82569ebc
			if (ctx.r11.u32 != ctx.r10.u32) goto loc_82569EBC;
		}
	loc_82569E04:
		// mr r3,r22
		ctx.r3.u64 = var_r22;
		// bl 0x8258678c
		__imp__XamSessionCreateHandle(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// bne 0x82569ec0
		if ((int32_t)var_r31 != 0) {
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			return;
		}
		// li r23,0
		var_r23 = 0;
		// lwz r3,0(r22)
		ctx.r3.u64 = PPC_LOAD_U32(var_r22 + 0);
		// addi r4,r1,80
		ctx.r4.s64 = ctx.r1.s64 + 80;
		// stw r23,80(r1)
		PPC_STORE_U32(ctx.r1.u32 + 80, var_r23);
		// bl 0x8258677c
		__imp__XamSessionRefObjByHandle(ctx, base);
		// mr. r31,r3
		var_r31 = ctx.r3.u32;
		// bne 0x82569ec0
		if ((int32_t)var_r31 != 0) {
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			return;
		}
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,28
		ctx.r7.s64 = 28;
		// stw r30,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r30);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// stw r29,112(r1)
		PPC_STORE_U32(ctx.r1.u32 + 112, var_r29);
		// mr r5,r26
		ctx.r5.u64 = var_r26;
		// stw r24,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, var_r24);
		// ori r4,r4,16
		ctx.r4.u64 = ctx.r4.u64 | 16;
		// stw r25,104(r1)
		PPC_STORE_U32(ctx.r1.u32 + 104, var_r25);
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r27,116(r1)
		PPC_STORE_U32(ctx.r1.u32 + 116, var_r27);
		// stw r28,120(r1)
		PPC_STORE_U32(ctx.r1.u32 + 120, var_r28);
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x82569e7c
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x82569eac
		} else {
		loc_82569E7C:
			// cmplwi cr6,r26,0
			// bne cr6,0x82569e98
			if (var_r26 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x82569e9c
			} else {
			loc_82569E98:
				// li r31,997
				var_r31 = 997;
			}
		loc_82569E9C:
			// cmplwi cr6,r31,997
			// beq cr6,0x82569ec0
			if (var_r31 == 997) {
				// mr r3,r31
				ctx.r3.u64 = var_r31;
				return;
			}
			// cmplwi cr6,r31,0
			// beq cr6,0x82569ec0
			if (var_r31 == 0) {
				// mr r3,r31
				ctx.r3.u64 = var_r31;
				return;
			}
		}
	loc_82569EAC:
		// lwz r3,0(r22)
		ctx.r3.u64 = PPC_LOAD_U32(var_r22 + 0);
		// bl 0x82566f10
		pg_6F10_g(ctx, base);
		// stw r23,0(r22)
		PPC_STORE_U32(var_r22 + 0, var_r23);
		// b 0x82569ec0
	} else {
	loc_82569EBC:
		// li r31,87
		var_r31 = 87;
	}
loc_82569EC0:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_9ED0"))) PPC_WEAK_FUNC(xam_9ED0);
PPC_FUNC_IMPL(__imp__xam_9ED0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=160, savegprlr_27
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// mr r30,r7
	var_r30 = ctx.r7.u32;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x82569f64
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,16
		ctx.r7.s64 = 16;
		// stw r29,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r29);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// stw r28,104(r1)
		PPC_STORE_U32(ctx.r1.u32 + 104, var_r28);
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// stw r27,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, var_r27);
		// ori r4,r4,24
		ctx.r4.u64 = ctx.r4.u64 | 24;
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x82569f3c
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x82569f5c
		} else {
		loc_82569F3C:
			// cmplwi cr6,r30,0
			// bne cr6,0x82569f58
			if (var_r30 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x82569f5c
			} else {
			loc_82569F58:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_82569F5C:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_82569F64:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_9F70"))) PPC_WEAK_FUNC(xam_9F70);
PPC_FUNC_IMPL(__imp__xam_9F70) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=144, manual
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256a000
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,16
		ctx.r7.s64 = 16;
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// ori r4,r4,17
		ctx.r4.u64 = ctx.r4.u64 | 17;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r11,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
		// std r11,104(r1)
		PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x82569fd8
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x82569ff8
		} else {
		loc_82569FD8:
			// cmplwi cr6,r30,0
			// bne cr6,0x82569ff4
			if (var_r30 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x82569ff8
			} else {
			loc_82569FF4:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_82569FF8:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_8256A000:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// blr
	return;
}

__attribute__((alias("__imp__xam_A020"))) PPC_WEAK_FUNC(xam_A020);
PPC_FUNC_IMPL(__imp__xam_A020) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=176, savegprlr_27
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// mr r30,r7
	var_r30 = ctx.r7.u32;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256a0bc
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,20
		ctx.r7.s64 = 20;
		// stw r29,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r29);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// stw r28,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, var_r28);
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// stw r27,112(r1)
		PPC_STORE_U32(ctx.r1.u32 + 112, var_r27);
		// ori r4,r4,18
		ctx.r4.u64 = ctx.r4.u64 | 18;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r11,104(r1)
		PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a094
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x8256a0b4
		} else {
		loc_8256A094:
			// cmplwi cr6,r30,0
			// bne cr6,0x8256a0b0
			if (var_r30 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x8256a0b4
			} else {
			loc_8256A0B0:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_8256A0B4:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_8256A0BC:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_A0C8"))) PPC_WEAK_FUNC(xam_A0C8);
PPC_FUNC_IMPL(__imp__xam_A0C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=176, savegprlr_27
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// mr r30,r7
	var_r30 = ctx.r7.u32;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256a164
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,20
		ctx.r7.s64 = 20;
		// stw r29,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r29);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// stw r28,104(r1)
		PPC_STORE_U32(ctx.r1.u32 + 104, var_r28);
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// stw r27,112(r1)
		PPC_STORE_U32(ctx.r1.u32 + 112, var_r27);
		// ori r4,r4,18
		ctx.r4.u64 = ctx.r4.u64 | 18;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r11,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a13c
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x8256a15c
		} else {
		loc_8256A13C:
			// cmplwi cr6,r30,0
			// bne cr6,0x8256a158
			if (var_r30 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x8256a15c
			} else {
			loc_8256A158:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_8256A15C:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_8256A164:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_A170"))) PPC_WEAK_FUNC(xam_A170);
PPC_FUNC_IMPL(__imp__xam_A170) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=160, savegprlr_28
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// mr r30,r6
	var_r30 = ctx.r6.u32;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256a208
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,20
		ctx.r7.s64 = 20;
		// stw r29,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r29);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// stw r28,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, var_r28);
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// ori r4,r4,19
		ctx.r4.u64 = ctx.r4.u64 | 19;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r11,104(r1)
		PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
		// stw r11,112(r1)
		PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a1e0
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x8256a200
		} else {
		loc_8256A1E0:
			// cmplwi cr6,r30,0
			// bne cr6,0x8256a1fc
			if (var_r30 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x8256a200
			} else {
			loc_8256A1FC:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_8256A200:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_8256A208:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_A218"))) PPC_WEAK_FUNC(xam_A218);
PPC_FUNC_IMPL(__imp__xam_A218) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=160, savegprlr_28
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// mr r30,r6
	var_r30 = ctx.r6.u32;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256a2b0
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,20
		ctx.r7.s64 = 20;
		// stw r29,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r29);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// stw r28,104(r1)
		PPC_STORE_U32(ctx.r1.u32 + 104, var_r28);
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// ori r4,r4,19
		ctx.r4.u64 = ctx.r4.u64 | 19;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r11,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
		// stw r11,112(r1)
		PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a288
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x8256a2a8
		} else {
		loc_8256A288:
			// cmplwi cr6,r30,0
			// bne cr6,0x8256a2a4
			if (var_r30 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x8256a2a8
			} else {
			loc_8256A2A4:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_8256A2A8:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_8256A2B0:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_A2C0"))) PPC_WEAK_FUNC(xam_A2C0);
PPC_FUNC_IMPL(__imp__xam_A2C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	PPCRegister temp{};
	// FRAME: size=192, savegprlr_26
	// mr r31,r7
	var_r31 = ctx.r7.u32;
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// mr r26,r5
	var_r26 = ctx.r5.u32;
	// mr r30,r6
	var_r30 = ctx.r6.u32;
	// mr r28,r8
	var_r28 = ctx.r8.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x8256a380
	if (var_r31 != 0) {
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmplwi cr6,r11,68
		// ble cr6,0x8256a380
		if (ctx.r11.u32 <= 68) goto loc_8256A380;
		// addi r4,r1,80
		ctx.r4.s64 = ctx.r1.s64 + 80;
		// bl 0x8258677c
		__imp__XamSessionRefObjByHandle(ctx, base);
		// mr. r29,r3
		var_r29 = ctx.r3.u32;
		// bne 0x8256a38c
		if ((int32_t)var_r29 != 0) {
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,32
		ctx.r7.s64 = 32;
		// stw r27,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r27);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// std r26,104(r1)
		PPC_STORE_U64(ctx.r1.u32 + 104, var_r26);
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// stw r31,120(r1)
		PPC_STORE_U32(ctx.r1.u32 + 120, var_r31);
		// ori r4,r4,26
		ctx.r4.u64 = ctx.r4.u64 | 26;
		// stw r11,116(r1)
		PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
		// li r3,251
		ctx.r3.s64 = 251;
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// li r11,300
		ctx.r11.s64 = 300;
		// stw r11,112(r1)
		PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a354
		if (ctx.r3.s32 < 0) {
			// li r29,1627
			var_r29 = 1627;
			// b 0x8256a374
		} else {
		loc_8256A354:
			// cmplwi cr6,r28,0
			// bne cr6,0x8256a370
			if (var_r28 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r29,r11,1627
				var_r29 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r29, 0, ctx.xer);
				// b 0x8256a374
			} else {
			loc_8256A370:
				// li r29,997
				var_r29 = 997;
			}
		}
	loc_8256A374:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
		// b 0x8256a38c
	} else {
	loc_8256A380:
		// li r11,1572
		ctx.r11.s64 = 1572;
		// li r29,122
		var_r29 = 122;
		// stw r11,0(r30)
		PPC_STORE_U32(var_r30 + 0, ctx.r11.u32);
	}
loc_8256A38C:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	return;
}

__attribute__((alias("__imp__xam_A398"))) PPC_WEAK_FUNC(xam_A398);
PPC_FUNC_IMPL(__imp__xam_A398) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=144, savegprlr_29
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256a424
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,16
		ctx.r7.s64 = 16;
		// stw r29,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r29);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// ori r4,r4,20
		ctx.r4.u64 = ctx.r4.u64 | 20;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// li r3,251
		ctx.r3.s64 = 251;
		// std r11,104(r1)
		PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a3fc
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x8256a41c
		} else {
		loc_8256A3FC:
			// cmplwi cr6,r30,0
			// bne cr6,0x8256a418
			if (var_r30 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x8256a41c
			} else {
			loc_8256A418:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_8256A41C:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_8256A424:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_A430"))) PPC_WEAK_FUNC(xam_A430);
PPC_FUNC_IMPL(__imp__xam_A430) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=144, manual
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256a4c0
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,16
		ctx.r7.s64 = 16;
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// ori r4,r4,21
		ctx.r4.u64 = ctx.r4.u64 | 21;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r11,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
		// std r11,104(r1)
		PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a498
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x8256a4b8
		} else {
		loc_8256A498:
			// cmplwi cr6,r30,0
			// bne cr6,0x8256a4b4
			if (var_r30 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x8256a4b8
			} else {
			loc_8256A4B4:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_8256A4B8:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_8256A4C0:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// blr
	return;
}

__attribute__((alias("__imp__xam_A4E0_h"))) PPC_WEAK_FUNC(xam_A4E0_h);
PPC_FUNC_IMPL(__imp__xam_A4E0_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r25 = 0;
	PPCRegister temp{};
	// FRAME: size=208, savegprlr_23
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// lwz r31,292(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 292));
	// mr r26,r7
	var_r26 = ctx.r7.u32;
	// mulli r7,r11,92
	ctx.r7.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(92));
	// addi r5,r7,8
	ctx.r5.s64 = ctx.r7.s64 + 8;
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// lwz r6,0(r31)
	ctx.r6.u64 = PPC_LOAD_U32(var_r31 + 0);
	// mulli r7,r11,1326
	ctx.r7.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(1326));
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// addi r24,r7,8
	var_r24 = (uint32_t)(ctx.r7.s64 + 8);
	// cmplw cr6,r6,r5
	// blt cr6,0x8256a5c4
	if (ctx.r6.u32 >= ctx.r5.u32) {
		// lwz r30,300(r1)
		var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 300));
		// cmplwi cr6,r30,0
		// beq cr6,0x8256a5c4
		if (var_r30 == 0) goto loc_8256A5C4;
		// li r23,0
		var_r23 = 0;
		// stw r11,88(r1)
		PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
		// lwz r25,308(r1)
		var_r25 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 308));
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,36
		ctx.r7.s64 = 36;
		// stw r29,80(r1)
		PPC_STORE_U32(ctx.r1.u32 + 80, var_r29);
		// addi r6,r1,80
		ctx.r6.s64 = ctx.r1.s64 + 80;
		// stw r28,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, var_r28);
		// mr r5,r25
		ctx.r5.u64 = var_r25;
		// stw r27,112(r1)
		PPC_STORE_U32(ctx.r1.u32 + 112, var_r27);
		// stw r23,0(r30)
		PPC_STORE_U32(var_r30 + 0, var_r23);
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// ori r4,r4,28
		ctx.r4.u64 = ctx.r4.u64 | 28;
		// li r3,251
		ctx.r3.s64 = 251;
		// sth r26,92(r1)
		PPC_STORE_U16(ctx.r1.u32 + 92, (uint16_t)var_r26);
		// sth r8,94(r1)
		PPC_STORE_U16(ctx.r1.u32 + 94, ctx.r8.u16);
		// stw r9,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
		// stw r10,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
		// stw r30,108(r1)
		PPC_STORE_U32(ctx.r1.u32 + 108, var_r30);
		// stw r11,104(r1)
		PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a5a0
		if (ctx.r3.s32 < 0) {
			// lis r11,-32747
			// ori r11,r11,20999
			ctx.r11.u64 = ctx.r11.u64 | 20999;
			// cmpw cr6,r3,r11
			// beq cr6,0x8256a5c4
			if (ctx.r3.s32 == ctx.r11.s32) goto loc_8256A5C4;
			// li r3,1627
			ctx.r3.s64 = 1627;
			// b 0x8256a5cc
			return;
		}
	loc_8256A5A0:
		// cmplwi cr6,r25,0
		// bne cr6,0x8256a5bc
		if (var_r25 == 0) {
			// bl 0x8242c368
			xam_C368(ctx, base);
			// subfic r11,r3,0
			ctx.xer.ca = ctx.r3.u32 <= 0;
			ctx.r11.s64 = 0 - ctx.r3.s64;
			// subfe r11,r11,r11
			temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
			ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
			ctx.xer.ca = temp.u8;
			// andi. r3,r11,1627
			ctx.r3.u64 = ctx.r11.u64 & 1627;
			ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
			// b 0x8256a5cc
			return;
		}
	loc_8256A5BC:
		// li r3,997
		ctx.r3.s64 = 997;
		// b 0x8256a5cc
	} else {
	loc_8256A5C4:
		// stw r24,0(r31)
		PPC_STORE_U32(var_r31 + 0, var_r24);
		// li r3,122
		ctx.r3.s64 = 122;
	}
loc_8256A5CC:
	return;
}

__attribute__((alias("__imp__xam_A5D8_g"))) PPC_WEAK_FUNC(xam_A5D8_g);
PPC_FUNC_IMPL(__imp__xam_A5D8_g) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=176, savegprlr_27
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// rldicl r11,r30,16,48
	ctx.r11.u64 = __builtin_rotateleft64(var_r30, 16) & 0xFFFF;
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// rotlwi r11,r11,0
	ctx.r11.u64 = ctx.r11.u32;
	// mr r29,r7
	var_r29 = ctx.r7.u32;
	// clrlwi r10,r11,28
	ctx.r10.u64 = ctx.r11.u32 & 0xF;
	// li r31,0
	var_r31 = 0;
	// cmplwi cr6,r10,9
	// bne cr6,0x8256a614
	if (ctx.r10.u32 == 9) {
		// rlwinm. r11,r11,0,24,25
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
		// bne 0x8256a68c
		if (ctx.r11.s32 != 0) {
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			return;
		}
	}
loc_8256A614:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8258677c
	__imp__XamSessionRefObjByHandle(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256a68c
	if ((int32_t)var_r31 == 0) {
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lis r4,11
		ctx.r4.s64 = 720896;
		// li r7,24
		ctx.r7.s64 = 24;
		// std r30,104(r1)
		PPC_STORE_U64(ctx.r1.u32 + 104, var_r30);
		// addi r6,r1,96
		ctx.r6.s64 = ctx.r1.s64 + 96;
		// stw r28,112(r1)
		PPC_STORE_U32(ctx.r1.u32 + 112, var_r28);
		// mr r5,r29
		ctx.r5.u64 = var_r29;
		// stw r27,116(r1)
		PPC_STORE_U32(ctx.r1.u32 + 116, var_r27);
		// ori r4,r4,37
		ctx.r4.u64 = ctx.r4.u64 | 37;
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8256a664
		if (ctx.r3.s32 < 0) {
			// li r31,1627
			var_r31 = 1627;
			// b 0x8256a684
		} else {
		loc_8256A664:
			// cmplwi cr6,r29,0
			// bne cr6,0x8256a680
			if (var_r29 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r31,r11,1627
				var_r31 = (uint32_t)(ctx.r11.u64 & 1627);
				ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
				// b 0x8256a684
			} else {
			loc_8256A680:
				// li r31,997
				var_r31 = 997;
			}
		}
	loc_8256A684:
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// bl 0x82585d1c
		__imp__ObDereferenceObject(ctx, base);
	}
loc_8256A68C:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__phInst_A698_p39"))) PPC_WEAK_FUNC(phInst_A698_p39);
PPC_FUNC_IMPL(__imp__phInst_A698_p39) {
	PPC_FUNC_PROLOGUE();
	// lhz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 0);
	// lhz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r4.u32 + 0);
	// subf r3,r10,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r10.s64;
	// blr
	return;
}

__attribute__((alias("__imp__xe_A6A8_h"))) PPC_WEAK_FUNC(xe_A6A8_h);
PPC_FUNC_IMPL(__imp__xe_A6A8_h) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=496, manual
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x82481af8
	util_1AF8(ctx, base);
	// cmpwi r3,0
	// bne 0x8256a6f4
	if (ctx.r3.s32 == 0) {
		// lis r11,-32161
		ctx.r11.s64 = -2107703296;
		// addi r3,r11,-22496
		ctx.r3.s64 = ctx.r11.s64 + -22496;
		// lis r11,-32164
		ctx.r11.s64 = -2107899904;
		// lwz r5,9640(r11)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 9640);  /* glob:lbl_825C25A8 @ 0x825c25a8 */
		// lis r11,-32164
		ctx.r11.s64 = -2107899904;
		// lwz r4,9644(r11)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 9644);  /* glob:lbl_825C25AC @ 0x825c25ac */
		// bl 0x8256a988
		phInst_A988_p39(ctx, base);
		// cmpwi r3,0
		// li r3,0
		ctx.r3.s64 = 0;
		// bge 0x8256a6f4
		if (ctx.r3.s32 >= 0) {
			// blr
			return;
		}
		// li r3,1627
		ctx.r3.s64 = 1627;
	}
loc_8256A6F4:
	// blr
	return;
}

__attribute__((alias("__imp__game_A708_h"))) PPC_WEAK_FUNC(game_A708_h);
PPC_FUNC_IMPL(__imp__game_A708_h) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// bl 0x82481b08
	rage_1B08(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__xam_A730"))) PPC_WEAK_FUNC(xam_A730);
PPC_FUNC_IMPL(__imp__xam_A730) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=112, manual
	// lis r11,-32169
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// addi r7,r11,-22888
	ctx.r7.s64 = ctx.r11.s64 + -22888;
	// lis r11,-32161
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r11,r11,-22496
	ctx.r11.s64 = ctx.r11.s64 + -22496;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// sth r10,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r10.u16);
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// lhz r5,40(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 40);
	// lwz r4,44(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	// bl 0x824330c8
	fiAsciiTokenizer_30C8_g(ctx, base);
	// cmplwi r3,0
	// beq 0x8256a788
	if (ctx.r3.u32 != 0) {
		// lhz r11,2(r3)
		ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 2);
		// li r3,0
		ctx.r3.s64 = 0;
		// stw r11,0(r31)
		PPC_STORE_U32(var_r31 + 0, ctx.r11.u32);
		// b 0x8256a790
	} else {
	loc_8256A788:
		// lis r3,-32768
		// ori r3,r3,16389
		ctx.r3.u64 = ctx.r3.u64 | 16389;
	}
loc_8256A790:
	// blr
	return;
}

__attribute__((alias("__imp__xam_A7A8"))) PPC_WEAK_FUNC(xam_A7A8);
PPC_FUNC_IMPL(__imp__xam_A7A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	// FRAME: size=160, savegprlr_26
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r10,-32161
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// addi r3,r10,-22496
	ctx.r3.s64 = ctx.r10.s64 + -22496;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// mr r26,r6
	var_r26 = ctx.r6.u32;
	// mr r28,r7
	var_r28 = ctx.r7.u32;
	// mr r31,r8
	var_r31 = ctx.r8.u32;
	// mr r27,r9
	var_r27 = ctx.r9.u32;
	// bl 0x8256a930
	xam_A930_h(ctx, base);
	// cmpwi r3,0
	// blt 0x8256a83c
	if (ctx.r3.s32 >= 0) {
		// rlwinm. r11,r30,0,28,28
		ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 0) & 0x8;
		// bne 0x8256a7f8
		if (ctx.r11.s32 == 0) {
			// lwz r29,92(r1)
			var_r29 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 92));
		}
	loc_8256A7F8:
		// mulli r11,r29,120
		ctx.r11.s64 = static_cast<int64_t>(var_r29 * static_cast<uint64_t>(120));
		// li r10,100
		ctx.r10.s64 = 100;
		// cmplwi cr6,r31,0
		// divwu r11,r11,r10
		ctx.r11.u32 = ctx.r10.u32 ? ctx.r11.u32 / ctx.r10.u32 : 0;
		// addi r11,r11,3
		ctx.r11.s64 = ctx.r11.s64 + 3;
		// rlwinm r11,r11,0,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
		// beq cr6,0x8256a818
		if (var_r31 != 0) {
			// stw r11,0(r31)
			PPC_STORE_U32(var_r31 + 0, ctx.r11.u32);
		}
	loc_8256A818:
		// cmplwi cr6,r27,0
		// beq cr6,0x8256a828
		if (var_r27 != 0) {
			// li r10,4096
			ctx.r10.s64 = 4096;
			// stw r10,0(r27)
			PPC_STORE_U32(var_r27 + 0, ctx.r10.u32);
		}
	loc_8256A828:
		// cmplwi cr6,r28,0
		// beq cr6,0x8256a83c
		if (var_r28 == 0) {
			return;
		}
		// add r11,r11,r26
		ctx.r11.u64 = ctx.r11.u64 + var_r26;
		// addi r11,r11,11884
		ctx.r11.s64 = ctx.r11.s64 + 11884;
		// stw r11,0(r28)
		PPC_STORE_U32(var_r28 + 0, ctx.r11.u32);
	}
loc_8256A83C:
	return;
}

__attribute__((alias("__imp__xam_A848"))) PPC_WEAK_FUNC(xam_A848);
PPC_FUNC_IMPL(__imp__xam_A848) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=240, savegprlr_22
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// lis r4,5
	ctx.r4.s64 = 327680;
	// addi r30,r6,7712
	var_r30 = (uint32_t)(ctx.r6.s64 + 7712);
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// mr r26,r5
	var_r26 = ctx.r5.u32;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// ori r4,r4,32772
	ctx.r4.u64 = ctx.r4.u64 | 32772;
	// li r3,252
	ctx.r3.s64 = 252;
	// mr r31,r7
	var_r31 = ctx.r7.u32;
	// mr r25,r8
	var_r25 = ctx.r8.u32;
	// mr r24,r9
	var_r24 = ctx.r9.u32;
	// mr r23,r10
	var_r23 = ctx.r10.u32;
	// addi r22,r30,4172
	var_r22 = (uint32_t)(var_r30 + 4172);
	// bl 0x825860dc
	__imp__XMsgInProcessCall(ctx, base);
	// cmpwi r3,0
	// li r10,0
	ctx.r10.s64 = 0;
	// blt 0x8256a8a0
	if (ctx.r3.s32 >= 0) {
		// lwz r10,144(r1)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	}
loc_8256A8A0:
	// lwz r11,324(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// li r8,4096
	ctx.r8.s64 = 4096;
	// mr r29,r31
	var_r29 = (uint32_t)(var_r31);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// mr r9,r30
	ctx.r9.u64 = var_r30;
	// stw r23,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, var_r23);
	// lis r10,-32161
	// stw r24,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, var_r24);
	// mr r7,r26
	ctx.r7.u64 = var_r26;
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r11.u32);
	// addi r11,r31,76
	ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 76;
	// subf r31,r22,r25
	var_r31 = var_r25 - var_r22;
	// stw r8,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r8.u32);
	// add r30,r30,r11
	var_r30 = (uint32_t)(var_r30 + ctx.r11.u64);
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// add r11,r31,r30
	ctx.r11.u64 = var_r31 + var_r30;
	// addi r5,r10,-22496
	ctx.r5.s64 = ctx.r10.s64 + -22496;
	// lwz r10,348(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// mr r6,r27
	ctx.r6.u64 = var_r27;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, var_r31);
	// mr r4,r28
	ctx.r4.u64 = var_r28;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, var_r30);
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// bl 0x8256aa58
	xam_AA58_h(ctx, base);
	// cmpwi r3,0
	// blt 0x8256a924
	if (ctx.r3.s32 >= 0) {
		// lwz r11,332(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
		// stw r30,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r30);
		// lwz r11,340(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
		// stw r31,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
		// lwz r11,356(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
		// stw r29,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r29);
	}
loc_8256A924:
	return;
}

__attribute__((alias("__imp__xam_A930_h"))) PPC_WEAK_FUNC(xam_A930_h);
PPC_FUNC_IMPL(__imp__xam_A930_h) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// lhz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 40);
	// cmplw cr6,r4,r10
	// blt cr6,0x8256a95c
	if (ctx.r4.u32 >= ctx.r10.u32) {
		// lis r3,-32768
		// ori r3,r3,16389
		ctx.r3.u64 = ctx.r3.u64 | 16389;
		// b 0x8256a978
	} else {
	loc_8256A95C:
		// lhz r9,42(r11)
		ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 42);
		// li r5,24
		ctx.r5.s64 = 24;
		// lwz r10,48(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
		// mullw r11,r9,r4
		ctx.r11.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r4.s32);
		// add r4,r11,r10
		ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
		// bl 0x82434100
		memcpy(ctx, base);
		// li r3,0
		ctx.r3.s64 = 0;
	}
loc_8256A978:
	// blr
	return;
}

__attribute__((alias("__imp__phInst_A988_p39"))) PPC_WEAK_FUNC(phInst_A988_p39);
PPC_FUNC_IMPL(__imp__phInst_A988_p39) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=112, savegprlr_29
	// li r5,44
	ctx.r5.s64 = 44;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// li r29,0
	var_r29 = 0;
	// bl 0x82434100
	memcpy(ctx, base);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
	// addi r9,r30,44
	ctx.r9.s64 = (int64_t)(int32_t)var_r30 + 44;
	// clrlwi. r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// beq 0x8256a9c4
	if (ctx.r11.s32 != 0) {
		// lis r29,-32768
		var_r29 = (uint32_t)(-2147483648);
		// ori r29,r29,16389
		var_r29 = (uint32_t)(var_r29 | 16389);
		// b 0x8256aa4c
	} else {
	loc_8256A9C4:
		// lhz r6,38(r31)
		ctx.r6.u64 = PPC_LOAD_U16(var_r31 + 38);
		// cmplwi r6,0
		// beq 0x8256a9dc
		if (ctx.r6.u32 != 0) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// add r9,r6,r9
			ctx.r9.u64 = ctx.r6.u64 + ctx.r9.u64;
			// stw r11,60(r31)
			PPC_STORE_U32(var_r31 + 60, ctx.r11.u32);
		}
	loc_8256A9DC:
		// lhz r10,26(r31)
		ctx.r10.u64 = PPC_LOAD_U16(var_r31 + 26);
		// lhz r8,24(r31)
		ctx.r8.u64 = PPC_LOAD_U16(var_r31 + 24);
		// lhz r11,40(r31)
		ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 40);
		// mullw r7,r10,r8
		ctx.r7.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r8.s32);
		// lwz r4,20(r31)
		ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 20);
		// rotlwi r10,r11,2
		ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 2);
		// stw r9,44(r31)
		PPC_STORE_U32(var_r31 + 44, ctx.r9.u32);
		// lhz r5,42(r31)
		ctx.r5.u64 = PPC_LOAD_U16(var_r31 + 42);
		// lhz r3,32(r31)
		ctx.r3.u64 = PPC_LOAD_U16(var_r31 + 32);
		// mullw r11,r5,r11
		ctx.r11.s64 = int64_t(ctx.r5.s32) * int64_t(ctx.r11.s32);
		// add r9,r10,r9
		ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
		// subf r10,r10,r4
		ctx.r10.s64 = ctx.r4.s64 - ctx.r10.s64;
		// rotlwi r8,r3,1
		ctx.r8.u64 = __builtin_rotateleft32(ctx.r3.u32, 1);
		// subf r10,r6,r10
		ctx.r10.s64 = ctx.r10.s64 - ctx.r6.s64;
		// subf r10,r11,r10
		ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
		// stw r9,48(r31)
		PPC_STORE_U32(var_r31 + 48, ctx.r9.u32);
		// add r11,r11,r9
		ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
		// addi r10,r10,-44
		ctx.r10.s64 = ctx.r10.s64 + -44;
		// mr r9,r11
		ctx.r9.u64 = ctx.r11.u64;
		// add r11,r10,r11
		ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
		// stw r10,56(r31)
		PPC_STORE_U32(var_r31 + 56, ctx.r10.u32);
		// mr r10,r11
		ctx.r10.u64 = ctx.r11.u64;
		// add r11,r7,r11
		ctx.r11.u64 = ctx.r7.u64 + ctx.r11.u64;
		// stw r9,52(r31)
		PPC_STORE_U32(var_r31 + 52, ctx.r9.u32);
		// stw r10,64(r31)
		PPC_STORE_U32(var_r31 + 64, ctx.r10.u32);
		// add r10,r8,r11
		ctx.r10.u64 = ctx.r8.u64 + ctx.r11.u64;
		// stw r11,68(r31)
		PPC_STORE_U32(var_r31 + 68, ctx.r11.u32);
		// stw r10,72(r31)
		PPC_STORE_U32(var_r31 + 72, ctx.r10.u32);
	}
loc_8256AA4C:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	return;
}

__attribute__((alias("__imp__xam_AA58_h"))) PPC_WEAK_FUNC(xam_AA58_h);
PPC_FUNC_IMPL(__imp__xam_AA58_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lwz r11,188(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	// addi r3,r31,52
	ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 52;
	// stw r6,8(r31)
	PPC_STORE_U32(var_r31 + 8, ctx.r6.u32);
	// lwz r6,196(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	// stw r5,4(r31)
	PPC_STORE_U32(var_r31 + 4, ctx.r5.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r8,16(r31)
	PPC_STORE_U32(var_r31 + 16, ctx.r8.u32);
	// stw r9,20(r31)
	PPC_STORE_U32(var_r31 + 20, ctx.r9.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(var_r31 + 24, ctx.r11.u32);
	// lwz r8,180(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r9,220(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// lwz r11,228(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	// stw r7,12(r31)
	PPC_STORE_U32(var_r31 + 12, ctx.r7.u32);
	// li r7,1
	ctx.r7.s64 = 1;
	// stw r6,32(r31)
	PPC_STORE_U32(var_r31 + 32, ctx.r6.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r4,0(r31)
	PPC_STORE_U32(var_r31 + 0, ctx.r4.u32);
	// stw r5,28(r31)
	PPC_STORE_U32(var_r31 + 28, ctx.r5.u32);
	// lwz r5,212(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// lwz r4,204(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	// stw r10,36(r31)
	PPC_STORE_U32(var_r31 + 36, ctx.r10.u32);
	// stw r8,40(r31)
	PPC_STORE_U32(var_r31 + 40, ctx.r8.u32);
	// stw r9,44(r31)
	PPC_STORE_U32(var_r31 + 44, ctx.r9.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(var_r31 + 48, ctx.r11.u32);
	// bl 0x8256ab18
	xam_AB18_2hr(ctx, base);
	// lwz r11,236(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmplwi cr6,r11,0
	// stw r11,72(r31)
	PPC_STORE_U32(var_r31 + 72, ctx.r11.u32);
	// beq cr6,0x8256aafc
	if (ctx.r11.u32 != 0) {
		// lwz r3,12(r11)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// cmplwi r3,0
		// beq 0x8256aaf0
		if (ctx.r3.u32 != 0) {
			// bl 0x82566ed8
			pg_6ED8_g(ctx, base);
		}
	loc_8256AAF0:
		// lwz r11,72(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 72);
		// li r10,997
		ctx.r10.s64 = 997;
		// stw r10,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	}
loc_8256AAFC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__xam_AB18_2hr"))) PPC_WEAK_FUNC(xam_AB18_2hr);
PPC_FUNC_IMPL(__imp__xam_AB18_2hr) {
	PPC_FUNC_PROLOGUE();
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// stw r5,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r5.u32);
	// stw r6,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r6.u32);
	// stw r7,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r7.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_AB38_sp"))) PPC_WEAK_FUNC(xam_AB38_sp);
PPC_FUNC_IMPL(__imp__xam_AB38_sp) {
	PPC_FUNC_PROLOGUE();
	// li r11,10
	ctx.r11.s64 = 10;
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r11.u32);
	// lwz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// cmpwi cr6,r11,1
	// bne cr6,0x8256ab58
	if (ctx.r11.s32 == 1) {
		// lis r11,-32164
		// addi r11,r11,9776
		ctx.r11.s64 = ctx.r11.s64 + 9776;
		// b 0x8256ab60
	} else {
	loc_8256AB58:
		// lis r11,-32164
		// addi r11,r11,9744
		ctx.r11.s64 = ctx.r11.s64 + 9744;
	}
loc_8256AB60:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phInst_AB68_p39"))) PPC_WEAK_FUNC(phInst_AB68_p39);
PPC_FUNC_IMPL(__imp__phInst_AB68_p39) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// blr
	return;
}

__attribute__((alias("__imp__util_AB80"))) PPC_WEAK_FUNC(util_AB80);
PPC_FUNC_IMPL(__imp__util_AB80) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82566898
	util_6898(ctx, base);
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(var_r31 + 0);
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(var_r30 + 12);
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 8);
	// bl 0x8256c1d8
	xam_C1D8_w(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi r3,0
	// bge 0x8256abe0
	if (ctx.r3.s32 < 0) {
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// stw r10,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r9,12(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// stw r9,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	}
loc_8256ABE0:
	// addi r11,r30,44
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 44;
	// stw r10,4(r31)
	PPC_STORE_U32(var_r31 + 4, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi r10,0
	// beq 0x8256abfc
	if (ctx.r10.u32 != 0) {
		// stw r31,4(r10)
		PPC_STORE_U32(ctx.r10.u32 + 4, var_r31);
		// b 0x8256ac00
	} else {
	loc_8256ABFC:
		// stw r31,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
	}
loc_8256AC00:
	// stw r31,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, var_r31);
	// blr
	return;
}

__attribute__((alias("__imp__phInst_AC20_p39"))) PPC_WEAK_FUNC(phInst_AC20_p39);
PPC_FUNC_IMPL(__imp__phInst_AC20_p39) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r28,0
	var_r28 = 0;
	// addi r30,r31,52
	var_r30 = (uint32_t)(var_r31 + 52);
loc_8256AC38:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(var_r30 + 0);
	// cmplwi r4,0
	// beq 0x8256ac88
	if (ctx.r4.u32 == 0) goto loc_8256AC88;
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r11,259
	// beq cr6,0x8256ac88
	if (ctx.r11.s32 == 259) goto loc_8256AC88;
	// rotlwi r11,r4,0
	ctx.r11.u64 = ctx.r4.u32;
	// cmplwi r11,0
	// beq 0x8256ac7c
	if (ctx.r11.u32 != 0) {
		// lwz r10,4(r30)
		ctx.r10.u64 = PPC_LOAD_U32(var_r30 + 4);
		// cmplw cr6,r11,r10
		// bne cr6,0x8256ac70
		if (ctx.r11.u32 == ctx.r10.u32) {
			// stw r28,4(r30)
			PPC_STORE_U32(var_r30 + 4, var_r28);
		}
	loc_8256AC70:
		// lwz r10,4(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// stw r10,0(r30)
		PPC_STORE_U32(var_r30 + 0, ctx.r10.u32);
		// stw r28,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r28);
	}
loc_8256AC7C:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256ab80
	util_AB80(ctx, base);
	// b 0x8256ac38
	goto loc_8256AC38;
loc_8256AC88:
	// addi r29,r31,44
	var_r29 = (uint32_t)(var_r31 + 44);
loc_8256AC8C:
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(var_r29 + 0);
	// cmplwi r4,0
	// beq 0x8256ada0
	if (ctx.r4.u32 == 0) {
		// li r3,0
		ctx.r3.s64 = 0;
		return;
	}
	// lwz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r11,259
	// beq cr6,0x8256ada0
	if (ctx.r11.s32 == 259) {
		// li r3,0
		ctx.r3.s64 = 0;
		return;
	}
	// rotlwi r11,r4,0
	ctx.r11.u64 = ctx.r4.u32;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// cmplwi r11,0
	// beq 0x8256acd4
	if (ctx.r11.u32 != 0) {
		// lwz r8,4(r29)
		ctx.r8.u64 = PPC_LOAD_U32(var_r29 + 4);
		// cmplw cr6,r11,r8
		// bne cr6,0x8256acc8
		if (ctx.r11.u32 == ctx.r8.u32) {
			// stw r28,4(r29)
			PPC_STORE_U32(var_r29 + 4, var_r28);
		}
	loc_8256ACC8:
		// lwz r8,4(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// stw r8,0(r29)
		PPC_STORE_U32(var_r29 + 0, ctx.r8.u32);
		// stw r28,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r28);
	}
loc_8256ACD4:
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r11,0
	// bne cr6,0x8256ad94
	if (ctx.r11.s32 != 0) goto loc_8256AD94;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 4);
	// lbz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U8(var_r31 + 60);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lbz r11,140(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 140);
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// cmplw cr6,r9,r8
	// beq cr6,0x8256ad00
	if (ctx.r9.u32 != ctx.r8.u32) {
		// stb r11,60(r31)
		PPC_STORE_U8(var_r31 + 60, ctx.r11.u8);
	}
loc_8256AD00:
	// lhz r11,62(r31)
	ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 62);
	// cmplwi cr6,r11,4096
	// ble cr6,0x8256ad10
	if (ctx.r11.u32 > 4096) {
		// sth r28,62(r31)
		PPC_STORE_U16(var_r31 + 62, (uint16_t)var_r28);
	}
loc_8256AD10:
	// lhz r11,-2(r10)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + -2);
	// li r8,259
	ctx.r8.s64 = 259;
	// lbz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U8(var_r31 + 60);
	// rlwimi r11,r9,12,0,19
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 12) & 0xFFFFF000) | (ctx.r11.u64 & 0xFFFFFFFF00000FFF);
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// sth r11,-2(r10)
	PPC_STORE_U16(ctx.r10.u32 + -2, ctx.r11.u16);
	// lhz r9,62(r31)
	ctx.r9.u64 = PPC_LOAD_U16(var_r31 + 62);
	// rlwimi r9,r11,0,16,19
	ctx.r9.u64 = (ctx.r11.u32 & 0xF000) | (ctx.r9.u64 & 0xFFFFFFFFFFFF0FFF);
	// sth r9,-2(r10)
	PPC_STORE_U16(ctx.r10.u32 + -2, ctx.r9.u16);
	// lhz r11,62(r31)
	ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 62);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// sth r11,62(r31)
	PPC_STORE_U16(var_r31 + 62, ctx.r11.u16);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// stw r28,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, var_r28);
	// stw r28,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, var_r28);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
	// cmplwi r11,0
	// beq 0x8256ad68
	if (ctx.r11.u32 != 0) {
		// stw r4,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r4.u32);
		// b 0x8256ad6c
	} else {
	loc_8256AD68:
		// stw r4,0(r30)
		PPC_STORE_U32(var_r30 + 0, ctx.r4.u32);
	}
loc_8256AD6C:
	// stw r4,4(r30)
	PPC_STORE_U32(var_r30 + 4, ctx.r4.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 4);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// slw r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// lwz r9,1268(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1268);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stw r10,1268(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1268, ctx.r10.u32);
	// b 0x8256ac8c
	goto loc_8256AC8C;
loc_8256AD94:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256ab80
	util_AB80(ctx, base);
	// b 0x8256ac8c
	goto loc_8256AC8C;
}

__attribute__((alias("__imp__xam_ADB0_g"))) PPC_WEAK_FUNC(xam_ADB0_g);
PPC_FUNC_IMPL(__imp__xam_ADB0_g) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=256, savegprlr_23
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// li r25,0
	var_r25 = 0;
	// mr r23,r25
	var_r23 = (uint32_t)(var_r25);
	// mr r26,r25
	var_r26 = (uint32_t)(var_r25);
	// lwz r3,68(r29)
	ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 68);
	// lwz r24,64(r29)
	var_r24 = (uint32_t)(PPC_LOAD_U32(var_r29 + 64));
	// bl 0x8256d098
	xam_D098(ctx, base);
	// addi r27,r29,44
	var_r27 = (uint32_t)(var_r29 + 44);
	// lwz r31,0(r27)
	var_r31 = (uint32_t)(PPC_LOAD_U32(var_r27 + 0));
	// cmplwi r31,0
	// bne 0x8256adf0
	if (var_r31 == 0) {
		// mr r30,r25
		var_r30 = (uint32_t)(var_r25);
		// b 0x8256ae08
	} else {
	loc_8256ADF0:
		// lwz r30,0(r31)
		var_r30 = (uint32_t)(PPC_LOAD_U32(var_r31 + 0));
		// cmplwi r30,0
		// beq 0x8256ae08
		if (var_r30 == 0) goto loc_8256AE08;
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmpwi cr6,r11,259
		// bne cr6,0x8256ae24
		if (ctx.r11.s32 != 259) goto loc_8256AE24;
	}
loc_8256AE08:
	// lwz r11,64(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 64);
	// cmpwi cr6,r11,0
	// bne cr6,0x8256ae24
	if (ctx.r11.s32 == 0) {
		// li r11,1
		ctx.r11.s64 = 1;
		// lwz r3,60(r29)
		ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 60);
		// stw r11,64(r29)
		PPC_STORE_U32(var_r29 + 64, ctx.r11.u32);
		// bl 0x82460cb0
		phInst_0CB0_p28(ctx, base);
	}
loc_8256AE24:
	// cmplwi cr6,r31,0
	// beq cr6,0x8256af08
	if (var_r31 != 0) {
	loc_8256AE2C:
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmpwi cr6,r11,259
		// beq cr6,0x8256af08
		if (ctx.r11.s32 == 259) goto loc_8256AF08;
		// lwz r11,20(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 20);
		// cmplw cr6,r26,r11
		// bge cr6,0x8256af08
		if (var_r26 >= ctx.r11.u32) goto loc_8256AF08;
		// addi r28,r29,52
		var_r28 = (uint32_t)(var_r29 + 52);
		// mr r3,r28
		ctx.r3.u64 = var_r28;
		// bl 0x8256c5e8
		xam_C5E8_gen(ctx, base);
		// lwz r11,20(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 20);
		// cmplw cr6,r3,r11
		// bge cr6,0x8256af08
		if (ctx.r3.u32 >= ctx.r11.u32) goto loc_8256AF08;
		// li r11,259
		ctx.r11.s64 = 259;
		// li r5,88
		ctx.r5.s64 = 88;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,80
		ctx.r3.s64 = ctx.r1.s64 + 80;
		// stw r11,0(r30)
		PPC_STORE_U32(var_r30 + 0, ctx.r11.u32);
		// bl 0x82566898
		util_6898(ctx, base);
		// lwz r11,8(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 8);
		// li r5,0
		ctx.r5.s64 = 0;
		// addi r4,r1,80
		ctx.r4.s64 = ctx.r1.s64 + 80;
		// lwz r3,60(r29)
		ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 60);
		// stw r11,80(r1)
		PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
		// lwz r11,12(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 12);
		// stw r31,164(r1)
		PPC_STORE_U32(ctx.r1.u32 + 164, var_r31);
		// stw r11,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
		// bl 0x82460b50
		xam_0B50_g(ctx, base);
		// mr. r23,r3
		var_r23 = ctx.r3.u32;
		// blt 0x8256af00
		if ((int32_t)var_r23 < 0) goto loc_8256AF00;
		// lwz r11,0(r27)
		ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
		// cmplwi r11,0
		// beq 0x8256aec8
		if (ctx.r11.u32 != 0) {
			// lwz r10,4(r27)
			ctx.r10.u64 = PPC_LOAD_U32(var_r27 + 4);
			// cmplw cr6,r11,r10
			// bne cr6,0x8256aebc
			if (ctx.r11.u32 == ctx.r10.u32) {
				// stw r25,4(r27)
				PPC_STORE_U32(var_r27 + 4, var_r25);
			}
		loc_8256AEBC:
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// stw r10,0(r27)
			PPC_STORE_U32(var_r27 + 0, ctx.r10.u32);
			// stw r25,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r25);
		}
	loc_8256AEC8:
		// stw r25,4(r31)
		PPC_STORE_U32(var_r31 + 4, var_r25);
		// lwz r11,4(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 4);
		// cmplwi r11,0
		// beq 0x8256aee0
		if (ctx.r11.u32 != 0) {
			// stw r31,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r31);
			// b 0x8256aee4
		} else {
		loc_8256AEE0:
			// stw r31,0(r28)
			PPC_STORE_U32(var_r28 + 0, var_r31);
		}
	loc_8256AEE4:
		// stw r31,4(r28)
		PPC_STORE_U32(var_r28 + 4, var_r31);
		// addi r26,r26,1
		var_r26 = (uint32_t)(var_r26 + 1);
		// lwz r31,0(r27)
		var_r31 = (uint32_t)(PPC_LOAD_U32(var_r27 + 0));
		// cmplwi r31,0
		// beq 0x8256af08
		if (var_r31 == 0) goto loc_8256AF08;
		// lwz r30,0(r31)
		var_r30 = (uint32_t)(PPC_LOAD_U32(var_r31 + 0));
		// b 0x8256ae2c
		goto loc_8256AE2C;
	loc_8256AF00:
		// mr r23,r25
		var_r23 = (uint32_t)(var_r25);
		// stw r25,0(r30)
		PPC_STORE_U32(var_r30 + 0, var_r25);
	}
loc_8256AF08:
	// lwz r11,64(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 64);
	// cmpwi cr6,r11,1
	// bne cr6,0x8256af3c
	if (ctx.r11.s32 == 1) {
		// cmpwi cr6,r24,1
		// bne cr6,0x8256af3c
		if ((int32_t)var_r24 != 1) goto loc_8256AF3C;
		// addi r3,r29,52
		ctx.r3.s64 = (int64_t)(int32_t)var_r29 + 52;
		// bl 0x8256c5e8
		xam_C5E8_gen(ctx, base);
		// cmplwi cr6,r3,2
		// blt cr6,0x8256af3c
		if (ctx.r3.u32 < 2) goto loc_8256AF3C;
		// li r4,0
		ctx.r4.s64 = 0;
		// lwz r3,60(r29)
		ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 60);
		// bl 0x82460c08
		xam_0C08_g(ctx, base);
		// stw r25,64(r29)
		PPC_STORE_U32(var_r29 + 64, var_r25);
	}
loc_8256AF3C:
	// addi r31,r29,52
	var_r31 = (uint32_t)(var_r29 + 52);
	// b 0x8256af84
	goto loc_8256AF84;
	do {
		// lwz r11,0(r4)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// lwz r11,0(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmpwi cr6,r11,259
		// beq cr6,0x8256af90
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// cmplwi r11,0
		// beq 0x8256af7c
		if (ctx.r11.u32 != 0) {
			// lwz r10,4(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 4);
			// cmplw cr6,r11,r10
			// bne cr6,0x8256af70
			if (ctx.r11.u32 == ctx.r10.u32) {
				// stw r25,4(r31)
				PPC_STORE_U32(var_r31 + 4, var_r25);
			}
		loc_8256AF70:
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// stw r10,0(r31)
			PPC_STORE_U32(var_r31 + 0, ctx.r10.u32);
			// stw r25,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r25);
		}
	loc_8256AF7C:
		// mr r3,r29
		ctx.r3.u64 = var_r29;
		// bl 0x8256ab80
		util_AB80(ctx, base);
		// lwz r4,0(r31)
		ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 0);
		// cmplwi r4,0
		// bne 0x8256af44
	} while (ctx.r4.u32 != 0);
loc_8256AF90:
	// mr r3,r23
	ctx.r3.u64 = var_r23;
	return;
}

__attribute__((alias("__imp__xam_AFA0_sp"))) PPC_WEAK_FUNC(xam_AFA0_sp);
PPC_FUNC_IMPL(__imp__xam_AFA0_sp) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// cmpwi cr6,r11,1
	// bne cr6,0x8256afb0
	if (ctx.r11.s32 == 1) {
		// b 0x8256adb0
		xam_ADB0_g(ctx, base);
		return;
	}
loc_8256AFB0:
	// b 0x8256ac20
	phInst_AC20_p39(ctx, base);
	return;
}

__attribute__((alias("__imp__phInst_AFB8"))) PPC_WEAK_FUNC(phInst_AFB8);
PPC_FUNC_IMPL(__imp__phInst_AFB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// bl 0x8256ba38
	phInst_BA38_2h(ctx, base);
	// cmpwi r3,0
	// blt 0x8256b03c
	if (ctx.r3.s32 >= 0) {
		// lwz r11,36(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 36);
		// cmpwi cr6,r11,0
		// bne cr6,0x8256b010
		if (ctx.r11.s32 == 0) {
			// lwz r11,52(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 52);
			// b 0x8256b008
			goto loc_8256B008;
			do {
				// lwz r10,0(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
				// li r9,0
				ctx.r9.s64 = 0;
				// stw r9,0(r10)
				PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
				// lwz r10,0(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
				// lwz r9,12(r10)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
				// stw r9,4(r10)
				PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
				// lwz r11,4(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// cmplwi r11,0
				// bne 0x8256afec
			} while (ctx.r11.u32 != 0);
		}
	loc_8256B010:
		// lwz r11,36(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 36);
		// cmpwi cr6,r11,1
		// bne cr6,0x8256b03c
		if (ctx.r11.s32 != 1) {
			// blr
			return;
		}
		// lwz r11,60(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 60);
		// cmplwi r11,0
		// beq 0x8256b03c
		if (ctx.r11.u32 == 0) {
			// blr
			return;
		}
		// li r10,1
		ctx.r10.s64 = 1;
		// li r4,0
		ctx.r4.s64 = 0;
		// mr r3,r11
		ctx.r3.u64 = ctx.r11.u64;
		// stw r10,64(r31)
		PPC_STORE_U32(var_r31 + 64, ctx.r10.u32);
		// bl 0x82460c58
		phInst_0C58(ctx, base);
	}
loc_8256B03C:
	// blr
	return;
}

__attribute__((alias("__imp__rage_B050"))) PPC_WEAK_FUNC(rage_B050);
PPC_FUNC_IMPL(__imp__rage_B050) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r4,24
	ctx.r4.s64 = 24;
	// addi r28,r31,16
	var_r28 = (uint32_t)(var_r31 + 16);
	// mr r7,r28
	ctx.r7.u64 = var_r28;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 36);
	// stw r6,12(r31)
	PPC_STORE_U32(var_r31 + 12, ctx.r6.u32);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r5,8(r31)
	PPC_STORE_U32(var_r31 + 8, ctx.r5.u32);
	// lwz r10,24(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(var_r31 + 20);
	// rlwinm r11,r11,28,30,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0x2;
	// xori r6,r11,2
	ctx.r6.u64 = ctx.r11.u64 ^ 2;
	// lwz r11,28(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// add r3,r11,r6
	ctx.r3.u64 = ctx.r11.u64 + ctx.r6.u64;
	// bl 0x8256c8d0
	rage_C8D0(ctx, base);
	// mr. r27,r3
	var_r27 = ctx.r3.u32;
	// blt 0x8256b114
	if ((int32_t)var_r27 >= 0) {
		// lwz r11,20(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
		// li r29,0
		var_r29 = 0;
		// cmplwi cr6,r11,0
		// ble cr6,0x8256b0f8
		if (ctx.r11.u32 > 0) {
			// li r30,0
			var_r30 = 0;
		loc_8256B0B8:
			// lwz r11,0(r28)
			ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// lwz r9,40(r31)
			ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 40);
			// lwz r8,8(r11)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// mullw r11,r8,r29
			ctx.r11.s64 = int64_t(ctx.r8.s32) * int64_t((int32_t)var_r29);
			// add r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
			// stwx r11,r30,r9
			PPC_STORE_U32(var_r30 + ctx.r9.u32, ctx.r11.u32);
			// lwz r11,40(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 40);
			// add r4,r30,r11
			ctx.r4.u64 = var_r30 + ctx.r11.u64;
			// bl 0x8256ab80
			util_AB80(ctx, base);
			// lwz r11,20(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// addi r30,r30,8
			var_r30 = (uint32_t)(var_r30 + 8);
			// cmplw cr6,r29,r11
			// blt cr6,0x8256b0b8
			if (var_r29 < ctx.r11.u32) goto loc_8256B0B8;
		}
	loc_8256B0F8:
		// lwz r11,36(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 36);
		// cmpwi cr6,r11,1
		// bne cr6,0x8256b114
		if (ctx.r11.s32 != 1) {
			// mr r3,r27
			ctx.r3.u64 = var_r27;
			return;
		}
		// addi r4,r31,68
		ctx.r4.s64 = (int64_t)(int32_t)var_r31 + 68;
		// lwz r3,8(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
		// bl 0x8256d5a8
		rage_D5A8(ctx, base);
		// mr r27,r3
		var_r27 = ctx.r3.u32;
	}
loc_8256B114:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	return;
}

__attribute__((alias("__imp__phInst_B120_w"))) PPC_WEAK_FUNC(phInst_B120_w);
PPC_FUNC_IMPL(__imp__phInst_B120_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x8256b1a0
	if (var_r31 != 0) {
		// lwz r11,36(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 36);
		// li r30,0
		var_r30 = 0;
		// cmpwi cr6,r11,1
		// bne cr6,0x8256b16c
		if (ctx.r11.s32 == 1) {
			// lwz r3,60(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 60);
			// cmplwi r3,0
			// beq 0x8256b164
			if (ctx.r3.u32 != 0) {
				// bl 0x824608b8
				phInst_08B8(ctx, base);
				// stw r30,60(r31)
				PPC_STORE_U32(var_r31 + 60, var_r30);
			}
		loc_8256B164:
			// lwz r3,68(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 68);
			// bl 0x8256d020
			phInst_D020_w(ctx, base);
		}
	loc_8256B16C:
		// lwz r3,40(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 40);
		// cmplwi r3,0
		// beq 0x8256b188
		if (ctx.r3.u32 != 0) {
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// ori r4,r4,3
			ctx.r4.u64 = ctx.r4.u64 | 3;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r30,40(r31)
			PPC_STORE_U32(var_r31 + 40, var_r30);
		}
	loc_8256B188:
		// lwz r3,16(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 16);
		// bl 0x8256c788
		util_C788(ctx, base);
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r4,r4,32785
		ctx.r4.u64 = ctx.r4.u64 | 32785;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_8256B1A0:
	// blr
	return;
}

__attribute__((alias("__imp__phInst_B1B8"))) PPC_WEAK_FUNC(phInst_B1B8);
PPC_FUNC_IMPL(__imp__phInst_B1B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r24 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=160, savegprlr_24
	// mr r24,r3
	var_r24 = ctx.r3.u32;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// lis r3,-32768
	// li r26,0
	var_r26 = 0;
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// mr r25,r5
	var_r25 = ctx.r5.u32;
	// ori r3,r3,10
	ctx.r3.u64 = ctx.r3.u64 | 10;
	// mr r30,r26
	var_r30 = (uint32_t)(var_r26);
	// cmplwi cr6,r28,0
	// beq cr6,0x8256b1f0
	if (var_r28 != 0) {
		// stw r26,0(r28)
		PPC_STORE_U32(var_r28 + 0, var_r26);
	}
loc_8256B1F0:
	// lwz r29,52(r24)
	var_r29 = (uint32_t)(PPC_LOAD_U32(var_r24 + 52));
	// cmplwi r29,0
	// beq 0x8256b2a4
while (var_r29 != 0) {
	loc_8256B1FC:
		// lwz r11,0(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0);
		// lwz r10,0(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmpwi cr6,r10,0
		// beq cr6,0x8256b298
		if (ctx.r10.s32 != 0) {
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// lwz r9,12(r11)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// lwz r8,0(r25)
			ctx.r8.u64 = PPC_LOAD_U32(var_r25 + 0);
			// subf r9,r10,r9
			ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
			// subf r8,r30,r8
			ctx.r8.s64 = ctx.r8.s64 - (int64_t)(int32_t)var_r30;
			// addi r31,r9,2
			var_r31 = (uint32_t)(ctx.r9.s64 + 2);
			// cmplw cr6,r31,r8
			// bgt cr6,0x8256b2d0
			if (var_r31 > ctx.r8.u32) goto loc_8256B2D0;
			// lwz r11,8(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
			// mr r5,r31
			ctx.r5.u64 = var_r31;
			// add r3,r30,r27
			ctx.r3.u64 = var_r30 + var_r27;
			// add r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
			// addi r4,r11,-2
			ctx.r4.s64 = ctx.r11.s64 + -2;
			// bl 0x82434100
			memcpy(ctx, base);
			// add r30,r31,r30
			var_r30 = (uint32_t)(var_r31 + var_r30);
			// mr r3,r26
			ctx.r3.u64 = var_r26;
			// cmplwi cr6,r28,0
			// beq cr6,0x8256b260
			if (var_r28 != 0) {
				// lwz r11,0(r28)
				ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
				// addi r11,r11,1
				ctx.r11.s64 = ctx.r11.s64 + 1;
				// stw r11,0(r28)
				PPC_STORE_U32(var_r28 + 0, ctx.r11.u32);
			}
		loc_8256B260:
			// lwz r11,0(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0);
			// addi r9,r31,-2
			ctx.r9.s64 = (int64_t)(int32_t)var_r31 + -2;
			// lwz r8,4(r11)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// lwz r10,12(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// add r9,r8,r9
			ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
			// cmplw cr6,r9,r10
			// bge cr6,0x8256b280
			if (ctx.r9.u32 < ctx.r10.u32) {
				// mr r10,r9
				ctx.r10.u64 = ctx.r9.u64;
			}
		loc_8256B280:
			// stw r10,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
			// lwz r11,0(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0);
			// lwz r9,12(r11)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// cmplw cr6,r10,r9
			// bne cr6,0x8256b29c
			if (ctx.r10.u32 != ctx.r9.u32) goto loc_8256B29C;
			// stw r26,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r26);
		}
	loc_8256B298:
		// lwz r29,4(r29)
		var_r29 = (uint32_t)(PPC_LOAD_U32(var_r29 + 4));
	loc_8256B29C:
		// cmplwi cr6,r29,0
		// bne cr6,0x8256b1fc
}
loc_8256B2A4:
	// lwz r9,4(r24)
	ctx.r9.u64 = PPC_LOAD_U32(var_r24 + 4);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,32(r24)
	ctx.r11.u64 = PPC_LOAD_U32(var_r24 + 32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// slw r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// lwz r9,1268(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1268);
	// andc r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ~ctx.r10.u64;
	// stw r10,1268(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1268, ctx.r10.u32);
loc_8256B2C4:
	// stw r30,0(r25)
	PPC_STORE_U32(var_r25 + 0, var_r30);
	return;
loc_8256B2D0:
	// cmplwi cr6,r30,0
	// bne cr6,0x8256b2c4
	if (var_r30 != 0) {
		// stw r30,0(r25)
		PPC_STORE_U32(var_r25 + 0, var_r30);
		return;
	}
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// mr r30,r31
	var_r30 = (uint32_t)(var_r31);
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x8256b2c4
	// stw r30,0(r25)
	PPC_STORE_U32(var_r25 + 0, var_r30);
	return;
}

__attribute__((alias("__imp__xam_B2E8_w"))) PPC_WEAK_FUNC(xam_B2E8_w);
PPC_FUNC_IMPL(__imp__xam_B2E8_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=256, savegprlr_27
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// lis r10,-32768
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// ori r3,r10,16385
	ctx.r3.u64 = ctx.r10.u64 | 16385;
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 36);
	// cmpwi cr6,r11,0
	// beq cr6,0x8256b420
	if (ctx.r11.s32 != 0) {
		// addi r28,r29,60
		var_r28 = (uint32_t)(var_r29 + 60);
		// li r30,1
		var_r30 = 1;
		// lwz r11,0(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
		// cmplwi r11,0
		// beq 0x8256b33c
		if (ctx.r11.u32 != 0) {
			// cmplwi cr6,r27,0
			// beq cr6,0x8256b41c
			if (var_r27 == 0) goto loc_8256B41C;
			// addi r4,r1,88
			ctx.r4.s64 = ctx.r1.s64 + 88;
			// mr r3,r11
			ctx.r3.u64 = ctx.r11.u64;
			// bl 0x824609f0
			phInst_09F0_p28(ctx, base);
			// b 0x8256b41c
		} else {
		loc_8256B33C:
			// li r5,8
			ctx.r5.s64 = 8;
			// li r4,0
			ctx.r4.s64 = 0;
			// addi r3,r1,80
			ctx.r3.s64 = ctx.r1.s64 + 80;
			// bl 0x82566898
			util_6898(ctx, base);
			// lis r11,-32256
			// li r31,0
			var_r31 = 0;
			// li r5,8
			ctx.r5.s64 = 8;
			// li r4,0
			ctx.r4.s64 = 0;
			// addi r3,r1,96
			ctx.r3.s64 = ctx.r1.s64 + 96;
			// lfs f0,15788(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
			ctx.f0.f64 = double(temp.f32);
			// stfs f0,84(r1)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
			// stb r31,80(r1)
			PPC_STORE_U8(ctx.r1.u32 + 80, (uint8_t)var_r31);
			// stb r31,81(r1)
			PPC_STORE_U8(ctx.r1.u32 + 81, (uint8_t)var_r31);
			// bl 0x82566898
			util_6898(ctx, base);
			// addi r11,r1,80
			ctx.r11.s64 = ctx.r1.s64 + 80;
			// stb r30,96(r1)
			PPC_STORE_U8(ctx.r1.u32 + 96, (uint8_t)var_r30);
			// li r5,8
			ctx.r5.s64 = 8;
			// li r4,0
			ctx.r4.s64 = 0;
			// addi r3,r1,104
			ctx.r3.s64 = ctx.r1.s64 + 104;
			// stw r11,100(r1)
			PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
			// bl 0x82566898
			util_6898(ctx, base);
			// addi r11,r1,96
			ctx.r11.s64 = ctx.r1.s64 + 96;
			// stw r27,104(r1)
			PPC_STORE_U32(ctx.r1.u32 + 104, var_r27);
			// li r5,8
			ctx.r5.s64 = 8;
			// li r4,0
			ctx.r4.s64 = 0;
			// addi r3,r1,88
			ctx.r3.s64 = ctx.r1.s64 + 88;
			// stw r11,108(r1)
			PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
			// bl 0x82566898
			util_6898(ctx, base);
			// addi r11,r1,104
			ctx.r11.s64 = ctx.r1.s64 + 104;
			// stb r30,88(r1)
			PPC_STORE_U8(ctx.r1.u32 + 88, (uint8_t)var_r30);
			// li r5,92
			ctx.r5.s64 = 92;
			// li r4,0
			ctx.r4.s64 = 0;
			// addi r3,r1,112
			ctx.r3.s64 = ctx.r1.s64 + 112;
			// stw r11,92(r1)
			PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
			// bl 0x82566898
			util_6898(ctx, base);
			// lwz r10,20(r29)
			ctx.r10.u64 = PPC_LOAD_U32(var_r29 + 20);
			// lis r11,-32169
			// li r9,16000
			ctx.r9.s64 = 16000;
			// stb r30,112(r1)
			PPC_STORE_U8(ctx.r1.u32 + 112, (uint8_t)var_r30);
			// addi r11,r11,-21656
			ctx.r11.s64 = ctx.r11.s64 + -21656;
			// stb r30,116(r1)
			PPC_STORE_U8(ctx.r1.u32 + 116, (uint8_t)var_r30);
			// mr r4,r28
			ctx.r4.u64 = var_r28;
			// stb r30,169(r1)
			PPC_STORE_U8(ctx.r1.u32 + 169, (uint8_t)var_r30);
			// addi r3,r1,112
			ctx.r3.s64 = ctx.r1.s64 + 112;
			// stb r30,170(r1)
			PPC_STORE_U8(ctx.r1.u32 + 170, (uint8_t)var_r30);
			// stb r10,171(r1)
			PPC_STORE_U8(ctx.r1.u32 + 171, ctx.r10.u8);
			// addi r10,r1,88
			ctx.r10.s64 = ctx.r1.s64 + 88;
			// stw r9,120(r1)
			PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r9.u32);
			// stb r31,176(r1)
			PPC_STORE_U8(ctx.r1.u32 + 176, (uint8_t)var_r31);
			// stw r31,180(r1)
			PPC_STORE_U32(ctx.r1.u32 + 180, var_r31);
			// stw r31,188(r1)
			PPC_STORE_U32(ctx.r1.u32 + 188, var_r31);
			// stw r10,184(r1)
			PPC_STORE_U32(ctx.r1.u32 + 184, ctx.r10.u32);
			// stw r11,192(r1)
			PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r11.u32);
			// stw r31,196(r1)
			PPC_STORE_U32(ctx.r1.u32 + 196, var_r31);
			// stw r29,200(r1)
			PPC_STORE_U32(ctx.r1.u32 + 200, var_r29);
			// bl 0x82461278
			game_1278(ctx, base);
		}
	loc_8256B41C:
		// stw r30,64(r29)
		PPC_STORE_U32(var_r29 + 64, var_r30);
	}
loc_8256B420:
	return;
}

__attribute__((alias("__imp__xam_B428_w"))) PPC_WEAK_FUNC(xam_B428_w);
PPC_FUNC_IMPL(__imp__xam_B428_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r26 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=144, savegprlr_26
	// mr r26,r3
	var_r26 = ctx.r3.u32;
	// li r29,0
	var_r29 = 0;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(var_r26 + 36);
	// cmpwi cr6,r11,0
	// bne cr6,0x8256b45c
	if (ctx.r11.s32 == 0) {
		// lis r3,-32768
		// ori r3,r3,16385
		ctx.r3.u64 = ctx.r3.u64 | 16385;
		// b 0x8256b4c0
	} else {
	loc_8256B45C:
		// lwz r11,8(r26)
		ctx.r11.u64 = PPC_LOAD_U32(var_r26 + 8);
		// lwz r10,0(r30)
		ctx.r10.u64 = PPC_LOAD_U32(var_r30 + 0);
		// lwz r11,24(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
		// lwz r11,24(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
		// stw r29,0(r30)
		PPC_STORE_U32(var_r30 + 0, var_r29);
		// addi r31,r11,2
		var_r31 = (uint32_t)(ctx.r11.s64 + 2);  // addr:0x82570002
		// divwu. r27,r10,r31
		var_r27 = var_r31 ? ctx.r10.u32 / var_r31 : 0;
		// twllei r31,0
		if ((int32_t)var_r31 == 0 || var_r31 < 0u) __builtin_trap();
		// beq 0x8256b4c0
		if ((int32_t)var_r27 == 0) {
			return;
		}
		// mr r28,r4
		var_r28 = ctx.r4.u32;
	loc_8256B484:
		// mr r5,r31
		ctx.r5.u64 = var_r31;
		// lwz r3,68(r26)
		ctx.r3.u64 = PPC_LOAD_U32(var_r26 + 68);
		// mr r4,r28
		ctx.r4.u64 = var_r28;
		// bl 0x8256d320
		xam_D320_w(ctx, base);
		// cmpwi r3,0
		// blt 0x8256b4c0
		if (ctx.r3.s32 < 0) {
			return;
		}
		// cmpwi cr6,r3,1
		// beq cr6,0x8256b4c0
		if (ctx.r3.s32 == 1) {
			return;
		}
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// addi r29,r29,1
		var_r29 = (uint32_t)(var_r29 + 1);
		// add r28,r28,r31
		var_r28 = (uint32_t)(var_r28 + var_r31);
		// add r11,r11,r31
		ctx.r11.u64 = ctx.r11.u64 + var_r31;
		// cmplw cr6,r29,r27
		// stw r11,0(r30)
		PPC_STORE_U32(var_r30 + 0, ctx.r11.u32);
		// blt cr6,0x8256b484
		if (var_r29 < var_r27) goto loc_8256B484;
	}
loc_8256B4C0:
	return;
}

__attribute__((alias("__imp__phInst_B4C8_2hr"))) PPC_WEAK_FUNC(phInst_B4C8_2hr);
PPC_FUNC_IMPL(__imp__phInst_B4C8_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 24);
	// cmpwi cr6,r11,0
	// bne cr6,0x8256b500
	if (ctx.r11.s32 == 0) {
		// lwz r11,36(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 36);
		// cmpwi cr6,r11,1
		// bne cr6,0x8256b500
		if (ctx.r11.s32 != 1) goto loc_8256B500;
		// lwz r3,68(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 68);
		// bl 0x8256d4f0
		phInst_D4F0_wrh(ctx, base);
	}
loc_8256B500:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256ba10
	phInst_BA10_wrh(ctx, base);
	// mr. r30,r3
	var_r30 = ctx.r3.u32;
	// bge 0x8256b518
	if ((int32_t)var_r30 < 0) {
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8256afb8
		phInst_AFB8(ctx, base);
	}
loc_8256B518:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// blr
	return;
}

__attribute__((alias("__imp__msgMsgSink_B538_w"))) PPC_WEAK_FUNC(msgMsgSink_B538_w);
PPC_FUNC_IMPL(__imp__msgMsgSink_B538_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=144, savegprlr_26
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// ori r4,r4,32785
	ctx.r4.u64 = ctx.r4.u64 | 32785;
	// li r3,72
	ctx.r3.s64 = 72;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// mr r26,r6
	var_r26 = ctx.r6.u32;
	// li r27,0
	var_r27 = 0;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// beq 0x8256b5e8
	if ((int32_t)var_r31 != 0) {
		// lis r11,-32164
		// stw r29,32(r31)
		PPC_STORE_U32(var_r31 + 32, var_r29);
		// li r10,2
		ctx.r10.s64 = 2;
		// stw r30,36(r31)
		PPC_STORE_U32(var_r31 + 36, var_r30);
		// addi r11,r11,9648
		ctx.r11.s64 = ctx.r11.s64 + 9648;
		// stw r28,4(r31)
		PPC_STORE_U32(var_r31 + 4,/* msgMsgSink::flags@+0x4 */ var_r28);
		// li r9,10
		ctx.r9.s64 = 10;
		// cmpwi cr6,r30,1
		// stw r10,28(r31)
		PPC_STORE_U32(var_r31 + 28, ctx.r10.u32);
		// stw r11,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* msgMsgSink::vtable@+0x0 */ ctx.r11.u32);
		// stw r9,20(r31)
		PPC_STORE_U32(var_r31 + 20, ctx.r9.u32);
		// bne cr6,0x8256b5c0
		if ((int32_t)var_r30 == 1) {
			// lwz r4,68(r28)
			ctx.r4.u64 = PPC_LOAD_U32(var_r28 + 68);
			// cmplwi r4,0
			// beq 0x8256b5c8
			if (ctx.r4.u32 == 0) goto loc_8256B5C8;
			// lwz r11,32(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// b 0x8256b5c8
		} else {
		loc_8256B5C0:
			// li r11,255
			ctx.r11.s64 = 255;
			// stb r11,60(r31)
			PPC_STORE_U8(var_r31 + 60, ctx.r11.u8);
		}
	loc_8256B5C8:
		// lwz r11,20(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// ori r4,r4,3
		ctx.r4.u64 = ctx.r4.u64 | 3;
		// rlwinm r3,r11,3,0,28
		ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
		// bl 0x820c01b8
		rage_01B8(ctx, base);
		// cmplwi r3,0
		// stw r3,40(r31)
		PPC_STORE_U32(var_r31 + 40, ctx.r3.u32);
		// bne 0x8256b5fc
		if (ctx.r3.u32 != 0) {
			// mr r3,r27
			ctx.r3.u64 = var_r27;
			// stw r31,0(r26)
			PPC_STORE_U32(var_r26 + 0, var_r31);
			return;
		}
	}
loc_8256B5E8:
	// lis r27,-32761
	var_r27 = (uint32_t)(-2147024896);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// ori r27,r27,14
	var_r27 = (uint32_t)(var_r27 | 14);
	// bl 0x8256b120
	phInst_B120_w(ctx, base);
	// li r31,0
	var_r31 = 0;
loc_8256B5FC:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// stw r31,0(r26)
	PPC_STORE_U32(var_r26 + 0, var_r31);
	return;
}

__attribute__((alias("__imp__phInst_B610_p42"))) PPC_WEAK_FUNC(phInst_B610_p42);
PPC_FUNC_IMPL(__imp__phInst_B610_p42) {
	PPC_FUNC_PROLOGUE();
	// clrlwi. r5,r5,24
	ctx.r5.u64 = ctx.r5.u32 & 0xFF;
	// bne 0x8256b620
	if (ctx.r5.s32 == 0) {
		// li r5,0
		ctx.r5.s64 = 0;
		// b 0x8256b538
		msgMsgSink_B538_w(ctx, base);
		return;
	}
loc_8256B620:
	// b 0x8256b538
	msgMsgSink_B538_w(ctx, base);
	return;
}

__attribute__((alias("__imp__phInst_B628"))) PPC_WEAK_FUNC(phInst_B628);
PPC_FUNC_IMPL(__imp__phInst_B628) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32169
	ctx.r11.s64 = -2108227584;
	// addi r3,r11,-18928
	ctx.r3.s64 = ctx.r11.s64 + -18928;
	// blr
	return;
}

__attribute__((alias("__imp__msgMsgSink_B638_w"))) PPC_WEAK_FUNC(msgMsgSink_B638_w);
PPC_FUNC_IMPL(__imp__msgMsgSink_B638_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// li r28,0
	var_r28 = 0;
	// cmplwi cr6,r29,0
	// beq cr6,0x8256b674
	if (var_r29 != 0) {
		// lbz r10,0(r29)
		ctx.r10.u64 = PPC_LOAD_U8(var_r29 + 0);
		// cmplwi r10,0
		// beq 0x8256b674
		if (ctx.r10.u32 == 0) goto loc_8256B674;
		// li r11,0
		ctx.r11.s64 = 0;
	loc_8256B664:
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// clrlwi r11,r11,24
		ctx.r11.u64 = ctx.r11.u32 & 0xFF;
		// cmplw cr6,r11,r10
		// blt cr6,0x8256b664
		if (ctx.r11.u32 < ctx.r10.u32) goto loc_8256B664;
	}
loc_8256B674:
	// lis r11,-32164
	ctx.r11.s64 = -2107899904;
	// addi r27,r11,9736
	var_r27 = (uint32_t)(ctx.r11.s64 + 9736);  // lbl_825C2608 @ 0x825c2608
	// lbz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U8(var_r27 + 0);
	// cmplwi r4,0
	// beq 0x8256b700
	if (ctx.r4.u32 != 0) {
		// lwz r5,4(r27)
		ctx.r5.u64 = PPC_LOAD_U32(var_r27 + 4);
		// li r8,0
		ctx.r8.s64 = 0;
	loc_8256B690:
		// li r6,0
		ctx.r6.s64 = 0;
		// cmplwi cr6,r29,0
		// beq cr6,0x8256b6e4
		if (var_r29 != 0) {
			// lbz r7,0(r29)
			ctx.r7.u64 = PPC_LOAD_U8(var_r29 + 0);
			// cmplwi r7,0
			// beq 0x8256b6e4
			if (ctx.r7.u32 == 0) goto loc_8256B6E4;
			// mulli r9,r8,12
			ctx.r9.s64 = static_cast<int64_t>(ctx.r8.u64 * static_cast<uint64_t>(12));
			// lwz r10,4(r29)
			ctx.r10.u64 = PPC_LOAD_U32(var_r29 + 4)/* msgMsgSink::flags@+0x4 */;
			// li r11,0
			ctx.r11.s64 = 0;
			// lbzx r9,r9,r5
			ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r5.u32);
		loc_8256B6B8:
			// mulli r3,r11,12
			ctx.r3.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(12));
			// lbzx r3,r3,r10
			ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r10.u32);
			// cmplw cr6,r3,r9
			// bne cr6,0x8256b6cc
			if (ctx.r3.u32 == ctx.r9.u32) {
				// li r6,1
				ctx.r6.s64 = 1;
			}
		loc_8256B6CC:
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// clrlwi r11,r11,24
			ctx.r11.u64 = ctx.r11.u32 & 0xFF;
			// cmplw cr6,r11,r7
			// blt cr6,0x8256b6b8
			if (ctx.r11.u32 < ctx.r7.u32) goto loc_8256B6B8;
			// cmpwi cr6,r6,0
			// bne cr6,0x8256b6f0
			if (ctx.r6.s32 != 0) goto loc_8256B6F0;
		}
	loc_8256B6E4:
		// clrlwi r11,r28,24
		ctx.r11.u64 = var_r28 & 0xFF;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// clrlwi r28,r11,24
		var_r28 = (uint32_t)(ctx.r11.u32 & 0xFF);
	loc_8256B6F0:
		// addi r11,r8,1
		ctx.r11.s64 = ctx.r8.s64 + 1;
		// clrlwi r8,r11,24
		ctx.r8.u64 = ctx.r11.u32 & 0xFF;
		// cmplw cr6,r8,r4
		// blt cr6,0x8256b690
		if (ctx.r8.u32 < ctx.r4.u32) goto loc_8256B690;
	}
loc_8256B700:
	// lis r11,24714
	ctx.r11.s64 = 1619656704;
	// li r3,8
	ctx.r3.s64 = 8;
	// ori r31,r11,8194
	var_r31 = (uint32_t)(ctx.r11.u64 | 8194);
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r30,r3
	var_r30 = ctx.r3.u32;
	// beq 0x8256b86c
	if ((int32_t)var_r30 != 0) {
		// cmplwi cr6,r29,0
		// beq cr6,0x8256b72c
		if (var_r29 != 0) {
			// lbz r11,0(r29)
			ctx.r11.u64 = PPC_LOAD_U8(var_r29 + 0);
			// stb r11,0(r30)
			PPC_STORE_U8(var_r30 + 0, ctx.r11.u8);
		}
	loc_8256B72C:
		// lbz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U8(var_r30 + 0);
		// clrlwi r10,r28,24
		ctx.r10.u64 = var_r28 & 0xFF;
		// mr r4,r31
		ctx.r4.u64 = var_r31;
		// add r11,r11,r10
		ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
		// clrlwi r11,r11,24
		ctx.r11.u64 = ctx.r11.u32 & 0xFF;
		// mr r10,r11
		ctx.r10.u64 = ctx.r11.u64;
		// mulli r3,r10,12
		ctx.r3.s64 = static_cast<int64_t>(ctx.r10.u64 * static_cast<uint64_t>(12));
		// stb r11,0(r30)
		PPC_STORE_U8(var_r30 + 0, ctx.r11.u8);
		// bl 0x820c01b8
		rage_01B8(ctx, base);
		// stw r3,4(r30)
		PPC_STORE_U32(var_r30 + 4,/* msgMsgSink::flags@+0x4 */ ctx.r3.u32);
		// cmplwi r3,0
		// beq 0x8256b840
		if (ctx.r3.u32 != 0) {
			// li r31,0
			var_r31 = 0;
			// cmplwi cr6,r29,0
			// beq cr6,0x8256b788
			if (var_r29 != 0) {
				// lbz r11,0(r29)
				ctx.r11.u64 = PPC_LOAD_U8(var_r29 + 0);
				// lwz r4,4(r29)
				ctx.r4.u64 = PPC_LOAD_U32(var_r29 + 4)/* msgMsgSink::flags@+0x4 */;
				// mr r31,r11
				var_r31 = ctx.r11.u32;
				// cmplwi r4,0
				// beq 0x8256b788
				if (ctx.r4.u32 == 0) goto loc_8256B788;
				// clrlwi r11,r11,24
				ctx.r11.u64 = ctx.r11.u32 & 0xFF;
				// mulli r5,r11,12
				ctx.r5.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(12));
				// bl 0x82434100
				memcpy(ctx, base);
			}
		loc_8256B788:
			// lbz r4,0(r27)
			ctx.r4.u64 = PPC_LOAD_U8(var_r27 + 0);
			// cmplwi r4,0
			// beq 0x8256b86c
			if (ctx.r4.u32 == 0) {
				// mr r3,r30
				ctx.r3.u64 = var_r30;
				return;
			}
			// lwz r5,4(r27)
			ctx.r5.u64 = PPC_LOAD_U32(var_r27 + 4);
			// li r6,0
			ctx.r6.s64 = 0;
		loc_8256B79C:
			// li r7,0
			ctx.r7.s64 = 0;
			// cmplwi cr6,r29,0
			// beq cr6,0x8256b7f0
			if (var_r29 != 0) {
				// lbz r8,0(r29)
				ctx.r8.u64 = PPC_LOAD_U8(var_r29 + 0);
				// cmplwi r8,0
				// beq 0x8256b7f0
				if (ctx.r8.u32 == 0) goto loc_8256B7F0;
				// mulli r9,r6,12
				ctx.r9.s64 = static_cast<int64_t>(ctx.r6.u64 * static_cast<uint64_t>(12));
				// lwz r10,4(r29)
				ctx.r10.u64 = PPC_LOAD_U32(var_r29 + 4)/* msgMsgSink::flags@+0x4 */;
				// li r11,0
				ctx.r11.s64 = 0;
				// lbzx r9,r9,r5
				ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r5.u32);
			loc_8256B7C4:
				// mulli r3,r11,12
				ctx.r3.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(12));
				// lbzx r3,r3,r10
				ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r10.u32);
				// cmplw cr6,r3,r9
				// bne cr6,0x8256b7d8
				if (ctx.r3.u32 == ctx.r9.u32) {
					// li r7,1
					ctx.r7.s64 = 1;
				}
			loc_8256B7D8:
				// addi r11,r11,1
				ctx.r11.s64 = ctx.r11.s64 + 1;
				// clrlwi r11,r11,24
				ctx.r11.u64 = ctx.r11.u32 & 0xFF;
				// cmplw cr6,r11,r8
				// blt cr6,0x8256b7c4
				if (ctx.r11.u32 < ctx.r8.u32) goto loc_8256B7C4;
				// cmpwi cr6,r7,0
				// bne cr6,0x8256b82c
				if (ctx.r7.s32 != 0) goto loc_8256B82C;
			}
		loc_8256B7F0:
			// clrlwi r11,r31,24
			ctx.r11.u64 = var_r31 & 0xFF;
			// lwz r8,4(r30)
			ctx.r8.u64 = PPC_LOAD_U32(var_r30 + 4)/* msgMsgSink::flags@+0x4 */;
			// mulli r10,r6,12
			ctx.r10.s64 = static_cast<int64_t>(ctx.r6.u64 * static_cast<uint64_t>(12));
			// mulli r9,r11,12
			ctx.r9.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(12));
			// add r7,r10,r5
			ctx.r7.u64 = ctx.r10.u64 + ctx.r5.u64;
			// li r10,12
			ctx.r10.s64 = 12;
			// add r9,r9,r8
			ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
			// mtctr r10
			ctx.ctr.u64 = ctx.r10.u64;
		loc_8256B810:
			// lbz r10,0(r7)
			ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
			// addi r7,r7,1
			ctx.r7.s64 = ctx.r7.s64 + 1;
			// stb r10,0(r9)
			PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r10.u8);
			// addi r9,r9,1
			ctx.r9.s64 = ctx.r9.s64 + 1;
			// bdnz 0x8256b810
			--ctx.ctr.u64;
			if (ctx.ctr.u32 != 0) goto loc_8256B810;
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// clrlwi r31,r11,24
			var_r31 = (uint32_t)(ctx.r11.u32 & 0xFF);
		loc_8256B82C:
			// addi r11,r6,1
			ctx.r11.s64 = ctx.r6.s64 + 1;
			// clrlwi r6,r11,24
			ctx.r6.u64 = ctx.r11.u32 & 0xFF;
			// cmplw cr6,r6,r4
			// blt cr6,0x8256b79c
			if (ctx.r6.u32 < ctx.r4.u32) goto loc_8256B79C;
			// b 0x8256b86c
		} else {
		loc_8256B840:
			// lwz r3,4(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 4)/* msgMsgSink::flags@+0x4 */;
			// cmplwi r3,0
			// beq 0x8256b85c
			if (ctx.r3.u32 != 0) {
				// mr r4,r31
				ctx.r4.u64 = var_r31;
				// bl 0x820c02d0
				_locale_register(ctx, base);
				// li r11,0
				ctx.r11.s64 = 0;
				// stw r11,4(r30)
				PPC_STORE_U32(var_r30 + 4,/* msgMsgSink::flags@+0x4 */ ctx.r11.u32);
			}
		loc_8256B85C:
			// mr r4,r31
			ctx.r4.u64 = var_r31;
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// li r30,0
			var_r30 = 0;
		}
	}
loc_8256B86C:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	return;
}

__attribute__((alias("__imp__msgMsgSink_B878_w"))) PPC_WEAK_FUNC(msgMsgSink_B878_w);
PPC_FUNC_IMPL(__imp__msgMsgSink_B878_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_29
	// lwz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// lwz r3,4(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// mr r29,r6
	var_r29 = ctx.r6.u32;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,4(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lwz r11,8(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bl 0x8256b638
	msgMsgSink_B638_w(ctx, base);
	// stw r3,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r3.u32);
	// cmplwi r3,0
	// bne 0x8256b8c8
	if (ctx.r3.u32 == 0) {
		// lis r30,-32761
		var_r30 = (uint32_t)(-2147024896);
		// ori r30,r30,14
		var_r30 = (uint32_t)(var_r30 | 14);
		// b 0x8256b974
	} else {
	loc_8256B8C8:
		// lbz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
		// cmplwi cr6,r11,4
		// bge cr6,0x8256b8dc
		if (ctx.r11.u32 < 4) {
			// li r11,4
			ctx.r11.s64 = 4;
			// stb r11,80(r1)
			PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r11.u8);
		}
	loc_8256B8DC:
		// lbz r11,81(r1)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
		// cmplwi cr6,r11,3
		// bge cr6,0x8256b8f0
		if (ctx.r11.u32 < 3) {
			// li r11,3
			ctx.r11.s64 = 3;
			// stb r11,81(r1)
			PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r11.u8);
		}
	loc_8256B8F0:
		// addi r3,r30,4
		ctx.r3.s64 = (int64_t)(int32_t)var_r30 + 4;
		// b 0x8256b908
		goto loc_8256B908;
		do {
			// lwz r11,0(r3)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* msgMsgSink::vtable@+0x0 */;
			// cmplwi cr6,r11,0
			// bne cr6,0x8256b910
			// addi r3,r3,4
			ctx.r3.s64 = ctx.r3.s64 + 4;
			// cmplw cr6,r3,r31
			// blt cr6,0x8256b8f8
		} while (ctx.r3.u32 < var_r31);
	loc_8256B910:
		// lwz r11,0(r3)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* msgMsgSink::vtable@+0x0 */;
		// mr r6,r29
		ctx.r6.u64 = var_r29;
		// addi r5,r1,80
		ctx.r5.s64 = ctx.r1.s64 + 80;
		// mr r4,r31
		ctx.r4.u64 = var_r31;
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// mr. r30,r3
		var_r30 = ctx.r3.u32;
		// bge 0x8256b974
		if ((int32_t)var_r30 >= 0) {
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			return;
		}
		// lwz r3,84(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
		// cmplwi cr6,r3,0
		// beq cr6,0x8256b974
		if (ctx.r3.u32 == 0) {
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			return;
		}
		// addi r31,r3,4
		var_r31 = (uint32_t)(ctx.r3.s64 + 4);
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0)/* msgMsgSink::vtable@+0x0 */;
		// cmplwi r11,0
		// beq 0x8256b968
		if (ctx.r11.u32 != 0) {
			// lis r4,24714
			ctx.r4.s64 = 1619656704;
			// mr r3,r11
			ctx.r3.u64 = ctx.r11.u64;
			// ori r4,r4,8194
			ctx.r4.u64 = ctx.r4.u64 | 8194;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// li r11,0
			ctx.r11.s64 = 0;
			// stw r11,0(r31)
			PPC_STORE_U32(var_r31 + 0,/* msgMsgSink::vtable@+0x0 */ ctx.r11.u32);
			// lwz r3,84(r1)
			ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
		}
	loc_8256B968:
		// lis r4,24714
		ctx.r4.s64 = 1619656704;
		// ori r4,r4,8194
		ctx.r4.u64 = ctx.r4.u64 | 8194;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_8256B974:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	return;
}

__attribute__((alias("__imp__xam_B980_w"))) PPC_WEAK_FUNC(xam_B980_w);
PPC_FUNC_IMPL(__imp__xam_B980_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=144, savegprlr_28
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r31,r6
	var_r31 = ctx.r6.u32;
	// bl 0x82566898
	util_6898(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, var_r30);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, var_r29);
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, var_r28);
	// bl 0x8256f150
	xam_F150(ctx, base);
	// mr. r30,r3
	var_r30 = ctx.r3.u32;
	// bge 0x8256b9f0
	if ((int32_t)var_r30 < 0) {
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// cmplwi r3,0
		// beq 0x8256b9f0
		if (ctx.r3.u32 == 0) {
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			return;
		}
		// lwz r11,4(r11)
		// bctrl
		VCALL(ctx.r3.u32, 1, ctx, base);  // vtable slot 1 (byte +4)
		// li r11,0
		ctx.r11.s64 = 0;
		// stw r11,0(r31)
		PPC_STORE_U32(var_r31 + 0, ctx.r11.u32);
	}
loc_8256B9F0:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	return;
}

__attribute__((alias("__imp__xe_BA00_h"))) PPC_WEAK_FUNC(xe_BA00_h);
PPC_FUNC_IMPL(__imp__xe_BA00_h) {
	PPC_FUNC_PROLOGUE();
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x8256b980
	xam_B980_w(ctx, base);
	return;
}

__attribute__((alias("__imp__phInst_BA10_wrh"))) PPC_WEAK_FUNC(phInst_BA10_wrh);
PPC_FUNC_IMPL(__imp__phInst_BA10_wrh) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r9.u32);
	// stw r9,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phInst_BA38_2h"))) PPC_WEAK_FUNC(phInst_BA38_2h);
PPC_FUNC_IMPL(__imp__phInst_BA38_2h) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r9,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r9.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r10,r8
	PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BA60_w"))) PPC_WEAK_FUNC(xam_BA60_w);
PPC_FUNC_IMPL(__imp__xam_BA60_w) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmpwi cr6,r11,1
	// bne cr6,0x8256badc
	if (ctx.r11.s32 == 1) {
		// lwz r9,8(r3)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
		// cmplwi r9,0
		// beq 0x8256badc
		if (ctx.r9.u32 == 0) goto loc_8256BADC;
		// li r10,0
		ctx.r10.s64 = 0;
		// addi r11,r9,16
		ctx.r11.s64 = ctx.r9.s64 + 16;
	loc_8256BA8C:
		// lwz r8,-8(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
		// cmplwi cr6,r8,0
		// beq cr6,0x8256baa4
		if (ctx.r8.u32 != 0) {
			// lwz r8,0(r11)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			// cmpwi cr6,r8,1
			// beq cr6,0x8256bacc
			if (ctx.r8.s32 == 1) goto loc_8256BACC;
		}
	loc_8256BAA4:
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// cmplwi cr6,r10,2
		// blt cr6,0x8256ba8c
		if (ctx.r10.u32 < 2) goto loc_8256BA8C;
		// li r3,0
		ctx.r3.s64 = 0;
	loc_8256BAB8:
		// addi r11,r3,0
		ctx.r11.s64 = ctx.r3.s64 + 0;
		// cntlzw r11,r11
		ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
		// rlwinm r11,r11,27,31,31
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
		// xori r3,r11,1
		ctx.r3.u64 = ctx.r11.u64 ^ 1;
		// b 0x8256bae0
		// blr
		return;
	loc_8256BACC:
		// lwz r11,4(r9)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
		// addi r3,r11,8
		ctx.r3.s64 = ctx.r11.s64 + 8;
		// bl 0x8256c5e8
		xam_C5E8_gen(ctx, base);
		// b 0x8256bab8
		// addi r11,r3,0
		ctx.r11.s64 = ctx.r3.s64 + 0;
		// cntlzw r11,r11
		ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
		// rlwinm r11,r11,27,31,31
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
		// xori r3,r11,1
		ctx.r3.u64 = ctx.r11.u64 ^ 1;
		// b 0x8256bae0
		// blr
		return;
	}
loc_8256BADC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8256BAE0:
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_BAF0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_BAF0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_BAF0_2h) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lis r4,25738
	ctx.r4.s64 = 1686765568;
	// mullw r3,r3,r11
	ctx.r3.s64 = int64_t(ctx.r3.s32) * int64_t(ctx.r11.s32);
	// ori r4,r4,24
	ctx.r4.u64 = ctx.r4.u64 | 24;
	// b 0x820c01b8
	rage_01B8(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_BB08_w"))) PPC_WEAK_FUNC(xam_BB08_w);
PPC_FUNC_IMPL(__imp__xam_BB08_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// bl 0x82566898
	util_6898(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_BB38"))) PPC_WEAK_FUNC(phBoundCapsule_BB38);
PPC_FUNC_IMPL(__imp__phBoundCapsule_BB38) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// bl 0x82434100
	memcpy(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// blr
	return;
}

__attribute__((alias("__imp__thunk_BB68_w"))) PPC_WEAK_FUNC(thunk_BB68_w);
PPC_FUNC_IMPL(__imp__thunk_BB68_w) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// addi r3,r3,52
	ctx.r3.s64 = ctx.r3.s64 + 52;
	// bl 0x8256f5f0
	thunk_fn_8256F530(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__thunk_BB90_w"))) PPC_WEAK_FUNC(thunk_BB90_w);
PPC_FUNC_IMPL(__imp__thunk_BB90_w) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// addi r3,r3,52
	ctx.r3.s64 = ctx.r3.s64 + 52;
	// bl 0x8256fa18
	thunk_fn_8256F960(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_BBB8_2h"))) PPC_WEAK_FUNC(phBoundCapsule_BBB8_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_BBB8_2h) {
	PPC_FUNC_PROLOGUE();
	// lis r4,25738
	ctx.r4.s64 = 1686765568;
	// ori r4,r4,24
	ctx.r4.u64 = ctx.r4.u64 | 24;
	// b 0x820c02d0
	_locale_register(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_BBC8"))) PPC_WEAK_FUNC(phBoundCapsule_BBC8);
PPC_FUNC_IMPL(__imp__phBoundCapsule_BBC8) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// lis r11,-32169
	ctx.r11.s64 = -2108227584;
	// addi r3,r11,-17680
	ctx.r3.s64 = ctx.r11.s64 + -17680;
	// bl 0x8256fb70
	phBoundCapsule_FB70_2h(ctx, base);
	// lis r11,-32169
	ctx.r11.s64 = -2108227584;
	// addi r3,r11,-17480
	ctx.r3.s64 = ctx.r11.s64 + -17480;
	// bl 0x8256fb80
	phBoundCapsule_FB80_2h(ctx, base);
	// lis r11,-32169
	ctx.r11.s64 = -2108227584;
	// addi r3,r11,-17656
	ctx.r3.s64 = ctx.r11.s64 + -17656;
	// bl 0x8256fb90
	phBoundCapsule_FB90_2h(ctx, base);
	// lis r11,-32169
	ctx.r11.s64 = -2108227584;
	// addi r3,r11,-17608
	ctx.r3.s64 = ctx.r11.s64 + -17608;
	// bl 0x8256fba0
	phBoundCapsule_FBA0_2h(ctx, base);
	// lis r11,-32189
	ctx.r11.s64 = -2109538304;
	// addi r3,r11,688
	ctx.r3.s64 = ctx.r11.s64 + 688;
	// bl 0x8256fbb0
	phBoundCapsule_FBB0_2h(ctx, base);
	// lis r11,-32189
	ctx.r11.s64 = -2109538304;
	// addi r3,r11,472
	ctx.r3.s64 = ctx.r11.s64 + 472;
	// bl 0x8256fbc0
	phBoundCapsule_FBC0_2h(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_BC30"))) PPC_WEAK_FUNC(phBoundCapsule_BC30);
PPC_FUNC_IMPL(__imp__phBoundCapsule_BC30) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// bl 0x8256bbc8
	phBoundCapsule_BBC8(ctx, base);
	// addi r30,r31,52
	var_r30 = (uint32_t)(var_r31 + 52);
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bl 0x8256f710
	phBoundCapsule_F710_2hr(ctx, base);
	// clrlwi. r11,r3,16
	ctx.r11.u64 = ctx.r3.u32 & 0xFFFF;
	// beq 0x8256bc74
	if (ctx.r11.s32 != 0) {
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// bl 0x8256f5f0
		thunk_fn_8256F530(ctx, base);
		// lis r3,-32768
		// ori r3,r3,16389
		ctx.r3.u64 = ctx.r3.u64 | 16389;
		// b 0x8256bc98
	} else {
	loc_8256BC74:
		// addi r11,r31,64
		ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 64;
		// li r10,160
		ctx.r10.s64 = 160;
		// addi r9,r31,384
		ctx.r9.s64 = (int64_t)(int32_t)var_r31 + 384;
		// li r8,9
		ctx.r8.s64 = 9;
		// li r3,0
		ctx.r3.s64 = 0;
		// stw r11,28(r31)
		PPC_STORE_U32(var_r31 + 28, ctx.r11.u32);
		// sth r10,32(r31)
		PPC_STORE_U16(var_r31 + 32, ctx.r10.u16);
		// stw r9,36(r31)
		PPC_STORE_U32(var_r31 + 36, ctx.r9.u32);
		// sth r8,40(r31)
		PPC_STORE_U16(var_r31 + 40, ctx.r8.u16);
	}
loc_8256BC98:
	// blr
	return;
}

__attribute__((alias("__imp__xam_BCB0_w"))) PPC_WEAK_FUNC(xam_BCB0_w);
PPC_FUNC_IMPL(__imp__xam_BCB0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=208, savegprlr_20
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r23,0
	var_r23 = 0;
	// addi r24,r31,8
	var_r24 = (uint32_t)(var_r31 + 8);
	// mr r21,r4
	var_r21 = ctx.r4.u32;
	// mr r20,r23
	var_r20 = (uint32_t)(var_r23);
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(var_r31 + 4);
	// li r22,1
	var_r22 = 1;
	// addi r11,r1,88
	ctx.r11.s64 = ctx.r1.s64 + 88;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r10,r24
	ctx.r10.u64 = var_r24;
	// lwz r25,8(r8)
	var_r25 = (uint32_t)(PPC_LOAD_U32(ctx.r8.u32 + 8));
	// addi r8,r31,28
	ctx.r8.s64 = (int64_t)(int32_t)var_r31 + 28;
	// stw r23,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, var_r23);
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
loc_8256BCF4:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r8,0
	// beq 0x8256bd30
	if (ctx.r8.u32 != 0) {
		// lwz r7,8(r10)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
		// cmpwi cr6,r7,1
		// bne cr6,0x8256bd18
		if (ctx.r7.s32 == 1) {
			// lwz r8,8(r8)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
			// stw r8,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
			// b 0x8256bd1c
		} else {
		loc_8256BD18:
			// stw r23,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r23);
		}
	loc_8256BD1C:
		// lwz r8,0(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmplwi cr6,r8,0
		// beq cr6,0x8256bd34
		if (ctx.r8.u32 == 0) goto loc_8256BD34;
		// addi r20,r20,1
		var_r20 = (uint32_t)(var_r20 + 1);
		// b 0x8256bd34
	} else {
	loc_8256BD30:
		// stw r23,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r23);
	}
loc_8256BD34:
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x8256bcf4
	if (ctx.r9.s32 != 0) goto loc_8256BCF4;
	// cmplwi cr6,r25,0
	// beq cr6,0x8256beb4
	if (var_r25 != 0) {
		// cmplwi cr6,r20,0
		// beq cr6,0x8256beb4
		if (var_r20 == 0) {
			// mr r3,r22
			ctx.r3.u64 = var_r22;
			return;
		}
		// mr r22,r23
		var_r22 = (uint32_t)(var_r23);
		// b 0x8256beac
		goto loc_8256BEAC;
		do {
			// addi r21,r21,-1
			var_r21 = (uint32_t)(var_r21 + -1);
			// cmplwi cr6,r25,0
			// beq cr6,0x8256beb4
			// cmplwi cr6,r20,0
			// beq cr6,0x8256beb4
			if (var_r20 == 0) {
				// mr r3,r22
				ctx.r3.u64 = var_r22;
				return;
			}
			// lwz r11,0(r25)
			ctx.r11.u64 = PPC_LOAD_U32(var_r25 + 0);
			// addi r9,r31,64
			ctx.r9.s64 = (int64_t)(int32_t)var_r31 + 64;
			// lwz r8,24(r31)
			ctx.r8.u64 = PPC_LOAD_U32(var_r31 + 24);
			// lwz r10,8(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
			// lwz r11,4(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// add r10,r10,r11
			ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
			// lwz r11,24(r8)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 24);
			// rlwinm. r11,r11,31,1,31
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
			// beq 0x8256bdac
		while (!ctx.cr0.eq) {
			loc_8256BD94:
				// lhz r8,0(r10)
				ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
				// addic. r11,r11,-2
				ctx.xer.ca = ctx.r11.u32 > 1;
				ctx.r11.s64 = ctx.r11.s64 + -2;
				ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
				// addi r10,r10,4
				ctx.r10.s64 = ctx.r10.s64 + 4;
				// sth r8,0(r9)
				PPC_STORE_U16(ctx.r9.u32 + 0, ctx.r8.u16);
				// addi r9,r9,2
				ctx.r9.s64 = ctx.r9.s64 + 2;
				// bne 0x8256bd94
		}
		loc_8256BDAC:
			// addi r5,r1,80
			ctx.r5.s64 = ctx.r1.s64 + 80;
			// stb r23,48(r31)
			PPC_STORE_U8(var_r31 + 48, (uint8_t)var_r23);
			// addi r4,r1,84
			ctx.r4.s64 = ctx.r1.s64 + 84;
			// sth r23,46(r31)
			PPC_STORE_U16(var_r31 + 46, (uint16_t)var_r23);
			// addi r3,r31,52
			ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 52;
			// bl 0x8256f488
			aud_F488(ctx, base);
			// clrlwi. r11,r3,16
			ctx.r11.u64 = ctx.r3.u32 & 0xFFFF;
			// bne 0x8256beb4
			if (ctx.r11.s32 != 0) {
				// mr r3,r22
				ctx.r3.u64 = var_r22;
				return;
			}
			// lhz r29,46(r31)
			var_r29 = (uint32_t)(PPC_LOAD_U16(var_r31 + 46));
			// mr r22,r23
			var_r22 = (uint32_t)(var_r23);
			// addi r28,r1,88
			var_r28 = (uint32_t)(ctx.r1.s64 + 88);
			// mr r27,r24
			var_r27 = (uint32_t)(var_r24);
			// li r26,2
			var_r26 = 2;
		loc_8256BDE0:
			// lwz r30,0(r28)
			var_r30 = (uint32_t)(PPC_LOAD_U32(var_r28 + 0));
			// cmplwi r30,0
			// beq 0x8256be54
			if (var_r30 != 0) {
				// lwz r11,0(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
				// mr r5,r29
				ctx.r5.u64 = var_r29;
				// addi r4,r31,384
				ctx.r4.s64 = (int64_t)(int32_t)var_r31 + 384;
				// lwz r10,8(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
				// lwz r11,4(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// add r3,r10,r11
				ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
				// bl 0x82434100
				memcpy(ctx, base);
				// lwz r11,0(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
				// lwz r9,4(r11)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// lwz r10,12(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
				// add r9,r29,r9
				ctx.r9.u64 = var_r29 + ctx.r9.u64;
				// cmplw cr6,r9,r10
				// bge cr6,0x8256be24
				if (ctx.r9.u32 < ctx.r10.u32) {
					// mr r10,r9
					ctx.r10.u64 = ctx.r9.u64;
				}
			loc_8256BE24:
				// stw r10,4(r11)
				PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
				// lwz r11,0(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
				// lwz r11,12(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
				// cmplw cr6,r10,r11
				// bne cr6,0x8256be54
				if (ctx.r10.u32 != ctx.r11.u32) goto loc_8256BE54;
				// mr r4,r30
				ctx.r4.u64 = var_r30;
				// lwz r3,0(r27)
				ctx.r3.u64 = PPC_LOAD_U32(var_r27 + 0);
				// bl 0x8256c608
				xam_C608_2h(ctx, base);
				// cmplwi r3,0
				// stw r3,0(r28)
				PPC_STORE_U32(var_r28 + 0, ctx.r3.u32);
				// bne 0x8256be54
				if (ctx.r3.u32 != 0) goto loc_8256BE54;
				// addi r20,r20,-1
				var_r20 = (uint32_t)(var_r20 + -1);
			}
		loc_8256BE54:
			// addic. r26,r26,-1
			ctx.xer.ca = var_r26 > 0;
			var_r26 = (uint32_t)(var_r26 + -1);
			// addi r27,r27,4
			var_r27 = (uint32_t)(var_r27 + 4);
			// addi r28,r28,4
			var_r28 = (uint32_t)(var_r28 + 4);
			// bne 0x8256bde0
			if ((int32_t)var_r26 != 0) goto loc_8256BDE0;
			// lwz r11,0(r25)
			ctx.r11.u64 = PPC_LOAD_U32(var_r25 + 0);
			// lwz r10,24(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 24);
			// lwz r8,4(r11)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// lwz r9,24(r10)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
			// lwz r10,12(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// add r9,r8,r9
			ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
			// cmplw cr6,r9,r10
			// bge cr6,0x8256be88
			if (ctx.r9.u32 < ctx.r10.u32) {
				// mr r10,r9
				ctx.r10.u64 = ctx.r9.u64;
			}
		loc_8256BE88:
			// stw r10,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
			// lwz r11,0(r25)
			ctx.r11.u64 = PPC_LOAD_U32(var_r25 + 0);
			// lwz r11,12(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// cmplw cr6,r10,r11
			// bne cr6,0x8256beac
			if (ctx.r10.u32 != ctx.r11.u32) goto loc_8256BEAC;
			// mr r4,r25
			ctx.r4.u64 = var_r25;
			// lwz r3,4(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
			// bl 0x8256c608
			xam_C608_2h(ctx, base);
			// mr r25,r3
			var_r25 = ctx.r3.u32;
			// cmplwi cr6,r21,0
			// bne cr6,0x8256bd5c
		} while (var_r21 != 0);
	}
loc_8256BEB4:
	// mr r3,r22
	ctx.r3.u64 = var_r22;
	return;
}

__attribute__((alias("__imp__thunk_BEC0"))) PPC_WEAK_FUNC(thunk_BEC0);
PPC_FUNC_IMPL(__imp__thunk_BEC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// bl 0x8256bbc8
	phBoundCapsule_BBC8(ctx, base);
	// addi r30,r31,52
	var_r30 = (uint32_t)(var_r31 + 52);
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bl 0x8256fb68
	thunk_fn_8256FA20(ctx, base);
	// clrlwi. r11,r3,16
	ctx.r11.u64 = ctx.r3.u32 & 0xFFFF;
	// beq 0x8256bf04
	if (ctx.r11.s32 != 0) {
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// bl 0x8256fa18
		thunk_fn_8256F960(ctx, base);
		// lis r3,-32768
		// ori r3,r3,16389
		ctx.r3.u64 = ctx.r3.u64 | 16389;
		// b 0x8256bf20
	} else {
	loc_8256BF04:
		// addi r11,r31,64
		ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 64;
		// addi r10,r31,704
		ctx.r10.s64 = (int64_t)(int32_t)var_r31 + 704;
		// li r9,9
		ctx.r9.s64 = 9;
		// li r3,0
		ctx.r3.s64 = 0;
		// stw r11,28(r31)
		PPC_STORE_U32(var_r31 + 28, ctx.r11.u32);
		// stw r10,36(r31)
		PPC_STORE_U32(var_r31 + 36, ctx.r10.u32);
		// sth r9,40(r31)
		PPC_STORE_U16(var_r31 + 40, ctx.r9.u16);
	}
loc_8256BF20:
	// blr
	return;
}

__attribute__((alias("__imp__xam_BF38"))) PPC_WEAK_FUNC(xam_BF38);
PPC_FUNC_IMPL(__imp__xam_BF38) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r19 = 0;
	uint32_t var_r18 = 0;
	uint32_t var_r17 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	// FRAME: size=240, savegprlr_17
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r23,0
	var_r23 = 0;
	// addi r21,r31,28
	var_r21 = (uint32_t)(var_r31 + 28);
	// addi r20,r31,8
	var_r20 = (uint32_t)(var_r31 + 8);
	// mr r19,r4
	var_r19 = ctx.r4.u32;
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(var_r31 + 4);
	// mr r18,r23
	var_r18 = (uint32_t)(var_r23);
	// li r17,1
	var_r17 = 1;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r10,r20
	ctx.r10.u64 = var_r20;
	// lwz r22,8(r8)
	var_r22 = (uint32_t)(PPC_LOAD_U32(ctx.r8.u32 + 8));
	// stw r21,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, var_r21);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, var_r23);
loc_8256BF7C:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r8,0
	// beq 0x8256bfb8
	if (ctx.r8.u32 != 0) {
		// lwz r7,8(r10)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
		// cmpwi cr6,r7,1
		// bne cr6,0x8256bfa0
		if (ctx.r7.s32 == 1) {
			// lwz r8,8(r8)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
			// stw r8,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
			// b 0x8256bfa4
		} else {
		loc_8256BFA0:
			// stw r23,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r23);
		}
	loc_8256BFA4:
		// lwz r8,0(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmplwi cr6,r8,0
		// beq cr6,0x8256bfbc
		if (ctx.r8.u32 == 0) goto loc_8256BFBC;
		// addi r18,r18,1
		var_r18 = (uint32_t)(var_r18 + 1);
		// b 0x8256bfbc
	} else {
	loc_8256BFB8:
		// stw r23,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r23);
	}
loc_8256BFBC:
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x8256bf7c
	if (ctx.r9.s32 != 0) goto loc_8256BF7C;
	// cmplwi cr6,r22,0
	// beq cr6,0x8256c1cc
	if (var_r22 != 0) {
		// cmplwi cr6,r18,0
		// beq cr6,0x8256c1cc
		if (var_r18 == 0) {
			// mr r3,r17
			ctx.r3.u64 = var_r17;
			return;
		}
		// mr r17,r23
		var_r17 = (uint32_t)(var_r23);
		// b 0x8256c1c4
		goto loc_8256C1C4;
		do {
			// addi r19,r19,-1
			var_r19 = (uint32_t)(var_r19 + -1);
			// cmplwi cr6,r22,0
			// beq cr6,0x8256c1cc
			// cmplwi cr6,r18,0
			// beq cr6,0x8256c1cc
			if (var_r18 == 0) {
				// mr r3,r17
				ctx.r3.u64 = var_r17;
				return;
			}
			// lwz r10,24(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 24);
			// addi r3,r31,704
			ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 704;
			// lwz r11,0(r22)
			ctx.r11.u64 = PPC_LOAD_U32(var_r22 + 0);
			// lwz r5,24(r10)
			ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
			// lwz r10,8(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
			// lwz r11,4(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// add r4,r10,r11
			ctx.r4.u64 = ctx.r10.u64 + ctx.r11.u64;
			// bl 0x82434100
			memcpy(ctx, base);
			// addi r28,r31,64
			var_r28 = (uint32_t)(var_r31 + 64);
			// addi r30,r31,52
			var_r30 = (uint32_t)(var_r31 + 52);
			// stb r23,44(r31)
			PPC_STORE_U8(var_r31 + 44, (uint8_t)var_r23);
			// sth r23,32(r31)
			PPC_STORE_U16(var_r31 + 32, (uint16_t)var_r23);
			// sth r23,42(r31)
			PPC_STORE_U16(var_r31 + 42, (uint16_t)var_r23);
			// stw r28,0(r21)
			PPC_STORE_U32(var_r21 + 0, var_r28);
		loc_8256C030:
			// addi r5,r1,84
			ctx.r5.s64 = ctx.r1.s64 + 84;
			// addi r4,r1,88
			ctx.r4.s64 = ctx.r1.s64 + 88;
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			// bl 0x8256f8b0
			xam_F8B0_h(ctx, base);
			// mr r29,r3
			var_r29 = ctx.r3.u32;
			// clrlwi. r11,r29,16
			ctx.r11.u64 = var_r29 & 0xFFFF;
			// bne 0x8256c07c
			if (ctx.r11.s32 != 0) goto loc_8256C07C;
			// lhz r11,32(r31)
			ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 32);
			// addi r4,r1,80
			ctx.r4.s64 = ctx.r1.s64 + 80;
			// lwz r10,0(r21)
			ctx.r10.u64 = PPC_LOAD_U32(var_r21 + 0);
			// rotlwi r11,r11,1
			ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
			// lwz r3,0(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
			// sth r23,32(r31)
			PPC_STORE_U16(var_r31 + 32, (uint16_t)var_r23);
			// add r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
			// stw r11,0(r21)
			PPC_STORE_U32(var_r21 + 0, ctx.r11.u32);
			// bl 0x8256f948
			xam_F948_2hr(ctx, base);
			// lbz r11,80(r1)
			ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
			// cmplwi r11,0
			// beq 0x8256c030
			if (ctx.r11.u32 == 0) goto loc_8256C030;
		loc_8256C07C:
			// clrlwi. r11,r29,16
			ctx.r11.u64 = var_r29 & 0xFFFF;
			// bne 0x8256c1cc
			if (ctx.r11.s32 != 0) {
				// mr r3,r17
				ctx.r3.u64 = var_r17;
				return;
			}
			// li r11,160
			ctx.r11.s64 = 160;
			// lhz r24,42(r31)
			var_r24 = (uint32_t)(PPC_LOAD_U16(var_r31 + 42));
			// li r9,160
			ctx.r9.s64 = 160;
			// addi r10,r31,384
			ctx.r10.s64 = (int64_t)(int32_t)var_r31 + 384;
			// sth r11,32(r31)
			PPC_STORE_U16(var_r31 + 32, ctx.r11.u16);
			// addi r11,r28,640
			ctx.r11.s64 = (int64_t)(int32_t)var_r28 + 640;
		loc_8256C09C:
			// addi r10,r10,-2
			ctx.r10.s64 = ctx.r10.s64 + -2;
			// addi r11,r11,-4
			ctx.r11.s64 = ctx.r11.s64 + -4;
			// addic. r9,r9,-1
			ctx.xer.ca = ctx.r9.u32 > 0;
			ctx.r9.s64 = ctx.r9.s64 + -1;
			// lhz r8,0(r10)
			ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
			// sth r8,2(r11)
			PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r8.u16);
			// sth r8,0(r11)
			PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r8.u16);
			// bne 0x8256c09c
			if (ctx.r9.s32 != 0) goto loc_8256C09C;
			// addi r27,r1,96
			var_r27 = (uint32_t)(ctx.r1.s64 + 96);
			// mr r26,r20
			var_r26 = (uint32_t)(var_r20);
			// li r25,2
			var_r25 = 2;
		loc_8256C0C4:
			// lwz r30,0(r27)
			var_r30 = (uint32_t)(PPC_LOAD_U32(var_r27 + 0));
			// cmplwi r30,0
			// beq 0x8256c174
			if (var_r30 != 0) {
				// lhz r11,32(r31)
				ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 32);
				// li r10,8000
				ctx.r10.s64 = 8000;
				// mulli r11,r11,16000
				ctx.r11.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(16000));
				// divw r11,r11,r10
				ctx.r11.s32 = ctx.r10.s32 ? ctx.r11.s32 / ctx.r10.s32 : 0;
				// rlwinm r29,r11,1,0,30
				var_r29 = (uint32_t)(__builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE);
				// lwz r11,0(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
				// lwz r10,12(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
				// lwz r11,4(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// subf r11,r11,r10
				ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
				// cmplw cr6,r29,r11
				// blt cr6,0x8256c10c
				if (var_r29 >= ctx.r11.u32) {
					// lwz r11,0(r30)
					ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
					// lwz r10,12(r11)
					ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
					// lwz r11,4(r11)
					ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
					// subf r29,r11,r10
					var_r29 = (uint32_t)(ctx.r10.s64 - ctx.r11.s64);
				}
			loc_8256C10C:
				// lwz r11,0(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
				// mr r5,r29
				ctx.r5.u64 = var_r29;
				// mr r4,r28
				ctx.r4.u64 = var_r28;
				// lwz r10,8(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
				// lwz r11,4(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// add r3,r10,r11
				ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
				// bl 0x82434100
				memcpy(ctx, base);
				// lwz r11,0(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
				// lwz r9,4(r11)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// lwz r10,12(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
				// add r9,r9,r29
				ctx.r9.u64 = ctx.r9.u64 + var_r29;
				// cmplw cr6,r9,r10
				// bge cr6,0x8256c144
				if (ctx.r9.u32 < ctx.r10.u32) {
					// mr r10,r9
					ctx.r10.u64 = ctx.r9.u64;
				}
			loc_8256C144:
				// stw r10,4(r11)
				PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
				// lwz r11,0(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
				// lwz r11,12(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
				// cmplw cr6,r10,r11
				// bne cr6,0x8256c174
				if (ctx.r10.u32 != ctx.r11.u32) goto loc_8256C174;
				// mr r4,r30
				ctx.r4.u64 = var_r30;
				// lwz r3,0(r26)
				ctx.r3.u64 = PPC_LOAD_U32(var_r26 + 0);
				// bl 0x8256c608
				xam_C608_2h(ctx, base);
				// cmplwi r3,0
				// stw r3,0(r27)
				PPC_STORE_U32(var_r27 + 0, ctx.r3.u32);
				// bne 0x8256c174
				if (ctx.r3.u32 != 0) goto loc_8256C174;
				// addi r18,r18,-1
				var_r18 = (uint32_t)(var_r18 + -1);
			}
		loc_8256C174:
			// addic. r25,r25,-1
			ctx.xer.ca = var_r25 > 0;
			var_r25 = (uint32_t)(var_r25 + -1);
			// addi r26,r26,4
			var_r26 = (uint32_t)(var_r26 + 4);
			// addi r27,r27,4
			var_r27 = (uint32_t)(var_r27 + 4);
			// bne 0x8256c0c4
			if ((int32_t)var_r25 != 0) goto loc_8256C0C4;
			// lwz r11,0(r22)
			ctx.r11.u64 = PPC_LOAD_U32(var_r22 + 0);
			// lwz r9,4(r11)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// lwz r10,12(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// add r9,r9,r24
			ctx.r9.u64 = ctx.r9.u64 + var_r24;
			// cmplw cr6,r9,r10
			// bge cr6,0x8256c1a0
			if (ctx.r9.u32 < ctx.r10.u32) {
				// mr r10,r9
				ctx.r10.u64 = ctx.r9.u64;
			}
		loc_8256C1A0:
			// stw r10,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
			// lwz r11,0(r22)
			ctx.r11.u64 = PPC_LOAD_U32(var_r22 + 0);
			// lwz r11,12(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// cmplw cr6,r10,r11
			// bne cr6,0x8256c1c4
			if (ctx.r10.u32 != ctx.r11.u32) goto loc_8256C1C4;
			// mr r4,r22
			ctx.r4.u64 = var_r22;
			// lwz r3,4(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
			// bl 0x8256c608
			xam_C608_2h(ctx, base);
			// mr r22,r3
			var_r22 = ctx.r3.u32;
			// cmplwi cr6,r19,0
			// bne cr6,0x8256bfe4
		} while (var_r19 != 0);
	}
loc_8256C1CC:
	// mr r3,r17
	ctx.r3.u64 = var_r17;
	return;
}

__attribute__((alias("__imp__xam_C1D8_w"))) PPC_WEAK_FUNC(xam_C1D8_w);
PPC_FUNC_IMPL(__imp__xam_C1D8_w) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,2
	// bne cr6,0x8256c1ec
	if (ctx.r11.u32 == 2) {
		// lwz r3,4(r3)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
		// b 0x8256c1f8
	} else {
	loc_8256C1EC:
		// addi r11,r11,2
		ctx.r11.s64 = ctx.r11.s64 + 2;
		// rlwinm r11,r11,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// lwzx r3,r11,r3
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	}
loc_8256C1F8:
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// b 0x8256c688
	xam_C688_w(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_C200_2h"))) PPC_WEAK_FUNC(xam_C200_2h);
PPC_FUNC_IMPL(__imp__xam_C200_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r27,0
	var_r27 = 0;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r10,r27
	ctx.r10.u64 = var_r27;
	// addi r11,r31,16
	ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 16;
loc_8256C220:
	// lwz r9,-8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// cmplwi cr6,r9,0
	// beq cr6,0x8256c238
	if (ctx.r9.u32 != 0) {
		// lwz r9,0(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmpwi cr6,r9,1
		// beq cr6,0x8256c264
		if (ctx.r9.s32 == 1) goto loc_8256C264;
	}
loc_8256C238:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmplwi cr6,r10,2
	// blt cr6,0x8256c220
	if (ctx.r10.u32 < 2) goto loc_8256C220;
	// mr r28,r27
	var_r28 = (uint32_t)(var_r27);
loc_8256C24C:
	// subf r30,r29,r4
	var_r30 = (uint32_t)(ctx.r4.s64 - (int64_t)(int32_t)var_r29);
	// cmpwi cr6,r29,-1
	// beq cr6,0x8256c2a0
	if ((int32_t)var_r29 == -1) goto loc_8256C2A0;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 4);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// b 0x8256c298
	goto loc_8256C298;
loc_8256C264:
	// li r28,1
	var_r28 = 1;
	// b 0x8256c24c
	goto loc_8256C24C;
	do {
		// addi r30,r30,-1
		var_r30 = (uint32_t)(var_r30 + -1);
		// cmplwi cr6,r4,0
		// beq cr6,0x8256c2a0
		// lwz r11,0(r4)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// stw r27,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r27);
		// lwz r11,0(r4)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// lwz r10,12(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// stw r10,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
		// lwz r3,4(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
		// bl 0x8256c608
		xam_C608_2h(ctx, base);
		// mr r4,r3
		ctx.r4.u64 = ctx.r3.u64;
		// cmplwi cr6,r30,0
		// bne cr6,0x8256c26c
	} while (var_r30 != 0);
loc_8256C2A0:
	// cmpwi cr6,r28,1
	// bne cr6,0x8256c2d8
	if ((int32_t)var_r28 == 1) {
		// lwz r11,24(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 24);
		// lwz r11,8(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// cmplwi r11,0
		// beq 0x8256c2cc
		if (ctx.r11.u32 != 0) {
			// mr r4,r29
			ctx.r4.u64 = var_r29;
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// b 0x8256c2d0
		} else {
		loc_8256C2CC:
			// li r3,1
			ctx.r3.s64 = 1;
		}
	loc_8256C2D0:
		// mr r27,r3
		var_r27 = ctx.r3.u32;
		// b 0x8256c318
	} else {
	loc_8256C2D8:
		// lwz r11,4(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 4);
		// lwz r4,8(r11)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// b 0x8256c310
		goto loc_8256C310;
		do {
			// addi r29,r29,-1
			var_r29 = (uint32_t)(var_r29 + -1);
			// cmplwi cr6,r4,0
			// beq cr6,0x8256c318
			// lwz r11,0(r4)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
			// stw r27,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r27);
			// lwz r11,0(r4)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
			// lwz r10,12(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// stw r10,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
			// lwz r3,4(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
			// bl 0x8256c608
			xam_C608_2h(ctx, base);
			// mr r4,r3
			ctx.r4.u64 = ctx.r3.u64;
			// cmplwi cr6,r29,0
			// bne cr6,0x8256c2e4
		} while (var_r29 != 0);
	}
loc_8256C318:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	return;
}

__attribute__((alias("__imp__xam_C328_fw"))) PPC_WEAK_FUNC(xam_C328_fw);
PPC_FUNC_IMPL(__imp__xam_C328_fw) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=144, savegprlr_26
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// mr r27,r5
	var_r27 = ctx.r5.u32;
	// mr r26,r6
	var_r26 = ctx.r6.u32;
	// li r30,0
	var_r30 = 0;
	// cmplwi cr6,r11,0
	// beq cr6,0x8256c354
	if (ctx.r11.u32 != 0) {
		// stw r30,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r30);
	}
loc_8256C354:
	// cmplwi cr6,r27,0
	// beq cr6,0x8256c360
	if (var_r27 != 0) {
		// stw r30,0(r27)
		PPC_STORE_U32(var_r27 + 0, var_r30);
	}
loc_8256C360:
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 4);
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// ori r31,r9,1
	var_r31 = (uint32_t)(ctx.r9.u64 | 1);
	// cmplwi r10,0
	// beq 0x8256c3c4
	if (ctx.r10.u32 != 0) {
		// lwz r4,8(r10)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
		// cmplwi cr6,r11,0
		// beq cr6,0x8256c3a4
		if (ctx.r11.u32 != 0) {
			// cmplwi cr6,r4,0
			// beq cr6,0x8256c3c4
			if (ctx.r4.u32 == 0) goto loc_8256C3C4;
			// lwz r10,0(r4)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
			// stw r31,0(r10)
			PPC_STORE_U32(ctx.r10.u32 + 0, var_r31);
			// lwz r10,0(r4)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
			// stw r10,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
			// lwz r3,4(r28)
			ctx.r3.u64 = PPC_LOAD_U32(var_r28 + 4);
			// bl 0x8256c608
			xam_C608_2h(ctx, base);
			// b 0x8256c3c4
		} else {
		loc_8256C3A4:
			// cmplwi cr6,r4,0
			// beq cr6,0x8256c3c4
		while (ctx.r4.s32 != 0) {
			loc_8256C3AC:
				// lwz r11,0(r4)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
				// stw r31,0(r11)
				PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
				// lwz r3,4(r28)
				ctx.r3.u64 = PPC_LOAD_U32(var_r28 + 4);
				// bl 0x8256c608
				xam_C608_2h(ctx, base);
				// mr. r4,r3
				ctx.r4.u64 = ctx.r3.u64;
				// bne 0x8256c3ac
		}
		}
	}
loc_8256C3C4:
	// addi r29,r28,8
	var_r29 = (uint32_t)(var_r28 + 8);
loc_8256C3C8:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0);
	// cmplwi r11,0
	// beq 0x8256c410
	if (ctx.r11.u32 != 0) {
		// cmplwi cr6,r27,0
		// beq cr6,0x8256c3e4
		if (var_r27 != 0) {
			// cmplw cr6,r30,r26
			// bne cr6,0x8256c410
			if (var_r30 != var_r26) goto loc_8256C410;
		}
	loc_8256C3E4:
		// lwz r4,8(r11)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// cmplwi cr6,r27,0
		// bne cr6,0x8256c424
		if (var_r27 != 0) goto loc_8256C424;
		// cmplwi cr6,r4,0
		// beq cr6,0x8256c410
	while (ctx.r4.s32 != 0) {
		loc_8256C3F8:
			// lwz r11,0(r4)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
			// stw r31,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
			// lwz r3,0(r29)
			ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 0);
			// bl 0x8256c608
			xam_C608_2h(ctx, base);
			// mr. r4,r3
			ctx.r4.u64 = ctx.r3.u64;
			// bne 0x8256c3f8
	}
	}
loc_8256C410:
	// addi r30,r30,1
	var_r30 = (uint32_t)(var_r30 + 1);
	// addi r29,r29,4
	var_r29 = (uint32_t)(var_r29 + 4);
	// cmplwi cr6,r30,2
	// blt cr6,0x8256c3c8
	if (var_r30 < 2) goto loc_8256C3C8;
	// b 0x8256c44c
	// li r3,0
	ctx.r3.s64 = 0;
	return;
loc_8256C424:
	// cmplwi cr6,r4,0
	// beq cr6,0x8256c44c
	if (ctx.r4.u32 != 0) {
		// lwz r11,0(r4)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// addi r10,r30,2
		ctx.r10.s64 = (int64_t)(int32_t)var_r30 + 2;
		// rlwinm r10,r10,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// stw r31,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
		// lwz r11,0(r4)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// stw r11,0(r27)
		PPC_STORE_U32(var_r27 + 0, ctx.r11.u32);
		// lwzx r3,r10,r28
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + var_r28);
		// bl 0x8256c608
		xam_C608_2h(ctx, base);
	}
loc_8256C44C:
	// li r3,0
	ctx.r3.s64 = 0;
	return;
}

__attribute__((alias("__imp__xam_C458_w"))) PPC_WEAK_FUNC(xam_C458_w);
PPC_FUNC_IMPL(__imp__xam_C458_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// cmplwi cr6,r30,0
	// beq cr6,0x8256c4f8
	if (var_r30 != 0) {
		// li r6,0
		ctx.r6.s64 = 0;
		// li r5,0
		ctx.r5.s64 = 0;
		// li r4,0
		ctx.r4.s64 = 0;
		// bl 0x8256c328
		xam_C328_fw(ctx, base);
		// lwz r11,24(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 24);
		// li r28,0
		var_r28 = 0;
		// cmplwi r11,0
		// beq 0x8256c4ac
		if (ctx.r11.u32 != 0) {
			// lwz r11,4(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// cmplwi r11,0
			// beq 0x8256c4a8
			if (ctx.r11.u32 != 0) {
				// mr r3,r30
				ctx.r3.u64 = var_r30;
				// bctrl
				PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			}
		loc_8256C4A8:
			// stw r28,24(r30)
			PPC_STORE_U32(var_r30 + 24, var_r28);
		}
	loc_8256C4AC:
		// lwz r3,4(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 4);
		// cmplwi r3,0
		// beq 0x8256c4c0
		if (ctx.r3.u32 != 0) {
			// bl 0x8256c728
			msgMsgSink_C728(ctx, base);
			// stw r28,4(r30)
			PPC_STORE_U32(var_r30 + 4, var_r28);
		}
	loc_8256C4C0:
		// addi r31,r30,8
		var_r31 = (uint32_t)(var_r30 + 8);
		// li r29,2
		var_r29 = 2;
	loc_8256C4C8:
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// cmplwi r3,0
		// beq 0x8256c4dc
		if (ctx.r3.u32 != 0) {
			// bl 0x8256c728
			msgMsgSink_C728(ctx, base);
			// stw r28,0(r31)
			PPC_STORE_U32(var_r31 + 0, var_r28);
		}
	loc_8256C4DC:
		// addic. r29,r29,-1
		ctx.xer.ca = var_r29 > 0;
		var_r29 = (uint32_t)(var_r29 + -1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// bne 0x8256c4c8
		if ((int32_t)var_r29 != 0) goto loc_8256C4C8;
		// lis r4,25738
		ctx.r4.s64 = 1686765568;
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// ori r4,r4,8
		ctx.r4.u64 = ctx.r4.u64 | 8;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_8256C4F8:
	return;
}

__attribute__((alias("__imp__msgMsgSink_C500_w"))) PPC_WEAK_FUNC(msgMsgSink_C500_w);
PPC_FUNC_IMPL(__imp__msgMsgSink_C500_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	// FRAME: size=144, savegprlr_25
	// mr r26,r4
	var_r26 = ctx.r4.u32;
	// lis r4,25738
	ctx.r4.s64 = 1686765568;
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// ori r4,r4,8
	ctx.r4.u64 = ctx.r4.u64 | 8;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// lwz r3,16(r26)
	ctx.r3.u64 = PPC_LOAD_U32(var_r26 + 16);
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r25,r7
	var_r25 = ctx.r7.u32;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256c544
	if ((int32_t)var_r31 == 0) {
		// lis r30,-32761
		var_r30 = (uint32_t)(-2147024896);
		// ori r30,r30,14
		var_r30 = (uint32_t)(var_r30 | 14);
		// b 0x8256c5c8
	} else {
	loc_8256C544:
		// addi r4,r31,4
		ctx.r4.s64 = (int64_t)(int32_t)var_r31 + 4;
		// stw r30,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* msgMsgSink::vtable@+0x0 */ var_r30);
		// mr r3,r29
		ctx.r3.u64 = var_r29;
		// bl 0x8256c810
		msgMsgSink_C810_w(ctx, base);
		// mr. r30,r3
		var_r30 = ctx.r3.u32;
		// blt 0x8256c5c8
		if ((int32_t)var_r30 < 0) goto loc_8256C5C8;
		// li r27,0
		var_r27 = 0;
		// addi r29,r31,8
		var_r29 = (uint32_t)(var_r31 + 8);
	loc_8256C564:
		// lwz r3,0(r28)
		ctx.r3.u64 = PPC_LOAD_U32(var_r28 + 0);
		// cmplwi r3,0
		// beq 0x8256c580
		if (ctx.r3.u32 != 0) {
			// mr r4,r29
			ctx.r4.u64 = var_r29;
			// bl 0x8256c810
			msgMsgSink_C810_w(ctx, base);
			// mr. r30,r3
			var_r30 = ctx.r3.u32;
			// blt 0x8256c5c8
			if ((int32_t)var_r30 < 0) goto loc_8256C5C8;
		}
	loc_8256C580:
		// addi r27,r27,1
		var_r27 = (uint32_t)(var_r27 + 1);
		// addi r29,r29,4
		var_r29 = (uint32_t)(var_r29 + 4);
		// addi r28,r28,4
		var_r28 = (uint32_t)(var_r28 + 4);
		// cmplwi cr6,r27,2
		// blt cr6,0x8256c564
		if (var_r27 < 2) goto loc_8256C564;
		// stw r26,24(r31)
		PPC_STORE_U32(var_r31 + 24, var_r26);
		// lwz r11,0(r26)
		ctx.r11.u64 = PPC_LOAD_U32(var_r26 + 0);
		// cmplwi cr6,r11,0
		// beq cr6,0x8256c5b8
		if (ctx.r11.u32 != 0) {
			// rotlwi r11,r11,0
			ctx.r11.u64 = ctx.r11.u32;
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// b 0x8256c5bc
		} else {
		loc_8256C5B8:
			// li r3,1
			ctx.r3.s64 = 1;
		}
	loc_8256C5BC:
		// mr r30,r3
		var_r30 = ctx.r3.u32;
		// cmpwi cr6,r3,0
		// bge cr6,0x8256c5d4
		if (ctx.r3.s32 >= 0) {
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			// stw r31,0(r25)
			PPC_STORE_U32(var_r25 + 0, var_r31);
			return;
		}
	}
loc_8256C5C8:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256c458
	xam_C458_w(ctx, base);
	// li r31,0
	var_r31 = 0;
loc_8256C5D4:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// stw r31,0(r25)
	PPC_STORE_U32(var_r25 + 0, var_r31);
	return;
}

__attribute__((alias("__imp__xam_C5E8_gen"))) PPC_WEAK_FUNC(xam_C5E8_gen);
PPC_FUNC_IMPL(__imp__xam_C5E8_gen) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8256c5fc
	goto loc_8256C5FC;
	do {
		// lwz r11,4(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// addi r3,r3,1
		ctx.r3.s64 = ctx.r3.s64 + 1;
		// cmplwi r11,0
		// bne 0x8256c5f4
	} while (ctx.r11.u32 != 0);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C608_2h"))) PPC_WEAK_FUNC(xam_C608_2h);
PPC_FUNC_IMPL(__imp__xam_C608_2h) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpwi cr6,r9,259
	// bne cr6,0x8256c624
	if (ctx.r9.s32 == 259) {
		// stw r10,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	}
loc_8256C624:
	// addi r11,r8,8
	ctx.r11.s64 = ctx.r8.s64 + 8;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r4,r9
	// bne cr6,0x8256c660
	if (ctx.r4.u32 == ctx.r9.u32) {
		// rotlwi r9,r9,0
		ctx.r9.u64 = ctx.r9.u32;
		// cmplwi r9,0
		// beq 0x8256c660
		if (ctx.r9.u32 == 0) goto loc_8256C660;
		// lwz r7,4(r11)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// cmplw cr6,r9,r7
		// bne cr6,0x8256c654
		if (ctx.r9.u32 == ctx.r7.u32) {
			// stw r10,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
		}
	loc_8256C654:
		// lwz r7,4(r9)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
		// stw r7,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
		// stw r10,4(r9)
		PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r10.u32);
	}
loc_8256C660:
	// stw r10,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r10.u32);
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplwi r10,0
	// beq 0x8256c678
	if (ctx.r10.u32 != 0) {
		// stw r4,4(r10)
		PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r4.u32);
		// b 0x8256c67c
	} else {
	loc_8256C678:
		// stw r4,0(r8)
		PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r4.u32);
	}
loc_8256C67C:
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r4,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r4.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C688_w"))) PPC_WEAK_FUNC(xam_C688_w);
PPC_FUNC_IMPL(__imp__xam_C688_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// li r28,0
	var_r28 = 0;
	// lwz r31,0(r30)
	var_r31 = (uint32_t)(PPC_LOAD_U32(var_r30 + 0));
	// cmplwi r31,0
	// beq 0x8256c704
	if (var_r31 != 0) {
		// lwz r11,4(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
		// cmplw cr6,r31,r11
		// bne cr6,0x8256c6bc
		if (var_r31 == ctx.r11.u32) {
			// stw r28,4(r30)
			PPC_STORE_U32(var_r30 + 4, var_r28);
		}
	loc_8256C6BC:
		// lwz r11,4(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 4);
		// li r5,8
		ctx.r5.s64 = 8;
		// li r4,0
		ctx.r4.s64 = 0;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// stw r11,0(r30)
		PPC_STORE_U32(var_r30 + 0, ctx.r11.u32);
		// stw r28,4(r31)
		PPC_STORE_U32(var_r31 + 4, var_r28);
		// bl 0x82566898
		util_6898(ctx, base);
		// li r10,259
		ctx.r10.s64 = 259;
		// stw r28,4(r29)
		PPC_STORE_U32(var_r29 + 4, var_r28);
		// addi r11,r30,8
		ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 8;
		// stw r10,0(r29)
		PPC_STORE_U32(var_r29 + 0, ctx.r10.u32);
		// stw r29,0(r31)
		PPC_STORE_U32(var_r31 + 0, var_r29);
		// stw r28,4(r31)
		PPC_STORE_U32(var_r31 + 4, var_r28);
		// lwz r10,4(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// cmplwi r10,0
		// beq 0x8256c710
		if (ctx.r10.u32 == 0) goto loc_8256C710;
		// stw r31,4(r10)
		PPC_STORE_U32(ctx.r10.u32 + 4, var_r31);
		// b 0x8256c714
	} else {
	loc_8256C704:
		// lis r28,-32761
		var_r28 = (uint32_t)(-2147024896);
		// ori r28,r28,122
		var_r28 = (uint32_t)(var_r28 | 122);
		// b 0x8256c718
		// mr r3,r28
		ctx.r3.u64 = var_r28;
		return;
	loc_8256C710:
		// stw r31,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
	}
loc_8256C714:
	// stw r31,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, var_r31);
loc_8256C718:
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	return;
}

__attribute__((alias("__imp__msgMsgSink_C728"))) PPC_WEAK_FUNC(msgMsgSink_C728);
PPC_FUNC_IMPL(__imp__msgMsgSink_C728) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x8256c774
	if (var_r31 != 0) {
		// lwz r3,16(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 16);
		// cmplwi r3,0
		// beq 0x8256c764
		if (ctx.r3.u32 != 0) {
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// ori r4,r4,3
			ctx.r4.u64 = ctx.r4.u64 | 3;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// li r11,0
			ctx.r11.s64 = 0;
			// stw r11,16(r31)
			PPC_STORE_U32(var_r31 + 16, ctx.r11.u32);
		}
	loc_8256C764:
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r4,r4,32773
		ctx.r4.u64 = ctx.r4.u64 | 32773;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_8256C774:
	// blr
	return;
}

__attribute__((alias("__imp__util_C788"))) PPC_WEAK_FUNC(util_C788);
PPC_FUNC_IMPL(__imp__util_C788) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x8256c7f4
	if (var_r31 != 0) {
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// li r30,0
		var_r30 = 0;
		// cmplwi r3,0
		// beq 0x8256c7c8
		if (ctx.r3.u32 != 0) {
			// lis r4,24714
			ctx.r4.s64 = 1619656704;
			// ori r4,r4,8194
			ctx.r4.u64 = ctx.r4.u64 | 8194;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r30,0(r31)
			PPC_STORE_U32(var_r31 + 0, var_r30);
		}
	loc_8256C7C8:
		// lwz r3,4(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
		// cmplwi r3,0
		// beq 0x8256c7e4
		if (ctx.r3.u32 != 0) {
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// ori r4,r4,9
			ctx.r4.u64 = ctx.r4.u64 | 9;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r30,4(r31)
			PPC_STORE_U32(var_r31 + 4, var_r30);
		}
	loc_8256C7E4:
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r4,r4,32774
		ctx.r4.u64 = ctx.r4.u64 | 32774;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_8256C7F4:
	// blr
	return;
}

__attribute__((alias("__imp__msgMsgSink_C810_w"))) PPC_WEAK_FUNC(msgMsgSink_C810_w);
PPC_FUNC_IMPL(__imp__msgMsgSink_C810_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// ori r4,r4,32773
	ctx.r4.u64 = ctx.r4.u64 | 32773;
	// li r3,20
	ctx.r3.s64 = 20;
	// li r28,0
	var_r28 = 0;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256c864
	if ((int32_t)var_r31 == 0) {
	loc_8256C840:
		// lis r28,-32761
		var_r28 = (uint32_t)(-2147024896);
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r28,r28,14
		var_r28 = (uint32_t)(var_r28 | 14);
		// bl 0x8256c728
		msgMsgSink_C728(ctx, base);
		// li r31,0
		var_r31 = 0;
	loc_8256C854:
		// mr r3,r28
		ctx.r3.u64 = var_r28;
		// stw r31,0(r27)
		PPC_STORE_U32(var_r27 + 0, var_r31);
		return;
	}
loc_8256C864:
	// rlwinm r29,r30,3,0,28
	var_r29 = (uint32_t)(__builtin_rotateleft64(var_r30 | (var_r30 << 32), 3) & 0xFFFFFFF8);
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// ori r4,r4,3
	ctx.r4.u64 = ctx.r4.u64 | 3;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// cmplwi r3,0
	// stw r3,16(r31)
	PPC_STORE_U32(var_r31 + 16, ctx.r3.u32);
	// beq 0x8256c840
	if (ctx.r3.u32 == 0) goto loc_8256C840;
	// cmplwi cr6,r30,0
	// beq cr6,0x8256c854
	if (var_r30 == 0) {
		// mr r3,r28
		ctx.r3.u64 = var_r28;
		// stw r31,0(r27)
		PPC_STORE_U32(var_r27 + 0, var_r31);
		return;
	}
	// mr r10,r29
	ctx.r10.u64 = var_r29;
loc_8256C890:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 16);
	// addi r10,r10,-8
	ctx.r10.s64 = ctx.r10.s64 + -8;
	// li r9,0
	ctx.r9.s64 = 0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r30,r30,-1
	var_r30 = (uint32_t)(var_r30 + -1);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 4)/* msgMsgSink::flags@+0x4 */;
	// cmplwi r9,0
	// beq 0x8256c8bc
	if (ctx.r9.u32 != 0) {
		// stw r11,4(r9)
		PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r11.u32);
		// b 0x8256c8c0
	} else {
	loc_8256C8BC:
		// stw r11,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* msgMsgSink::vtable@+0x0 */ ctx.r11.u32);
	}
loc_8256C8C0:
	// cmplwi cr6,r30,0
	// stw r11,4(r31)
	PPC_STORE_U32(var_r31 + 4,/* msgMsgSink::flags@+0x4 */ ctx.r11.u32);
	// bne cr6,0x8256c890
	if (var_r30 != 0) goto loc_8256C890;
	// b 0x8256c854
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	// stw r31,0(r27)
	PPC_STORE_U32(var_r27 + 0, var_r31);
	return;
}

__attribute__((alias("__imp__rage_C8D0"))) PPC_WEAK_FUNC(rage_C8D0);
PPC_FUNC_IMPL(__imp__rage_C8D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	// FRAME: size=160, savegprlr_24
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// ori r4,r4,32774
	ctx.r4.u64 = ctx.r4.u64 | 32774;
	// li r3,12
	ctx.r3.s64 = 12;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// mr r24,r7
	var_r24 = ctx.r7.u32;
	// li r25,0
	var_r25 = 0;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// beq 0x8256c998
	if ((int32_t)var_r31 != 0) {
		// mullw r26,r29,r30
		var_r26 = (uint32_t)(int64_t((int32_t)var_r29) * int64_t((int32_t)var_r30));
		// stw r28,8(r31)
		PPC_STORE_U32(var_r31 + 8, var_r28);
		// lis r4,24714
		ctx.r4.s64 = 1619656704;
		// mr r3,r26
		ctx.r3.u64 = var_r26;
		// ori r4,r4,8194
		ctx.r4.u64 = ctx.r4.u64 | 8194;
		// bl 0x820c01b8
		rage_01B8(ctx, base);
		// mr r11,r3
		ctx.r11.u64 = ctx.r3.u64;
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mullw r3,r28,r30
		ctx.r3.s64 = int64_t((int32_t)var_r28) * int64_t((int32_t)var_r30);
		// stw r11,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* rage_GameObject::vtable@+0x0 */ ctx.r11.u32);
		// ori r4,r4,9
		ctx.r4.u64 = ctx.r4.u64 | 9;
		// bl 0x820c01b8
		rage_01B8(ctx, base);
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0)/* rage_GameObject::vtable@+0x0 */;
		// stw r3,4(r31)
		PPC_STORE_U32(var_r31 + 4,/* rage_GameObject::flags@+0x4 */ ctx.r3.u32);
		// cmplwi cr6,r11,0
		// beq cr6,0x8256c998
		if (!(ctx.r3.u32 == 0)) {
			// cmplwi cr6,r30,0
			// beq cr6,0x8256c9ac
			if (var_r30 == 0) {
			// mr r3,r25
			ctx.r3.u64 = var_r25;
			// stw r31,0(r24)
			PPC_STORE_U32(var_r24 + 0, var_r31);
			return;
			}
			// subf r8,r27,r29
			ctx.r8.s64 = (int64_t)(int32_t)var_r29 - (int64_t)(int32_t)var_r27;
			// mr r11,r26
			ctx.r11.u64 = var_r26;
			loc_8256C964:
			// lwz r10,8(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 8);
			// addic. r30,r30,-1
			ctx.xer.ca = var_r30 > 0;
			var_r30 = (uint32_t)(var_r30 + -1);
			// lwz r9,4(r31)
			ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 4)/* rage_GameObject::flags@+0x4 */;
			// subf r11,r29,r11
			ctx.r11.s64 = ctx.r11.s64 - (int64_t)(int32_t)var_r29;
			// mullw r10,r10,r30
			ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t((int32_t)var_r30);
			// add r10,r10,r9
			ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
			// stw r8,12(r10)
			PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r8.u32);
			// lwz r9,0(r31)
			ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 0)/* rage_GameObject::vtable@+0x0 */;
			// add r9,r9,r11
			ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
			// add r9,r9,r27
			ctx.r9.u64 = ctx.r9.u64 + var_r27;
			// stw r9,8(r10)
			PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
			// bne 0x8256c964
			if ((int32_t)var_r30 != 0) goto loc_8256C964;
			// b 0x8256c9ac
			} else {
		}
	loc_8256C998:
		// lis r25,-32761
		var_r25 = (uint32_t)(-2147024896);
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r25,r25,14
		var_r25 = (uint32_t)(var_r25 | 14);
		// bl 0x8256c788
		util_C788(ctx, base);
		// li r31,0
		var_r31 = 0;
	}
loc_8256C9AC:
	// mr r3,r25
	ctx.r3.u64 = var_r25;
	// stw r31,0(r24)
	PPC_STORE_U32(var_r24 + 0, var_r31);
	return;
}

__attribute__((alias("__imp__xam_C9C0_w"))) PPC_WEAK_FUNC(xam_C9C0_w);
PPC_FUNC_IMPL(__imp__xam_C9C0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x825681b0
	util_81B0(ctx, base);
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// ld r9,328(r31)
	ctx.r9.u64 = PPC_LOAD_U64(var_r31 + 328);
	// mulli r10,r11,1000
	ctx.r10.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(1000));
	// rotldi r11,r10,1
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u64, 1);
	// divd r3,r10,r9
	ctx.r3.s64 = ctx.r9.s64 ? ctx.r10.s64 / ctx.r9.s64 : 0;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// tdllei r9,0
	if (ctx.r9.s64 == 0ll || ctx.r9.u64 < 0ull) __builtin_trap();
	// andc r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 & ~ctx.r11.u64;
	// tdlgei r11,-1
	if (ctx.r11.s64 == -1ll || ctx.r11.u64 > 18446744073709551615ull) __builtin_trap();
	// blr
	return;
}

__attribute__((alias("__imp__xam_CA18_2hr"))) PPC_WEAK_FUNC(xam_CA18_2hr);
PPC_FUNC_IMPL(__imp__xam_CA18_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r30,0
	var_r30 = 0;
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 72);
	// cmpwi cr6,r11,0
	// beq cr6,0x8256ca68
	if (ctx.r11.s32 != 0) {
		// bl 0x8256c9c0
		xam_C9C0_w(ctx, base);
		// ld r10,24(r31)
		ctx.r10.u64 = PPC_LOAD_U64(var_r31 + 24);
		// ld r9,16(r31)
		ctx.r9.u64 = PPC_LOAD_U64(var_r31 + 16);
		// subf r10,r10,r3
		ctx.r10.s64 = ctx.r3.s64 - ctx.r10.s64;
		// ld r11,40(r31)
		ctx.r11.u64 = PPC_LOAD_U64(var_r31 + 40);
		// subf r10,r9,r10
		ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
		// cmpld cr6,r10,r11
		// blt cr6,0x8256ca68
		if (ctx.r10.u64 < ctx.r11.u64) {
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			// blr
			return;
		}
		// li r30,1
		var_r30 = 1;
		// std r11,56(r31)
		PPC_STORE_U64(var_r31 + 56, ctx.r11.u64);
	}
loc_8256CA68:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// blr
	return;
}

__attribute__((alias("__imp__xam_CA88_wrh"))) PPC_WEAK_FUNC(xam_CA88_wrh);
PPC_FUNC_IMPL(__imp__xam_CA88_wrh) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// li r10,20
	ctx.r10.s64 = 20;
	// li r6,0
	ctx.r6.s64 = 0;
	// ld r7,16(r9)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r9.u32 + 16);
	// lhz r8,32(r9)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r9.u32 + 32);
	// divdu r10,r7,r10
	ctx.r10.u64 = ctx.r10.u64 ? ctx.r7.u64 / ctx.r10.u64 : 0;
	// lhz r11,66(r9)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r9.u32 + 66);
	// std r6,0(r5)
	PPC_STORE_U64(ctx.r5.u32 + 0, ctx.r6.u64);
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// srawi r8,r10,12
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFFF) != 0);
	ctx.r8.s64 = ctx.r10.s32 >> 12;
	// addze r8,r8
	temp.s64 = ctx.r8.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r8.u32;
	ctx.r8.s64 = temp.s64;
	// rlwinm r8,r8,12,0,19
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFFFF000;
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// clrlwi r7,r10,16
	ctx.r7.u64 = ctx.r10.u32 & 0xFFFF;
	// addi r10,r7,4096
	ctx.r10.s64 = ctx.r7.s64 + 4096;
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srawi r11,r8,12
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0xFFF) != 0);
	ctx.r11.s64 = ctx.r8.s32 >> 12;
	// addze r11,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r11.s64 = temp.s64;
	// srawi r3,r10,12
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFFF) != 0);
	ctx.r3.s64 = ctx.r10.s32 >> 12;
	// rlwinm r11,r11,12,0,19
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 12) & 0xFFFFF000;
	// addze r3,r3
	temp.s64 = ctx.r3.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r3.u32;
	ctx.r3.s64 = temp.s64;
	// subf r11,r11,r8
	ctx.r11.s64 = ctx.r8.s64 - ctx.r11.s64;
	// rlwinm r8,r3,12,0,19
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 12) & 0xFFFFF000;
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// clrlwi r8,r4,16
	ctx.r8.u64 = ctx.r4.u32 & 0xFFFF;
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// cmplw cr6,r11,r10
	// bge cr6,0x8256cb30
	if (ctx.r11.u32 < ctx.r10.u32) {
		// cmplw cr6,r8,r11
		// blt cr6,0x8256cb1c
		if (ctx.r8.u32 < ctx.r11.u32) {
			// lwz r11,356(r9)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 356);
			// li r3,2
			ctx.r3.s64 = 2;
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// stw r11,356(r9)
			PPC_STORE_U32(ctx.r9.u32 + 356, ctx.r11.u32);
			// blr
			return;
		}
		// cmplw cr6,r8,r10
		// ble cr6,0x8256cb6c
		if (ctx.r8.u32 <= ctx.r10.u32) goto loc_8256CB6C;
	loc_8256CB1C:
		// lwz r11,356(r9)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 356);
		// li r3,2
		ctx.r3.s64 = 2;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// stw r11,356(r9)
		PPC_STORE_U32(ctx.r9.u32 + 356, ctx.r11.u32);
		// blr
		return;
	}
loc_8256CB30:
	// cmplw cr6,r8,r11
	// bge cr6,0x8256cb40
	if (ctx.r8.u32 >= ctx.r11.u32) goto loc_8256CB40;
	// cmplw cr6,r8,r10
	// bgt cr6,0x8256cb1c
	if (ctx.r8.u32 > ctx.r10.u32) {
		// lwz r11,356(r9)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 356);
		// li r3,2
		ctx.r3.s64 = 2;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// stw r11,356(r9)
		PPC_STORE_U32(ctx.r9.u32 + 356, ctx.r11.u32);
		// blr
		return;
	}
loc_8256CB40:
	// cmplw cr6,r7,r10
	// bge cr6,0x8256cb64
	if (ctx.r7.u32 < ctx.r10.u32) {
		// cmplw cr6,r7,r8
		// bgt cr6,0x8256cb58
		if (ctx.r7.u32 > ctx.r8.u32) goto loc_8256CB58;
		// cmplw cr6,r8,r10
		// ble cr6,0x8256cb74
		if (ctx.r8.u32 <= ctx.r10.u32) goto loc_8256CB74;
	loc_8256CB58:
		// li r3,1
		ctx.r3.s64 = 1;
	loc_8256CB5C:
		// stw r6,356(r9)
		PPC_STORE_U32(ctx.r9.u32 + 356, ctx.r6.u32);
		// blr
		return;
	}
loc_8256CB64:
	// cmplw cr6,r11,r8
	// bgt cr6,0x8256cb74
	if (ctx.r11.u32 > ctx.r8.u32) goto loc_8256CB74;
loc_8256CB6C:
	// cmplw cr6,r8,r7
	// blt cr6,0x8256cb58
	if (ctx.r8.u32 < ctx.r7.u32) goto loc_8256CB58;
loc_8256CB74:
	// subf r11,r7,r8
	ctx.r11.s64 = ctx.r8.s64 - ctx.r7.s64;
	// ld r10,16(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 16);
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// addi r11,r11,4096
	ctx.r11.s64 = ctx.r11.s64 + 4096;
	// srawi r8,r11,12
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0xFFF) != 0);
	ctx.r8.s64 = ctx.r11.s32 >> 12;
	// addze r8,r8
	temp.s64 = ctx.r8.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r8.u32;
	ctx.r8.s64 = temp.s64;
	// rlwinm r8,r8,12,0,19
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFFFF000;
	// subf r11,r8,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r8.s64;
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// mulli r11,r11,20
	ctx.r11.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(20));
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// std r11,0(r5)
	PPC_STORE_U64(ctx.r5.u32 + 0, ctx.r11.u64);
	// b 0x8256cb5c
	// stw r6,356(r9)
	PPC_STORE_U32(ctx.r9.u32 + 356, ctx.r6.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_CBB0_wrh"))) PPC_WEAK_FUNC(xam_CBB0_wrh);
PPC_FUNC_IMPL(__imp__xam_CBB0_wrh) {
	PPC_FUNC_PROLOGUE();
	// addi r10,r3,372
	ctx.r10.s64 = ctx.r3.s64 + 372;
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r11,0
	// beq 0x8256cc10
	if (ctx.r11.u32 != 0) {
		// ld r7,24(r8)
		ctx.r7.u64 = PPC_LOAD_U64(ctx.r8.u32 + 24);
	loc_8256CBD0:
		// lwz r8,0(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// ld r6,24(r8)
		ctx.r6.u64 = PPC_LOAD_U64(ctx.r8.u32 + 24);
		// cmpld cr6,r7,r6
		// blt cr6,0x8256cbf0
		if (ctx.r7.u64 < ctx.r6.u64) goto loc_8256CBF0;
		// mr r9,r11
		ctx.r9.u64 = ctx.r11.u64;
		// lwz r11,4(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// cmplwi r11,0
		// bne 0x8256cbd0
		if (ctx.r11.u32 != 0) goto loc_8256CBD0;
	loc_8256CBF0:
		// cmplwi cr6,r11,0
		// bne cr6,0x8256cc34
		if (ctx.r11.u32 != 0) goto loc_8256CC34;
		// cmplwi cr6,r9,0
		// beq cr6,0x8256cc10
		if (ctx.r9.u32 == 0) goto loc_8256CC10;
		// lwz r11,0(r9)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// ld r11,24(r11)
		ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
		// cmpld cr6,r11,r7
		// beq cr6,0x8256cc74
		if (ctx.r11.u64 == ctx.r7.u64) {
			// lis r3,-32768
			// ori r3,r3,16389
			ctx.r3.u64 = ctx.r3.u64 | 16389;
			// blr
			return;
		}
	}
loc_8256CC10:
	// stw r3,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r3.u32);
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplwi r11,0
	// beq 0x8256cc28
	if (ctx.r11.u32 != 0) {
		// stw r4,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r4.u32);
		// b 0x8256cc2c
		// stw r4,4(r10)
		PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r4.u32);
		// blr
		return;
	}
loc_8256CC28:
	// stw r4,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r4.u32);
loc_8256CC2C:
	// stw r4,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r4.u32);
	// blr
	return;
loc_8256CC34:
	// ld r11,24(r8)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r8.u32 + 24);
	// cmpld cr6,r11,r7
	// beq cr6,0x8256cc74
	if (ctx.r11.u64 == ctx.r7.u64) {
		// lis r3,-32768
		// ori r3,r3,16389
		ctx.r3.u64 = ctx.r3.u64 | 16389;
		// blr
		return;
	}
	// cmplwi cr6,r9,0
	// bne cr6,0x8256cc64
	if (ctx.r9.u32 != 0) {
		// lwz r11,4(r9)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
		// stw r11,4(r4)
		PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r11.u32);
		// stw r4,4(r9)
		PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r4.u32);
		// blr
		return;
	}
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r11.u32);
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r4,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r4.u32);
	// cmplwi cr6,r11,0
	// bnelr cr6
	if (ctx.r11.u32 != 0) return;
	// b 0x8256cc2c
	// stw r4,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r4.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_CC80_wrh"))) PPC_WEAK_FUNC(xam_CC80_wrh);
PPC_FUNC_IMPL(__imp__xam_CC80_wrh) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lhz r11,64(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 64);
	// clrlwi r8,r4,16
	ctx.r8.u64 = ctx.r4.u32 & 0xFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// subf r11,r11,r8
	ctx.r11.s64 = ctx.r8.s64 - ctx.r11.s64;
	// addi r10,r3,372
	ctx.r10.s64 = ctx.r3.s64 + 372;
	// addi r11,r11,4096
	ctx.r11.s64 = ctx.r11.s64 + 4096;
	// srawi r8,r11,12
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0xFFF) != 0);
	ctx.r8.s64 = ctx.r11.s32 >> 12;
	// stw r9,312(r3)
	PPC_STORE_U32(ctx.r3.u32 + 312, ctx.r9.u32);
	// stw r9,304(r3)
	PPC_STORE_U32(ctx.r3.u32 + 304, ctx.r9.u32);
	// addze r8,r8
	temp.s64 = ctx.r8.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r8.u32;
	ctx.r8.s64 = temp.s64;
	// rlwinm r8,r8,12,0,19
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFFFF000;
	// subf r11,r8,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r8.s64;
	// ld r8,24(r3)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// sth r11,32(r3)
	PPC_STORE_U16(ctx.r3.u32 + 32, ctx.r11.u16);
	// ld r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// std r9,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r9.u64);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// std r11,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, ctx.r11.u64);
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r11,0
	// beq 0x8256ccf0
	if (ctx.r11.u32 != 0) {
		// lwz r8,4(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
		// cmplw cr6,r11,r8
		// bne cr6,0x8256cce4
		if (ctx.r11.u32 == ctx.r8.u32) {
			// stw r9,4(r10)
			PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
		}
	loc_8256CCE4:
		// lwz r8,4(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// stw r8,0(r10)
		PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
		// stw r9,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	}
loc_8256CCF0:
	// cmplwi cr6,r11,0
	// beqlr cr6
	if (ctx.r11.u32 == 0) return;
	// addi r7,r3,364
	ctx.r7.s64 = ctx.r3.s64 + 364;
loc_8256CCFC:
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// lwz r8,4(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// cmplwi r8,0
	// beq 0x8256cd14
	if (ctx.r8.u32 != 0) {
		// stw r11,4(r8)
		PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r11.u32);
		// b 0x8256cd18
	} else {
	loc_8256CD14:
		// stw r11,0(r7)
		PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r11.u32);
	}
loc_8256CD18:
	// stw r11,4(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4, ctx.r11.u32);
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r11,0
	// beq 0x8256cd44
	if (ctx.r11.u32 != 0) {
		// lwz r8,4(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
		// cmplw cr6,r11,r8
		// bne cr6,0x8256cd38
		if (ctx.r11.u32 == ctx.r8.u32) {
			// stw r9,4(r10)
			PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
		}
	loc_8256CD38:
		// lwz r8,4(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// stw r8,0(r10)
		PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
		// stw r9,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	}
loc_8256CD44:
	// cmplwi cr6,r11,0
	// bne cr6,0x8256ccfc
	if (ctx.r11.u32 != 0) goto loc_8256CCFC;
	// blr
	return;
}

__attribute__((alias("__imp__xam_CD50_w"))) PPC_WEAK_FUNC(xam_CD50_w);
PPC_FUNC_IMPL(__imp__xam_CD50_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=160, savegprlr_26
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lwz r8,312(r31)
	ctx.r8.u64 = PPC_LOAD_U32(var_r31 + 312);
	// lwz r9,304(r31)
	ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 304);
	// lhz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 68);
	// lhz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U16(var_r31 + 64);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// lis r11,-32248
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f12,f0
	ctx.f12.f64 = double(ctx.f0.s64);
	// fcfid f0,f13
	ctx.f0.f64 = double(ctx.f13.s64);
	// lfd f13,-25848(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + -25848);
	// fdiv f11,f12,f0
	ctx.f11.f64 = ctx.f12.f64 / ctx.f0.f64;
	// fcmpu cr6,f11,f13
	// bge cr6,0x8256cda8
	if (ctx.f11.f64 < ctx.f13.f64) {
		// fdiv f12,f12,f0
		ctx.f12.f64 = ctx.f12.f64 / ctx.f0.f64;
		// b 0x8256cdac
	} else {
	loc_8256CDA8:
		// fmr f12,f13
		ctx.fpscr.disableFlushMode();
		ctx.f12.f64 = ctx.f13.f64;
	}
loc_8256CDAC:
	// lfd f11,288(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(var_r31 + 288);
	// fmul f0,f11,f0
	ctx.f0.f64 = ctx.f11.f64 * ctx.f0.f64;
	// fcmpu cr6,f0,f13
	// blt cr6,0x8256cdc0
	if (ctx.f0.f64 >= ctx.f13.f64) {
		// fmr f0,f13
		ctx.f0.f64 = ctx.f13.f64;
	}
loc_8256CDC0:
	// fsub f13,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f13.f64 - ctx.f0.f64;
	// addi r11,r10,10
	ctx.r11.s64 = ctx.r10.s64 + 10;
	// fmul f12,f0,f12
	ctx.f12.f64 = ctx.f0.f64 * ctx.f12.f64;
	// li r26,0
	var_r26 = 0;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// stfd f0,296(r31)
	PPC_STORE_U64(var_r31 + 296, ctx.f0.u64);
	// lfdx f0,r11,r31
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + var_r31);
	// fmadd f0,f13,f0,f12
	ctx.f0.f64 = ctx.f13.f64 * ctx.f0.f64 + ctx.f12.f64;
	// stfdx f0,r11,r31
	PPC_STORE_U64(ctx.r11.u32 + var_r31, ctx.f0.u64);
	// stw r26,304(r31)
	PPC_STORE_U32(var_r31 + 304, var_r26);
	// lfd f0,280(r31)
	ctx.f0.u64 = PPC_LOAD_U64(var_r31 + 280);
	// stw r26,312(r31)
	PPC_STORE_U32(var_r31 + 312, var_r26);
	// lfdx f13,r11,r31
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + var_r31);
	// fcmpu cr6,f13,f0
	// bge cr6,0x8256cf20
	if (ctx.f13.f64 < ctx.f0.f64) {
		// cmplwi cr6,r10,0
		// beq cr6,0x8256cf7c
		if (ctx.r10.u32 == 0) {
			return;
		}
		// addi r11,r10,9
		ctx.r11.s64 = ctx.r10.s64 + 9;
		// fsub f13,f13,f0
		ctx.f13.f64 = ctx.f13.f64 - ctx.f0.f64;
		// rlwinm r11,r11,3,0,28
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
		// lfdx f12,r11,r31
		ctx.f12.u64 = PPC_LOAD_U64(ctx.r11.u32 + var_r31);
		// fsub f12,f12,f0
		ctx.f12.f64 = ctx.f12.f64 - ctx.f0.f64;
		// fabs f0,f13
		ctx.f0.u64 = ctx.f13.u64 & ~0x8000000000000000;
		// fabs f13,f12
		ctx.f13.u64 = ctx.f12.u64 & ~0x8000000000000000;
		// fcmpu cr6,f13,f0
		// bge cr6,0x8256cf7c
		if (ctx.f13.f64 >= ctx.f0.f64) {
			return;
		}
		// ld r11,40(r31)
		ctx.r11.u64 = PPC_LOAD_U64(var_r31 + 40);
		// addi r30,r31,372
		var_r30 = (uint32_t)(var_r31 + 372);
		// li r10,20
		ctx.r10.s64 = 20;
		// addi r11,r11,-20
		ctx.r11.s64 = ctx.r11.s64 + -20;
		// divdu r10,r11,r10
		ctx.r10.u64 = ctx.r10.u64 ? ctx.r11.u64 / ctx.r10.u64 : 0;
		// lwz r28,0(r30)
		var_r28 = (uint32_t)(PPC_LOAD_U32(var_r30 + 0));
		// cmplwi r28,0
		// std r11,40(r31)
		PPC_STORE_U64(var_r31 + 40, ctx.r11.u64);
		// sth r10,64(r31)
		PPC_STORE_U16(var_r31 + 64, ctx.r10.u16);
		// beq 0x8256cf7c
		if (var_r28 == 0) {
			return;
		}
		// ld r11,16(r31)
		ctx.r11.u64 = PPC_LOAD_U64(var_r31 + 16);
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// lwz r27,0(r28)
		var_r27 = (uint32_t)(PPC_LOAD_U32(var_r28 + 0));
		// addi r11,r11,20
		ctx.r11.s64 = ctx.r11.s64 + 20;
		// ld r29,24(r27)
		var_r29 = (uint32_t)(PPC_LOAD_U64(var_r27 + 24));
		// std r11,16(r31)
		PPC_STORE_U64(var_r31 + 16, ctx.r11.u64);
		// bl 0x8256c5e8
		xam_C5E8_gen(ctx, base);
		// cmplwi r3,0
		// beq 0x8256cf7c
		if (ctx.r3.u32 == 0) {
			return;
		}
		// ld r11,16(r31)
		ctx.r11.u64 = PPC_LOAD_U64(var_r31 + 16);
		// cmpld cr6,r11,r29
		// ble cr6,0x8256cf7c
		if (ctx.r11.u64 <= var_r29) {
			return;
		}
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// addi r9,r29,20
		ctx.r9.s64 = (int64_t)(int32_t)var_r29 + 20;
		// mr r8,r26
		ctx.r8.u64 = var_r26;
		// cmplwi r11,0
		// beq 0x8256cf10
		if (ctx.r11.u32 != 0) {
		loc_8256CE94:
			// lwz r10,0(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			// ld r10,24(r10)
			ctx.r10.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
			// cmpld cr6,r10,r9
			// bgt cr6,0x8256ceb8
			if (ctx.r10.u64 > ctx.r9.u64) goto loc_8256CEB8;
			// bne cr6,0x8256ceac
			if (ctx.cr6.eq) {
				// li r8,1
				ctx.r8.s64 = 1;
			}
		loc_8256CEAC:
			// lwz r11,4(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// cmplwi r11,0
			// bne 0x8256ce94
			if (ctx.r11.u32 != 0) goto loc_8256CE94;
		loc_8256CEB8:
			// cmpwi cr6,r8,0
			// beq cr6,0x8256cf10
			if (ctx.r8.s32 == 0) goto loc_8256CF10;
			// lwz r11,0(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
			// cmplwi r11,0
			// beq 0x8256cee8
			if (ctx.r11.u32 != 0) {
				// lwz r10,4(r30)
				ctx.r10.u64 = PPC_LOAD_U32(var_r30 + 4);
				// cmplw cr6,r11,r10
				// bne cr6,0x8256cedc
				if (ctx.r11.u32 == ctx.r10.u32) {
					// stw r26,4(r30)
					PPC_STORE_U32(var_r30 + 4, var_r26);
				}
			loc_8256CEDC:
				// lwz r10,4(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// stw r10,0(r30)
				PPC_STORE_U32(var_r30 + 0, ctx.r10.u32);
				// stw r26,4(r11)
				PPC_STORE_U32(ctx.r11.u32 + 4, var_r26);
			}
		loc_8256CEE8:
			// addi r11,r31,364
			ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 364;
			// stw r26,4(r28)
			PPC_STORE_U32(var_r28 + 4, var_r26);
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// cmplwi r10,0
			// beq 0x8256cf04
			if (ctx.r10.u32 != 0) {
				// stw r28,4(r10)
				PPC_STORE_U32(ctx.r10.u32 + 4, var_r28);
				// b 0x8256cf08
			} else {
			loc_8256CF04:
				// stw r28,0(r11)
				PPC_STORE_U32(ctx.r11.u32 + 0, var_r28);
			}
		loc_8256CF08:
			// stw r28,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r28);
			// b 0x8256cf7c
			return;
		}
	loc_8256CF10:
		// ld r11,24(r27)
		ctx.r11.u64 = PPC_LOAD_U64(var_r27 + 24);
		// addi r11,r11,20
		ctx.r11.s64 = ctx.r11.s64 + 20;
		// std r11,24(r27)
		PPC_STORE_U64(var_r27 + 24, ctx.r11.u64);
		// b 0x8256cf7c
	} else {
	loc_8256CF20:
		// addi r11,r10,1
		ctx.r11.s64 = ctx.r10.s64 + 1;
		// cmplwi cr6,r11,25
		// bge cr6,0x8256cf7c
		if (ctx.r11.u32 >= 25) {
			return;
		}
		// addi r11,r10,11
		ctx.r11.s64 = ctx.r10.s64 + 11;
		// fsub f13,f13,f0
		ctx.fpscr.disableFlushMode();
		ctx.f13.f64 = ctx.f13.f64 - ctx.f0.f64;
		// rlwinm r11,r11,3,0,28
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
		// lfdx f12,r11,r31
		ctx.f12.u64 = PPC_LOAD_U64(ctx.r11.u32 + var_r31);
		// fsub f12,f12,f0
		ctx.f12.f64 = ctx.f12.f64 - ctx.f0.f64;
		// fabs f0,f13
		ctx.f0.u64 = ctx.f13.u64 & ~0x8000000000000000;
		// fabs f13,f12
		ctx.f13.u64 = ctx.f12.u64 & ~0x8000000000000000;
		// fcmpu cr6,f13,f0
		// bge cr6,0x8256cf7c
		if (ctx.f13.f64 >= ctx.f0.f64) {
			return;
		}
		// ld r11,16(r31)
		ctx.r11.u64 = PPC_LOAD_U64(var_r31 + 16);
		// cmpldi cr6,r11,0
		// beq cr6,0x8256cf7c
		if (ctx.r11.u64 == 0) {
			return;
		}
		// addi r11,r11,-20
		ctx.r11.s64 = ctx.r11.s64 + -20;
		// li r10,20
		ctx.r10.s64 = 20;
		// std r11,16(r31)
		PPC_STORE_U64(var_r31 + 16, ctx.r11.u64);
		// ld r11,40(r31)
		ctx.r11.u64 = PPC_LOAD_U64(var_r31 + 40);
		// addi r11,r11,20
		ctx.r11.s64 = ctx.r11.s64 + 20;
		// divdu r10,r11,r10
		ctx.r10.u64 = ctx.r10.u64 ? ctx.r11.u64 / ctx.r10.u64 : 0;
		// std r11,40(r31)
		PPC_STORE_U64(var_r31 + 40, ctx.r11.u64);
		// sth r10,64(r31)
		PPC_STORE_U16(var_r31 + 64, ctx.r10.u16);
	}
loc_8256CF7C:
	return;
}

__attribute__((alias("__imp__xam_CF88_2hr"))) PPC_WEAK_FUNC(xam_CF88_2hr);
PPC_FUNC_IMPL(__imp__xam_CF88_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=112, savegprlr_29
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r31,0(r30)
	var_r31 = (uint32_t)(PPC_LOAD_U32(var_r30 + 0));
	// mr r5,r31
	ctx.r5.u64 = var_r31;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 8);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 12);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r11,r11,-2
	ctx.r11.s64 = ctx.r11.s64 + -2;
	// stw r10,8(r31)
	PPC_STORE_U32(var_r31 + 8, ctx.r10.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(var_r31 + 12, ctx.r11.u32);
	// lwz r3,392(r29)
	ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 392);
	// bl 0x8256c1d8
	xam_C1D8_w(ctx, base);
	// cmpwi r3,0
	// bge 0x8256cfec
	if (ctx.r3.s32 < 0) {
		// lwz r10,8(r31)
		ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 8);
		// lwz r11,12(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 12);
		// addi r10,r10,-2
		ctx.r10.s64 = ctx.r10.s64 + -2;
		// addi r11,r11,2
		ctx.r11.s64 = ctx.r11.s64 + 2;
		// stw r10,8(r31)
		PPC_STORE_U32(var_r31 + 8, ctx.r10.u32);
		// stw r11,12(r31)
		PPC_STORE_U32(var_r31 + 12, ctx.r11.u32);
		// b 0x8256d014
	} else {
	loc_8256CFEC:
		// li r10,0
		ctx.r10.s64 = 0;
		// addi r11,r29,380
		ctx.r11.s64 = (int64_t)(int32_t)var_r29 + 380;
		// stw r10,4(r30)
		PPC_STORE_U32(var_r30 + 4, ctx.r10.u32);
		// lwz r10,4(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// cmplwi r10,0
		// beq 0x8256d00c
		if (ctx.r10.u32 != 0) {
			// stw r30,4(r10)
			PPC_STORE_U32(ctx.r10.u32 + 4, var_r30);
			// b 0x8256d010
		} else {
		loc_8256D00C:
			// stw r30,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r30);
		}
	loc_8256D010:
		// stw r30,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r30);
	}
loc_8256D014:
	return;
}

__attribute__((alias("__imp__phInst_D020_w"))) PPC_WEAK_FUNC(phInst_D020_w);
PPC_FUNC_IMPL(__imp__phInst_D020_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x8256d07c
	if (var_r31 != 0) {
		// lwz r3,4(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
		// li r30,0
		var_r30 = 0;
		// cmplwi r3,0
		// beq 0x8256d060
		if (ctx.r3.u32 != 0) {
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// ori r4,r4,3
			ctx.r4.u64 = ctx.r4.u64 | 3;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r30,4(r31)
			PPC_STORE_U32(var_r31 + 4, var_r30);
		}
	loc_8256D060:
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// bl 0x8256c788
		util_C788(ctx, base);
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// stw r30,0(r31)
		PPC_STORE_U32(var_r31 + 0, var_r30);
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r4,r4,32787
		ctx.r4.u64 = ctx.r4.u64 | 32787;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_8256D07C:
	// blr
	return;
}

__attribute__((alias("__imp__xam_D098"))) PPC_WEAK_FUNC(xam_D098);
PPC_FUNC_IMPL(__imp__xam_D098) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_27
	// lis r28,-32768
	var_r28 = (uint32_t)(-2147483648);
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// ori r28,r28,16389
	var_r28 = (uint32_t)(var_r28 | 16389);
	// bl 0x8256ca18
	xam_CA18_2hr(ctx, base);
	// li r27,0
	var_r27 = 0;
	// cmpwi r3,0
	// beq 0x8256d21c
	if (ctx.r3.s32 != 0) {
		// addi r31,r30,372
		var_r31 = (uint32_t)(var_r30 + 372);
		// lwz r29,0(r31)
		var_r29 = (uint32_t)(PPC_LOAD_U32(var_r31 + 0));
		// cmplwi r29,0
		// beq 0x8256d218
		if (var_r29 != 0) {
			// lwz r10,0(r29)
			ctx.r10.u64 = PPC_LOAD_U32(var_r29 + 0);
			// ld r11,16(r30)
			ctx.r11.u64 = PPC_LOAD_U64(var_r30 + 16);
			// ld r9,24(r10)
			ctx.r9.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
			// cmpld cr6,r9,r11
			// beq cr6,0x8256d194
			if (ctx.r9.u64 != ctx.r11.u64) {
				// lwz r11,316(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 316);
				// addi r11,r11,1
				ctx.r11.s64 = ctx.r11.s64 + 1;
				// stw r11,316(r30)
				PPC_STORE_U32(var_r30 + 316, ctx.r11.u32);
				// lwz r11,352(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 352);
				// cmpwi cr6,r11,0
				// beq cr6,0x8256d210
				if (ctx.r11.s32 == 0) goto loc_8256D210;
				// addi r29,r30,364
				var_r29 = (uint32_t)(var_r30 + 364);
				// lwz r31,0(r29)
				var_r31 = (uint32_t)(PPC_LOAD_U32(var_r29 + 0));
				// cmplwi r31,0
				// beq 0x8256d250
				if (var_r31 == 0) goto loc_8256D250;
				// lwz r11,4(r29)
				ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 4);
				// cmplw cr6,r31,r11
				// bne cr6,0x8256d11c
				if (var_r31 == ctx.r11.u32) {
					// stw r27,4(r29)
					PPC_STORE_U32(var_r29 + 4, var_r27);
				}
			loc_8256D11C:
				// lwz r9,4(r31)
				ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 4);
				// addi r10,r30,340
				ctx.r10.s64 = (int64_t)(int32_t)var_r30 + 340;
				// li r11,10
				ctx.r11.s64 = 10;
				// stw r9,0(r29)
				PPC_STORE_U32(var_r29 + 0, ctx.r9.u32);
				// stw r27,4(r31)
				PPC_STORE_U32(var_r31 + 4, var_r27);
				// lwz r9,0(r31)
				ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 0);
				// lwz r9,8(r9)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
				// mtctr r11
				ctx.ctr.u64 = ctx.r11.u64;
			loc_8256D13C:
				// lbz r8,0(r10)
				ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
				// addi r10,r10,1
				ctx.r10.s64 = ctx.r10.s64 + 1;
				// stb r8,0(r9)
				PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r8.u8);
				// addi r9,r9,1
				ctx.r9.s64 = ctx.r9.s64 + 1;
				// bdnz 0x8256d13c
				--ctx.ctr.u64;
				if (ctx.ctr.u32 != 0) goto loc_8256D13C;
				// lwz r10,0(r31)
				ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 0);
				// mr r4,r31
				ctx.r4.u64 = var_r31;
				// mr r3,r30
				ctx.r3.u64 = var_r30;
				// stw r11,4(r10)
				PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r11.u32);
				// bl 0x8256cf88
				xam_CF88_2hr(ctx, base);
				// mr. r28,r3
				var_r28 = ctx.r3.u32;
				// bge 0x8256d208
				if ((int32_t)var_r28 >= 0) goto loc_8256D208;
				// lwz r11,0(r31)
				ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
				// stw r27,4(r11)
				PPC_STORE_U32(ctx.r11.u32 + 4, var_r27);
				// lwz r11,0(r29)
				ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0);
				// stw r11,4(r31)
				PPC_STORE_U32(var_r31 + 4, ctx.r11.u32);
				// lwz r11,4(r29)
				ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 4);
				// stw r31,0(r29)
				PPC_STORE_U32(var_r29 + 0, var_r31);
				// cmplwi cr6,r11,0
				// bne cr6,0x8256d230
				if (ctx.r11.u32 != 0) goto loc_8256D230;
				// stw r31,4(r29)
				PPC_STORE_U32(var_r29 + 4, var_r31);
				// b 0x8256d230
				goto loc_8256D230;
			}
		loc_8256D194:
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
			// cmplwi r11,0
			// beq 0x8256d1bc
			if (ctx.r11.u32 != 0) {
				// lwz r9,4(r31)
				ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 4);
				// cmplw cr6,r11,r9
				// bne cr6,0x8256d1b0
				if (ctx.r11.u32 == ctx.r9.u32) {
					// stw r27,4(r31)
					PPC_STORE_U32(var_r31 + 4, var_r27);
				}
			loc_8256D1B0:
				// lwz r9,4(r11)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// stw r9,0(r31)
				PPC_STORE_U32(var_r31 + 0, ctx.r9.u32);
				// stw r27,4(r11)
				PPC_STORE_U32(ctx.r11.u32 + 4, var_r27);
			}
		loc_8256D1BC:
			// addi r3,r30,340
			ctx.r3.s64 = (int64_t)(int32_t)var_r30 + 340;
			// lwz r5,12(r10)
			ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
			// lwz r4,8(r10)
			ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
			// bl 0x82434100
			memcpy(ctx, base);
			// li r11,1
			ctx.r11.s64 = 1;
			// mr r4,r29
			ctx.r4.u64 = var_r29;
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			// stw r11,352(r30)
			PPC_STORE_U32(var_r30 + 352, ctx.r11.u32);
			// bl 0x8256cf88
			xam_CF88_2hr(ctx, base);
			// mr. r28,r3
			var_r28 = ctx.r3.u32;
			// bge 0x8256d224
			if ((int32_t)var_r28 >= 0) goto loc_8256D224;
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
			// stw r11,4(r29)
			PPC_STORE_U32(var_r29 + 4, ctx.r11.u32);
			// lwz r11,4(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 4);
			// stw r29,0(r31)
			PPC_STORE_U32(var_r31 + 0, var_r29);
			// cmplwi cr6,r11,0
			// bne cr6,0x8256d230
			if (ctx.r11.u32 != 0) goto loc_8256D230;
			// stw r29,4(r31)
			PPC_STORE_U32(var_r31 + 4, var_r29);
			// b 0x8256d230
			goto loc_8256D230;
		loc_8256D208:
			// stw r27,352(r30)
			PPC_STORE_U32(var_r30 + 352, var_r27);
			// b 0x8256d230
			goto loc_8256D230;
		loc_8256D210:
			// mr r28,r27
			var_r28 = (uint32_t)(var_r27);
			// b 0x8256d230
			goto loc_8256D230;
		}
	loc_8256D218:
		// stw r27,72(r30)
		PPC_STORE_U32(var_r30 + 72, var_r27);
	}
loc_8256D21C:
	// std r27,56(r30)
	PPC_STORE_U64(var_r30 + 56, var_r27);
	// b 0x8256d230
	goto loc_8256D230;
loc_8256D224:
	// ld r11,56(r30)
	ctx.r11.u64 = PPC_LOAD_U64(var_r30 + 56);
	// addi r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 + 20;
	// std r11,56(r30)
	PPC_STORE_U64(var_r30 + 56, ctx.r11.u64);
loc_8256D230:
	// cmpwi cr6,r28,0
	// blt cr6,0x8256d250
	if ((int32_t)var_r28 >= 0) {
		// ld r10,16(r30)
		ctx.r10.u64 = PPC_LOAD_U64(var_r30 + 16);
		// lwz r11,320(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 320);
		// addi r10,r10,20
		ctx.r10.s64 = ctx.r10.s64 + 20;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// std r10,16(r30)
		PPC_STORE_U64(var_r30 + 16, ctx.r10.u64);
		// stw r11,320(r30)
		PPC_STORE_U32(var_r30 + 320, ctx.r11.u32);
	}
loc_8256D250:
	// ld r11,56(r30)
	ctx.r11.u64 = PPC_LOAD_U64(var_r30 + 56);
	// cmpdi cr6,r11,0
	// ble cr6,0x8256d264
	if (ctx.r11.s64 > 0) {
		// addi r11,r11,-20
		ctx.r11.s64 = ctx.r11.s64 + -20;
		// std r11,56(r30)
		PPC_STORE_U64(var_r30 + 56, ctx.r11.u64);
	}
loc_8256D264:
	// addi r29,r30,380
	var_r29 = (uint32_t)(var_r30 + 380);
	// b 0x8256d304
	goto loc_8256D304;
	do {
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r11,0(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmpwi cr6,r11,259
		// beq cr6,0x8256d310
		// lwz r11,0(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0);
		// cmplwi r11,0
		// beq 0x8256d2a4
		if (ctx.r11.u32 != 0) {
			// lwz r10,4(r29)
			ctx.r10.u64 = PPC_LOAD_U32(var_r29 + 4);
			// cmplw cr6,r11,r10
			// bne cr6,0x8256d298
			if (ctx.r11.u32 == ctx.r10.u32) {
				// stw r27,4(r29)
				PPC_STORE_U32(var_r29 + 4, var_r27);
			}
		loc_8256D298:
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// stw r10,0(r29)
			PPC_STORE_U32(var_r29 + 0, ctx.r10.u32);
			// stw r27,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r27);
		}
	loc_8256D2A4:
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// li r4,0
		ctx.r4.s64 = 0;
		// lwz r10,8(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// addi r10,r10,-2
		ctx.r10.s64 = ctx.r10.s64 + -2;
		// stw r10,8(r11)
		PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r10,12(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// addi r10,r10,2
		ctx.r10.s64 = ctx.r10.s64 + 2;
		// stw r10,12(r11)
		PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// stw r27,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r27);
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r5,12(r11)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// lwz r3,8(r11)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// bl 0x82566898
		util_6898(ctx, base);
		// addi r11,r30,364
		ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 364;
		// stw r27,4(r31)
		PPC_STORE_U32(var_r31 + 4, var_r27);
		// lwz r10,4(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// cmplwi r10,0
		// beq 0x8256d2fc
		if (ctx.r10.u32 != 0) {
			// stw r31,4(r10)
			PPC_STORE_U32(ctx.r10.u32 + 4, var_r31);
			// b 0x8256d300
		} else {
		loc_8256D2FC:
			// stw r31,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
		}
	loc_8256D300:
		// stw r31,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r31);
		// lwz r31,0(r29)
		var_r31 = (uint32_t)(PPC_LOAD_U32(var_r29 + 0));
		// cmplwi r31,0
		// bne 0x8256d26c
	} while (var_r31 != 0);
loc_8256D310:
	// li r3,0
	ctx.r3.s64 = 0;
	return;
}

__attribute__((alias("__imp__xam_D320_w"))) PPC_WEAK_FUNC(xam_D320_w);
PPC_FUNC_IMPL(__imp__xam_D320_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=160, savegprlr_24
	// mr r26,r4
	var_r26 = ctx.r4.u32;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r24,0
	var_r24 = 0;
	// mr r25,r5
	var_r25 = ctx.r5.u32;
	// mr r28,r24
	var_r28 = (uint32_t)(var_r24);
	// lhz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U16(var_r26 + 0);
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 72);
	// rlwinm r9,r11,20,12,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 20) & 0xFFFFF;
	// clrlwi r27,r11,20
	var_r27 = (uint32_t)(ctx.r11.u32 & 0xFFF);
	// clrlwi r30,r9,28
	var_r30 = (uint32_t)(ctx.r9.u32 & 0xF);
	// cmpwi cr6,r10,0
	// bne cr6,0x8256d3c0
	if (ctx.r10.s32 == 0) {
		// lwz r11,336(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 336);
		// cmpwi cr6,r11,0
		// beq cr6,0x8256d3a0
		if (ctx.r11.s32 != 0) {
			// lis r11,0
			ctx.r11.s64 = 0;
			// mftb r10
			ctx.r10.u64 = PPC_QUERY_TIMEBASE();
			// ori r8,r11,50000
			ctx.r8.u64 = ctx.r11.u64 | 50000;
			// lis r11,-32161
			// divdu r10,r10,r8
			ctx.r10.u64 = ctx.r8.u64 ? ctx.r10.u64 / ctx.r8.u64 : 0;
			// addi r11,r11,-22416
			ctx.r11.s64 = ctx.r11.s64 + -22416;
			// ld r9,0(r11)
			ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
			// cmpldi cr6,r9,0
			// bne cr6,0x8256d398
			if (ctx.r9.u64 == 0) {
				// li r9,20
				ctx.r9.s64 = 20;
				// std r10,0(r11)
				PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
				// std r9,8(r11)
				PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r9.u64);
			}
		loc_8256D398:
			// std r10,24(r31)
			PPC_STORE_U64(var_r31 + 24, ctx.r10.u64);
			// b 0x8256d3ac
		} else {
		loc_8256D3A0:
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bl 0x8256c9c0
			xam_C9C0_w(ctx, base);
			// std r3,24(r31)
			PPC_STORE_U64(var_r31 + 24, ctx.r3.u64);
		}
	loc_8256D3AC:
		// li r11,1
		ctx.r11.s64 = 1;
		// std r24,16(r31)
		PPC_STORE_U64(var_r31 + 16, var_r24);
		// stb r30,308(r31)
		PPC_STORE_U8(var_r31 + 308, (uint8_t)var_r30);
		// sth r27,32(r31)
		PPC_STORE_U16(var_r31 + 32, (uint16_t)var_r27);
		// stw r11,72(r31)
		PPC_STORE_U32(var_r31 + 72, ctx.r11.u32);
	}
loc_8256D3C0:
	// lbz r11,308(r31)
	ctx.r11.u64 = PPC_LOAD_U8(var_r31 + 308);
	// clrlwi r29,r30,24
	var_r29 = (uint32_t)(var_r30 & 0xFF);
	// cmplw cr6,r29,r11
	// beq cr6,0x8256d3dc
	if (var_r29 != ctx.r11.u32) {
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8256cd50
		xam_CD50_w(ctx, base);
		// stb r30,308(r31)
		PPC_STORE_U8(var_r31 + 308, (uint8_t)var_r30);
	}
loc_8256D3DC:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r27
	ctx.r4.u64 = var_r27;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256ca88
	xam_CA88_wrh(ctx, base);
	// lwz r11,304(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 304);
	// cmplwi cr6,r3,1
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,304(r31)
	PPC_STORE_U32(var_r31 + 304, ctx.r11.u32);
	// blt cr6,0x8256d42c
	if (ctx.r3.u32 >= 1) {
		// beq cr6,0x8256d4ac
		if (ctx.cr6.eq) goto loc_8256D4AC;
		// cmplwi cr6,r3,3
		// bge cr6,0x8256d4e4
		if (ctx.r3.u32 >= 3) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// lwz r11,360(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 360);
		// lwz r10,356(r31)
		ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 356);
		// cmplw cr6,r11,r10
		// bge cr6,0x8256d4e0
		if (ctx.r11.u32 >= ctx.r10.u32) goto loc_8256D4E0;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8256cc80
		xam_CC80_wrh(ctx, base);
		// addi r5,r1,80
		ctx.r5.s64 = ctx.r1.s64 + 80;
		// bl 0x8256ca88
		xam_CA88_wrh(ctx, base);
	}
loc_8256D42C:
	// addi r29,r31,364
	var_r29 = (uint32_t)(var_r31 + 364);
	// lwz r30,0(r29)
	var_r30 = (uint32_t)(PPC_LOAD_U32(var_r29 + 0));
	// cmplwi r30,0
	// beq 0x8256d4e0
	if (var_r30 != 0) {
		// lwz r11,4(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 4);
		// cmplw cr6,r30,r11
		// bne cr6,0x8256d44c
		if (var_r30 == ctx.r11.u32) {
			// stw r24,4(r29)
			PPC_STORE_U32(var_r29 + 4, var_r24);
		}
	loc_8256D44C:
		// lwz r11,4(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
		// mr r5,r25
		ctx.r5.u64 = var_r25;
		// ld r10,80(r1)
		ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
		// mr r4,r26
		ctx.r4.u64 = var_r26;
		// stw r11,0(r29)
		PPC_STORE_U32(var_r29 + 0, ctx.r11.u32);
		// stw r24,4(r30)
		PPC_STORE_U32(var_r30 + 4, var_r24);
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// std r10,24(r11)
		PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r10.u64);
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// lwz r3,8(r11)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// bl 0x82434100
		memcpy(ctx, base);
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// stw r25,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r25);
		// bl 0x8256cbb0
		xam_CBB0_wrh(ctx, base);
		// mr. r28,r3
		var_r28 = ctx.r3.u32;
		// bge 0x8256d4e4
		if ((int32_t)var_r28 >= 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// stw r24,4(r30)
		PPC_STORE_U32(var_r30 + 4, var_r24);
		// lwz r11,4(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 4);
		// cmplwi r11,0
		// beq 0x8256d4cc
		if (ctx.r11.u32 != 0) {
			// stw r30,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r30);
			// b 0x8256d4d0
			goto loc_8256D4D0;
		loc_8256D4AC:
			// lbz r11,308(r31)
			ctx.r11.u64 = PPC_LOAD_U8(var_r31 + 308);
			// li r28,1
			var_r28 = 1;
			// cmplw cr6,r29,r11
			// bne cr6,0x8256d4e4
			if (var_r29 != ctx.r11.u32) {
				// mr r3,r28
				ctx.r3.u64 = var_r28;
				return;
			}
			// lwz r11,312(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 312);
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// stw r11,312(r31)
			PPC_STORE_U32(var_r31 + 312, ctx.r11.u32);
			// b 0x8256d4e4
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
	loc_8256D4CC:
		// stw r30,0(r29)
		PPC_STORE_U32(var_r29 + 0, var_r30);
	loc_8256D4D0:
		// stw r30,4(r29)
		PPC_STORE_U32(var_r29 + 4, var_r30);
		// lwz r11,304(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 304);
		// addi r11,r11,-1
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// stw r11,304(r31)
		PPC_STORE_U32(var_r31 + 304, ctx.r11.u32);
	}
loc_8256D4E0:
	// li r28,1
	var_r28 = 1;
loc_8256D4E4:
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	return;
}

__attribute__((alias("__imp__phInst_D4F0_wrh"))) PPC_WEAK_FUNC(phInst_D4F0_wrh);
PPC_FUNC_IMPL(__imp__phInst_D4F0_wrh) {
	PPC_FUNC_PROLOGUE();
	// ld r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 40);
	// li r9,20
	ctx.r9.s64 = 20;
	// addi r8,r3,372
	ctx.r8.s64 = ctx.r3.s64 + 372;
	// divdu r10,r10,r9
	ctx.r10.u64 = ctx.r9.u64 ? ctx.r10.u64 / ctx.r9.u64 : 0;
	// li r11,0
	ctx.r11.s64 = 0;
	// sth r10,64(r3)
	PPC_STORE_U16(ctx.r3.u32 + 64, ctx.r10.u16);
	// lwz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r11.u64);
	// std r11,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, ctx.r11.u64);
	// cmplwi r10,0
	// stw r11,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, ctx.r11.u32);
	// std r11,296(r3)
	PPC_STORE_U64(ctx.r3.u32 + 296, ctx.r11.u64);
	// stw r11,304(r3)
	PPC_STORE_U32(ctx.r3.u32 + 304, ctx.r11.u32);
	// stb r11,308(r3)
	PPC_STORE_U8(ctx.r3.u32 + 308, ctx.r11.u8);
	// stw r11,312(r3)
	PPC_STORE_U32(ctx.r3.u32 + 312, ctx.r11.u32);
	// beq 0x8256d588
	if (ctx.r10.u32 != 0) {
		// addi r7,r3,364
		ctx.r7.s64 = ctx.r3.s64 + 364;
	loc_8256D534:
		// lwz r9,0(r8)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		// cmplwi r9,0
		// beq 0x8256d55c
		if (ctx.r9.u32 != 0) {
			// lwz r6,4(r8)
			ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
			// cmplw cr6,r9,r6
			// bne cr6,0x8256d550
			if (ctx.r9.u32 == ctx.r6.u32) {
				// stw r11,4(r8)
				PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r11.u32);
			}
		loc_8256D550:
			// lwz r6,4(r9)
			ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
			// stw r6,0(r8)
			PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r6.u32);
			// stw r11,4(r9)
			PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r11.u32);
		}
	loc_8256D55C:
		// stw r11,4(r10)
		PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r11.u32);
		// lwz r9,4(r7)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
		// cmplwi r9,0
		// beq 0x8256d574
		if (ctx.r9.u32 != 0) {
			// stw r10,4(r9)
			PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r10.u32);
			// b 0x8256d578
		} else {
		loc_8256D574:
			// stw r10,0(r7)
			PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
		}
	loc_8256D578:
		// stw r10,4(r7)
		PPC_STORE_U32(ctx.r7.u32 + 4, ctx.r10.u32);
		// lwz r10,0(r8)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		// cmplwi r10,0
		// bne 0x8256d534
		if (ctx.r10.u32 != 0) goto loc_8256D534;
	}
loc_8256D588:
	// addi r10,r3,80
	ctx.r10.s64 = ctx.r3.s64 + 80;
	// li r11,25
	ctx.r11.s64 = 25;
loc_8256D590:
	// ld r9,280(r3)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 280);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bne 0x8256d590
	if (ctx.r11.s32 != 0) goto loc_8256D590;
	// blr
	return;
}

__attribute__((alias("__imp__rage_D5A8"))) PPC_WEAK_FUNC(rage_D5A8);
PPC_FUNC_IMPL(__imp__rage_D5A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=112, savegprlr_29
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// ori r4,r4,32787
	ctx.r4.u64 = ctx.r4.u64 | 32787;
	// li r3,400
	ctx.r3.s64 = 400;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256d5e0
	if ((int32_t)var_r31 == 0) {
	loc_8256D5D4:
		// lis r30,-32761
		var_r30 = (uint32_t)(-2147024896);
		// ori r30,r30,14
		var_r30 = (uint32_t)(var_r30 | 14);
		// b 0x8256d744
		goto loc_8256D744;
	}
loc_8256D5E0:
	// lis r11,-32254
	// stw r30,392(r31)
	PPC_STORE_U32(var_r31 + 392, var_r30);
	// li r10,28
	ctx.r10.s64 = 28;
	// li r9,12
	ctx.r9.s64 = 12;
	// li r8,4
	ctx.r8.s64 = 4;
	// li r7,10
	ctx.r7.s64 = 10;
	// lfd f0,10192(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 10192);
	// lis r11,-32254
	// li r6,1
	ctx.r6.s64 = 1;
	// stfd f0,280(r31)
	PPC_STORE_U64(var_r31 + 280, ctx.f0.u64);
	// addi r3,r31,328
	ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 328;
	// sth r9,64(r31)
	PPC_STORE_U16(var_r31 + 64, ctx.r9.u16);
	// sth r8,68(r31)
	PPC_STORE_U16(var_r31 + 68, ctx.r8.u16);
	// sth r10,66(r31)
	PPC_STORE_U16(var_r31 + 66, ctx.r10.u16);
	// lfd f13,10184(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 10184);
	// li r11,240
	ctx.r11.s64 = 240;
	// stfd f13,288(r31)
	PPC_STORE_U64(var_r31 + 288, ctx.f13.u64);
	// stw r7,360(r31)
	PPC_STORE_U32(var_r31 + 360, ctx.r7.u32);
	// stw r6,336(r31)
	PPC_STORE_U32(var_r31 + 336, ctx.r6.u32);
	// stw r10,8(r31)
	PPC_STORE_U32(var_r31 + 8, ctx.r10.u32);
	// std r11,48(r31)
	PPC_STORE_U64(var_r31 + 48, ctx.r11.u64);
	// std r11,40(r31)
	PPC_STORE_U64(var_r31 + 40, ctx.r11.u64);
	// bl 0x82568800
	rage_8800(ctx, base);
	// cmpwi r3,0
	// bne 0x8256d664
	if (ctx.r3.s32 == 0) {
		// bl 0x8242c3b0
		thunk_fn_8242C368(ctx, base);
		// cmpwi r3,0
		// bgt 0x8256d658
		if (ctx.r3.s32 <= 0) {
			// mr r30,r3
			var_r30 = ctx.r3.u32;
			// b 0x8256d73c
			goto loc_8256D73C;
		}
	loc_8256D658:
		// clrlwi r11,r3,16
		ctx.r11.u64 = ctx.r3.u32 & 0xFFFF;
		// oris r30,r11,32775
		var_r30 = (uint32_t)(ctx.r11.u64 | 2147942400);
		// b 0x8256d73c
		goto loc_8256D73C;
	}
loc_8256D664:
	// addi r10,r31,80
	ctx.r10.s64 = (int64_t)(int32_t)var_r31 + 80;
	// li r11,25
	ctx.r11.s64 = 25;
loc_8256D66C:
	// lfd f0,280(r31)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(var_r31 + 280);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stfd f0,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.f0.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bne 0x8256d66c
	if (ctx.r11.s32 != 0) goto loc_8256D66C;
	// lwz r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 24);
	// mr r7,r31
	ctx.r7.u64 = var_r31;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(var_r31 + 8);
	// li r4,32
	ctx.r4.s64 = 32;
	// lwz r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// bl 0x8256c8d0
	rage_C8D0(ctx, base);
	// mr. r30,r3
	var_r30 = ctx.r3.u32;
	// blt 0x8256d744
	if ((int32_t)var_r30 < 0) goto loc_8256D744;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// ori r4,r4,3
	ctx.r4.u64 = ctx.r4.u64 | 3;
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// cmplwi r3,0
	// stw r3,4(r31)
	PPC_STORE_U32(var_r31 + 4,/* rage_GameObject::flags@+0x4 */ ctx.r3.u32);
	// beq 0x8256d5d4
	if (ctx.r3.u32 == 0) goto loc_8256D5D4;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r11,0
	// ble cr6,0x8256d73c
	if (ctx.r11.u32 > 0) {
		// addi r7,r31,364
		ctx.r7.s64 = (int64_t)(int32_t)var_r31 + 364;
		// li r10,0
		ctx.r10.s64 = 0;
	loc_8256D6E0:
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0)/* rage_GameObject::vtable@+0x0 */;
		// lwz r6,4(r31)
		ctx.r6.u64 = PPC_LOAD_U32(var_r31 + 4)/* rage_GameObject::flags@+0x4 */;
		// lwz r5,8(r11)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// lwz r9,4(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// mullw r11,r5,r8
		ctx.r11.s64 = int64_t(ctx.r5.s32) * int64_t(ctx.r8.s32);
		// add r11,r11,r9
		ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
		// li r9,0
		ctx.r9.s64 = 0;
		// stwx r11,r10,r6
		PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, ctx.r11.u32);
		// lwz r11,4(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 4)/* rage_GameObject::flags@+0x4 */;
		// add r11,r10,r11
		ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
		// stw r9,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
		// lwz r9,4(r7)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
		// cmplwi r9,0
		// beq 0x8256d720
		if (ctx.r9.u32 != 0) {
			// stw r11,4(r9)
			PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r11.u32);
			// b 0x8256d724
		} else {
		loc_8256D720:
			// stw r11,0(r7)
			PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r11.u32);
		}
	loc_8256D724:
		// stw r11,4(r7)
		PPC_STORE_U32(ctx.r7.u32 + 4, ctx.r11.u32);
		// addi r8,r8,1
		ctx.r8.s64 = ctx.r8.s64 + 1;
		// lwz r11,8(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
		// addi r10,r10,8
		ctx.r10.s64 = ctx.r10.s64 + 8;
		// cmplw cr6,r8,r11
		// blt cr6,0x8256d6e0
		if (ctx.r8.u32 < ctx.r11.u32) goto loc_8256D6E0;
	}
loc_8256D73C:
	// cmpwi cr6,r30,0
	// bge cr6,0x8256d750
	if ((int32_t)var_r30 < 0) {
	loc_8256D744:
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8256d020
		phInst_D020_w(ctx, base);
		// li r31,0
		var_r31 = 0;
	}
loc_8256D750:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// stw r31,0(r29)
	PPC_STORE_U32(var_r29 + 0,/* rage_GameObject::vtable@+0x0 */ var_r31);
	return;
}

__attribute__((alias("__imp__xam_D760_sp"))) PPC_WEAK_FUNC(xam_D760_sp);
PPC_FUNC_IMPL(__imp__xam_D760_sp) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	// beq cr6,0x8256d770
	if (ctx.r4.u32 != 0) {
		// li r11,6172
		ctx.r11.s64 = 6172;
		// stw r11,0(r4)
		PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	}
loc_8256D770:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__xam_D778_2h"))) PPC_WEAK_FUNC(xam_D778_2h);
PPC_FUNC_IMPL(__imp__xam_D778_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
loc_8256D77C:
	// mfmsr r9
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
	// mtmsrd r13,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_ENTER_GLOBAL_LOCK();
	// lwarx r10,0,r11
	ea = ctx.r11.u32;
	ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r11
	ea = ctx.r11.u32;
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_LEAVE_GLOBAL_LOCK();
	// bne 0x8256d77c
	if (!ctx.cr0.eq) goto loc_8256D77C;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// blr
	return;
}

__attribute__((alias("__imp__xam_D7A0_sp"))) PPC_WEAK_FUNC(xam_D7A0_sp);
PPC_FUNC_IMPL(__imp__xam_D7A0_sp) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
loc_8256D7A4:
	// mfmsr r9
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
	// mtmsrd r13,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_ENTER_GLOBAL_LOCK();
	// lwarx r10,0,r11
	ea = ctx.r11.u32;
	ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r11
	ea = ctx.r11.u32;
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_LEAVE_GLOBAL_LOCK();
	// bne 0x8256d7a4
	if (!ctx.cr0.eq) goto loc_8256D7A4;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// blr
	return;
}

__attribute__((alias("__imp__xam_D7C8_sp"))) PPC_WEAK_FUNC(xam_D7C8_sp);
PPC_FUNC_IMPL(__imp__xam_D7C8_sp) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	// beq cr6,0x8256d7e4
	if (ctx.r4.u32 != 0) {
		// li r11,0
		ctx.r11.s64 = 0;
		// li r10,1
		ctx.r10.s64 = 1;
		// sth r11,2(r4)
		PPC_STORE_U16(ctx.r4.u32 + 2, ctx.r11.u16);
		// stb r10,0(r4)
		PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r10.u8);
		// stb r11,4(r4)
		PPC_STORE_U8(ctx.r4.u32 + 4, ctx.r11.u8);
	}
loc_8256D7E4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__xam_D7F0_sp"))) PPC_WEAK_FUNC(xam_D7F0_sp);
PPC_FUNC_IMPL(__imp__xam_D7F0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32761
	// clrlwi. r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// ori r11,r11,87
	ctx.r11.u64 = ctx.r11.u64 | 87;
	// bne 0x8256d80c
	if (ctx.r10.s32 == 0) {
		// lwz r10,0(r6)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		// li r11,0
		ctx.r11.s64 = 0;
		// stw r10,8(r3)
		PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	}
loc_8256D80C:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr
	return;
}

__attribute__((alias("__imp__xam_D818_sp"))) PPC_WEAK_FUNC(xam_D818_sp);
PPC_FUNC_IMPL(__imp__xam_D818_sp) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r4,0
	// beq cr6,0x8256d828
	if (ctx.r4.u32 != 0) {
		// lwz r11,8(r3)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
		// stw r11,0(r4)
		PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r11.u32);
	}
loc_8256D828:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__xam_D830_sp"))) PPC_WEAK_FUNC(xam_D830_sp);
PPC_FUNC_IMPL(__imp__xam_D830_sp) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// li r30,0
	var_r30 = 0;
	// li r4,6172
	ctx.r4.s64 = 6172;
	// lwz r11,20(r11)
	// bctrl
	VCALL(ctx.r3.u32, 5, ctx, base);  // vtable slot 5 (byte +20)
	// mr. r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// bne 0x8256d884
	if (ctx.r11.s32 == 0) {
		// lis r30,-32761
		var_r30 = (uint32_t)(-2147024896);
		// li r11,0
		ctx.r11.s64 = 0;
		// ori r30,r30,14
		var_r30 = (uint32_t)(var_r30 | 14);
	loc_8256D874:
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// stw r11,0(r29)
		PPC_STORE_U32(var_r29 + 0, ctx.r11.u32);
		return;
	}
loc_8256D884:
	// lis r10,-32164
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r10,r10,9808
	ctx.r10.s64 = ctx.r10.s64 + 9808;
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 4);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// b 0x8256d874
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// stw r11,0(r29)
	PPC_STORE_U32(var_r29 + 0, ctx.r11.u32);
	return;
}

__attribute__((alias("__imp__KfAcquireSpinLock_D8A8_w"))) PPC_WEAK_FUNC(KfAcquireSpinLock_D8A8_w);
PPC_FUNC_IMPL(__imp__KfAcquireSpinLock_D8A8_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r25 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=176, savegprlr_25
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// li r26,0
	var_r26 = 0;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(var_r30 + 8);
	// cmplwi cr6,r10,0
	// beq cr6,0x8256da04
	if (ctx.r10.u32 != 0) {
		// addi r4,r1,88
		ctx.r4.s64 = ctx.r1.s64 + 88;
		// mr r3,r11
		ctx.r3.u64 = ctx.r11.u64;
		// bl 0x82465da8
		util_5DA8(ctx, base);
		// cmpwi r3,0
		// blt 0x8256da04
		if (ctx.r3.s32 < 0) {
			return;
		}
		// lis r11,-32248
		// mr r28,r26
		var_r28 = (uint32_t)(var_r26);
		// mr r29,r26
		var_r29 = (uint32_t)(var_r26);
		// addi r31,r30,6156
		var_r31 = (uint32_t)(var_r30 + 6156);
		// addi r27,r30,24
		var_r27 = (uint32_t)(var_r30 + 24);
		// lfs f31,-23892(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -23892);
		var_f31 = double(temp.f32);
		// subfic r25,r30,-5044
		ctx.xer.ca = var_r30 <= 4294962252;
		var_r25 = (uint32_t)(-5044 - (int64_t)(int32_t)var_r30);
	loc_8256D904:
		// lwz r11,8(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 8);
		// add r10,r25,r31
		ctx.r10.u64 = var_r25 + var_r31;
		// lwzx r3,r10,r11
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
		// cmplwi r3,0
		// beq 0x8256d9e4
		if (ctx.r3.u32 != 0) {
			// lwz r11,196(r3)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 196);
			// rlwinm r11,r11,0,29,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
			// cmplwi cr6,r11,4
			// bne cr6,0x8256d9e4
			if (ctx.r11.u32 != 4) goto loc_8256D9E4;
			// lwz r10,0(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 0);
			// lfs f0,184(r3)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 184);
			ctx.f0.f64 = double(temp.f32);
			// lwz r11,96(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
			// li r9,256
			ctx.r9.s64 = 256;
			// add r10,r10,r28
			ctx.r10.u64 = ctx.r10.u64 + var_r28;
			// add r11,r29,r11
			ctx.r11.u64 = var_r29 + ctx.r11.u64;
			// rlwinm r10,r10,9,0,22
			ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 9) & 0xFFFFFE00;
			// add r10,r10,r30
			ctx.r10.u64 = ctx.r10.u64 + var_r30;
			// addi r10,r10,12
			ctx.r10.s64 = ctx.r10.s64 + 12;
		loc_8256D94C:
			// lfs f13,0(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			ctx.f13.f64 = double(temp.f32);
			// addi r8,r1,80
			ctx.r8.s64 = ctx.r1.s64 + 80;
			// fmuls f13,f13,f0
			ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
			// fmuls f13,f13,f31
			ctx.f13.f64 = double(float(ctx.f13.f64 * var_f31));
			// fctiwz f13,f13
			ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
			// stfiwx f13,0,r8
			PPC_STORE_U32(ctx.r8.u32, ctx.f13.u32);
			// lwz r8,80(r1)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
			// cmpwi cr6,r8,32767
			// blt cr6,0x8256d978
			if (ctx.r8.s32 >= 32767) {
				// li r8,32767
				ctx.r8.s64 = 32767;
				// b 0x8256d984
			} else {
			loc_8256D978:
				// cmpwi cr6,r8,-32768
				// bgt cr6,0x8256d984
				if (ctx.r8.s32 > -32768) goto loc_8256D984;
				// li r8,-32738
			}
		loc_8256D984:
			// sth r8,0(r10)
			PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r8.u16);
			// addic. r9,r9,-1
			ctx.xer.ca = ctx.r9.u32 > 0;
			ctx.r9.s64 = ctx.r9.s64 + -1;
			// addi r10,r10,2
			ctx.r10.s64 = ctx.r10.s64 + 2;
			// addi r11,r11,4
			ctx.r11.s64 = ctx.r11.s64 + 4;
			// bne 0x8256d94c
			if (ctx.r9.s32 != 0) goto loc_8256D94C;
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// cmplwi cr6,r11,3
			// stw r11,0(r31)
			PPC_STORE_U32(var_r31 + 0, ctx.r11.u32);
			// blt cr6,0x8256d9e8
			if (ctx.r11.u32 < 3) goto loc_8256D9E8;
			// addi r4,r27,-12
			ctx.r4.s64 = (int64_t)(int32_t)var_r27 + -12;
			// stw r26,0(r31)
			PPC_STORE_U32(var_r31 + 0, var_r26);
			// addi r9,r27,-10
			ctx.r9.s64 = (int64_t)(int32_t)var_r27 + -10;
			// mr r10,r27
			ctx.r10.u64 = var_r27;
			// li r11,127
			ctx.r11.s64 = 127;
		loc_8256D9C0:
			// lhz r8,0(r10)
			ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
			// addic. r11,r11,-1
			ctx.xer.ca = ctx.r11.u32 > 0;
			ctx.r11.s64 = ctx.r11.s64 + -1;
			// addi r10,r10,12
			ctx.r10.s64 = ctx.r10.s64 + 12;
			// sth r8,0(r9)
			PPC_STORE_U16(ctx.r9.u32 + 0, ctx.r8.u16);
			// addi r9,r9,2
			ctx.r9.s64 = ctx.r9.s64 + 2;
			// bne 0x8256d9c0
			if (ctx.r11.s32 != 0) goto loc_8256D9C0;
			// li r5,256
			ctx.r5.s64 = 256;
			// bl 0x8256ffc0
			KfAcquireSpinLock_FFC0_w(ctx, base);
			// b 0x8256d9e8
		} else {
		loc_8256D9E4:
			// stw r26,0(r31)
			PPC_STORE_U32(var_r31 + 0, var_r26);
		}
	loc_8256D9E8:
		// addi r29,r29,1024
		var_r29 = (uint32_t)(var_r29 + 1024);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// addi r28,r28,3
		var_r28 = (uint32_t)(var_r28 + 3);
		// addi r27,r27,1536
		var_r27 = (uint32_t)(var_r27 + 1536);
		// cmplwi cr6,r29,4096
		// blt cr6,0x8256d904
		if (var_r29 < 4096) goto loc_8256D904;
		// mr r3,r26
		ctx.r3.u64 = var_r26;
	}
loc_8256DA04:
	return;
}

__attribute__((alias("__imp__msgMsgSink_DA10_p46"))) PPC_WEAK_FUNC(msgMsgSink_DA10_p46);
PPC_FUNC_IMPL(__imp__msgMsgSink_DA10_p46) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* msgMsgSink::vtable@+0x0 */;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,1092(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1092, ctx.r10.u32);
	// blr
	return;
}

__attribute__((alias("__imp__game_DA20"))) PPC_WEAK_FUNC(game_DA20);
PPC_FUNC_IMPL(__imp__game_DA20) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// FRAME: size=352, savegprlr_26
	// li r31,0
	var_r31 = 0;
	// addi r11,r1,116
	ctx.r11.s64 = ctx.r1.s64 + 116;
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// mr r26,r4
	var_r26 = ctx.r4.u32;
	// li r5,8
	ctx.r5.s64 = 8;
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, var_r31);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
	// bl 0x82566898
	util_6898(ctx, base);
	// li r11,127
	ctx.r11.s64 = 127;
	// li r5,8
	ctx.r5.s64 = 8;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, var_r28);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// stb r11,120(r1)
	PPC_STORE_U8(ctx.r1.u32 + 120, ctx.r11.u8);
	// bl 0x82566898
	util_6898(ctx, base);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// stb r31,104(r1)
	PPC_STORE_U8(ctx.r1.u32 + 104, (uint8_t)var_r31);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// bl 0x82566898
	util_6898(ctx, base);
	// lis r9,-32256
	// mr r10,r31
	ctx.r10.u64 = var_r31;
	// addi r11,r1,161
	ctx.r11.s64 = ctx.r1.s64 + 161;
	// li r27,2
	var_r27 = 2;
	// lfs f0,15784(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15784);
	ctx.f0.f64 = double(temp.f32);
loc_8256DAA0:
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// stfs f0,3(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 3, temp.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stb r27,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, (uint8_t)var_r27);
	// cmplwi cr6,r10,4
	// stb r9,-1(r11)
	PPC_STORE_U8(ctx.r11.u32 + -1, ctx.r9.u8);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// blt cr6,0x8256daa0
	if (ctx.r10.u32 < 4) goto loc_8256DAA0;
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82566898
	util_6898(ctx, base);
	// addi r11,r1,160
	ctx.r11.s64 = ctx.r1.s64 + 160;
	// li r29,4
	var_r29 = 4;
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// stb r29,96(r1)
	PPC_STORE_U8(ctx.r1.u32 + 96, (uint8_t)var_r29);
	// bl 0x82566898
	util_6898(ctx, base);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, var_r31);
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82566898
	util_6898(ctx, base);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// li r30,1
	var_r30 = 1;
	// li r5,28
	ctx.r5.s64 = 28;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stb r30,88(r1)
	PPC_STORE_U8(ctx.r1.u32 + 88, (uint8_t)var_r30);
	// bl 0x82566898
	util_6898(ctx, base);
	// lis r10,0
	ctx.r10.s64 = 0;
	// lwz r11,44(r26)
	ctx.r11.u64 = PPC_LOAD_U32(var_r26 + 44);
	// stb r31,128(r1)
	PPC_STORE_U8(ctx.r1.u32 + 128, (uint8_t)var_r31);
	// ori r26,r10,48000
	var_r26 = (uint32_t)(ctx.r10.u64 | 48000);
	// stb r29,129(r1)
	PPC_STORE_U8(ctx.r1.u32 + 129, (uint8_t)var_r29);
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// stb r30,136(r1)
	PPC_STORE_U8(ctx.r1.u32 + 136, (uint8_t)var_r30);
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, (uint8_t)var_r29);
	// cmplwi r11,0
	// stb r27,138(r1)
	PPC_STORE_U8(ctx.r1.u32 + 138, (uint8_t)var_r27);
	// stw r31,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, var_r31);
	// stw r26,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, var_r26);
	// stw r10,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r10.u32);
	// addi r10,r1,88
	ctx.r10.s64 = ctx.r1.s64 + 88;
	// stw r28,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, var_r28);
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
	// beq 0x8256dbb0
	if (ctx.r11.u32 != 0) {
		// lbz r10,0(r11)
		ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
		// mr r9,r31
		ctx.r9.u64 = var_r31;
		// cmplwi r10,0
		// beq 0x8256dba8
		if (ctx.r10.u32 != 0) {
			// mr r10,r31
			ctx.r10.u64 = var_r31;
		loc_8256DB84:
			// lwz r8,4(r11)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// addi r7,r1,112
			ctx.r7.s64 = ctx.r1.s64 + 112;
			// addi r9,r9,1
			ctx.r9.s64 = ctx.r9.s64 + 1;
			// lwzx r8,r8,r10
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
			// stwx r8,r10,r7
			PPC_STORE_U32(ctx.r10.u32 + ctx.r7.u32, ctx.r8.u32);
			// addi r10,r10,4
			ctx.r10.s64 = ctx.r10.s64 + 4;
			// lbz r8,0(r11)
			ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
			// cmplw cr6,r9,r8
			// blt cr6,0x8256db84
			if (ctx.r9.u32 < ctx.r8.u32) goto loc_8256DB84;
		}
	loc_8256DBA8:
		// lbz r11,0(r11)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
		// b 0x8256dbb4
	} else {
	loc_8256DBB0:
		// lbz r11,104(r1)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 104);
	}
loc_8256DBB4:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,120
	ctx.r9.s64 = ctx.r1.s64 + 120;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r27,r28,56
	var_r27 = (uint32_t)(var_r28 + 56);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// mr r4,r27
	ctx.r4.u64 = var_r27;
	// stwx r9,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r9.u32);
	// stb r11,104(r1)
	PPC_STORE_U8(ctx.r1.u32 + 104, ctx.r11.u8);
	// bl 0x824612d8
	game_12D8(ctx, base);
	// cmpwi r3,0
	// blt 0x8256dcd0
	if (ctx.r3.s32 >= 0) {
		// li r5,32
		ctx.r5.s64 = 32;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,160
		ctx.r3.s64 = ctx.r1.s64 + 160;
		// bl 0x82566898
		util_6898(ctx, base);
		// lis r9,-32256
		// mr r10,r31
		ctx.r10.u64 = var_r31;
		// addi r11,r1,161
		ctx.r11.s64 = ctx.r1.s64 + 161;
		// lfs f0,15788(r9)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15788);
		ctx.f0.f64 = double(temp.f32);
	loc_8256DC08:
		// clrlwi r9,r10,24
		ctx.r9.u64 = ctx.r10.u32 & 0xFF;
		// stfs f0,3(r11)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 3, temp.u32);
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// cmplwi cr6,r10,4
		// stb r9,-1(r11)
		PPC_STORE_U8(ctx.r11.u32 + -1, ctx.r9.u8);
		// stb r9,0(r11)
		PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
		// addi r11,r11,8
		ctx.r11.s64 = ctx.r11.s64 + 8;
		// blt cr6,0x8256dc08
		if (ctx.r10.u32 < 4) goto loc_8256DC08;
		// li r5,8
		ctx.r5.s64 = 8;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,96
		ctx.r3.s64 = ctx.r1.s64 + 96;
		// bl 0x82566898
		util_6898(ctx, base);
		// addi r11,r1,160
		ctx.r11.s64 = ctx.r1.s64 + 160;
		// li r5,8
		ctx.r5.s64 = 8;
		// stb r29,96(r1)
		PPC_STORE_U8(ctx.r1.u32 + 96, (uint8_t)var_r29);
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,80
		ctx.r3.s64 = ctx.r1.s64 + 80;
		// stw r11,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
		// bl 0x82566898
		util_6898(ctx, base);
		// lwz r11,0(r27)
		ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
		// li r5,8
		ctx.r5.s64 = 8;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,88
		ctx.r3.s64 = ctx.r1.s64 + 88;
		// stw r11,80(r1)
		PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
		// addi r11,r1,96
		ctx.r11.s64 = ctx.r1.s64 + 96;
		// stw r11,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
		// bl 0x82566898
		util_6898(ctx, base);
		// addi r11,r1,80
		ctx.r11.s64 = ctx.r1.s64 + 80;
		// stb r30,88(r1)
		PPC_STORE_U8(ctx.r1.u32 + 88, (uint8_t)var_r30);
		// li r5,92
		ctx.r5.s64 = 92;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,192
		ctx.r3.s64 = ctx.r1.s64 + 192;
		// stw r11,92(r1)
		PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
		// bl 0x82566898
		util_6898(ctx, base);
		// lis r11,-32169
		// stb r31,192(r1)
		PPC_STORE_U8(ctx.r1.u32 + 192, (uint8_t)var_r31);
		// addi r10,r1,88
		ctx.r10.s64 = ctx.r1.s64 + 88;
		// stb r29,196(r1)
		PPC_STORE_U8(ctx.r1.u32 + 196, (uint8_t)var_r29);
		// addi r11,r11,-9712
		ctx.r11.s64 = ctx.r11.s64 + -9712;
		// stw r26,200(r1)
		PPC_STORE_U32(ctx.r1.u32 + 200, var_r26);
		// addi r4,r28,64
		ctx.r4.s64 = (int64_t)(int32_t)var_r28 + 64;
		// stb r30,249(r1)
		PPC_STORE_U8(ctx.r1.u32 + 249, (uint8_t)var_r30);
		// addi r3,r1,192
		ctx.r3.s64 = ctx.r1.s64 + 192;
		// stb r29,250(r1)
		PPC_STORE_U8(ctx.r1.u32 + 250, (uint8_t)var_r29);
		// stb r30,251(r1)
		PPC_STORE_U8(ctx.r1.u32 + 251, (uint8_t)var_r30);
		// stb r30,256(r1)
		PPC_STORE_U8(ctx.r1.u32 + 256, (uint8_t)var_r30);
		// stw r10,264(r1)
		PPC_STORE_U32(ctx.r1.u32 + 264, ctx.r10.u32);
		// stw r11,272(r1)
		PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r11.u32);
		// stw r28,280(r1)
		PPC_STORE_U32(ctx.r1.u32 + 280, var_r28);
		// bl 0x82461278
		game_1278(ctx, base);
	}
loc_8256DCD0:
	return;
}

__attribute__((alias("__imp__xam_DCD8_2hr"))) PPC_WEAK_FUNC(xam_DCD8_2hr);
PPC_FUNC_IMPL(__imp__xam_DCD8_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f894
	ctx.lr = 0x8256DCE0;
	__savegprlr_27(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmpwi cr6,r4,1
	// bne cr6,0x8256dd60
	if (ctx.r4.s32 == 1) {
		// addi r10,r5,344
		ctx.r10.s64 = ctx.r5.s64 + 344;
		// lwz r31,1320(r11)
		var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r11.u32 + 1320));
		// addi r7,r11,1328
		ctx.r7.s64 = ctx.r11.s64 + 1328;
		// rlwinm r9,r10,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r29,r11,1376
		var_r29 = (uint32_t)(ctx.r11.s64 + 1376);  // addr:0x82570560
		// addi r8,r11,1112
		ctx.r8.s64 = ctx.r11.s64 + 1112;
		// add r9,r9,r11
		ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
		// li r4,0
		ctx.r4.s64 = 0;
		// li r10,4
		ctx.r10.s64 = 4;
		// li r11,4
		ctx.r11.s64 = 4;
	loc_8256DD18:
		// lwz r30,0(r8)
		var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r8.u32 + 0));
		// cmplwi cr6,r30,0
		// beq cr6,0x8256dd34
		if (var_r30 != 0) {
			// lwz r30,0(r9)
			var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r9.u32 + 0));
			// cmplwi cr6,r30,0
			// beq cr6,0x8256dd34
			if (var_r30 == 0) goto loc_8256DD34;
			// addi r4,r4,1
			ctx.r4.s64 = ctx.r4.s64 + 1;
		}
	loc_8256DD34:
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// addi r9,r9,12
		ctx.r9.s64 = ctx.r9.s64 + 12;
		// bne 0x8256dd18
		if (ctx.r11.s32 != 0) goto loc_8256DD18;
		// cmplwi cr6,r4,0
		// beq cr6,0x8256dd70
		if (ctx.r4.u32 == 0) goto loc_8256DD70;
		// divwu r11,r31,r4
		ctx.r11.u32 = ctx.r4.u32 ? var_r31 / ctx.r4.u32 : 0;
		// twllei r4,0
		if (ctx.r4.s32 == 0 || ctx.r4.u32 < 0u) __builtin_trap();
		// mullw r11,r11,r4
		ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r4.s32);
		// subf r31,r11,r31
		var_r31 = (uint32_t)((int64_t)(int32_t)var_r31 - ctx.r11.s64);
		// b 0x8256dd70
	} else {
	loc_8256DD60:
		// li r31,0
		var_r31 = 0;
		// addi r7,r11,1424
		ctx.r7.s64 = ctx.r11.s64 + 1424;
		// addi r29,r11,1832
		var_r29 = (uint32_t)(ctx.r11.s64 + 1832);  // addr:0x82570728
		// li r10,34
		ctx.r10.s64 = 34;
	}
loc_8256DD70:
	// mulli r11,r10,12
	ctx.r11.s64 = static_cast<int64_t>(ctx.r10.u64 * static_cast<uint64_t>(12));
	// add r28,r11,r7
	var_r28 = (uint32_t)(ctx.r11.u64 + ctx.r7.u64);
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// cmplw cr6,r7,r28
	// bge cr6,0x8256dda4
	if (ctx.r7.u32 >= var_r28) goto loc_8256DDA4;
	// rlwinm r8,r5,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
loc_8256DD88:
	// add r9,r8,r11
	ctx.r9.u64 = ctx.r8.u64 + ctx.r11.u64;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmplw cr6,r11,r28
	// lwz r4,0(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// neg r4,r4
	ctx.r4.s64 = static_cast<int64_t>(-ctx.r4.u64);
	// stw r4,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r4.u32);
	// blt cr6,0x8256dd88
	if (ctx.r11.u32 < var_r28) goto loc_8256DD88;
loc_8256DDA4:
	// li r30,0
	var_r30 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r10,0
	// beq cr6,0x8256de28
	if (ctx.r10.u32 == 0) goto loc_8256DE28;
loc_8256DDB4:
	// cmplwi cr6,r6,0
	// beq cr6,0x8256de18
	if (ctx.r6.u32 == 0) goto loc_8256DE18;
	// add r11,r4,r31
	ctx.r11.u64 = ctx.r4.u64 + var_r31;
	// rlwinm r8,r5,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// divwu r9,r11,r10
	ctx.r9.u32 = ctx.r10.u32 ? ctx.r11.u32 / ctx.r10.u32 : 0;
	// twllei r10,0
	if (ctx.r10.s32 == 0 || ctx.r10.u32 < 0u) __builtin_trap();
	// mullw r9,r9,r10
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// subf r11,r9,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r9.s64;
	// mulli r9,r11,12
	ctx.r9.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(12));
	// mulli r11,r11,3
	ctx.r11.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(3));
	// add r11,r11,r5
	ctx.r11.u64 = ctx.r11.u64 + ctx.r5.u64;
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r27,r11,r29
	var_r27 = (uint32_t)(PPC_LOAD_U32(ctx.r11.u32 + var_r29));
	// lwzx r11,r8,r9
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// cmpw cr6,r11,r27
	// bge cr6,0x8256de0c
	if (ctx.r11.s32 < (int32_t)var_r27) {
		// addic. r11,r11,1
		ctx.xer.ca = ctx.r11.u32 > 4294967294;
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// stwx r11,r8,r9
		PPC_STORE_U32(ctx.r8.u32 + ctx.r9.u32, ctx.r11.u32);
		// ble 0x8256de0c
		if (ctx.r11.s32 <= 0) goto loc_8256DE0C;
		// addi r6,r6,-1
		ctx.r6.s64 = ctx.r6.s64 + -1;
	}
loc_8256DE0C:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// cmplw cr6,r4,r10
	// blt cr6,0x8256ddb4
	if (ctx.r4.u32 < ctx.r10.u32) goto loc_8256DDB4;
loc_8256DE18:
	// cmplwi cr6,r30,0
	// beq cr6,0x8256de28
	if (var_r30 == 0) goto loc_8256DE28;
	// cmplwi cr6,r6,0
	// bne cr6,0x8256dda4
	if (ctx.r6.u32 != 0) goto loc_8256DDA4;
loc_8256DE28:
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// cmplw cr6,r7,r28
	// bge cr6,0x8256de64
	if (ctx.r7.u32 < var_r28) {
		// rlwinm r9,r5,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	loc_8256DE38:
		// add r10,r9,r11
		ctx.r10.u64 = ctx.r9.u64 + ctx.r11.u64;
		// lwz r8,0(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// cmpwi cr6,r8,0
		// bge cr6,0x8256de50
		if (ctx.r8.s32 < 0) {
			// li r8,0
			ctx.r8.s64 = 0;
			// stw r8,0(r10)
			PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
		}
	loc_8256DE50:
		// lwz r10,0(r10)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// addi r11,r11,12
		ctx.r11.s64 = ctx.r11.s64 + 12;
		// add r3,r3,r10
		ctx.r3.u64 = ctx.r3.u64 + ctx.r10.u64;
		// cmplw cr6,r11,r28
		// blt cr6,0x8256de38
		if (ctx.r11.u32 < var_r28) goto loc_8256DE38;
	}
loc_8256DE64:
	// b 0x8242f8e4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__RtlTryEnterCriticalSection_DE68_w"))) PPC_WEAK_FUNC(RtlTryEnterCriticalSection_DE68_w);
PPC_FUNC_IMPL(__imp__RtlTryEnterCriticalSection_DE68_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// li r31,0
	var_r31 = 0;
	// cmplwi cr6,r4,1
	// blt cr6,0x8256decc
	if (ctx.r4.u32 >= 1) {
		// beq cr6,0x8256dea8
		if (!(ctx.cr6.eq)) {
			// cmplwi cr6,r4,3
			// blt cr6,0x8256de9c
			if (ctx.r4.u32 >= 3) {
				// lis r31,-32761
				var_r31 = (uint32_t)(-2147024896);
				// ori r31,r31,87
				var_r31 = (uint32_t)(var_r31 | 87);
				// b 0x8256ded4
				// mr r3,r31
				ctx.r3.u64 = var_r31;
				// blr
				return;
			}
		loc_8256DE9C:
			// addi r3,r3,1272
			ctx.r3.s64 = ctx.r3.s64 + 1272;
			// bl 0x82585dfc
			__imp__RtlLeaveCriticalSection(ctx, base);
			// b 0x8256ded4
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// blr
			return;
		}
	loc_8256DEA8:
		// addi r3,r3,1272
		ctx.r3.s64 = ctx.r3.s64 + 1272;
		// bl 0x8258625c
		__imp__RtlTryEnterCriticalSection(ctx, base);
		// cmplwi cr6,r3,1
		// bne cr6,0x8256dec0
		if (ctx.r3.u32 == 1) {
			// li r31,0
			var_r31 = 0;
			// b 0x8256ded4
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// blr
			return;
		}
	loc_8256DEC0:
		// lis r31,-32768
		var_r31 = (uint32_t)(-2147483648);
		// ori r31,r31,16388
		var_r31 = (uint32_t)(var_r31 | 16388);
		// b 0x8256ded4
	} else {
	loc_8256DECC:
		// addi r3,r3,1272
		ctx.r3.s64 = ctx.r3.s64 + 1272;
		// bl 0x82585e0c
		__imp__RtlEnterCriticalSection(ctx, base);
	}
loc_8256DED4:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// blr
	return;
}

__attribute__((alias("__imp__xam_DEF0_w"))) PPC_WEAK_FUNC(xam_DEF0_w);
PPC_FUNC_IMPL(__imp__xam_DEF0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r27,r31,1272
	var_r27 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// addi r11,r30,278
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 278;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
	// cmplwi r3,0
	// bne 0x8256df38
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256df48
	} else {
	loc_8256DF38:
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x82570370
		xam_0370_2hr(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256DF48:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_DF60_w"))) PPC_WEAK_FUNC(xam_DF60_w);
PPC_FUNC_IMPL(__imp__xam_DF60_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r27,r31,1272
	var_r27 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// addi r11,r30,278
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 278;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
	// cmplwi r3,0
	// bne 0x8256dfa8
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256dfb8
	} else {
	loc_8256DFA8:
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x825703e8
		xam_03E8_2h(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256DFB8:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_DFD0_2h"))) PPC_WEAK_FUNC(xam_DFD0_2h);
PPC_FUNC_IMPL(__imp__xam_DFD0_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// addi r11,r3,1324
	ctx.r11.s64 = ctx.r3.s64 + 1324;
loc_8256DFD4:
	// mfmsr r9
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
	// mtmsrd r13,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_ENTER_GLOBAL_LOCK();
	// lwarx r10,0,r11
	ea = ctx.r11.u32;
	ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// stwcx. r4,0,r11
	ea = ctx.r11.u32;
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r4.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_LEAVE_GLOBAL_LOCK();
	// bne 0x8256dfd4
	if (!ctx.cr0.eq) goto loc_8256DFD4;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__xam_DFF8_w"))) PPC_WEAK_FUNC(xam_DFF8_w);
PPC_FUNC_IMPL(__imp__xam_DFF8_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=112, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r29,r31,1272
	var_r29 = (uint32_t)(var_r31 + 1272);
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 12);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi r9,0
	// beq 0x8256e04c
	if (ctx.r9.u32 != 0) {
		// addi r10,r31,1096
		ctx.r10.s64 = (int64_t)(int32_t)var_r31 + 1096;
	loc_8256E02C:
		// lwz r8,0(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// cmplwi cr6,r8,0
		// bne cr6,0x8256e04c
		if (ctx.r8.u32 != 0) goto loc_8256E04C;
		// lwz r8,12(r31)
		ctx.r8.u64 = PPC_LOAD_U32(var_r31 + 12);
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// cmplw cr6,r11,r8
		// blt cr6,0x8256e02c
		if (ctx.r11.u32 < ctx.r8.u32) goto loc_8256E02C;
	}
loc_8256E04C:
	// cmplw cr6,r11,r9
	// bne cr6,0x8256e060
	if (ctx.r11.u32 == ctx.r9.u32) {
		// lis r30,-32768
		var_r30 = (uint32_t)(-2147483648);
		// ori r30,r30,16389
		var_r30 = (uint32_t)(var_r30 | 16389);
		// b 0x8256e09c
	} else {
	loc_8256E060:
		// addi r11,r11,274
		ctx.r11.s64 = ctx.r11.s64 + 274;
		// addi r9,r30,278
		ctx.r9.s64 = (int64_t)(int32_t)var_r30 + 278;
		// rlwinm r10,r11,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// rlwinm r11,r9,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// lwzx r9,r10,r31
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + var_r31);
		// stwx r9,r11,r31
		PPC_STORE_U32(ctx.r11.u32 + var_r31, ctx.r9.u32);
		// li r9,0
		ctx.r9.s64 = 0;
		// stwx r9,r10,r31
		PPC_STORE_U32(ctx.r10.u32 + var_r31, ctx.r9.u32);
		// lwzx r3,r11,r31
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
		// bl 0x82570968
		xam_0968(ctx, base);
		// mr. r30,r3
		var_r30 = ctx.r3.u32;
		// blt 0x8256e09c
		if ((int32_t)var_r30 < 0) {
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			// bl 0x82585dfc
			__imp__RtlLeaveCriticalSection(ctx, base);
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			return;
		}
		// li r11,1
		ctx.r11.s64 = 1;
		// stw r11,1316(r31)
		PPC_STORE_U32(var_r31 + 1316, ctx.r11.u32);
	}
loc_8256E09C:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	return;
}

__attribute__((alias("__imp__xam_E0B0_w"))) PPC_WEAK_FUNC(xam_E0B0_w);
PPC_FUNC_IMPL(__imp__xam_E0B0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=112, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r29,r31,1272
	var_r29 = (uint32_t)(var_r31 + 1272);
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// addi r11,r30,278
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 278;
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
	// stwx r10,r11,r31
	PPC_STORE_U32(ctx.r11.u32 + var_r31, ctx.r10.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 12);
	// cmplwi r11,0
	// beq 0x8256e120
	if (ctx.r11.u32 != 0) {
		// addi r9,r31,1096
		ctx.r9.s64 = (int64_t)(int32_t)var_r31 + 1096;
	loc_8256E0F4:
		// lwz r8,0(r9)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// cmplwi cr6,r8,0
		// beq cr6,0x8256e114
		if (ctx.r8.u32 != 0) {
			// addi r10,r10,1
			ctx.r10.s64 = ctx.r10.s64 + 1;
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// cmplw cr6,r10,r11
			// blt cr6,0x8256e0f4
			if (ctx.r10.u32 < ctx.r11.u32) goto loc_8256E0F4;
			// b 0x8256e120
		} else {
		loc_8256E114:
			// addi r11,r10,274
			ctx.r11.s64 = ctx.r10.s64 + 274;
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// stwx r3,r11,r31
			PPC_STORE_U32(ctx.r11.u32 + var_r31, ctx.r3.u32);
		}
	}
loc_8256E120:
	// bl 0x82570258
	xam_0258(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	return;
}

__attribute__((alias("__imp__phBoundCapsule_E138_w"))) PPC_WEAK_FUNC(phBoundCapsule_E138_w);
PPC_FUNC_IMPL(__imp__phBoundCapsule_E138_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r29,r31,1272
	var_r29 = (uint32_t)(var_r31 + 1272);
	// li r28,0
	var_r28 = 0;
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// addi r11,r30,278
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 278;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
	// cmplwi r3,0
	// beq 0x8256e178
	if (ctx.r3.u32 != 0) {
		// bl 0x8256fbd0
		phBoundCapsule_vfn_12(ctx, base);
		// mr r28,r3
		var_r28 = ctx.r3.u32;
	}
loc_8256E178:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	return;
}

__attribute__((alias("__imp__xam_E190_2h"))) PPC_WEAK_FUNC(xam_E190_2h);
PPC_FUNC_IMPL(__imp__xam_E190_2h) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r4,278
	ctx.r11.s64 = ctx.r4.s64 + 278;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	// cmplwi r11,0
	// beq 0x8256e1b8
	if (ctx.r11.u32 != 0) {
		// lwz r11,4(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// cmplwi r11,0
		// beq 0x8256e1b8
		if (ctx.r11.u32 == 0) {
			// li r3,0
			ctx.r3.s64 = 0;
			// blr
			return;
		}
		// lwz r3,144(r11)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 144);
		// blr
		return;
	}
loc_8256E1B8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__get_E1C0"))) PPC_WEAK_FUNC(get_E1C0);
PPC_FUNC_IMPL(__imp__get_E1C0) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,1268(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1268);
	// blr
	return;
}

__attribute__((alias("__imp__xam_E1C8_w"))) PPC_WEAK_FUNC(xam_E1C8_w);
PPC_FUNC_IMPL(__imp__xam_E1C8_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	// FRAME: size=144, savegprlr_26
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r26,r31,1272
	var_r26 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r27,r7
	var_r27 = ctx.r7.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// addi r11,r30,278
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 278;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
	// cmplwi r3,0
	// bne 0x8256e214
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256e230
	} else {
	loc_8256E214:
		// lis r11,-32254
		// mr r7,r27
		ctx.r7.u64 = var_r27;
		// mr r6,r28
		ctx.r6.u64 = var_r28;
		// mr r5,r29
		ctx.r5.u64 = var_r29;
		// lwz r4,10176(r11)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10176);
		// bl 0x82570768
		xam_0768_2h(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256E230:
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_E248_2hr"))) PPC_WEAK_FUNC(xam_E248_2hr);
PPC_FUNC_IMPL(__imp__xam_E248_2hr) {
	PPC_FUNC_PROLOGUE();
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi r9,0
	// beq 0x8256e27c
	if (ctx.r9.u32 != 0) {
		// addi r10,r3,1128
		ctx.r10.s64 = ctx.r3.s64 + 1128;
	loc_8256E25C:
		// lwz r8,0(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// ld r8,0(r8)
		ctx.r8.u64 = PPC_LOAD_U64(ctx.r8.u32 + 0);
		// cmpld cr6,r4,r8
		// beq cr6,0x8256e27c
		if (ctx.r4.u64 == ctx.r8.u64) goto loc_8256E27C;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// cmplw cr6,r11,r9
		// blt cr6,0x8256e25c
		if (ctx.r11.u32 < ctx.r9.u32) goto loc_8256E25C;
	}
loc_8256E27C:
	// cmplw cr6,r11,r9
	// bge cr6,0x8256e294
	if (ctx.r11.u32 < ctx.r9.u32) {
		// addi r11,r11,282
		ctx.r11.s64 = ctx.r11.s64 + 282;
		// rlwinm r11,r11,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// lwzx r3,r11,r3
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
		// blr
		return;
	}
loc_8256E294:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__xam_E2A0_h"))) PPC_WEAK_FUNC(xam_E2A0_h);
PPC_FUNC_IMPL(__imp__xam_E2A0_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r26 = 0;
	// FRAME: size=176, savegprlr_22
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r5,48
	ctx.r5.s64 = 48;
	// addi r24,r31,1376
	var_r24 = (uint32_t)(var_r31 + 1376);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = var_r24;
	// li r22,0
	var_r22 = 0;
	// bl 0x82566898
	util_6898(ctx, base);
	// addi r30,r31,1112
	var_r30 = (uint32_t)(var_r31 + 1112);
	// mr r29,r24
	var_r29 = (uint32_t)(var_r24);
	// li r28,4
	var_r28 = 4;
loc_8256E2D4:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
	// cmplwi r3,0
	// beq 0x8256e2e8
	if (ctx.r3.u32 != 0) {
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x825707c0
		xam_07C0_w(ctx, base);
	}
loc_8256E2E8:
	// addic. r28,r28,-1
	ctx.xer.ca = var_r28 > 0;
	var_r28 = (uint32_t)(var_r28 + -1);
	// addi r30,r30,4
	var_r30 = (uint32_t)(var_r30 + 4);
	// addi r29,r29,12
	var_r29 = (uint32_t)(var_r29 + 12);
	// bne 0x8256e2d4
	if ((int32_t)var_r28 != 0) goto loc_8256E2D4;
	// addi r23,r31,1832
	var_r23 = (uint32_t)(var_r31 + 1832);
	// li r5,408
	ctx.r5.s64 = 408;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r23
	ctx.r3.u64 = var_r23;
	// bl 0x82566898
	util_6898(ctx, base);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
	// mr r27,r22
	var_r27 = (uint32_t)(var_r22);
	// cmplwi cr6,r11,0
	// ble cr6,0x8256e458
	if (ctx.r11.u32 > 0) {
		// addi r30,r31,1128
		var_r30 = (uint32_t)(var_r31 + 1128);
		// mr r25,r23
		var_r25 = (uint32_t)(var_r23);
		// li r26,-1
		var_r26 = (uint32_t)(-1);
	loc_8256E328:
		// lwz r11,1308(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 1308);
		// cmpwi cr6,r11,1
		// bne cr6,0x8256e428
		if (ctx.r11.s32 == 1) {
			// lwz r29,0(r30)
			var_r29 = (uint32_t)(PPC_LOAD_U32(var_r30 + 0));
			// mr r28,r27
			var_r28 = (uint32_t)(var_r27);
			// ld r11,0(r29)
			ctx.r11.u64 = PPC_LOAD_U64(var_r29 + 0);
			// cmpldi cr6,r11,0
			// beq cr6,0x8256e378
			if (ctx.r11.u64 != 0) {
				// mr r10,r26
				ctx.r10.u64 = var_r26;
				// li r8,4
				ctx.r8.s64 = 4;
				// addi r11,r29,36
				ctx.r11.s64 = (int64_t)(int32_t)var_r29 + 36;
			loc_8256E354:
				// lwz r9,0(r11)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
				// cmplw cr6,r10,r9
				// blt cr6,0x8256e364
				if (ctx.r10.u32 >= ctx.r9.u32) {
					// mr r10,r9
					ctx.r10.u64 = ctx.r9.u64;
				}
			loc_8256E364:
				// addic. r8,r8,-1
				ctx.xer.ca = ctx.r8.u32 > 0;
				ctx.r8.s64 = ctx.r8.s64 + -1;
				// addi r11,r11,4
				ctx.r11.s64 = ctx.r11.s64 + 4;
				// bne 0x8256e354
				if (ctx.r8.s32 != 0) goto loc_8256E354;
				// mr r3,r10
				ctx.r3.u64 = ctx.r10.u64;
				// b 0x8256e37c
			} else {
			loc_8256E378:
				// mr r3,r26
				ctx.r3.u64 = var_r26;
			}
		loc_8256E37C:
			// lwz r10,8(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 8);
			// addi r11,r27,1
			ctx.r11.s64 = (int64_t)(int32_t)var_r27 + 1;
			// mr r5,r11
			ctx.r5.u64 = ctx.r11.u64;
			// cmplw cr6,r11,r10
			// bge cr6,0x8256e428
			if (ctx.r11.u32 >= ctx.r10.u32) goto loc_8256E428;
			// rotlwi r4,r10,0
			ctx.r4.u64 = ctx.r10.u32;
			// addi r6,r30,4
			ctx.r6.s64 = (int64_t)(int32_t)var_r30 + 4;
		loc_8256E398:
			// lwz r7,0(r6)
			ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
			// mr r11,r26
			ctx.r11.u64 = var_r26;
			// li r9,4
			ctx.r9.s64 = 4;
			// addi r10,r7,36
			ctx.r10.s64 = ctx.r7.s64 + 36;
		loc_8256E3A8:
			// lwz r8,0(r10)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			// cmplw cr6,r11,r8
			// blt cr6,0x8256e3b8
			if (ctx.r11.u32 >= ctx.r8.u32) {
				// mr r11,r8
				ctx.r11.u64 = ctx.r8.u64;
			}
		loc_8256E3B8:
			// addic. r9,r9,-1
			ctx.xer.ca = ctx.r9.u32 > 0;
			ctx.r9.s64 = ctx.r9.s64 + -1;
			// addi r10,r10,4
			ctx.r10.s64 = ctx.r10.s64 + 4;
			// bne 0x8256e3a8
			if (ctx.r9.s32 != 0) goto loc_8256E3A8;
			// ld r10,0(r7)
			ctx.r10.u64 = PPC_LOAD_U64(ctx.r7.u32 + 0);
			// cmpldi cr6,r10,0
			// beq cr6,0x8256e3e0
			if (ctx.r10.u64 != 0) {
				// cmplw cr6,r11,r3
				// bge cr6,0x8256e3e0
				if (ctx.r11.u32 >= ctx.r3.u32) goto loc_8256E3E0;
				// mr r28,r5
				var_r28 = ctx.r5.u32;
				// mr r3,r11
				ctx.r3.u64 = ctx.r11.u64;
			}
		loc_8256E3E0:
			// addi r5,r5,1
			ctx.r5.s64 = ctx.r5.s64 + 1;
			// addi r6,r6,4
			ctx.r6.s64 = ctx.r6.s64 + 4;
			// cmplw cr6,r5,r4
			// blt cr6,0x8256e398
			if (ctx.r5.u32 < ctx.r4.u32) goto loc_8256E398;
			// cmplw cr6,r28,r27
			// beq cr6,0x8256e428
			if (var_r28 == var_r27) goto loc_8256E428;
			// addi r11,r28,282
			ctx.r11.s64 = (int64_t)(int32_t)var_r28 + 282;
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// lwzx r10,r11,r31
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
			// xor r10,r10,r29
			ctx.r10.u64 = ctx.r10.u64 ^ var_r29;
			// stw r10,0(r30)
			PPC_STORE_U32(var_r30 + 0, ctx.r10.u32);
			// lwzx r10,r11,r31
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
			// lwz r9,0(r30)
			ctx.r9.u64 = PPC_LOAD_U32(var_r30 + 0);
			// xor r10,r10,r9
			ctx.r10.u64 = ctx.r10.u64 ^ ctx.r9.u64;
			// stwx r10,r11,r31
			PPC_STORE_U32(ctx.r11.u32 + var_r31, ctx.r10.u32);
			// lwz r11,0(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
			// xor r11,r10,r11
			ctx.r11.u64 = ctx.r10.u64 ^ ctx.r11.u64;
			// stw r11,0(r30)
			PPC_STORE_U32(var_r30 + 0, ctx.r11.u32);
		}
	loc_8256E428:
		// lwz r3,0(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
		// ld r11,0(r3)
		ctx.r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
		// cmpldi cr6,r11,0
		// beq cr6,0x8256e440
		if (ctx.r11.u64 != 0) {
			// mr r4,r25
			ctx.r4.u64 = var_r25;
			// bl 0x82571990
			xam_1990_w(ctx, base);
		}
	loc_8256E440:
		// lwz r11,8(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
		// addi r27,r27,1
		var_r27 = (uint32_t)(var_r27 + 1);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// addi r25,r25,12
		var_r25 = (uint32_t)(var_r25 + 12);
		// cmplw cr6,r27,r11
		// blt cr6,0x8256e328
		if (var_r27 < ctx.r11.u32) goto loc_8256E328;
	}
loc_8256E458:
	// lis r10,-32164
	// stw r22,1308(r31)
	PPC_STORE_U32(var_r31 + 1308, var_r22);
	// addi r11,r31,1328
	ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 1328;
	// addi r10,r10,9848
	ctx.r10.s64 = ctx.r10.s64 + 9848;
	// addi r7,r11,48
	ctx.r7.s64 = ctx.r11.s64 + 48;
	// mr r8,r22
	ctx.r8.u64 = var_r22;
	// cmplw cr6,r11,r7
	// lwz r6,12(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// bge cr6,0x8256e4b8
	if (ctx.r11.u32 < ctx.r7.u32) {
		// addi r5,r24,48
		ctx.r5.s64 = (int64_t)(int32_t)var_r24 + 48;
		// subf r4,r11,r24
		ctx.r4.s64 = (int64_t)(int32_t)var_r24 - ctx.r11.s64;
	loc_8256E484:
		// add r9,r4,r11
		ctx.r9.u64 = ctx.r4.u64 + ctx.r11.u64;
		// cmplw cr6,r9,r5
		// bge cr6,0x8256e4ac
		if (ctx.r9.u32 >= ctx.r5.u32) goto loc_8256E4AC;
		// rlwinm r10,r6,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
		// lwzx r9,r10,r9
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
		// add r8,r9,r8
		ctx.r8.u64 = ctx.r9.u64 + ctx.r8.u64;
		// stwx r9,r10,r11
		PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
		// addi r11,r11,12
		ctx.r11.s64 = ctx.r11.s64 + 12;
		// cmplw cr6,r11,r7
		// blt cr6,0x8256e484
		if (ctx.r11.u32 < ctx.r7.u32) goto loc_8256E484;
	loc_8256E4AC:
		// cmplwi cr6,r8,0
		// beq cr6,0x8256e4b8
		if (ctx.r8.u32 == 0) goto loc_8256E4B8;
		// mr r22,r8
		var_r22 = ctx.r8.u32;
	}
loc_8256E4B8:
	// lis r11,-32164
	// li r6,2
	ctx.r6.s64 = 2;
	// addi r11,r11,9744
	ctx.r11.s64 = ctx.r11.s64 + 9744;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// bl 0x8256dcd8
	xam_DCD8_2hr(ctx, base);
	// cmplw cr6,r3,r22
	// ble cr6,0x8256e4e0
	if (ctx.r3.u32 > var_r22) {
		// mr r22,r3
		var_r22 = ctx.r3.u32;
	}
loc_8256E4E0:
	// lwz r11,1324(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 1324);
	// cmplwi cr6,r11,0
	// bne cr6,0x8256e4f4
	if (ctx.r11.u32 == 0) {
		// li r11,2
		ctx.r11.s64 = 2;
		// stw r11,1324(r31)
		PPC_STORE_U32(var_r31 + 1324, ctx.r11.u32);
	}
loc_8256E4F4:
	// lis r11,-32164
	// lwz r6,1324(r31)
	ctx.r6.u64 = PPC_LOAD_U32(var_r31 + 1324);
	// addi r29,r23,408
	var_r29 = (uint32_t)(var_r23 + 408);
	// addi r11,r11,9776
	ctx.r11.s64 = ctx.r11.s64 + 9776;
	// addi r30,r31,1424
	var_r30 = (uint32_t)(var_r31 + 1424);
	// cmplw cr6,r23,r29
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// mr r11,r23
	ctx.r11.u64 = var_r23;
	// bge cr6,0x8256e53c
	if (var_r23 < var_r29) {
		// rlwinm r10,r5,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	loc_8256E51C:
		// lwzx r9,r10,r11
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
		// cmplwi cr6,r9,1
		// ble cr6,0x8256e530
		if (ctx.r9.u32 > 1) {
			// li r9,1
			ctx.r9.s64 = 1;
			// stwx r9,r10,r11
			PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
		}
	loc_8256E530:
		// addi r11,r11,12
		ctx.r11.s64 = ctx.r11.s64 + 12;
		// cmplw cr6,r11,r29
		// blt cr6,0x8256e51c
		if (ctx.r11.u32 < var_r29) goto loc_8256E51C;
	}
loc_8256E53C:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256dcd8
	xam_DCD8_2hr(ctx, base);
	// addi r10,r30,408
	ctx.r10.s64 = (int64_t)(int32_t)var_r30 + 408;
	// mr r11,r23
	ctx.r11.u64 = var_r23;
	// cmplw cr6,r30,r10
	// bge cr6,0x8256e584
	if (var_r30 < ctx.r10.u32) {
		// subf r8,r23,r30
		ctx.r8.s64 = (int64_t)(int32_t)var_r30 - (int64_t)(int32_t)var_r23;
	loc_8256E55C:
		// cmplw cr6,r11,r29
		// bge cr6,0x8256e584
		if (ctx.r11.u32 >= var_r29) goto loc_8256E584;
		// rlwinm r9,r5,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
		// add r7,r9,r11
		ctx.r7.u64 = ctx.r9.u64 + ctx.r11.u64;
		// lwzx r7,r7,r8
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
		// stwx r7,r9,r11
		PPC_STORE_U32(ctx.r9.u32 + ctx.r11.u32, ctx.r7.u32);
		// addi r11,r11,12
		ctx.r11.s64 = ctx.r11.s64 + 12;
		// add r9,r11,r8
		ctx.r9.u64 = ctx.r11.u64 + ctx.r8.u64;
		// cmplw cr6,r9,r10
		// blt cr6,0x8256e55c
		if (ctx.r9.u32 < ctx.r10.u32) goto loc_8256E55C;
	}
loc_8256E584:
	// cmplw cr6,r3,r22
	// ble cr6,0x8256e590
	if (ctx.r3.u32 > var_r22) {
		// mr r22,r3
		var_r22 = ctx.r3.u32;
	}
loc_8256E590:
	// cmplwi cr6,r22,0
	// beq cr6,0x8256e5a4
	if (var_r22 != 0) {
		// lwz r11,1320(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 1320);
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// stw r11,1320(r31)
		PPC_STORE_U32(var_r31 + 1320, ctx.r11.u32);
	}
loc_8256E5A4:
	// mr r3,r22
	ctx.r3.u64 = var_r22;
	return;
}

__attribute__((alias("__imp__phBoundCapsule_E5B0_h"))) PPC_WEAK_FUNC(phBoundCapsule_E5B0_h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_E5B0_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=160, savegprlr_29
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82566898
	util_6898(ctx, base);
	// lis r11,-32256
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lfs f31,15784(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	var_f31 = double(temp.f32);
	// stfs f31,84(r1)
	temp.f32 = float(var_f31);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stb r10,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r10.u8);
	// bl 0x82566898
	util_6898(ctx, base);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// li r30,1
	var_r30 = 1;
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stb r30,88(r1)
	PPC_STORE_U8(ctx.r1.u32 + 88, (uint8_t)var_r30);
	// bl 0x82566898
	util_6898(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// stb r11,96(r1)
	PPC_STORE_U8(ctx.r1.u32 + 96, ctx.r11.u8);
	// addi r11,r1,88
	ctx.r11.s64 = ctx.r1.s64 + 88;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// bl 0x82566898
	util_6898(ctx, base);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// stb r30,104(r1)
	PPC_STORE_U8(ctx.r1.u32 + 104, (uint8_t)var_r30);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// lwz r11,56(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 56);
	// cmplwi cr6,r11,0
	// beq cr6,0x8256e698
	if (ctx.r11.u32 != 0) {
		// lwz r11,196(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 196);
		// rlwinm. r11,r11,0,30,30
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
		// bne 0x8256e670
		if (ctx.r11.s32 == 0) {
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bl 0x8256fbd0
			phBoundCapsule_vfn_12(ctx, base);
			// cmpwi r3,0
			// bne 0x8256e688
			if (ctx.r3.s32 != 0) goto loc_8256E688;
		}
	loc_8256E670:
		// lwz r11,196(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 196);
		// rlwinm. r11,r11,0,12,15
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xF0000;
		// beq 0x8256e688
		if (ctx.r11.s32 != 0) {
			// lfs f0,184(r31)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(var_r31 + 184);
			ctx.f0.f64 = double(temp.f32);
			// stfs f0,84(r1)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
			// b 0x8256e68c
		} else {
		loc_8256E688:
			// stfs f31,84(r1)
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(var_f31);
			PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
		}
	loc_8256E68C:
		// addi r4,r1,104
		ctx.r4.s64 = ctx.r1.s64 + 104;
		// lwz r3,56(r29)
		ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 56);
		// bl 0x82460a48
		phBoundCapsule_0A48(ctx, base);
	}
loc_8256E698:
	return;
}

__attribute__((alias("__imp__xam_E6A8_2hr"))) PPC_WEAK_FUNC(xam_E6A8_2hr);
PPC_FUNC_IMPL(__imp__xam_E6A8_2hr) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi r10,0
	// beq 0x8256e6dc
	if (ctx.r10.u32 != 0) {
		// addi r9,r3,1128
		ctx.r9.s64 = ctx.r3.s64 + 1128;
	loc_8256E6BC:
		// lwz r8,0(r9)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// ld r8,0(r8)
		ctx.r8.u64 = PPC_LOAD_U64(ctx.r8.u32 + 0);
		// cmpld cr6,r4,r8
		// beq cr6,0x8256e6dc
		if (ctx.r4.u64 == ctx.r8.u64) goto loc_8256E6DC;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// cmplw cr6,r11,r10
		// blt cr6,0x8256e6bc
		if (ctx.r11.u32 < ctx.r10.u32) goto loc_8256E6BC;
	}
loc_8256E6DC:
	// lwz r10,12(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// mulli r11,r11,3
	ctx.r11.s64 = static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(3));
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r10,r11,458
	ctx.r10.s64 = ctx.r11.s64 + 458;
	// addi r11,r11,356
	ctx.r11.s64 = ctx.r11.s64 + 356;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r3
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// lwzx r11,r11,r3
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r11.u32);
	// blr
	return;
}

__attribute__((alias("__imp__pg_E710_g"))) PPC_WEAK_FUNC(pg_E710_g);
PPC_FUNC_IMPL(__imp__pg_E710_g) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x8256e878
	if (var_r31 != 0) {
		// lwz r11,1264(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 1264);
		// li r28,0
		var_r28 = 0;
		// li r30,-1
		var_r30 = (uint32_t)(-1);
		// cmplwi r11,0
		// beq 0x8256e770
		if (ctx.r11.u32 != 0) {
			// cmpwi cr6,r11,-1
			// beq cr6,0x8256e770
			if (ctx.r11.s32 == -1) goto loc_8256E770;
			// lwz r3,1304(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 1304);
			// bl 0x82566ed8
			pg_6ED8_g(ctx, base);
			// li r11,3
			ctx.r11.s64 = 3;
			// lwz r3,1264(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 1264);
			// li r4,-1
			// stw r11,1300(r31)
			PPC_STORE_U32(var_r31 + 1300, ctx.r11.u32);
			// bl 0x8242c3b8
			pg_C3B8_g(ctx, base);
			// lwz r3,1264(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 1264);
			// stw r28,1300(r31)
			PPC_STORE_U32(var_r31 + 1300, var_r28);
			// bl 0x82566f10
			pg_6F10_g(ctx, base);
			// stw r30,1264(r31)
			PPC_STORE_U32(var_r31 + 1264, var_r30);
		}
	loc_8256E770:
		// lwz r3,1304(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 1304);
		// cmplwi r3,0
		// beq 0x8256e78c
		if (ctx.r3.u32 != 0) {
			// cmpwi cr6,r3,-1
			// beq cr6,0x8256e78c
			if (ctx.r3.s32 == -1) goto loc_8256E78C;
			// bl 0x82566f10
			pg_6F10_g(ctx, base);
			// stw r30,1304(r31)
			PPC_STORE_U32(var_r31 + 1304, var_r30);
		}
	loc_8256E78C:
		// lwz r3,1312(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 1312);
		// cmplwi r3,0
		// beq 0x8256e7a8
		if (ctx.r3.u32 != 0) {
			// cmpwi cr6,r3,-1
			// beq cr6,0x8256e7a8
			if (ctx.r3.s32 == -1) goto loc_8256E7A8;
			// bl 0x82566f10
			pg_6F10_g(ctx, base);
			// stw r30,1312(r31)
			PPC_STORE_U32(var_r31 + 1312, var_r30);
		}
	loc_8256E7A8:
		// lwz r3,60(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 60);
		// cmplwi r3,0
		// beq 0x8256e7b8
		if (ctx.r3.u32 != 0) {
			// bl 0x824608b8
			phInst_08B8(ctx, base);
		}
	loc_8256E7B8:
		// lwz r3,64(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 64);
		// cmplwi r3,0
		// beq 0x8256e7cc
		if (ctx.r3.u32 != 0) {
			// bl 0x824608b8
			phInst_08B8(ctx, base);
			// stw r28,64(r31)
			PPC_STORE_U32(var_r31 + 64, var_r28);
		}
	loc_8256E7CC:
		// lwz r3,56(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 56);
		// cmplwi r3,0
		// beq 0x8256e7e0
		if (ctx.r3.u32 != 0) {
			// bl 0x824608b8
			phInst_08B8(ctx, base);
			// stw r28,56(r31)
			PPC_STORE_U32(var_r31 + 56, var_r28);
		}
	loc_8256E7E0:
		// lwz r11,12(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 12);
		// mr r29,r28
		var_r29 = (uint32_t)(var_r28);
		// cmplwi cr6,r11,0
		// ble cr6,0x8256e814
		if (ctx.r11.u32 > 0) {
			// addi r30,r31,1096
			var_r30 = (uint32_t)(var_r31 + 1096);
		loc_8256E7F4:
			// lwz r3,0(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
			// bl 0x82570870
			xam_0870(ctx, base);
			// stw r28,0(r30)
			PPC_STORE_U32(var_r30 + 0, var_r28);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// lwz r11,12(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 12);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
			// cmplw cr6,r29,r11
			// blt cr6,0x8256e7f4
			if (var_r29 < ctx.r11.u32) goto loc_8256E7F4;
		}
	loc_8256E814:
		// addi r30,r31,1112
		var_r30 = (uint32_t)(var_r31 + 1112);
		// li r29,4
		var_r29 = 4;
	loc_8256E81C:
		// lwz r3,0(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
		// bl 0x82570870
		xam_0870(ctx, base);
		// stw r28,0(r30)
		PPC_STORE_U32(var_r30 + 0, var_r28);
		// addic. r29,r29,-1
		ctx.xer.ca = var_r29 > 0;
		var_r29 = (uint32_t)(var_r29 + -1);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// bne 0x8256e81c
		if ((int32_t)var_r29 != 0) goto loc_8256E81C;
		// lwz r11,8(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
		// mr r29,r28
		var_r29 = (uint32_t)(var_r28);
		// cmplwi cr6,r11,0
		// ble cr6,0x8256e868
		if (ctx.r11.u32 > 0) {
			// addi r30,r31,1128
			var_r30 = (uint32_t)(var_r31 + 1128);
		loc_8256E848:
			// lwz r3,0(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
			// bl 0x825714a0
			xam_14A0_w(ctx, base);
			// stw r28,0(r30)
			PPC_STORE_U32(var_r30 + 0, var_r28);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// lwz r11,8(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
			// cmplw cr6,r29,r11
			// blt cr6,0x8256e848
			if (var_r29 < ctx.r11.u32) goto loc_8256E848;
		}
	loc_8256E868:
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r4,r4,32780
		ctx.r4.u64 = ctx.r4.u64 | 32780;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_8256E878:
	return;
}

__attribute__((alias("__imp__xam_E880_h"))) PPC_WEAK_FUNC(xam_E880_h);
PPC_FUNC_IMPL(__imp__xam_E880_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t ea{};
	// FRAME: size=96, manual
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
loc_8256E894:
	// mfmsr r9
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
	// mtmsrd r13,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_ENTER_GLOBAL_LOCK();
	// lwarx r10,0,r11
	ea = ctx.r11.u32;
	ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r11
	ea = ctx.r11.u32;
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_LEAVE_GLOBAL_LOCK();
	// bne 0x8256e894
	if (!ctx.cr0.eq) goto loc_8256E894;
	// mr r31,r10
	var_r31 = ctx.r10.u32;
	// cmplwi cr6,r31,0
	// bne cr6,0x8256e8c0
	if (var_r31 == 0) {
		// bl 0x8256e710
		pg_E710_g(ctx, base);
	}
loc_8256E8C0:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// blr
	return;
}

__attribute__((alias("__imp__xam_E8D8_g"))) PPC_WEAK_FUNC(xam_E8D8_g);
PPC_FUNC_IMPL(__imp__xam_E8D8_g) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=240, savegprlr_26
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r27,0
	var_r27 = 0;
	// addi r26,r31,1272
	var_r26 = (uint32_t)(var_r31 + 1272);
	// mr r28,r27
	var_r28 = (uint32_t)(var_r27);
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// lwz r11,1300(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 1300);
	// cmplwi cr6,r11,3
	// beq cr6,0x8256ea34
	if (ctx.r11.u32 != 3) {
		// addi r6,r1,84
		ctx.r6.s64 = ctx.r1.s64 + 84;
		// lwz r3,1312(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 1312);
		// addi r5,r1,80
		ctx.r5.s64 = ctx.r1.s64 + 80;
		// li r4,0
		ctx.r4.s64 = 0;
		// bl 0x82585f1c
		__imp__XNotifyGetNext(ctx, base);
		// li r30,1
		var_r30 = 1;
		// cmpwi r3,0
		// beq 0x8256e960
		if (ctx.r3.s32 != 0) {
			// lwz r11,80(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
			// cmplwi cr6,r11,10
			// beq cr6,0x8256e95c
			if (ctx.r11.u32 != 10) {
				// cmplwi cr6,r11,14
				// beq cr6,0x8256e95c
				if (ctx.r11.u32 == 14) goto loc_8256E95C;
				// lis r10,1024
				ctx.r10.s64 = 67108864;
				// ori r10,r10,2
				ctx.r10.u64 = ctx.r10.u64 | 2;
				// cmplw cr6,r11,r10
				// beq cr6,0x8256e95c
				if (ctx.r11.u32 == ctx.r10.u32) goto loc_8256E95C;
				// lis r10,1024
				ctx.r10.s64 = 67108864;
				// ori r10,r10,3
				ctx.r10.u64 = ctx.r10.u64 | 3;
				// cmplw cr6,r11,r10
				// bne cr6,0x8256e960
				if (ctx.r11.u32 != ctx.r10.u32) goto loc_8256E960;
			}
		loc_8256E95C:
			// stw r30,1316(r31)
			PPC_STORE_U32(var_r31 + 1316, var_r30);
		}
	loc_8256E960:
		// lwz r11,1092(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 1092);
		// cmpwi cr6,r11,0
		// bne cr6,0x8256e9bc
		if (ctx.r11.s32 == 0) {
			// li r5,88
			ctx.r5.s64 = 88;
			// li r4,0
			ctx.r4.s64 = 0;
			// addi r3,r1,96
			ctx.r3.s64 = ctx.r1.s64 + 96;
			// bl 0x82566898
			util_6898(ctx, base);
			// addi r11,r31,68
			ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 68;
			// li r10,-1
			// lwz r3,64(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 64);
			// li r5,1
			ctx.r5.s64 = 1;
			// stw r27,108(r1)
			PPC_STORE_U32(ctx.r1.u32 + 108, var_r27);
			// addi r4,r1,96
			ctx.r4.s64 = ctx.r1.s64 + 96;
			// stw r11,96(r1)
			PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
			// li r11,1024
			ctx.r11.s64 = 1024;
			// stw r10,104(r1)
			PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
			// stw r11,100(r1)
			PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
			// stw r11,112(r1)
			PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
			// bl 0x82460b50
			xam_0B50_g(ctx, base);
			// li r4,0
			ctx.r4.s64 = 0;
			// lwz r3,64(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 64);
			// bl 0x82460c08
			xam_0C08_g(ctx, base);
			// stw r30,1092(r31)
			PPC_STORE_U32(var_r31 + 1092, var_r30);
		}
	loc_8256E9BC:
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8256e2a0
		xam_E2A0_h(ctx, base);
		// mr r28,r3
		var_r28 = ctx.r3.u32;
		// addi r30,r31,1112
		var_r30 = (uint32_t)(var_r31 + 1112);
		// li r29,4
		var_r29 = 4;
	loc_8256E9D0:
		// lwz r3,0(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmplwi r3,0
		// beq 0x8256e9e0
		if (ctx.r3.u32 != 0) {
			// bl 0x82570460
			xam_0460(ctx, base);
		}
	loc_8256E9E0:
		// addic. r29,r29,-1
		ctx.xer.ca = var_r29 > 0;
		var_r29 = (uint32_t)(var_r29 + -1);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// bne 0x8256e9d0
		if ((int32_t)var_r29 != 0) goto loc_8256E9D0;
		// lwz r11,8(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
		// mr r29,r27
		var_r29 = (uint32_t)(var_r27);
		// cmplwi cr6,r11,0
		// ble cr6,0x8256ea30
		if (ctx.r11.u32 > 0) {
			// addi r30,r31,1128
			var_r30 = (uint32_t)(var_r31 + 1128);
		loc_8256EA00:
			// lwz r3,0(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
			// cmplwi r3,0
			// beq 0x8256ea1c
			if (ctx.r3.u32 != 0) {
				// ld r11,0(r3)
				ctx.r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
				// cmpldi cr6,r11,0
				// beq cr6,0x8256ea1c
				if (ctx.r11.u64 == 0) goto loc_8256EA1C;
				// bl 0x82571588
				xam_1588(ctx, base);
			}
		loc_8256EA1C:
			// lwz r11,8(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
			// cmplw cr6,r29,r11
			// blt cr6,0x8256ea00
			if (var_r29 < ctx.r11.u32) goto loc_8256EA00;
		}
	loc_8256EA30:
		// stw r27,1316(r31)
		PPC_STORE_U32(var_r31 + 1316, var_r27);
	}
loc_8256EA34:
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// cntlzw r11,r28
	ctx.r11.u64 = var_r28 == 0 ? 32 : __builtin_clz(var_r28);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	return;
}

__attribute__((alias("__imp__xam_EA50"))) PPC_WEAK_FUNC(xam_EA50);
PPC_FUNC_IMPL(__imp__xam_EA50) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r27,r31,1272
	var_r27 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// bne 0x8256ea98
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256eaa8
	} else {
	loc_8256EA98:
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x82571638
		xam_1638_2h(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256EAA8:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_EAC0"))) PPC_WEAK_FUNC(xam_EAC0);
PPC_FUNC_IMPL(__imp__xam_EAC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r27,r31,1272
	var_r27 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// bne 0x8256eb08
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256eb18
	} else {
	loc_8256EB08:
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x825716b0
		xam_16B0_2h(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256EB18:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_EB30_w"))) PPC_WEAK_FUNC(xam_EB30_w);
PPC_FUNC_IMPL(__imp__xam_EB30_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	// FRAME: size=144, savegprlr_26
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// addi r26,r30,1272
	var_r26 = (uint32_t)(var_r30 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r27,r7
	var_r27 = ctx.r7.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82566898
	util_6898(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// ld r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// bne 0x8256eb8c
	if (ctx.r3.u32 == 0) {
		// lis r29,-32768
		var_r29 = (uint32_t)(-2147483648);
		// ori r29,r29,16389
		var_r29 = (uint32_t)(var_r29 | 16389);
		// b 0x8256ec24
	} else {
	loc_8256EB8C:
		// li r8,0
		ctx.r8.s64 = 0;
		// mr r7,r27
		ctx.r7.u64 = var_r27;
		// mr r6,r28
		ctx.r6.u64 = var_r28;
		// mr r5,r29
		ctx.r5.u64 = var_r29;
		// mr r4,r31
		ctx.r4.u64 = var_r31;
		// bl 0x82571728
		xam_1728_w(ctx, base);
		// mr. r29,r3
		var_r29 = ctx.r3.u32;
		// blt 0x8256ec24
		if ((int32_t)var_r29 < 0) {
			// mr r3,r26
			ctx.r3.u64 = var_r26;
			// bl 0x82585dfc
			__imp__RtlLeaveCriticalSection(ctx, base);
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
		// lis r12,-1057
		// lis r10,-5413
		// ori r12,r12,221
		ctx.r12.u64 = ctx.r12.u64 | 221;
		// lis r9,-1057
		// rldicr r12,r12,32,31
		ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 32) & 0xFFFFFFFF00000000;
		// ori r10,r10,61168
		ctx.r10.u64 = ctx.r10.u64 | 61168;
		// oris r12,r12,60123
		ctx.r12.u64 = ctx.r12.u64 | 3940220928;
		// ori r9,r9,221
		ctx.r9.u64 = ctx.r9.u64 | 221;
		// ori r12,r12,61168
		ctx.r12.u64 = ctx.r12.u64 | 61168;
		// rldimi r10,r9,32,0
		ctx.r10.u64 = (__builtin_rotateleft64(ctx.r9.u64, 32) & 0xFFFFFFFF00000000) | (ctx.r10.u64 & 0xFFFFFFFF);
		// and r11,r31,r12
		ctx.r11.u64 = var_r31 & ctx.r12.u64;
		// cmpld cr6,r11,r10
		// beq cr6,0x8256ec24
		if (ctx.r11.u64 == ctx.r10.u64) {
			// mr r3,r26
			ctx.r3.u64 = var_r26;
			// bl 0x82585dfc
			__imp__RtlLeaveCriticalSection(ctx, base);
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
		// li r10,0
		ctx.r10.s64 = 0;
		// addi r11,r30,1112
		ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 1112;
	loc_8256EBE8:
		// lwz r9,0(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmplwi r9,0
		// beq 0x8256ec08
		if (ctx.r9.u32 != 0) {
			// lwz r9,196(r9)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 196);
			// lis r8,1
			ctx.r8.s64 = 65536;
			// rlwinm r9,r9,0,12,15
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xF0000;
			// cmplw cr6,r9,r8
			// beq cr6,0x8256ec1c
			if (ctx.r9.u32 == ctx.r8.u32) goto loc_8256EC1C;
		}
	loc_8256EC08:
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// cmplwi cr6,r10,4
		// blt cr6,0x8256ebe8
		if (ctx.r10.u32 < 4) goto loc_8256EBE8;
		// b 0x8256ec24
		// mr r3,r26
		ctx.r3.u64 = var_r26;
		// bl 0x82585dfc
		__imp__RtlLeaveCriticalSection(ctx, base);
		// mr r3,r29
		ctx.r3.u64 = var_r29;
		return;
	loc_8256EC1C:
		// li r11,1
		ctx.r11.s64 = 1;
		// stw r11,1316(r30)
		PPC_STORE_U32(var_r30 + 1316, ctx.r11.u32);
	}
loc_8256EC24:
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	return;
}

__attribute__((alias("__imp__xam_EC38_w"))) PPC_WEAK_FUNC(xam_EC38_w);
PPC_FUNC_IMPL(__imp__xam_EC38_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=112, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r29,r31,1272
	var_r29 = (uint32_t)(var_r31 + 1272);
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// bne 0x8256ec78
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256ec80
	} else {
	loc_8256EC78:
		// bl 0x825717c8
		xam_17C8_w(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256EC80:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__RtlEnterCriticalSection_EC98_h"))) PPC_WEAK_FUNC(RtlEnterCriticalSection_EC98_h);
PPC_FUNC_IMPL(__imp__RtlEnterCriticalSection_EC98_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r28,r31,1272
	var_r28 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,0(r30)
	PPC_STORE_U32(var_r30 + 0, ctx.r10.u32);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
	// cmplwi cr6,r11,0
	// ble cr6,0x8256ed40
	if (ctx.r11.u32 > 0) {
		// addi r9,r31,1128
		ctx.r9.s64 = (int64_t)(int32_t)var_r31 + 1128;
	loc_8256ECD4:
		// lwz r11,0(r9)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// ld r11,0(r11)
		ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
		// cmpldi cr6,r11,0
		// beq cr6,0x8256ed2c
		if (ctx.r11.u64 != 0) {
			// lis r12,-1057
			// lis r7,-5413
			// ori r12,r12,221
			ctx.r12.u64 = ctx.r12.u64 | 221;
			// lis r6,-1057
			// rldicr r12,r12,32,31
			ctx.r12.u64 = __builtin_rotateleft64(ctx.r12.u64, 32) & 0xFFFFFFFF00000000;
			// ori r7,r7,61168
			ctx.r7.u64 = ctx.r7.u64 | 61168;
			// oris r12,r12,60123
			ctx.r12.u64 = ctx.r12.u64 | 3940220928;
			// ori r6,r6,221
			ctx.r6.u64 = ctx.r6.u64 | 221;
			// ori r12,r12,61168
			ctx.r12.u64 = ctx.r12.u64 | 61168;
			// rldimi r7,r6,32,0
			ctx.r7.u64 = (__builtin_rotateleft64(ctx.r6.u64, 32) & 0xFFFFFFFF00000000) | (ctx.r7.u64 & 0xFFFFFFFF);
			// and r8,r11,r12
			ctx.r8.u64 = ctx.r11.u64 & ctx.r12.u64;
			// cmpld cr6,r8,r7
			// beq cr6,0x8256ed2c
			if (ctx.r8.u64 == ctx.r7.u64) goto loc_8256ED2C;
			// std r11,0(r29)
			PPC_STORE_U64(var_r29 + 0, ctx.r11.u64);
			// addi r29,r29,8
			var_r29 = (uint32_t)(var_r29 + 8);
			// lwz r11,0(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// stw r11,0(r30)
			PPC_STORE_U32(var_r30 + 0, ctx.r11.u32);
		}
	loc_8256ED2C:
		// lwz r11,8(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// cmplw cr6,r10,r11
		// blt cr6,0x8256ecd4
		if (ctx.r10.u32 < ctx.r11.u32) goto loc_8256ECD4;
	}
loc_8256ED40:
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	return;
}

__attribute__((alias("__imp__xam_ED58_w"))) PPC_WEAK_FUNC(xam_ED58_w);
PPC_FUNC_IMPL(__imp__xam_ED58_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r29,r31,1272
	var_r29 = (uint32_t)(var_r31 + 1272);
	// li r28,0
	var_r28 = 0;
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// beq 0x8256ed98
	if (ctx.r3.u32 != 0) {
		// bl 0x825718c8
		atSingleton_18C8(ctx, base);
		// mr r28,r3
		var_r28 = ctx.r3.u32;
	}
loc_8256ED98:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	return;
}

__attribute__((alias("__imp__xam_EDB0_w"))) PPC_WEAK_FUNC(xam_EDB0_w);
PPC_FUNC_IMPL(__imp__xam_EDB0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r28,r31,1272
	var_r28 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// bne 0x8256edf4
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256ee00
	} else {
	loc_8256EDF4:
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x82571070
		phInst_1070_w(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256EE00:
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_EE18"))) PPC_WEAK_FUNC(xam_EE18);
PPC_FUNC_IMPL(__imp__xam_EE18) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	// FRAME: size=160, savegprlr_24
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r24,r31,1272
	var_r24 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r24
	ctx.r3.u64 = var_r24;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r27,r7
	var_r27 = ctx.r7.u32;
	// mr r26,r8
	var_r26 = ctx.r8.u32;
	// mr r25,r9
	var_r25 = ctx.r9.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// bne 0x8256ee6c
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256ee88
	} else {
	loc_8256EE6C:
		// mr r8,r25
		ctx.r8.u64 = var_r25;
		// mr r7,r26
		ctx.r7.u64 = var_r26;
		// mr r6,r27
		ctx.r6.u64 = var_r27;
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x82571178
		xam_1178_2h(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256EE88:
	// mr r3,r24
	ctx.r3.u64 = var_r24;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_EEA0"))) PPC_WEAK_FUNC(xam_EEA0);
PPC_FUNC_IMPL(__imp__xam_EEA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r27,r31,1272
	var_r27 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// bne 0x8256eee8
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256eef8
	} else {
	loc_8256EEE8:
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x825718a0
		xam_18A0_2h(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256EEF8:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_EF10"))) PPC_WEAK_FUNC(xam_EF10);
PPC_FUNC_IMPL(__imp__xam_EF10) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r27,r31,1272
	var_r27 = (uint32_t)(var_r31 + 1272);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// bl 0x82585e0c
	__imp__RtlEnterCriticalSection(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8256e248
	xam_E248_2hr(ctx, base);
	// cmplwi r3,0
	// bne 0x8256ef58
	if (ctx.r3.u32 == 0) {
		// lis r31,-32761
		var_r31 = (uint32_t)(-2147024896);
		// ori r31,r31,87
		var_r31 = (uint32_t)(var_r31 | 87);
		// b 0x8256ef68
	} else {
	loc_8256EF58:
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// bl 0x82571850
		xam_1850_2h(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_8256EF68:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82585dfc
	__imp__RtlLeaveCriticalSection(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__nt_EF80"))) PPC_WEAK_FUNC(nt_EF80);
PPC_FUNC_IMPL(__imp__nt_EF80) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=112, manual
	// lis r11,-2
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// ori r11,r11,31072
	ctx.r11.u64 = ctx.r11.u64 | 31072;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// bl 0x8257b5a0
	nt_B5A0(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256efc4
	if ((int32_t)var_r31 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// bl 0x82566eb0
		pg_6EB0_g(ctx, base);
	}
loc_8256EFC4:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,10
	ctx.r5.s64 = 10;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x8257b538
	nt_B538(ctx, base);
	// cmpwi r3,0
	// bne 0x8256eff0
	if (ctx.r3.s32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// bl 0x82566eb0
		pg_6EB0_g(ctx, base);
	}
loc_8256EFF0:
	// lwz r3,1304(r30)
	ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 1304);
	// bl 0x82566c40
	pg_6C40_g(ctx, base);
	// b 0x8256f00c
	goto loc_8256F00C;
	do {
		// li r4,-1
		// bl 0x8242c3b8
		pg_C3B8_g(ctx, base);
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// bl 0x8256e8d8
		xam_E8D8_g(ctx, base);
		// lwz r11,1300(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 1300);
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// cmplwi cr6,r11,3
		// bne cr6,0x8256effc
	} while (ctx.r11.u32 != 3);
	// bl 0x8257b4f8
	nt_B4F8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x82566f10
	pg_6F10_g(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82566eb0
	pg_6EB0_g(ctx, base);
}

__attribute__((alias("__imp__xam_F030"))) PPC_WEAK_FUNC(xam_F030);
PPC_FUNC_IMPL(__imp__xam_F030) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r18 = 0;
	uint32_t var_r19 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f870
	ctx.lr = 0x8256F038;
	__savegprlr_18(ctx, base);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,0
	// bne cr6,0x8256f14c
	if (ctx.r11.u32 == 0) {
		// lis r18,-32169
		var_r18 = (uint32_t)(-2108227584);
		// lis r19,-32169
		var_r19 = (uint32_t)(-2108227584);
		// lis r20,-32169
		var_r20 = (uint32_t)(-2108227584);
		// lis r21,-32169
		var_r21 = (uint32_t)(-2108227584);
		// lis r22,-32169
		var_r22 = (uint32_t)(-2108227584);
		// lis r23,-32169
		var_r23 = (uint32_t)(-2108227584);
		// lis r24,-32169
		var_r24 = (uint32_t)(-2108227584);
		// lis r25,-32169
		var_r25 = (uint32_t)(-2108227584);
		// lis r26,-32169
		var_r26 = (uint32_t)(-2108227584);
		// lis r27,-32169
		var_r27 = (uint32_t)(-2108227584);
		// lis r28,-32169
		var_r28 = (uint32_t)(-2108227584);
		// lis r29,-32169
		var_r29 = (uint32_t)(-2108227584);
		// lis r30,-32169
		var_r30 = (uint32_t)(-2108227584);
		// lis r31,-32169
		var_r31 = (uint32_t)(-2108227584);
		// lis r4,-32169
		// lis r5,-32169
		// lis r6,-32169
		// lis r7,-32169
		// lis r8,-32169
		// lis r9,-32169
		// lis r10,-32169
		// lis r11,-32169
		// addi r18,r18,-10376
		var_r18 = (uint32_t)(var_r18 + -10376);
		// addi r19,r19,-6016
		var_r19 = (uint32_t)(var_r19 + -6016);
		// addi r20,r20,-8600
		var_r20 = (uint32_t)(var_r20 + -8600);
		// addi r21,r21,-8464
		var_r21 = (uint32_t)(var_r21 + -8464);
		// addi r22,r22,-8352
		var_r22 = (uint32_t)(var_r22 + -8352);
		// addi r23,r23,-5552
		var_r23 = (uint32_t)(var_r23 + -5552);
		// stw r18,0(r3)
		PPC_STORE_U32(ctx.r3.u32 + 0, var_r18);
		// addi r24,r24,-5440
		var_r24 = (uint32_t)(var_r24 + -5440);
		// stw r19,4(r3)
		PPC_STORE_U32(ctx.r3.u32 + 4, var_r19);
		// addi r25,r25,-8240
		var_r25 = (uint32_t)(var_r25 + -8240);
		// stw r20,8(r3)
		PPC_STORE_U32(ctx.r3.u32 + 8, var_r20);
		// addi r26,r26,-8200
		var_r26 = (uint32_t)(var_r26 + -8200);
		// stw r21,12(r3)
		PPC_STORE_U32(ctx.r3.u32 + 12, var_r21);
		// addi r27,r27,-8016
		var_r27 = (uint32_t)(var_r27 + -8016);
		// stw r22,16(r3)
		PPC_STORE_U32(ctx.r3.u32 + 16, var_r22);
		// addi r28,r28,-5328
		var_r28 = (uint32_t)(var_r28 + -5328);
		// stw r23,20(r3)
		PPC_STORE_U32(ctx.r3.u32 + 20, var_r23);
		// addi r29,r29,-5064
		var_r29 = (uint32_t)(var_r29 + -5064);
		// stw r24,24(r3)
		PPC_STORE_U32(ctx.r3.u32 + 24, var_r24);
		// addi r30,r30,-4968
		var_r30 = (uint32_t)(var_r30 + -4968);
		// stw r25,28(r3)
		PPC_STORE_U32(ctx.r3.u32 + 28, var_r25);
		// addi r31,r31,-7880
		var_r31 = (uint32_t)(var_r31 + -7880);
		// stw r26,32(r3)
		PPC_STORE_U32(ctx.r3.u32 + 32, var_r26);
		// addi r4,r4,-7792
		ctx.r4.s64 = ctx.r4.s64 + -7792;
		// stw r27,36(r3)
		PPC_STORE_U32(ctx.r3.u32 + 36, var_r27);
		// addi r5,r5,-4776
		ctx.r5.s64 = ctx.r5.s64 + -4776;
		// stw r28,40(r3)
		PPC_STORE_U32(ctx.r3.u32 + 40, var_r28);
		// addi r6,r6,-4688
		ctx.r6.s64 = ctx.r6.s64 + -4688;
		// stw r29,44(r3)
		PPC_STORE_U32(ctx.r3.u32 + 44, var_r29);
		// addi r7,r7,-4584
		ctx.r7.s64 = ctx.r7.s64 + -4584;
		// stw r30,48(r3)
		PPC_STORE_U32(ctx.r3.u32 + 48, var_r30);
		// addi r8,r8,-7744
		ctx.r8.s64 = ctx.r8.s64 + -7744;
		// stw r31,52(r3)
		PPC_STORE_U32(ctx.r3.u32 + 52, var_r31);
		// addi r9,r9,-7736
		ctx.r9.s64 = ctx.r9.s64 + -7736;
		// stw r4,56(r3)
		PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r4.u32);
		// addi r10,r10,-4448
		ctx.r10.s64 = ctx.r10.s64 + -4448;
		// stw r5,60(r3)
		PPC_STORE_U32(ctx.r3.u32 + 60, ctx.r5.u32);
		// addi r11,r11,-4336
		ctx.r11.s64 = ctx.r11.s64 + -4336;
		// stw r6,64(r3)
		PPC_STORE_U32(ctx.r3.u32 + 64, ctx.r6.u32);
		// stw r7,68(r3)
		PPC_STORE_U32(ctx.r3.u32 + 68, ctx.r7.u32);
		// stw r8,72(r3)
		PPC_STORE_U32(ctx.r3.u32 + 72, ctx.r8.u32);
		// stw r9,76(r3)
		PPC_STORE_U32(ctx.r3.u32 + 76, ctx.r9.u32);
		// stw r10,80(r3)
		PPC_STORE_U32(ctx.r3.u32 + 80, ctx.r10.u32);
		// stw r11,84(r3)
		PPC_STORE_U32(ctx.r3.u32 + 84, ctx.r11.u32);
	}
loc_8256F14C:
	// b 0x8242f8c0
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_F150"))) PPC_WEAK_FUNC(xam_F150);
PPC_FUNC_IMPL(__imp__xam_F150) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r25 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=160, savegprlr_24
	// lis r11,-32161
	// mr r25,r3
	var_r25 = ctx.r3.u32;
	// addi r29,r11,-22400
	var_r29 = (uint32_t)(ctx.r11.s64 + -22400);  // lbl_825EA880 @ 0x825ea880
	// mr r24,r4
	var_r24 = ctx.r4.u32;
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// lwz r30,0(r25)
	var_r30 = (uint32_t)(PPC_LOAD_U32(var_r25 + 0));
	// bl 0x8256f030
	xam_F030(ctx, base);
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// li r3,2240
	ctx.r3.s64 = 2240;
	// ori r4,r4,32780
	ctx.r4.u64 = ctx.r4.u64 | 32780;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// bne 0x8256f19c
	if ((int32_t)var_r31 == 0) {
		// lis r27,-32761
		var_r27 = (uint32_t)(-2147024896);
		// ori r27,r27,14
		var_r27 = (uint32_t)(var_r27 | 14);
		// b 0x8256f354
	} else {
	loc_8256F19C:
		// li r26,1
		var_r26 = 1;
		// stw r29,0(r31)
		PPC_STORE_U32(var_r31 + 0, var_r29);
		// addi r11,r31,8
		ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 8;
		// mr r9,r30
		ctx.r9.u64 = var_r30;
		// li r10,12
		ctx.r10.s64 = 12;
		// stw r26,4(r31)
		PPC_STORE_U32(var_r31 + 4, var_r26);
		// mtctr r10
		ctx.ctr.u64 = ctx.r10.u64;
	loc_8256F1B8:
		// lwz r10,0(r9)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// stw r10,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bdnz 0x8256f1b8
		--ctx.ctr.u64;
		if (ctx.ctr.u32 != 0) goto loc_8256F1B8;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8256da20
		game_DA20(ctx, base);
		// mr. r27,r3
		var_r27 = ctx.r3.u32;
		// blt 0x8256f348
		if ((int32_t)var_r27 >= 0) {
			// lwz r11,4(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
			// li r28,0
			var_r28 = 0;
			// cmplwi cr6,r11,0
			// ble cr6,0x8256f224
			if (ctx.r11.u32 > 0) {
				// addi r29,r31,1096
				var_r29 = (uint32_t)(var_r31 + 1096);
			loc_8256F1F4:
				// mr r6,r29
				ctx.r6.u64 = var_r29;
				// lwz r5,12(r30)
				ctx.r5.u64 = PPC_LOAD_U32(var_r30 + 12);
				// mr r3,r31
				ctx.r3.u64 = var_r31;
				// lwz r4,8(r30)
				ctx.r4.u64 = PPC_LOAD_U32(var_r30 + 8);
				// bl 0x82570a20
				xam_0A20(ctx, base);
				// mr. r27,r3
				var_r27 = ctx.r3.u32;
				// blt 0x8256f348
				if ((int32_t)var_r27 < 0) goto loc_8256F348;
				// lwz r11,4(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
				// addi r28,r28,1
				var_r28 = (uint32_t)(var_r28 + 1);
				// addi r29,r29,4
				var_r29 = (uint32_t)(var_r29 + 4);
				// cmplw cr6,r28,r11
				// blt cr6,0x8256f1f4
				if (var_r28 < ctx.r11.u32) goto loc_8256F1F4;
			}
		loc_8256F224:
			// lwz r11,0(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
			// li r28,0
			var_r28 = 0;
			// cmplwi cr6,r11,0
			// ble cr6,0x8256f270
			if (ctx.r11.u32 > 0) {
				// addi r29,r31,1128
				var_r29 = (uint32_t)(var_r31 + 1128);
			loc_8256F238:
				// mr r8,r29
				ctx.r8.u64 = var_r29;
				// lwz r7,40(r30)
				ctx.r7.u64 = PPC_LOAD_U32(var_r30 + 40);
				// mr r3,r31
				ctx.r3.u64 = var_r31;
				// lwz r6,36(r30)
				ctx.r6.u64 = PPC_LOAD_U32(var_r30 + 36);
				// lwz r5,20(r30)
				ctx.r5.u64 = PPC_LOAD_U32(var_r30 + 20);
				// lwz r4,16(r30)
				ctx.r4.u64 = PPC_LOAD_U32(var_r30 + 16);
				// bl 0x82571a40
				msgMsgSink_1A40_w(ctx, base);
				// mr. r27,r3
				var_r27 = ctx.r3.u32;
				// blt 0x8256f348
				if ((int32_t)var_r27 < 0) goto loc_8256F348;
				// lwz r11,0(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
				// addi r28,r28,1
				var_r28 = (uint32_t)(var_r28 + 1);
				// addi r29,r29,4
				var_r29 = (uint32_t)(var_r29 + 4);
				// cmplw cr6,r28,r11
				// blt cr6,0x8256f238
				if (var_r28 < ctx.r11.u32) goto loc_8256F238;
			}
		loc_8256F270:
			// li r6,0
			ctx.r6.s64 = 0;
			// li r5,0
			ctx.r5.s64 = 0;
			// li r4,0
			ctx.r4.s64 = 0;
			// li r3,0
			ctx.r3.s64 = 0;
			// bl 0x82566c88
			xam_6C88_g(ctx, base);
			// cmplwi r3,0
			// stw r3,1304(r31)
			PPC_STORE_U32(var_r31 + 1304, ctx.r3.u32);
			// bne 0x8256f29c
			if (ctx.r3.u32 == 0) {
			loc_8256F290:
				// lis r27,-32768
				var_r27 = (uint32_t)(-2147483648);
				// ori r27,r27,16389
				var_r27 = (uint32_t)(var_r27 | 16389);
				// b 0x8256f348
				goto loc_8256F348;
			}
		loc_8256F29C:
			// li r4,0
			ctx.r4.s64 = 0;
			// li r3,5
			ctx.r3.s64 = 5;
			// bl 0x8258611c
			__imp__XamNotifyCreateListener(ctx, base);
			// cmplwi r3,0
			// stw r3,1312(r31)
			PPC_STORE_U32(var_r31 + 1312, ctx.r3.u32);
			// beq 0x8256f290
			if (ctx.r3.u32 == 0) goto loc_8256F290;
			// addi r3,r31,1272
			ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 1272;
			// stw r26,1316(r31)
			PPC_STORE_U32(var_r31 + 1316, var_r26);
			// bl 0x82585ecc
			__imp__RtlInitializeCriticalSection(ctx, base);
			// lwz r11,8(r25)
			ctx.r11.u64 = PPC_LOAD_U32(var_r25 + 8);
			// cmpwi cr6,r11,0
			// bne cr6,0x8256f340
			if (ctx.r11.s32 != 0) goto loc_8256F340;
			// lis r11,-32169
			// li r9,0
			ctx.r9.s64 = 0;
			// li r8,1
			ctx.r8.s64 = 1;
			// li r7,0
			ctx.r7.s64 = 0;
			// mr r6,r31
			ctx.r6.u64 = var_r31;
			// addi r5,r11,-4224
			ctx.r5.s64 = ctx.r11.s64 + -4224;
			// lis r4,1
			ctx.r4.s64 = 65536;
			// li r3,0
			ctx.r3.s64 = 0;
			// bl 0x82568da0
			xam_8DA0_h(ctx, base);
			// cmplwi r3,0
			// stw r3,1264(r31)
			PPC_STORE_U32(var_r31 + 1264, ctx.r3.u32);
			// beq 0x8256f290
			if (ctx.r3.u32 == 0) goto loc_8256F290;
			// li r4,-1
			// lwz r3,1304(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 1304);
			// bl 0x8242c3b8
			pg_C3B8_g(ctx, base);
			// lwz r6,4(r25)
			ctx.r6.u64 = PPC_LOAD_U32(var_r25 + 4);
			// cmplwi r6,0
			// beq 0x8256f340
			if (ctx.r6.u32 != 0) {
				// li r9,0
				ctx.r9.s64 = 0;
				// lwz r4,1264(r31)
				ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 1264);
				// li r8,0
				ctx.r8.s64 = 0;
				// li r7,0
				ctx.r7.s64 = 0;
				// li r5,0
				ctx.r5.s64 = 0;
				// li r3,0
				ctx.r3.s64 = 0;
				// bl 0x8257b628
				nt_B628(ctx, base);
				// cmpwi r3,0
				// bne 0x8256f340
				if (ctx.r3.s32 != 0) goto loc_8256F340;
				// lis r27,-32768
				var_r27 = (uint32_t)(-2147483648);
				// ori r27,r27,16389
				var_r27 = (uint32_t)(var_r27 | 16389);
			}
		loc_8256F340:
			// cmpwi cr6,r27,0
			// bge cr6,0x8256f354
			if ((int32_t)var_r27 >= 0) {
				// mr r3,r27
				ctx.r3.u64 = var_r27;
				// stw r31,0(r24)
				PPC_STORE_U32(var_r24 + 0, var_r31);
				return;
			}
		}
	loc_8256F348:
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8256e880
		xam_E880_h(ctx, base);
		// li r31,0
		var_r31 = 0;
	}
loc_8256F354:
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// stw r31,0(r24)
	PPC_STORE_U32(var_r24 + 0, var_r31);
	return;
}

__attribute__((alias("__imp__aud_F368"))) PPC_WEAK_FUNC(aud_F368);
PPC_FUNC_IMPL(__imp__aud_F368) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=272, savegprlr_28
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// bne cr6,0x8256f38c
	if (var_r31 == 0) {
		// li r3,6170
		ctx.r3.s64 = 6170;
		// b 0x8256f47c
	} else {
	loc_8256F38C:
		// lwz r11,8(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
		// cmplwi cr6,r11,0
		// bne cr6,0x8256f3a0
		if (ctx.r11.u32 == 0) {
			// li r3,6130
			ctx.r3.s64 = 6130;
			// b 0x8256f47c
		} else {
		loc_8256F3A0:
			// lwz r3,0(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
			// cmplwi r3,0
			// bne 0x8256f3b4
			if (ctx.r3.u32 == 0) {
				// li r3,6125
				ctx.r3.s64 = 6125;
				// b 0x8256f47c
			} else {
			loc_8256F3B4:
				// lhz r10,14(r31)
				ctx.r10.u64 = PPC_LOAD_U16(var_r31 + 14);
				// lhz r11,12(r31)
				ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 12);
				// cmplw cr6,r10,r11
				// blt cr6,0x8256f3cc
				if (ctx.r10.u32 >= ctx.r11.u32) {
					// li r3,6145
					ctx.r3.s64 = 6145;
					// b 0x8256f47c
				} else {
				loc_8256F3CC:
					// addi r29,r31,18
					var_r29 = (uint32_t)(var_r31 + 18);
					// lhz r10,0(r29)
					ctx.r10.u64 = PPC_LOAD_U16(var_r29 + 0);
					// cmplw cr6,r10,r11
					// blt cr6,0x8256f3e4
					if (ctx.r10.u32 >= ctx.r11.u32) {
						// li r3,6150
						ctx.r3.s64 = 6150;
						// b 0x8256f47c
					} else {
					loc_8256F3E4:
						// lbz r11,16(r31)
						ctx.r11.u64 = PPC_LOAD_U8(var_r31 + 16);
						// cmplwi cr6,r11,7
						// ble cr6,0x8256f3f8
						if (ctx.r11.u32 > 7) {
							// li r3,6135
							ctx.r3.s64 = 6135;
							// b 0x8256f47c
						} else {
						loc_8256F3F8:
							// addi r30,r31,20
							var_r30 = (uint32_t)(var_r31 + 20);
							// lbz r11,0(r30)
							ctx.r11.u64 = PPC_LOAD_U8(var_r30 + 0);
							// cmplwi cr6,r11,7
							// ble cr6,0x8256f410
							if (ctx.r11.u32 > 7) {
								// li r3,6140
								ctx.r3.s64 = 6140;
								// b 0x8256f47c
							} else {
							loc_8256F410:
								// cmplwi cr6,r28,0
								// beq cr6,0x8256f478
								if (var_r28 != 0) {
									// lwz r11,0(r28)
									ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
									// cmplwi cr6,r11,64206
									// bne cr6,0x8256f478
									if (ctx.r11.u32 != 64206) goto loc_8256F478;
									// lbz r11,12(r28)
									ctx.r11.u64 = PPC_LOAD_U8(var_r28 + 12);
									// cmplwi cr6,r11,10
									// beq cr6,0x8256f438
									if (ctx.r11.u32 != 10) {
										// li r3,6110
										ctx.r3.s64 = 6110;
										// b 0x8256f47c
										return;
									}
								loc_8256F438:
									// addi r5,r1,80
									ctx.r5.s64 = ctx.r1.s64 + 80;
									// lwz r4,16(r28)
									ctx.r4.u64 = PPC_LOAD_U32(var_r28 + 16);
									// bl 0x82572488
									phBoundCapsule_2488(ctx, base);
									// addi r5,r1,80
									ctx.r5.s64 = ctx.r1.s64 + 80;
									// addi r3,r1,160
									ctx.r3.s64 = ctx.r1.s64 + 160;
									// lwz r4,16(r28)
									ctx.r4.u64 = PPC_LOAD_U32(var_r28 + 16);
									// bl 0x82571d10
									aud_1D10(ctx, base);
									// li r8,0
									ctx.r8.s64 = 0;
									// mr r6,r30
									ctx.r6.u64 = var_r30;
									// lhz r7,12(r31)
									ctx.r7.u64 = PPC_LOAD_U16(var_r31 + 12);
									// mr r5,r29
									ctx.r5.u64 = var_r29;
									// lwz r4,8(r31)
									ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 8);
									// addi r3,r1,160
									ctx.r3.s64 = ctx.r1.s64 + 160;
									// bl 0x82571ca0
									phBoundCapsule_1CA0_p39(ctx, base);
									// li r3,0
									ctx.r3.s64 = 0;
									// b 0x8256f47c
								} else {
								loc_8256F478:
									// li r3,6100
									ctx.r3.s64 = 6100;
								}
							}
						}
					}
				}
			}
		}
	}
loc_8256F47C:
	return;
}

__attribute__((alias("__imp__aud_F488"))) PPC_WEAK_FUNC(aud_F488);
PPC_FUNC_IMPL(__imp__aud_F488) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// bl 0x825681b0
	util_81B0(ctx, base);
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(var_r30 + 0);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
	// bl 0x8256f368
	aud_F368(ctx, base);
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x825681b0
	util_81B0(ctx, base);
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// ld r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lis r11,-32140
	// addi r11,r11,-25216
	ctx.r11.s64 = ctx.r11.s64 + -25216;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// cmpd cr6,r10,r9
	// bge cr6,0x8256f4e8
	if (ctx.r10.s64 < ctx.r9.s64) {
		// std r10,0(r11)
		PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	}
loc_8256F4E8:
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// cmpd cr6,r10,r9
	// ble cr6,0x8256f4f8
	if (ctx.r10.s64 > ctx.r9.s64) {
		// std r10,16(r11)
		PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r10.u64);
	}
loc_8256F4F8:
	// ld r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// std r10,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r10.u64);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r10.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_F530_p39"))) PPC_WEAK_FUNC(phBoundCapsule_F530_p39);
PPC_FUNC_IMPL(__imp__phBoundCapsule_F530_p39) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// cmplwi cr6,r28,0
	// bne cr6,0x8256f550
	if (var_r28 == 0) {
		// li r3,6170
		ctx.r3.s64 = 6170;
		// b 0x8256f5e8
	} else {
	loc_8256F550:
		// lwz r31,0(r28)
		var_r31 = (uint32_t)(PPC_LOAD_U32(var_r28 + 0));
		// cmplwi r31,0
		// beq 0x8256f5e4
		if (var_r31 != 0) {
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
			// cmplwi cr6,r11,64206
			// bne cr6,0x8256f5e4
			if (ctx.r11.u32 != 64206) goto loc_8256F5E4;
			// lbz r11,12(r31)
			ctx.r11.u64 = PPC_LOAD_U8(var_r31 + 12);
			// cmplwi cr6,r11,10
			// beq cr6,0x8256f57c
			if (ctx.r11.u32 != 10) {
				// li r3,6115
				ctx.r3.s64 = 6115;
				// b 0x8256f5e8
				return;
			}
		loc_8256F57C:
			// li r29,0
			var_r29 = 0;
			// addi r3,r31,16
			ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 16;
			// stw r29,0(r31)
			PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ var_r29);
			// bl 0x82571ed8
			phBoundCapsule_1ED8_p33(ctx, base);
			// lwz r3,36(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 36);
			// lis r30,-32161
			var_r30 = (uint32_t)(-2107703296);
			// cmplwi r3,0
			// beq 0x8256f5ac
			if (ctx.r3.u32 != 0) {
				// lwz r11,-22268(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
				// bctrl
				PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
				// stw r29,36(r31)
				PPC_STORE_U32(var_r31 + 36, var_r29);
			}
		loc_8256F5AC:
			// lwz r3,40(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 40);
			// cmplwi r3,0
			// beq 0x8256f5c8
			if (ctx.r3.u32 != 0) {
				// lwz r11,-22268(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
				// bctrl
				PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
				// stw r29,40(r31)
				PPC_STORE_U32(var_r31 + 40, var_r29);
			}
		loc_8256F5C8:
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// li r3,0
			ctx.r3.s64 = 0;
			// stw r29,0(r28)
			PPC_STORE_U32(var_r28 + 0, var_r29);
			// b 0x8256f5e8
		} else {
		loc_8256F5E4:
			// li r3,6100
			ctx.r3.s64 = 6100;
		}
	}
loc_8256F5E8:
	return;
}

__attribute__((alias("__imp__thunk_fn_8256F530"))) PPC_WEAK_FUNC(thunk_fn_8256F530);
PPC_FUNC_IMPL(__imp__thunk_fn_8256F530) {
	PPC_FUNC_PROLOGUE();
	// b 0x8256f530
	phBoundCapsule_F530_p39(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_F5F8_p39"))) PPC_WEAK_FUNC(phBoundCapsule_F5F8_p39);
PPC_FUNC_IMPL(__imp__phBoundCapsule_F5F8_p39) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// bne cr6,0x8256f61c
	if (var_r31 == 0) {
		// li r3,6170
		ctx.r3.s64 = 6170;
		// b 0x8256f6fc
	} else {
	loc_8256F61C:
		// li r11,0
		ctx.r11.s64 = 0;
		// lis r10,-32161
		// stw r11,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
		// lwz r11,-22272(r10)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22272);
		// cmplwi cr6,r11,0
		// beq cr6,0x8256f6f8
		if (ctx.r11.u32 != 0) {
			// lis r11,-32161
			ctx.r11.s64 = -2107703296;
			// lwz r11,-22268(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22268);
			// cmplwi cr6,r11,0
			// beq cr6,0x8256f6f8
			if (!(ctx.r11.u32 == 0)) {
				// lis r11,-32161
				ctx.r11.s64 = -2107703296;
				// lwz r11,-22264(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22264);
			} else {
				if (!(ctx.r11.u32 == 0)) {
					// lis r11,-32161
					ctx.r11.s64 = -2107703296;
					// lwz r11,-22260(r11)
					ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22260);
				} else {
					if (!(ctx.r11.u32 == 0)) {
						// lis r11,-32161
						ctx.r11.s64 = -2107703296;
						// lwz r11,-22256(r11)
						ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22256);
					} else {
						if (!(ctx.r11.u32 == 0)) {
							// lis r11,-32161
							ctx.r11.s64 = -2107703296;
							// lwz r11,-22252(r11)
							ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22252);
						} else {
							if (!(ctx.r11.u32 == 0)) {
								// lwz r11,-22272(r10)
								ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22272);
								// li r4,44
								ctx.r4.s64 = 44;
								// li r3,1
								ctx.r3.s64 = 1;
								// bctrl
								PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
								// mr. r11,r3
								ctx.r11.u64 = ctx.r3.u64;
								// bne 0x8256f6a8
								if (ctx.r11.s32 == 0) {
								loc_8256F6A0:
								// li r3,6000
								ctx.r3.s64 = 6000;
								// b 0x8256f6fc
								// blr
								return;
								}
								loc_8256F6A8:
								// lis r9,0
								ctx.r9.s64 = 0;
								// stw r11,0(r31)
								PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
								// li r10,10
								ctx.r10.s64 = 10;
								// lwz r4,24(r11)
								ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
								// ori r9,r9,64206
								ctx.r9.u64 = ctx.r9.u64 | 64206;
								// li r8,100
								ctx.r8.s64 = 100;
								// li r7,3000
								ctx.r7.s64 = 3000;
								// addi r3,r11,16
								ctx.r3.s64 = ctx.r11.s64 + 16;
								// stb r10,12(r11)
								PPC_STORE_U8(ctx.r11.u32 + 12, ctx.r10.u8);
								// stw r9,0(r11)
								PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
								// stw r8,4(r11)
								PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r8.u32);
								// stw r7,8(r11)
								PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r7.u32);
								// bl 0x82571da8
								phBoundCapsule_1DA8_p33(ctx, base);
								// clrlwi. r11,r3,16
								ctx.r11.u64 = ctx.r3.u32 & 0xFFFF;
								// beq 0x8256f6f0
								if (ctx.r11.s32 == 0) goto loc_8256F6F0;
								// mr r3,r31
								ctx.r3.u64 = var_r31;
								// bl 0x8256f530
								phBoundCapsule_F530_p39(ctx, base);
								// b 0x8256f6a0
								// li r3,6000
								ctx.r3.s64 = 6000;
								// b 0x8256f6fc
								// blr
								return;
								loc_8256F6F0:
								// li r3,0
								ctx.r3.s64 = 0;
								// b 0x8256f6fc
								} else {
							}
						}
					}
				}
			}
		loc_8256F6F8:
			// li r3,6001
			ctx.r3.s64 = 6001;
		}
	}
loc_8256F6FC:
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_F710_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_F710_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_F710_2hr) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32140
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,-25216
	ctx.r11.s64 = ctx.r11.s64 + -25216;
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// std r10,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r10.u64);
	// std r10,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r10.u64);
	// std r10,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r10.u64);
	// std r10,32(r11)
	PPC_STORE_U64(ctx.r11.u32 + 32, ctx.r10.u64);
	// lis r10,15258
	ctx.r10.s64 = 999948288;
	// ori r10,r10,51712
	ctx.r10.u64 = ctx.r10.u64 | 51712;
	// std r10,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	// b 0x8256f5f8
	phBoundCapsule_F5F8_p39(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_F740_2hr"))) PPC_WEAK_FUNC(xam_F740_2hr);
PPC_FUNC_IMPL(__imp__xam_F740_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// FRAME: size=240, manual
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// mr r31,r5
	var_r31 = ctx.r5.u32;
	// cmplwi cr6,r7,0
	// beq cr6,0x8256f890
	if (ctx.r7.u32 != 0) {
		// lwz r11,0(r7)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
		// cmplwi cr6,r11,64206
		// bne cr6,0x8256f890
		if (ctx.r11.u32 != 64206) goto loc_8256F890;
		// lbz r11,12(r7)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 12);
		// cmplwi cr6,r11,11
		// beq cr6,0x8256f784
		if (ctx.r11.u32 != 11) {
			// li r3,6115
			ctx.r3.s64 = 6115;
			// b 0x8256f894
			// blr
			return;
		}
	loc_8256F784:
		// cmplwi cr6,r4,0
		// bne cr6,0x8256f794
		if (ctx.r4.u32 == 0) {
			// li r3,6170
			ctx.r3.s64 = 6170;
			// b 0x8256f894
			// blr
			return;
		}
	loc_8256F794:
		// lwz r11,8(r4)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
		// cmplwi cr6,r11,0
		// bne cr6,0x8256f7a8
		if (ctx.r11.u32 == 0) {
			// li r3,6130
			ctx.r3.s64 = 6130;
			// b 0x8256f894
			// blr
			return;
		}
	loc_8256F7A8:
		// lwz r11,0(r4)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// cmplwi cr6,r11,0
		// bne cr6,0x8256f7bc
		if (ctx.r11.u32 == 0) {
			// li r3,6125
			ctx.r3.s64 = 6125;
			// b 0x8256f894
			// blr
			return;
		}
	loc_8256F7BC:
		// addi r8,r4,14
		ctx.r8.s64 = ctx.r4.s64 + 14;
		// lhz r11,12(r4)
		ctx.r11.u64 = PPC_LOAD_U16(ctx.r4.u32 + 12);
		// lhz r10,0(r8)
		ctx.r10.u64 = PPC_LOAD_U16(ctx.r8.u32 + 0);
		// cmplw cr6,r10,r11
		// blt cr6,0x8256f7d8
		if (ctx.r10.u32 >= ctx.r11.u32) {
			// li r3,6145
			ctx.r3.s64 = 6145;
			// b 0x8256f894
			// blr
			return;
		}
	loc_8256F7D8:
		// lhz r10,18(r4)
		ctx.r10.u64 = PPC_LOAD_U16(ctx.r4.u32 + 18);
		// cmplw cr6,r10,r11
		// blt cr6,0x8256f7ec
		if (ctx.r10.u32 >= ctx.r11.u32) {
			// li r3,6150
			ctx.r3.s64 = 6150;
			// b 0x8256f894
			// blr
			return;
		}
	loc_8256F7EC:
		// addi r9,r4,16
		ctx.r9.s64 = ctx.r4.s64 + 16;
		// lbz r11,0(r9)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
		// cmplwi cr6,r11,7
		// ble cr6,0x8256f804
		if (ctx.r11.u32 > 7) {
			// li r3,6135
			ctx.r3.s64 = 6135;
			// b 0x8256f894
			// blr
			return;
		}
	loc_8256F804:
		// lbz r11,20(r4)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 20);
		// cmplwi cr6,r11,7
		// ble cr6,0x8256f818
		if (ctx.r11.u32 > 7) {
			// li r3,6140
			ctx.r3.s64 = 6140;
			// b 0x8256f894
			// blr
			return;
		}
	loc_8256F818:
		// addi r11,r1,96
		ctx.r11.s64 = ctx.r1.s64 + 96;
		// lwz r3,16(r7)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + 16);
		// addi r30,r1,160
		var_r30 = (uint32_t)(ctx.r1.s64 + 160);
		// stw r4,28(r7)
		PPC_STORE_U32(ctx.r7.u32 + 28, ctx.r4.u32);
		// addi r5,r4,4
		ctx.r5.s64 = ctx.r4.s64 + 4;
		// lhz r7,12(r4)
		ctx.r7.u64 = PPC_LOAD_U16(ctx.r4.u32 + 12);
		// addi r10,r1,112
		ctx.r10.s64 = ctx.r1.s64 + 112;
		// lwz r6,8(r4)
		ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
		// lwz r4,0(r4)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// stw r11,92(r1)
		PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
		// stw r30,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, var_r30);
		// bl 0x82572888
		phBoundCapsule_2888_h(ctx, base);
		// cmplwi cr6,r31,0
		// beq cr6,0x8256f888
		if (var_r31 != 0) {
			// lfs f0,96(r1)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
			ctx.f0.f64 = double(temp.f32);
			// addi r10,r31,52
			ctx.r10.s64 = (int64_t)(int32_t)var_r31 + 52;
			// stfs f0,0(r31)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(var_r31 + 0, temp.u32);
			// li r11,0
			ctx.r11.s64 = 0;
		loc_8256F860:
			// addi r9,r1,160
			ctx.r9.s64 = ctx.r1.s64 + 160;
			// addi r8,r1,112
			ctx.r8.s64 = ctx.r1.s64 + 112;
			// lfsx f0,r11,r9
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
			ctx.f0.f64 = double(temp.f32);
			// lfsx f13,r11,r8
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
			ctx.f13.f64 = double(temp.f32);
			// addi r11,r11,4
			ctx.r11.s64 = ctx.r11.s64 + 4;
			// stfs f0,-48(r10)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r10.u32 + -48, temp.u32);
			// stfs f13,0(r10)
			temp.f32 = float(ctx.f13.f64);
			PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
			// cmpwi cr6,r11,48
			// addi r10,r10,4
			ctx.r10.s64 = ctx.r10.s64 + 4;
			// blt cr6,0x8256f860
			if (ctx.r11.s32 < 48) goto loc_8256F860;
		}
	loc_8256F888:
		// li r3,0
		ctx.r3.s64 = 0;
		// b 0x8256f894
	} else {
	loc_8256F890:
		// li r3,6100
		ctx.r3.s64 = 6100;
	}
loc_8256F894:
	// blr
	return;
}

__attribute__((alias("__imp__xam_F8B0_h"))) PPC_WEAK_FUNC(xam_F8B0_h);
PPC_FUNC_IMPL(__imp__xam_F8B0_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// bl 0x825681b0
	util_81B0(ctx, base);
	// lwz r5,0(r29)
	ctx.r5.u64 = PPC_LOAD_U32(var_r29 + 0);
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(var_r30 + 0);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
	// bl 0x8256f740
	xam_F740_2hr(ctx, base);
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x825681b0
	util_81B0(ctx, base);
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// ld r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// lis r11,-32161
	// addi r11,r11,-22312
	ctx.r11.s64 = ctx.r11.s64 + -22312;
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// cmpd cr6,r10,r9
	// bge cr6,0x8256f910
	if (ctx.r10.s64 < ctx.r9.s64) {
		// std r10,0(r11)
		PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r10.u64);
	}
loc_8256F910:
	// ld r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// cmpd cr6,r10,r9
	// ble cr6,0x8256f920
	if (ctx.r10.s64 > ctx.r9.s64) {
		// std r10,16(r11)
		PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r10.u64);
	}
loc_8256F920:
	// ld r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// std r10,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r10.u64);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r10.u32);
	return;
}

__attribute__((alias("__imp__xam_F948_2hr"))) PPC_WEAK_FUNC(xam_F948_2hr);
PPC_FUNC_IMPL(__imp__xam_F948_2hr) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// li r3,0
	ctx.r3.s64 = 0;
	// lhz r11,92(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 92);
	// stb r11,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r11.u8);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_F960_p33"))) PPC_WEAK_FUNC(phBoundCapsule_F960_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_F960_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, savegprlr_29
	// cmplwi cr6,r3,0
	// bne cr6,0x8256f97c
	if (ctx.r3.u32 == 0) {
		// li r3,6170
		ctx.r3.s64 = 6170;
		// b 0x8256fa10
	} else {
	loc_8256F97C:
		// lwz r31,0(r3)
		var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */);
		// cmplwi r31,0
		// beq 0x8256fa0c
		if (var_r31 != 0) {
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
			// cmplwi cr6,r11,64206
			// bne cr6,0x8256fa0c
			if (ctx.r11.u32 != 64206) goto loc_8256FA0C;
			// lbz r11,12(r31)
			ctx.r11.u64 = PPC_LOAD_U8(var_r31 + 12);
			// cmplwi cr6,r11,11
			// beq cr6,0x8256f9a8
			if (ctx.r11.u32 != 11) {
				// li r3,6115
				ctx.r3.s64 = 6115;
				// b 0x8256fa10
				return;
			}
		loc_8256F9A8:
			// li r29,0
			var_r29 = 0;
			// addi r3,r31,16
			ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 16;
			// stw r29,0(r31)
			PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ var_r29);
			// bl 0x82572c50
			phBoundCapsule_2C50_p33(ctx, base);
			// lwz r3,36(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 36);
			// lis r30,-32161
			var_r30 = (uint32_t)(-2107703296);
			// cmplwi r3,0
			// beq 0x8256f9d8
			if (ctx.r3.u32 != 0) {
				// lwz r11,-22268(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
				// bctrl
				PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
				// stw r29,36(r31)
				PPC_STORE_U32(var_r31 + 36, var_r29);
			}
		loc_8256F9D8:
			// lwz r3,40(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 40);
			// cmplwi r3,0
			// beq 0x8256f9f4
			if (ctx.r3.u32 != 0) {
				// lwz r11,-22268(r30)
				ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
				// bctrl
				PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
				// stw r29,40(r31)
				PPC_STORE_U32(var_r31 + 40, var_r29);
			}
		loc_8256F9F4:
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// li r3,0
			ctx.r3.s64 = 0;
			// b 0x8256fa10
		} else {
		loc_8256FA0C:
			// li r3,6100
			ctx.r3.s64 = 6100;
		}
	}
loc_8256FA10:
	return;
}

__attribute__((alias("__imp__thunk_fn_8256F960"))) PPC_WEAK_FUNC(thunk_fn_8256F960);
PPC_FUNC_IMPL(__imp__thunk_fn_8256F960) {
	PPC_FUNC_PROLOGUE();
	// b 0x8256f960
	phBoundCapsule_F960_p33(ctx, base);
	return;
}

__attribute__((alias("__imp__rage_FA20"))) PPC_WEAK_FUNC(rage_FA20);
PPC_FUNC_IMPL(__imp__rage_FA20) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// bne cr6,0x8256fa48
	if (var_r31 == 0) {
		// li r3,6170
		ctx.r3.s64 = 6170;
		// b 0x8256fb4c
	} else {
	loc_8256FA48:
		// li r30,0
		var_r30 = 0;
		// lis r10,-32161
		// stw r30,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* rage_GameObject::vtable@+0x0 */ var_r30);
		// lwz r11,-22272(r10)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22272);
		// cmplwi cr6,r11,0
		// beq cr6,0x8256fb48
		if (ctx.r11.u32 != 0) {
			// lis r11,-32161
			ctx.r11.s64 = -2107703296;
			// lwz r11,-22268(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22268);
			// cmplwi cr6,r11,0
			// beq cr6,0x8256fb48
			if (!(ctx.r11.u32 == 0)) {
				// lis r11,-32161
				ctx.r11.s64 = -2107703296;
				// lwz r11,-22264(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22264);
			} else {
				if (!(ctx.r11.u32 == 0)) {
					// lis r11,-32161
					ctx.r11.s64 = -2107703296;
					// lwz r11,-22260(r11)
					ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22260);
				} else {
					if (!(ctx.r11.u32 == 0)) {
						// lis r11,-32161
						ctx.r11.s64 = -2107703296;
						// lwz r11,-22256(r11)
						ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22256);
					} else {
						if (!(ctx.r11.u32 == 0)) {
							// lis r11,-32161
							ctx.r11.s64 = -2107703296;
							// lwz r11,-22252(r11)
							ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22252);
						} else {
							if (!(ctx.r11.u32 == 0)) {
								// lwz r11,-22272(r10)
								ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22272);
								// li r4,44
								ctx.r4.s64 = 44;
								// li r3,1
								ctx.r3.s64 = 1;
								// bctrl
								PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
								// mr. r11,r3
								ctx.r11.u64 = ctx.r3.u64;
								// bne 0x8256fad4
								if (ctx.r11.s32 == 0) {
								loc_8256FACC:
								// li r3,6000
								ctx.r3.s64 = 6000;
								// b 0x8256fb4c
								// blr
								return;
								}
								loc_8256FAD4:
								// lis r9,0
								ctx.r9.s64 = 0;
								// stw r11,0(r31)
								PPC_STORE_U32(var_r31 + 0,/* rage_GameObject::vtable@+0x0 */ ctx.r11.u32);
								// li r10,11
								ctx.r10.s64 = 11;
								// ori r9,r9,64206
								ctx.r9.u64 = ctx.r9.u64 | 64206;
								// addi r3,r11,16
								ctx.r3.s64 = ctx.r11.s64 + 16;
								// stb r10,12(r11)
								PPC_STORE_U8(ctx.r11.u32 + 12, ctx.r10.u8);
								// stw r9,0(r11)
								PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
								// bl 0x82572a80
								phBoundCapsule_2A80_p33(ctx, base);
								// clrlwi. r11,r3,16
								ctx.r11.u64 = ctx.r3.u32 & 0xFFFF;
								// beq 0x8256fb08
								if (ctx.r11.s32 == 0) goto loc_8256FB08;
								// mr r3,r31
								ctx.r3.u64 = var_r31;
								// bl 0x8256f960
								phBoundCapsule_F960_p33(ctx, base);
								// b 0x8256facc
								// li r3,6000
								ctx.r3.s64 = 6000;
								// b 0x8256fb4c
								// blr
								return;
								loc_8256FB08:
								// lis r11,-32161
								// addi r3,r1,80
								ctx.r3.s64 = ctx.r1.s64 + 80;
								// addi r31,r11,-22312
								var_r31 = (uint32_t)(ctx.r11.s64 + -22312);  // lbl_825EA8D8 @ 0x825ea8d8
								// lis r11,15258
								ctx.r11.s64 = 999948288;
								// ori r11,r11,51712
								ctx.r11.u64 = ctx.r11.u64 | 51712;
								// std r30,0(r31)
								PPC_STORE_U64(var_r31 + 0, var_r30);
								// std r30,8(r31)
								PPC_STORE_U64(var_r31 + 8, var_r30);
								// std r30,16(r31)
								PPC_STORE_U64(var_r31 + 16, var_r30);
								// std r30,24(r31)
								PPC_STORE_U64(var_r31 + 24, var_r30);
								// std r30,32(r31)
								PPC_STORE_U64(var_r31 + 32, var_r30);
								// std r11,0(r31)
								PPC_STORE_U64(var_r31 + 0, ctx.r11.u64);
								// bl 0x82568800
								rage_8800(ctx, base);
								// ld r11,80(r1)
								ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
								// li r3,0
								ctx.r3.s64 = 0;
								// stw r11,32(r31)
								PPC_STORE_U32(var_r31 + 32, ctx.r11.u32);
								// b 0x8256fb4c
								} else {
							}
						}
					}
				}
			}
		loc_8256FB48:
			// li r3,6001
			ctx.r3.s64 = 6001;
		}
	}
loc_8256FB4C:
	// blr
	return;
}

__attribute__((alias("__imp__thunk_fn_8256FA20"))) PPC_WEAK_FUNC(thunk_fn_8256FA20);
PPC_FUNC_IMPL(__imp__thunk_fn_8256FA20) {
	PPC_FUNC_PROLOGUE();
	// b 0x8256fa20
	rage_FA20(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_FB70_2h"))) PPC_WEAK_FUNC(phBoundCapsule_FB70_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_FB70_2h) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32161
	ctx.r11.s64 = -2107703296;
	// stw r3,-22272(r11)
	PPC_STORE_U32(ctx.r11.u32 + -22272, ctx.r3.u32);  /* glob:lbl_825EA900 @ 0x825ea900 */
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_FB80_2h"))) PPC_WEAK_FUNC(phBoundCapsule_FB80_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_FB80_2h) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32161
	ctx.r11.s64 = -2107703296;
	// stw r3,-22268(r11)
	PPC_STORE_U32(ctx.r11.u32 + -22268, ctx.r3.u32);  /* glob:lbl_825EA904 @ 0x825ea904 */
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_FB90_2h"))) PPC_WEAK_FUNC(phBoundCapsule_FB90_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_FB90_2h) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32161
	ctx.r11.s64 = -2107703296;
	// stw r3,-22264(r11)
	PPC_STORE_U32(ctx.r11.u32 + -22264, ctx.r3.u32);  /* glob:lbl_825EA908 @ 0x825ea908 */
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_FBA0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_FBA0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_FBA0_2h) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32161
	ctx.r11.s64 = -2107703296;
	// stw r3,-22260(r11)
	PPC_STORE_U32(ctx.r11.u32 + -22260, ctx.r3.u32);  /* glob:lbl_825EA90C @ 0x825ea90c */
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_FBB0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_FBB0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_FBB0_2h) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32161
	ctx.r11.s64 = -2107703296;
	// stw r3,-22256(r11)
	PPC_STORE_U32(ctx.r11.u32 + -22256, ctx.r3.u32);  /* glob:lbl_825EA910 @ 0x825ea910 */
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_FBC0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_FBC0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_FBC0_2h) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32161
	ctx.r11.s64 = -2107703296;
	// stw r3,-22252(r11)
	PPC_STORE_U32(ctx.r11.u32 + -22252, ctx.r3.u32);  /* glob:lbl_825EA914 @ 0x825ea914 */
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_vfn_12"))) PPC_WEAK_FUNC(phBoundCapsule_vfn_12);
PPC_FUNC_IMPL(__imp__phBoundCapsule_vfn_12) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,192(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 192);
	// blr
	return;
}

__attribute__((alias("__imp__xam_FBD8"))) PPC_WEAK_FUNC(xam_FBD8);
PPC_FUNC_IMPL(__imp__xam_FBD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// li r29,0
	var_r29 = 0;
	// lwz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 32);
	// cmplwi cr6,r11,0
	// ble cr6,0x8256fc30
	if (ctx.r11.u32 > 0) {
		// addi r31,r30,12
		var_r31 = (uint32_t)(var_r30 + 12);
	loc_8256FC00:
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r11,24(r11)
		// bctrl
		VCALL(ctx.r3.u32, 6, ctx, base);  // vtable slot 6 (byte +24)
		// cmplw cr6,r28,r3
		// beq cr6,0x8256fc3c
		if (var_r28 == ctx.r3.u32) {
			// addi r11,r29,3
			ctx.r11.s64 = (int64_t)(int32_t)var_r29 + 3;
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// lwzx r3,r11,r30
			ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r30);
			// b 0x8256fc34
			return;
		}
		// lwz r11,32(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 32);
		// addi r29,r29,1
		var_r29 = (uint32_t)(var_r29 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// cmplw cr6,r29,r11
		// blt cr6,0x8256fc00
		if (var_r29 < ctx.r11.u32) goto loc_8256FC00;
	}
loc_8256FC30:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8256FC34:
	return;
}

__attribute__((alias("__imp__xam_FC50"))) PPC_WEAK_FUNC(xam_FC50);
PPC_FUNC_IMPL(__imp__xam_FC50) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// FRAME: size=416, savegprlr_27
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r28,0
	var_r28 = 0;
	// mr r27,r28
	var_r27 = (uint32_t)(var_r28);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
	// bl 0x825867dc
	__imp__XamVoiceHeadsetPresent(ctx, base);
	// lwz r11,192(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 192);
	// cmpwi r11,0
	// beq 0x8256fc84
	if (ctx.r11.s32 != 0) {
		// cmpwi cr6,r3,0
		// beq cr6,0x8256fc94
		if (ctx.r3.s32 == 0) goto loc_8256FC94;
	}
loc_8256FC84:
	// cmpwi cr6,r11,0
	// bne cr6,0x8256fc98
	if (ctx.r11.s32 == 0) {
		// cmpwi cr6,r3,0
		// beq cr6,0x8256fc98
		if (ctx.r3.s32 == 0) goto loc_8256FC98;
	loc_8256FC94:
		// li r27,1
		var_r27 = 1;
	}
loc_8256FC98:
	// lwz r11,144(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 144);
	// stw r3,192(r31)
	PPC_STORE_U32(var_r31 + 192, ctx.r3.u32);
	// lwz r11,1316(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1316);
	// cmpwi cr6,r11,0
	// bne cr6,0x8256fcb8
	if (ctx.r11.s32 == 0) {
		// lwz r11,188(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 188);
		// cmpwi cr6,r11,0
		// beq cr6,0x8256fe34
		if (ctx.r11.s32 == 0) goto loc_8256FE34;
	}
loc_8256FCB8:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
	// bl 0x825867cc
	__imp__XamUserGetSigninState(ctx, base);
	// lwz r11,188(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 188);
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// cmpwi cr6,r11,0
	// beq cr6,0x8256fe74
	if (ctx.r11.s32 != 0) {
		// addi r30,r31,148
		var_r30 = (uint32_t)(var_r31 + 148);
		// li r5,0
		ctx.r5.s64 = 0;
		// li r4,0
		ctx.r4.s64 = 0;
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// bl 0x8242bf18
		pg_BF18_g(ctx, base);
		// cmpwi cr6,r29,0
		// beq cr6,0x8256fe08
		if ((int32_t)var_r29 != 0) {
			// cmplwi cr6,r3,0
			// bne cr6,0x8256fe08
			if (ctx.r3.u32 != 0) goto loc_8256FE08;
			// lwz r11,176(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 176);
			// mr r8,r28
			ctx.r8.u64 = var_r28;
			// stw r28,188(r31)
			PPC_STORE_U32(var_r31 + 188, var_r28);
			// lwz r11,0(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			// cmplwi cr6,r11,0
			// ble cr6,0x8256fe34
			if (ctx.r11.u32 <= 0) goto loc_8256FE34;
			// mr r9,r28
			ctx.r9.u64 = var_r28;
		loc_8256FD10:
			// lwz r11,176(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 176);
			// lwz r11,4(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// add r11,r11,r9
			ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
			// lwz r10,16(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
			// addis r10,r10,-4100
			ctx.r10.s64 = ctx.r10.s64 + -268697600;
			// addic. r10,r10,-12
			ctx.xer.ca = ctx.r10.u32 > 11;
			ctx.r10.s64 = ctx.r10.s64 + -12;
			// beq 0x8256fdcc
			if (ctx.r10.s32 != 0) {
				// cmplwi cr6,r10,1
				// beq cr6,0x8256fd8c
				if (ctx.r10.u32 != 1) {
					// cmplwi cr6,r10,2
					// bne cr6,0x8256fdec
					if (ctx.r10.u32 != 2) goto loc_8256FDEC;
					// lwz r10,32(r11)
					ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
					// cmpwi cr6,r10,100
					// ble cr6,0x8256fd50
					if (ctx.r10.s32 > 100) {
						// li r10,100
						ctx.r10.s64 = 100;
						// stw r10,32(r11)
						PPC_STORE_U32(ctx.r11.u32 + 32, ctx.r10.u32);
					}
				loc_8256FD50:
					// lwa r10,32(r11)
					ctx.r10.s64 = int32_t(PPC_LOAD_U32(ctx.r11.u32 + 32));
					// lfs f0,184(r31)
					ctx.fpscr.disableFlushMode();
					temp.u32 = PPC_LOAD_U32(var_r31 + 184);
					ctx.f0.f64 = double(temp.f32);
					// std r10,104(r1)
					PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
					// lfd f13,104(r1)
					ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
					// fcfid f13,f13
					ctx.f13.f64 = double(ctx.f13.s64);
					// frsp f13,f13
					ctx.f13.f64 = double(float(ctx.f13.f64));
					// fcmpu cr6,f13,f0
					// beq cr6,0x8256fdec
					if (ctx.f13.f64 == ctx.f0.f64) goto loc_8256FDEC;
					// stb r28,198(r31)
					PPC_STORE_U8(var_r31 + 198, (uint8_t)var_r28);
					// li r27,1
					var_r27 = 1;
					// lwz r11,32(r11)
					ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
					// lwz r10,196(r31)
					ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 196);
					// rlwinm r11,r11,8,0,23
					ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFFFFFF00;
					// or r11,r11,r10
					ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
					// b 0x8256fde8
					goto loc_8256FDE8;
				}
			loc_8256FD8C:
				// lwz r10,32(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
				// cmpwi cr6,r10,0
				// lwz r10,196(r31)
				ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 196);
				// beq cr6,0x8256fda4
				if (ctx.r10.s32 != 0) {
					// ori r10,r10,2
					ctx.r10.u64 = ctx.r10.u64 | 2;
					// b 0x8256fda8
				} else {
				loc_8256FDA4:
					// rlwinm r10,r10,0,31,29
					ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
				}
			loc_8256FDA8:
				// stw r10,196(r31)
				PPC_STORE_U32(var_r31 + 196, ctx.r10.u32);
				// lwz r11,32(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
				// cmpwi cr6,r11,1
				// rotlwi r11,r10,0
				ctx.r11.u64 = ctx.r10.u32;
				// beq cr6,0x8256fdc4
				if (ctx.r11.s32 != 1) {
					// ori r11,r11,4
					ctx.r11.u64 = ctx.r11.u64 | 4;
					// b 0x8256fde8
					goto loc_8256FDE8;
				}
			loc_8256FDC4:
				// rlwinm r11,r11,0,30,28
				ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
				// b 0x8256fde8
			} else {
			loc_8256FDCC:
				// lwz r11,32(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
				// cmpwi cr6,r11,0
				// lwz r11,196(r31)
				ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 196);
				// beq cr6,0x8256fde4
				if (ctx.r11.s32 != 0) {
					// ori r11,r11,1
					ctx.r11.u64 = ctx.r11.u64 | 1;
					// b 0x8256fde8
				} else {
				loc_8256FDE4:
					// rlwinm r11,r11,0,0,30
					ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
				}
			}
		loc_8256FDE8:
			// stw r11,196(r31)
			PPC_STORE_U32(var_r31 + 196, ctx.r11.u32);
		loc_8256FDEC:
			// lwz r11,176(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 176);
			// addi r8,r8,1
			ctx.r8.s64 = ctx.r8.s64 + 1;
			// addi r9,r9,40
			ctx.r9.s64 = ctx.r9.s64 + 40;
			// lwz r11,0(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			// cmplw cr6,r8,r11
			// blt cr6,0x8256fd10
			if (ctx.r8.u32 < ctx.r11.u32) goto loc_8256FD10;
			// b 0x8256fe34
			goto loc_8256FE34;
		}
	loc_8256FE08:
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmplwi cr6,r11,997
		// beq cr6,0x8256fe34
		if (ctx.r11.u32 == 997) goto loc_8256FE34;
		// stw r28,188(r31)
		PPC_STORE_U32(var_r31 + 188, var_r28);
	loc_8256FE18:
		// lis r11,2
		ctx.r11.s64 = 131072;
		// lwz r10,196(r31)
		ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 196);
		// ori r11,r11,25604
		ctx.r11.u64 = ctx.r11.u64 | 25604;
		// cmplw cr6,r10,r11
		// beq cr6,0x8256fe34
		if (ctx.r10.u32 == ctx.r11.u32) goto loc_8256FE34;
	loc_8256FE2C:
		// li r27,1
		var_r27 = 1;
		// stw r11,196(r31)
		PPC_STORE_U32(var_r31 + 196, ctx.r11.u32);
	loc_8256FE34:
		// cmpwi cr6,r27,1
		// bne cr6,0x8256fe6c
		if ((int32_t)var_r27 == 1) {
			// lbz r11,198(r31)
			ctx.r11.u64 = PPC_LOAD_U8(var_r31 + 198);
			// mr r4,r31
			ctx.r4.u64 = var_r31;
			// lwz r3,144(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 144);
			// std r11,104(r1)
			PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
			// lis r11,-32256
			// lfd f0,104(r1)
			ctx.fpscr.disableFlushMode();
			ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
			// fcfid f0,f0
			ctx.f0.f64 = double(ctx.f0.s64);
			// frsp f13,f0
			ctx.f13.f64 = double(float(ctx.f0.f64));
			// lfs f0,18992(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 18992);
			ctx.f0.f64 = double(temp.f32);
			// fmuls f0,f13,f0
			ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
			// stfs f0,184(r31)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(var_r31 + 184, temp.u32);
			// bl 0x8256e5b0
			phBoundCapsule_E5B0_h(ctx, base);
		}
	loc_8256FE6C:
		return;
	}
loc_8256FE74:
	// cmpwi cr6,r29,0
	// beq cr6,0x8256fe18
	if ((int32_t)var_r29 == 0) goto loc_8256FE18;
	// addi r5,r31,148
	ctx.r5.s64 = (int64_t)(int32_t)var_r31 + 148;
	// lwz r10,176(r31)
	ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 176);
	// lis r11,-32164
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 0);
	// lis r3,-2
	// addi r8,r11,9836
	ctx.r8.s64 = ctx.r11.s64 + 9836;
	// addi r9,r31,180
	ctx.r9.s64 = (int64_t)(int32_t)var_r31 + 180;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// ori r3,r3,2001
	ctx.r3.u64 = ctx.r3.u64 | 2001;
	// bl 0x825867bc
	__imp__XamUserReadProfileSettings(ctx, base);
	// cmplwi r3,0
	// beq 0x8256fee0
	if (ctx.r3.u32 != 0) {
		// cmplwi cr6,r3,997
		// beq cr6,0x8256fee0
		if (ctx.r3.u32 == 997) goto loc_8256FEE0;
		// lis r11,2
		ctx.r11.s64 = 131072;
		// lwz r10,196(r31)
		ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 196);
		// ori r11,r11,25604
		ctx.r11.u64 = ctx.r11.u64 | 25604;
		// cmplw cr6,r10,r11
		// beq cr6,0x8256fee8
		if (ctx.r10.u32 == ctx.r11.u32) goto loc_8256FEE8;
		// li r27,1
		var_r27 = 1;
		// stw r11,196(r31)
		PPC_STORE_U32(var_r31 + 196, ctx.r11.u32);
		// b 0x8256fee8
	} else {
	loc_8256FEE0:
		// li r11,1
		ctx.r11.s64 = 1;
		// stw r11,188(r31)
		PPC_STORE_U32(var_r31 + 188, ctx.r11.u32);
	}
loc_8256FEE8:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
	// li r4,252
	ctx.r4.s64 = 252;
	// bl 0x825867ac
	__imp__XamUserCheckPrivilege(ctx, base);
	// cmplwi r3,0
	// bne 0x8256ff40
	if (ctx.r3.u32 == 0) {
		// lwz r11,96(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
		// cmpwi cr6,r11,1
		// beq cr6,0x8256ff40
		if (ctx.r11.s32 == 1) goto loc_8256FF40;
		// addi r5,r1,96
		ctx.r5.s64 = ctx.r1.s64 + 96;
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// li r4,251
		ctx.r4.s64 = 251;
		// bl 0x825867ac
		__imp__XamUserCheckPrivilege(ctx, base);
		// cmplwi r3,0
		// bne 0x8256ff38
		if (ctx.r3.u32 == 0) {
			// lwz r11,96(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
			// cmpwi cr6,r11,1
			// bne cr6,0x8256ff38
			if (ctx.r11.s32 != 1) goto loc_8256FF38;
			// lis r11,1
			ctx.r11.s64 = 65536;
			// b 0x8256ff44
			goto loc_8256FF44;
		}
	loc_8256FF38:
		// mr r11,r28
		ctx.r11.u64 = var_r28;
		// b 0x8256ff44
	} else {
	loc_8256FF40:
		// lis r11,2
		ctx.r11.s64 = 131072;
	}
loc_8256FF44:
	// lwz r3,144(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 144);
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// cmpwi cr6,r10,0
	// beq cr6,0x8256ff58
	if (ctx.r10.s32 != 0) {
		// lis r11,2
		ctx.r11.s64 = 131072;
	}
loc_8256FF58:
	// lwz r9,196(r31)
	ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 196);
	// lis r10,1
	ctx.r10.s64 = 65536;
	// rlwinm r9,r9,0,16,11
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFF0FFFF;
	// or r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 | ctx.r11.u64;
	// rlwinm r9,r11,0,12,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xF0000;
	// cmplw cr6,r9,r10
	// stw r11,196(r31)
	PPC_STORE_U32(var_r31 + 196, ctx.r11.u32);
	// bne cr6,0x8256fe34
	if (ctx.r9.u32 != ctx.r10.u32) goto loc_8256FE34;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8256ec98
	RtlEnterCriticalSection_EC98_h(ctx, base);
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmplwi cr6,r5,0
	// beq cr6,0x8256fe34
	if (ctx.r5.u32 == 0) goto loc_8256FE34;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8258679c
	__imp__XamUserAreUsersFriends(ctx, base);
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r11,0
	// bne cr6,0x8256fe34
	if (ctx.r11.s32 != 0) goto loc_8256FE34;
	// lwz r11,196(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 196);
	// rlwinm r11,r11,0,16,11
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFF0FFFF;
	// b 0x8256fe2c
	goto loc_8256FE2C;
}

__attribute__((alias("__imp__KfAcquireSpinLock_FFC0_w"))) PPC_WEAK_FUNC(KfAcquireSpinLock_FFC0_w);
PPC_FUNC_IMPL(__imp__KfAcquireSpinLock_FFC0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t ea{};
	// FRAME: size=192, savegprlr_20
	// mr r27,r3
	var_r27 = ctx.r3.u32;
	// li r22,0
	var_r22 = 0;
	// mr r24,r4
	var_r24 = ctx.r4.u32;
	// mr r25,r5
	var_r25 = ctx.r5.u32;
	// mr r29,r22
	var_r29 = (uint32_t)(var_r22);
	// addi r23,r27,72
	var_r23 = (uint32_t)(var_r27 + 72);
	// li r20,1
	var_r20 = 1;
	// li r21,2
	var_r21 = 2;
loc_8256FFEC:
	// mfmsr r10
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.r10.u64 = PPC_CHECK_GLOBAL_LOCK();
	// mtmsrd r13,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_ENTER_GLOBAL_LOCK();
	// lwarx r11,0,r23
	ea = var_r23;
	ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r20
	// bne cr6,0x82570010
	if (ctx.r11.s32 == (int32_t)var_r20) {
		// stwcx. r21,0,r23
		ea = var_r23;
		ctx.cr0.lt = 0;
		ctx.cr0.gt = 0;
		ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32((int32_t)var_r21));
		ctx.cr0.so = ctx.xer.so;
		// mtmsrd r10,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_LEAVE_GLOBAL_LOCK();
		// bne 0x8256ffec
		if (!ctx.cr0.eq) goto loc_8256FFEC;
		// b 0x82570018
	} else {
	loc_82570010:
		// stwcx. r11,0,r23
		ea = var_r23;
		ctx.cr0.lt = 0;
		ctx.cr0.gt = 0;
		ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
		ctx.cr0.so = ctx.xer.so;
		// mtmsrd r10,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_LEAVE_GLOBAL_LOCK();
	}
loc_82570018:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,1
	// bne cr6,0x825701a0
	if (ctx.r11.s32 == 1) {
		// lwz r11,8(r27)
		ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 8);
		// cmplwi cr6,r11,0
		// beq cr6,0x8257019c
		if (ctx.r11.u32 != 0) {
			// lwz r11,196(r27)
			ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 196);
			// rlwinm. r11,r11,0,12,15
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xF0000;
			// beq 0x8257019c
			if (ctx.r11.s32 == 0) goto loc_8257019C;
			// addi r26,r27,68
			var_r26 = (uint32_t)(var_r27 + 68);
			// mr r29,r22
			var_r29 = (uint32_t)(var_r22);
			// mr r3,r26
			ctx.r3.u64 = var_r26;
			// mr r31,r22
			var_r31 = (uint32_t)(var_r22);
			// bl 0x825862cc
			__imp__KfAcquireSpinLock(ctx, base);
			// addi r28,r27,52
			var_r28 = (uint32_t)(var_r27 + 52);
			// mr r4,r3
			ctx.r4.u64 = ctx.r3.u64;
			// lwz r11,0(r28)
			ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
			// b 0x82570080
			goto loc_82570080;
			do {
				// cmplw cr6,r31,r25
				// bge cr6,0x82570088
				// lwz r10,0(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
				// lwz r11,4(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// lwz r9,12(r10)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
				// lwz r10,4(r10)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
				// subf r10,r10,r9
				ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
				// add r31,r10,r31
				var_r31 = (uint32_t)(ctx.r10.u64 + var_r31);
				// cmplwi r11,0
				// bne 0x82570060
			} while (ctx.r11.u32 != 0);
		loc_82570088:
			// mr r3,r26
			ctx.r3.u64 = var_r26;
			// bl 0x825862ec
			__imp__KfReleaseSpinLock(ctx, base);
			// cmplw cr6,r31,r25
			// blt cr6,0x825701a0
			if (var_r31 < var_r25) goto loc_825701A0;
			// lwz r31,0(r28)
			var_r31 = (uint32_t)(PPC_LOAD_U32(var_r28 + 0));
			// cmplwi r31,0
			// beq 0x825701a0
			if (var_r31 == 0) goto loc_825701A0;
		loc_825700A4:
			// cmplw cr6,r29,r25
			// bge cr6,0x825701a0
			if (var_r29 >= var_r25) goto loc_825701A0;
			// lwz r11,0(r23)
			ctx.r11.u64 = PPC_LOAD_U32(var_r23 + 0);
			// cmpwi cr6,r11,3
			// beq cr6,0x825701a0
			if (ctx.r11.s32 == 3) goto loc_825701A0;
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
			// subf r9,r29,r25
			ctx.r9.s64 = (int64_t)(int32_t)var_r25 - (int64_t)(int32_t)var_r29;
			// mr r30,r9
			var_r30 = ctx.r9.u32;
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// lwz r8,12(r11)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// subf r8,r10,r8
			ctx.r8.s64 = ctx.r8.s64 - ctx.r10.s64;
			// cmplw cr6,r9,r8
			// blt cr6,0x825700dc
			if (ctx.r9.u32 >= ctx.r8.u32) {
				// mr r30,r8
				var_r30 = ctx.r8.u32;
			}
		loc_825700DC:
			// lwz r11,8(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
			// mr r5,r30
			ctx.r5.u64 = var_r30;
			// add r4,r29,r24
			ctx.r4.u64 = var_r29 + var_r24;
			// add r3,r11,r10
			ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
			// bl 0x82434100
			memcpy(ctx, base);
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
			// lwz r9,4(r11)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// lwz r10,12(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// add r9,r9,r30
			ctx.r9.u64 = ctx.r9.u64 + var_r30;
			// cmplw cr6,r9,r10
			// bge cr6,0x8257010c
			if (ctx.r9.u32 < ctx.r10.u32) {
				// mr r10,r9
				ctx.r10.u64 = ctx.r9.u64;
			}
		loc_8257010C:
			// stw r10,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
			// lwz r11,12(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// cmplw cr6,r10,r11
			// bne cr6,0x8257018c
			if (ctx.r10.u32 == ctx.r11.u32) {
				// mr r3,r26
				ctx.r3.u64 = var_r26;
				// bl 0x825862cc
				__imp__KfAcquireSpinLock(ctx, base);
				// lwz r11,0(r28)
				ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
				// mr r4,r3
				ctx.r4.u64 = ctx.r3.u64;
				// cmplwi r11,0
				// beq 0x82570154
				if (ctx.r11.u32 != 0) {
					// lwz r10,4(r28)
					ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 4);
					// cmplw cr6,r11,r10
					// bne cr6,0x82570148
					if (ctx.r11.u32 == ctx.r10.u32) {
						// stw r22,4(r28)
						PPC_STORE_U32(var_r28 + 4, var_r22);
					}
				loc_82570148:
					// lwz r10,4(r11)
					ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
					// stw r10,0(r28)
					PPC_STORE_U32(var_r28 + 0, ctx.r10.u32);
					// stw r22,4(r11)
					PPC_STORE_U32(ctx.r11.u32 + 4, var_r22);
				}
			loc_82570154:
				// cmplw cr6,r31,r11
				// bne cr6,0x82570180
				if (var_r31 == ctx.r11.u32) {
					// addi r11,r27,60
					ctx.r11.s64 = (int64_t)(int32_t)var_r27 + 60;
					// stw r22,4(r31)
					PPC_STORE_U32(var_r31 + 4, var_r22);
					// lwz r10,4(r11)
					ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
					// cmplwi r10,0
					// beq 0x82570178
					if (ctx.r10.u32 != 0) {
						// stw r31,4(r10)
						PPC_STORE_U32(ctx.r10.u32 + 4, var_r31);
						// b 0x8257017c
					} else {
					loc_82570178:
						// stw r31,0(r11)
						PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
					}
				loc_8257017C:
					// stw r31,4(r11)
					PPC_STORE_U32(ctx.r11.u32 + 4, var_r31);
				}
			loc_82570180:
				// mr r3,r26
				ctx.r3.u64 = var_r26;
				// bl 0x825862ec
				__imp__KfReleaseSpinLock(ctx, base);
				// lwz r31,0(r28)
				var_r31 = (uint32_t)(PPC_LOAD_U32(var_r28 + 0));
			}
		loc_8257018C:
			// add r29,r30,r29
			var_r29 = (uint32_t)(var_r30 + var_r29);
			// cmplwi cr6,r31,0
			// bne cr6,0x825700a4
			if (var_r31 != 0) goto loc_825700A4;
			// b 0x825701a0
		} else {
		loc_8257019C:
			// mr r29,r25
			var_r29 = (uint32_t)(var_r25);
		}
	}
loc_825701A0:
	// li r10,3
	ctx.r10.s64 = 3;
loc_825701A4:
	// mfmsr r9
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
	// mtmsrd r13,1
	std::atomic_thread_fence(std::memory_order_seq_cst);
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	PPC_ENTER_GLOBAL_LOCK();
	// lwarx r11,0,r23
	ea = var_r23;
	ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r10
	// bne cr6,0x82570234
	if (ctx.r11.s32 == ctx.r10.s32) {
		// stwcx. r22,0,r23
		ea = var_r23;
		ctx.cr0.lt = 0;
		ctx.cr0.gt = 0;
		ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32((int32_t)var_r22));
		ctx.cr0.so = ctx.xer.so;
		// mtmsrd r9,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_LEAVE_GLOBAL_LOCK();
		// bne 0x825701a4
		if (!ctx.cr0.eq) goto loc_825701A4;
		// b 0x8257023c
		goto loc_8257023C;
	loc_825701C8:
		// mfmsr r9
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
		// mtmsrd r13,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_ENTER_GLOBAL_LOCK();
		// lwarx r11,0,r23
		ea = var_r23;
		ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
		ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
		// cmpw cr6,r11,r21
		// bne cr6,0x825701ec
		if (ctx.r11.s32 == (int32_t)var_r21) {
			// stwcx. r20,0,r23
			ea = var_r23;
			ctx.cr0.lt = 0;
			ctx.cr0.gt = 0;
			ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32((int32_t)var_r20));
			ctx.cr0.so = ctx.xer.so;
			// mtmsrd r9,1
			std::atomic_thread_fence(std::memory_order_seq_cst);
			ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
			PPC_LEAVE_GLOBAL_LOCK();
			// bne 0x825701c8
			if (!ctx.cr0.eq) goto loc_825701C8;
			// b 0x825701f4
		} else {
		loc_825701EC:
			// stwcx. r11,0,r23
			ea = var_r23;
			ctx.cr0.lt = 0;
			ctx.cr0.gt = 0;
			ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
			ctx.cr0.so = ctx.xer.so;
			// mtmsrd r9,1
			std::atomic_thread_fence(std::memory_order_seq_cst);
			ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
			PPC_LEAVE_GLOBAL_LOCK();
		}
	loc_825701F4:
		// mr r11,r11
		ctx.r11.u64 = ctx.r11.u64;
		// cmpwi cr6,r11,2
		// beq cr6,0x82570248
		if (ctx.r11.s32 == 2) {
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
		// cmpwi cr6,r11,1
		// beq cr6,0x82570248
		if (ctx.r11.s32 == 1) {
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
		// cmpwi cr6,r11,0
		// beq cr6,0x82570248
		if (ctx.r11.s32 == 0) {
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
	loc_82570210:
		// mfmsr r9
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
		// mtmsrd r13,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_ENTER_GLOBAL_LOCK();
		// lwarx r11,0,r23
		ea = var_r23;
		ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
		ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
		// cmpw cr6,r11,r10
		// bne cr6,0x82570234
		if (ctx.r11.s32 != ctx.r10.s32) goto loc_82570234;
		// stwcx. r22,0,r23
		ea = var_r23;
		ctx.cr0.lt = 0;
		ctx.cr0.gt = 0;
		ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32((int32_t)var_r22));
		ctx.cr0.so = ctx.xer.so;
		// mtmsrd r9,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_LEAVE_GLOBAL_LOCK();
		// bne 0x82570210
		if (!ctx.cr0.eq) goto loc_82570210;
		// b 0x8257023c
	} else {
	loc_82570234:
		// stwcx. r11,0,r23
		ea = var_r23;
		ctx.cr0.lt = 0;
		ctx.cr0.gt = 0;
		ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
		ctx.cr0.so = ctx.xer.so;
		// mtmsrd r9,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_LEAVE_GLOBAL_LOCK();
	}
loc_8257023C:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,3
	// bne cr6,0x825701c8
	if (ctx.r11.s32 != 3) goto loc_825701C8;
loc_82570248:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	return;
}

__attribute__((alias("__imp__xam_0258"))) PPC_WEAK_FUNC(xam_0258);
PPC_FUNC_IMPL(__imp__xam_0258) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t ea{};
	// FRAME: size=112, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r31,148
	ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 148;
	// addi r30,r31,72
	var_r30 = (uint32_t)(var_r31 + 72);
	// bl 0x825867fc
	__imp__XMsgCancelIORequest(ctx, base);
	// li r29,0
	var_r29 = 0;
	// b 0x825702f0
	goto loc_825702F0;
	do {
		// li r11,2
		ctx.r11.s64 = 2;
		// li r10,3
		ctx.r10.s64 = 3;
	loc_82570288:
		// mfmsr r8
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.r8.u64 = PPC_CHECK_GLOBAL_LOCK();
		// mtmsrd r13,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_ENTER_GLOBAL_LOCK();
		// lwarx r9,0,r30
		ea = var_r30;
		ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
		ctx.r9.u64 = __builtin_bswap32(ctx.reserved.u32);
		// cmpw cr6,r9,r11
		// bne cr6,0x825702ac
		if (ctx.r9.s32 == ctx.r11.s32) {
			// stwcx. r10,0,r30
			ea = var_r30;
			ctx.cr0.lt = 0;
			ctx.cr0.gt = 0;
			ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
			ctx.cr0.so = ctx.xer.so;
			// mtmsrd r8,1
			std::atomic_thread_fence(std::memory_order_seq_cst);
			ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
			PPC_LEAVE_GLOBAL_LOCK();
			// bne 0x82570288
			if (!ctx.cr0.eq) goto loc_82570288;
			// b 0x825702b4
		} else {
		loc_825702AC:
			// stwcx. r9,0,r30
			ea = var_r30;
			ctx.cr0.lt = 0;
			ctx.cr0.gt = 0;
			ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r9.s32));
			ctx.cr0.so = ctx.xer.so;
			// mtmsrd r8,1
			std::atomic_thread_fence(std::memory_order_seq_cst);
			ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
			PPC_LEAVE_GLOBAL_LOCK();
		}
	loc_825702B4:
		// mr r11,r9
		ctx.r11.u64 = ctx.r9.u64;
		// cmplwi cr6,r11,2
		// beq cr6,0x82570300
		if (ctx.r11.u32 == 2) goto loc_82570300;
		// li r11,1
		ctx.r11.s64 = 1;
	loc_825702C4:
		// mfmsr r9
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
		// mtmsrd r13,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_ENTER_GLOBAL_LOCK();
		// lwarx r10,0,r30
		ea = var_r30;
		ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
		ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
		// cmpw cr6,r10,r11
		// bne cr6,0x825702e8
		if (ctx.r10.s32 == ctx.r11.s32) {
			// stwcx. r29,0,r30
			ea = var_r30;
			ctx.cr0.lt = 0;
			ctx.cr0.gt = 0;
			ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32((int32_t)var_r29));
			ctx.cr0.so = ctx.xer.so;
			// mtmsrd r9,1
			std::atomic_thread_fence(std::memory_order_seq_cst);
			ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
			PPC_LEAVE_GLOBAL_LOCK();
			// bne 0x825702c4
			if (!ctx.cr0.eq) goto loc_825702C4;
			// b 0x825702f0
		} else {
		loc_825702E8:
			// stwcx. r10,0,r30
			ea = var_r30;
			ctx.cr0.lt = 0;
			ctx.cr0.gt = 0;
			ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
			ctx.cr0.so = ctx.xer.so;
			// mtmsrd r9,1
			std::atomic_thread_fence(std::memory_order_seq_cst);
			ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
			PPC_LEAVE_GLOBAL_LOCK();
		}
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmpwi cr6,r11,0
		// bne cr6,0x82570280
	} while (ctx.r11.s32 != 0);
	// b 0x8257030c
	goto loc_8257030C;
loc_82570300:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
	// cmpwi cr6,r11,0
	// bne cr6,0x82570300
	if (ctx.r11.s32 != 0) goto loc_82570300;
loc_8257030C:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
	// cmplwi r3,0
	// beq 0x82570320
	if (ctx.r3.u32 != 0) {
		// bl 0x825867ec
		__imp__XamVoiceClose(ctx, base);
		// stw r29,8(r31)
		PPC_STORE_U32(var_r31 + 8, var_r29);
	}
loc_82570320:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
	// bl 0x82574780
	xam_4780(ctx, base);
	// li r11,4
	ctx.r11.s64 = 4;
	// stw r11,0(r31)
	PPC_STORE_U32(var_r31 + 0, ctx.r11.u32);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
	// cmplwi cr6,r11,0
	// ble cr6,0x82570368
	if (ctx.r11.u32 > 0) {
		// addi r30,r31,12
		var_r30 = (uint32_t)(var_r31 + 12);
	loc_82570340:
		// lwz r3,0(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
		// lwz r11,12(r11)
		// bctrl
		VCALL(ctx.r3.u32, 3, ctx, base);  // vtable slot 3 (byte +12)
		// lwz r11,32(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
		// addi r29,r29,1
		var_r29 = (uint32_t)(var_r29 + 1);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// cmplw cr6,r29,r11
		// blt cr6,0x82570340
		if (var_r29 < ctx.r11.u32) goto loc_82570340;
	}
loc_82570368:
	return;
}

__attribute__((alias("__imp__xam_0370_2hr"))) PPC_WEAK_FUNC(xam_0370_2hr);
PPC_FUNC_IMPL(__imp__xam_0370_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// lis r28,-32761
	var_r28 = (uint32_t)(-2147024896);
	// mr r27,r3
	var_r27 = ctx.r3.u32;
	// ori r28,r28,87
	var_r28 = (uint32_t)(var_r28 | 87);
	// li r30,0
	var_r30 = 0;
	// cmplwi cr6,r29,0
	// beq cr6,0x825703d8
	if (var_r29 != 0) {
		// mr r31,r4
		var_r31 = ctx.r4.u32;
	loc_8257039C:
		// mr r3,r27
		ctx.r3.u64 = var_r27;
		// lwz r4,0(r31)
		ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 0);
		// bl 0x8256fbd8
		xam_FBD8(ctx, base);
		// cmplwi r3,0
		// beq 0x825703d8
		if (ctx.r3.u32 == 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// lwz r11,8(r11)
		// bctrl
		VCALL(ctx.r3.u32, 2, ctx, base);  // vtable slot 2 (byte +8)
		// mr. r28,r3
		var_r28 = ctx.r3.u32;
		// blt 0x825703d8
		if ((int32_t)var_r28 < 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// cmplw cr6,r30,r29
		// blt cr6,0x8257039c
		if (var_r30 < var_r29) goto loc_8257039C;
	}
loc_825703D8:
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	return;
}

__attribute__((alias("__imp__xam_03E8_2h"))) PPC_WEAK_FUNC(xam_03E8_2h);
PPC_FUNC_IMPL(__imp__xam_03E8_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// lis r28,-32761
	var_r28 = (uint32_t)(-2147024896);
	// mr r27,r3
	var_r27 = ctx.r3.u32;
	// ori r28,r28,87
	var_r28 = (uint32_t)(var_r28 | 87);
	// li r30,0
	var_r30 = 0;
	// cmplwi cr6,r29,0
	// beq cr6,0x82570450
	if (var_r29 != 0) {
		// mr r31,r4
		var_r31 = ctx.r4.u32;
	loc_82570414:
		// mr r3,r27
		ctx.r3.u64 = var_r27;
		// lwz r4,0(r31)
		ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 0);
		// bl 0x8256fbd8
		xam_FBD8(ctx, base);
		// cmplwi r3,0
		// beq 0x82570450
		if (ctx.r3.u32 == 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// lwz r11,12(r11)
		// bctrl
		VCALL(ctx.r3.u32, 3, ctx, base);  // vtable slot 3 (byte +12)
		// mr. r28,r3
		var_r28 = ctx.r3.u32;
		// blt 0x82570450
		if ((int32_t)var_r28 < 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// cmplw cr6,r30,r29
		// blt cr6,0x82570414
		if (var_r30 < var_r29) goto loc_82570414;
	}
loc_82570450:
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	return;
}

__attribute__((alias("__imp__xam_0460"))) PPC_WEAK_FUNC(xam_0460);
PPC_FUNC_IMPL(__imp__xam_0460) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=176, savegprlr_23
	// mr r25,r3
	var_r25 = ctx.r3.u32;
	// bl 0x8256fc50
	xam_FC50(ctx, base);
	// addi r24,r25,76
	var_r24 = (uint32_t)(var_r25 + 76);
	// li r26,0
	var_r26 = 0;
	// b 0x82570520
	goto loc_82570520;
	do {
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r11,0(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmpwi cr6,r11,259
		// beq cr6,0x8257052c
		// lwz r11,0(r24)
		ctx.r11.u64 = PPC_LOAD_U32(var_r24 + 0);
		// cmplwi r11,0
		// beq 0x825704b8
		if (ctx.r11.u32 != 0) {
			// lwz r10,4(r24)
			ctx.r10.u64 = PPC_LOAD_U32(var_r24 + 4);
			// cmplw cr6,r11,r10
			// bne cr6,0x825704ac
			if (ctx.r11.u32 == ctx.r10.u32) {
				// stw r26,4(r24)
				PPC_STORE_U32(var_r24 + 4, var_r26);
			}
		loc_825704AC:
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// stw r10,0(r24)
			PPC_STORE_U32(var_r24 + 0, ctx.r10.u32);
			// stw r26,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r26);
		}
	loc_825704B8:
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r10,20(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
		// cmpwi cr6,r10,1
		// bne cr6,0x825704dc
		if (ctx.r10.s32 == 1) {
			// lwz r10,12(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// rlwinm r10,r10,2,0,29
			ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
			// stw r10,12(r11)
			PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
			// stw r26,20(r11)
			PPC_STORE_U32(ctx.r11.u32 + 20, var_r26);
		}
	loc_825704DC:
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// addi r30,r25,68
		var_r30 = (uint32_t)(var_r25 + 68);
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// stw r26,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r26);
		// bl 0x825862cc
		__imp__KfAcquireSpinLock(ctx, base);
		// addi r11,r25,52
		ctx.r11.s64 = (int64_t)(int32_t)var_r25 + 52;
		// stw r26,4(r31)
		PPC_STORE_U32(var_r31 + 4, var_r26);
		// mr r4,r3
		ctx.r4.u64 = ctx.r3.u64;
		// lwz r10,4(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// cmplwi r10,0
		// beq 0x82570510
		if (ctx.r10.u32 != 0) {
			// stw r31,4(r10)
			PPC_STORE_U32(ctx.r10.u32 + 4, var_r31);
			// b 0x82570514
		} else {
		loc_82570510:
			// stw r31,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
		}
	loc_82570514:
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// stw r31,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r31);
		// bl 0x825862ec
		__imp__KfReleaseSpinLock(ctx, base);
		// lwz r31,0(r24)
		var_r31 = (uint32_t)(PPC_LOAD_U32(var_r24 + 0));
		// cmplwi r31,0
		// bne 0x82570480
	} while (var_r31 != 0);
loc_8257052C:
	// addi r23,r25,60
	var_r23 = (uint32_t)(var_r25 + 60);
	// b 0x825706e4
	goto loc_825706E4;
	do {
		// lwz r11,0(r27)
		ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
		// lwz r10,12(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// lwz r11,4(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// subf. r11,r11,r10
		ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
		// bne 0x8257070c
		// addi r31,r25,68
		var_r31 = (uint32_t)(var_r25 + 68);
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x825862cc
		__imp__KfAcquireSpinLock(ctx, base);
		// mr r30,r3
		var_r30 = ctx.r3.u32;
		// mr r3,r24
		ctx.r3.u64 = var_r24;
		// bl 0x8256c5e8
		xam_C5E8_gen(ctx, base);
		// cmplwi r3,0
		// bne 0x82570578
		if (ctx.r3.u32 == 0) {
			// mr r3,r23
			ctx.r3.u64 = var_r23;
			// bl 0x8256c5e8
			xam_C5E8_gen(ctx, base);
			// cmplwi cr6,r3,1
			// ble cr6,0x825706f4
			if (ctx.r3.u32 <= 1) goto loc_825706F4;
		}
	loc_82570578:
		// lwz r11,0(r23)
		ctx.r11.u64 = PPC_LOAD_U32(var_r23 + 0);
		// cmplwi r11,0
		// beq 0x825705a0
		if (ctx.r11.u32 != 0) {
			// lwz r10,4(r23)
			ctx.r10.u64 = PPC_LOAD_U32(var_r23 + 4);
			// cmplw cr6,r11,r10
			// bne cr6,0x82570594
			if (ctx.r11.u32 == ctx.r10.u32) {
				// stw r26,4(r23)
				PPC_STORE_U32(var_r23 + 4, var_r26);
			}
		loc_82570594:
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// stw r10,0(r23)
			PPC_STORE_U32(var_r23 + 0, ctx.r10.u32);
			// stw r26,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r26);
		}
	loc_825705A0:
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x825862ec
		__imp__KfReleaseSpinLock(ctx, base);
		// stw r26,4(r27)
		PPC_STORE_U32(var_r27 + 4, var_r26);
		// lwz r11,4(r24)
		ctx.r11.u64 = PPC_LOAD_U32(var_r24 + 4);
		// cmplwi r11,0
		// beq 0x825705c4
		if (ctx.r11.u32 != 0) {
			// stw r27,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r27);
			// b 0x825705c8
		} else {
		loc_825705C4:
			// stw r27,0(r24)
			PPC_STORE_U32(var_r24 + 0, var_r27);
		}
	loc_825705C8:
		// stw r27,4(r24)
		PPC_STORE_U32(var_r24 + 4, var_r27);
		// addi r28,r25,84
		var_r28 = (uint32_t)(var_r25 + 84);
		// lwz r11,0(r27)
		ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
		// lwz r10,12(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// lwz r31,8(r11)
		var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r11.u32 + 8));
		// mr r30,r31
		var_r30 = (uint32_t)(var_r31);
		// rlwinm. r11,r10,31,1,31
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
		// ble 0x825706b0
		if (ctx.r11.s32 > 0) {
			// addi r11,r11,-1
			ctx.r11.s64 = ctx.r11.s64 + -1;
			// rlwinm r11,r11,31,1,31
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
			// addi r29,r11,1
			var_r29 = (uint32_t)(ctx.r11.s64 + 1);  // addr:0x825c0001
		loc_825705F4:
			// lha r11,0(r31)
			ctx.r11.s64 = int16_t(PPC_LOAD_U16(var_r31 + 0));
			// li r12,-7880
			// mr r6,r28
			ctx.r6.u64 = var_r28;
			// sth r26,82(r1)
			PPC_STORE_U16(ctx.r1.u32 + 82, (uint16_t)var_r26);
			// addi r10,r11,-7880
			ctx.r10.s64 = ctx.r11.s64 + -7880;
			// sth r26,80(r1)
			PPC_STORE_U16(ctx.r1.u32 + 80, (uint16_t)var_r26);
			// addi r5,r1,82
			ctx.r5.s64 = ctx.r1.s64 + 82;
			// srawi r10,r10,16
			ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFFFF) != 0);
			ctx.r10.s64 = ctx.r10.s32 >> 16;
			// li r3,0
			ctx.r3.s64 = 0;
			// not r9,r10
			ctx.r9.u64 = ~ctx.r10.u64;
			// and r11,r10,r11
			ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
			// andi. r10,r9,7880
			ctx.r10.u64 = ctx.r9.u64 & 7880;
			ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
			// or r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
			// addi r10,r11,7880
			ctx.r10.s64 = ctx.r11.s64 + 7880;
			// srawi r10,r10,16
			ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFFFF) != 0);
			ctx.r10.s64 = ctx.r10.s32 >> 16;
			// and r9,r10,r12
			ctx.r9.u64 = ctx.r10.u64 & ctx.r12.u64;
			// andc r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
			// or r11,r11,r9
			ctx.r11.u64 = ctx.r11.u64 | ctx.r9.u64;
			// extsh r4,r11
			ctx.r4.s64 = ctx.r11.s16;
			// bl 0x825730b8
			xam_30B8_w(ctx, base);
			// addi r31,r31,2
			var_r31 = (uint32_t)(var_r31 + 2);
			// li r12,-7880
			// mr r6,r28
			ctx.r6.u64 = var_r28;
			// addi r5,r1,80
			ctx.r5.s64 = ctx.r1.s64 + 80;
			// li r3,0
			ctx.r3.s64 = 0;
			// lha r11,0(r31)
			ctx.r11.s64 = int16_t(PPC_LOAD_U16(var_r31 + 0));
			// addi r10,r11,-7880
			ctx.r10.s64 = ctx.r11.s64 + -7880;
			// srawi r10,r10,16
			ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFFFF) != 0);
			ctx.r10.s64 = ctx.r10.s32 >> 16;
			// not r9,r10
			ctx.r9.u64 = ~ctx.r10.u64;
			// and r11,r10,r11
			ctx.r11.u64 = ctx.r10.u64 & ctx.r11.u64;
			// andi. r10,r9,7880
			ctx.r10.u64 = ctx.r9.u64 & 7880;
			ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
			// or r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
			// addi r10,r11,7880
			ctx.r10.s64 = ctx.r11.s64 + 7880;
			// srawi r10,r10,16
			ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFFFF) != 0);
			ctx.r10.s64 = ctx.r10.s32 >> 16;
			// and r9,r10,r12
			ctx.r9.u64 = ctx.r10.u64 & ctx.r12.u64;
			// andc r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 & ~ctx.r10.u64;
			// or r11,r11,r9
			ctx.r11.u64 = ctx.r11.u64 | ctx.r9.u64;
			// extsh r4,r11
			ctx.r4.s64 = ctx.r11.s16;
			// bl 0x825730b8
			xam_30B8_w(ctx, base);
			// addic. r29,r29,-1
			ctx.xer.ca = var_r29 > 0;
			var_r29 = (uint32_t)(var_r29 + -1);
			// addi r31,r31,2
			var_r31 = (uint32_t)(var_r31 + 2);
			// lha r11,80(r1)
			ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r1.u32 + 80));
			// lha r10,82(r1)
			ctx.r10.s64 = int16_t(PPC_LOAD_U16(ctx.r1.u32 + 82));
			// rlwimi r10,r11,4,0,27
			ctx.r10.u64 = (__builtin_rotateleft32(ctx.r11.u32, 4) & 0xFFFFFFF0) | (ctx.r10.u64 & 0xFFFFFFFF0000000F);
			// stb r10,0(r30)
			PPC_STORE_U8(var_r30 + 0, ctx.r10.u8);
			// addi r30,r30,1
			var_r30 = (uint32_t)(var_r30 + 1);
			// bne 0x825705f4
			if ((int32_t)var_r29 != 0) goto loc_825705F4;
		}
	loc_825706B0:
		// lwz r11,0(r27)
		ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
		// li r10,1
		ctx.r10.s64 = 1;
		// li r4,0
		ctx.r4.s64 = 0;
		// lwz r9,12(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// rlwinm r9,r9,30,2,31
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
		// stw r9,12(r11)
		PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
		// lwz r11,0(r27)
		ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
		// stw r10,20(r11)
		PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r10.u32);
		// lwz r5,0(r27)
		ctx.r5.u64 = PPC_LOAD_U32(var_r27 + 0);
		// lwz r3,8(r25)
		ctx.r3.u64 = PPC_LOAD_U32(var_r25 + 8);
		// bl 0x8258680c
		__imp__XamVoiceSubmitPacket(ctx, base);
		// cmpwi r3,0
		// blt 0x82570704
		if (ctx.r3.s32 < 0) goto loc_82570704;
		// lwz r27,0(r23)
		var_r27 = (uint32_t)(PPC_LOAD_U32(var_r23 + 0));
		// cmplwi r27,0
		// bne 0x82570534
	} while (var_r27 != 0);
	// b 0x8257070c
	goto loc_8257070C;
loc_825706F4:
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// addi r3,r25,68
	ctx.r3.s64 = (int64_t)(int32_t)var_r25 + 68;
	// bl 0x825862ec
	__imp__KfReleaseSpinLock(ctx, base);
	// b 0x8257070c
	goto loc_8257070C;
loc_82570704:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
	// stw r26,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, var_r26);
loc_8257070C:
	// lwz r3,4(r25)
	ctx.r3.u64 = PPC_LOAD_U32(var_r25 + 4);
	// bl 0x82574840
	xam_4840_h(ctx, base);
	// mr. r29,r3
	var_r29 = ctx.r3.u32;
	// blt 0x82570758
	if ((int32_t)var_r29 >= 0) {
		// lwz r11,32(r25)
		ctx.r11.u64 = PPC_LOAD_U32(var_r25 + 32);
		// mr r30,r26
		var_r30 = (uint32_t)(var_r26);
		// cmplwi cr6,r11,0
		// ble cr6,0x82570758
		if (ctx.r11.u32 <= 0) {
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
		// addi r31,r25,12
		var_r31 = (uint32_t)(var_r25 + 12);
	loc_82570730:
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r11,16(r11)
		// bctrl
		VCALL(ctx.r3.u32, 4, ctx, base);  // vtable slot 4 (byte +16)
		// lwz r11,32(r25)
		ctx.r11.u64 = PPC_LOAD_U32(var_r25 + 32);
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// cmplw cr6,r30,r11
		// blt cr6,0x82570730
		if (var_r30 < ctx.r11.u32) goto loc_82570730;
	}
loc_82570758:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	return;
}

__attribute__((alias("__imp__xam_0768_2h"))) PPC_WEAK_FUNC(xam_0768_2h);
PPC_FUNC_IMPL(__imp__xam_0768_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_28
	// lis r31,-32761
	var_r31 = (uint32_t)(-2147024896);
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// mr r29,r6
	var_r29 = ctx.r6.u32;
	// mr r28,r7
	var_r28 = ctx.r7.u32;
	// ori r31,r31,87
	var_r31 = (uint32_t)(var_r31 | 87);
	// bl 0x8256fbd8
	xam_FBD8(ctx, base);
	// cmplwi r3,0
	// beq 0x825707b4
	if (ctx.r3.u32 != 0) {
		// lwz r11,0(r3)
  // [ph4a] vtable load collapsed
		// mr r6,r28
		ctx.r6.u64 = var_r28;
		// mr r5,r29
		ctx.r5.u64 = var_r29;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// lwz r11,28(r11)
  // [ph4a] slot load collapsed
		// bctrl
		VCALL(ctx.r3.u32, 7, ctx, base);  // pattern-B slot 7 (byte +28)
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_825707B4:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_07C0_w"))) PPC_WEAK_FUNC(xam_07C0_w);
PPC_FUNC_IMPL(__imp__xam_07C0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82566898
	util_6898(ctx, base);
	// lwz r11,44(r28)
	ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 44);
	// li r30,0
	var_r30 = 0;
	// cmplwi cr6,r11,0
	// ble cr6,0x82570854
	if (ctx.r11.u32 > 0) {
		// addi r31,r28,36
		var_r31 = (uint32_t)(var_r28 + 36);
	loc_825707F8:
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// li r9,0
		ctx.r9.s64 = 0;
		// lwz r10,24(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
		// lwz r29,12(r10)
		var_r29 = (uint32_t)(PPC_LOAD_U32(ctx.r10.u32 + 12));
		// addi r10,r11,16
		ctx.r10.s64 = ctx.r11.s64 + 16;
	loc_8257080C:
		// lwz r8,-8(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + -8);
		// cmplwi cr6,r8,0
		// beq cr6,0x82570824
		if (ctx.r8.u32 != 0) {
			// lwz r8,0(r10)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			// cmpwi cr6,r8,1
			// beq cr6,0x8257085c
			if (ctx.r8.s32 == 1) goto loc_8257085C;
		}
	loc_82570824:
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// cmplwi cr6,r9,2
		// blt cr6,0x8257080c
		if (ctx.r9.u32 < 2) goto loc_8257080C;
		// li r3,0
		ctx.r3.s64 = 0;
	loc_82570838:
		// rlwinm r11,r29,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r29 | (var_r29 << 32), 2) & 0xFFFFFFFC;
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// stwx r3,r11,r27
		PPC_STORE_U32(ctx.r11.u32 + var_r27, ctx.r3.u32);
		// lwz r11,44(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 44);
		// cmplw cr6,r30,r11
		// blt cr6,0x825707f8
		if (var_r30 < ctx.r11.u32) goto loc_825707F8;
	}
loc_82570854:
	return;
loc_8257085C:
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r3,r11,8
	ctx.r3.s64 = ctx.r11.s64 + 8;
	// bl 0x8256c5e8
	xam_C5E8_gen(ctx, base);
	// b 0x82570838
	goto loc_82570838;
}

__attribute__((alias("__imp__xam_0870"))) PPC_WEAK_FUNC(xam_0870);
PPC_FUNC_IMPL(__imp__xam_0870) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x82570960
	if (var_r31 != 0) {
		// lwz r3,8(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
		// li r28,0
		var_r28 = 0;
		// cmplwi r3,0
		// beq 0x825708a0
		if (ctx.r3.u32 != 0) {
			// bl 0x825867ec
			__imp__XamVoiceClose(ctx, base);
			// stw r28,8(r31)
			PPC_STORE_U32(var_r31 + 8, var_r28);
		}
	loc_825708A0:
		// lwz r3,4(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
		// bl 0x82574d80
		xam_4D80_w(ctx, base);
		// lwz r11,44(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 44);
		// mr r29,r28
		var_r29 = (uint32_t)(var_r28);
		// stw r28,4(r31)
		PPC_STORE_U32(var_r31 + 4, var_r28);
		// cmplwi cr6,r11,0
		// ble cr6,0x825708e0
		if (ctx.r11.u32 > 0) {
			// addi r30,r31,36
			var_r30 = (uint32_t)(var_r31 + 36);
		loc_825708C0:
			// lwz r3,0(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
			// bl 0x8256c458
			xam_C458_w(ctx, base);
			// stw r28,0(r30)
			PPC_STORE_U32(var_r30 + 0, var_r28);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// lwz r11,44(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 44);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
			// cmplw cr6,r29,r11
			// blt cr6,0x825708c0
			if (var_r29 < ctx.r11.u32) goto loc_825708C0;
		}
	loc_825708E0:
		// lwz r11,32(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
		// mr r29,r28
		var_r29 = (uint32_t)(var_r28);
		// cmplwi cr6,r11,0
		// ble cr6,0x82570920
		if (ctx.r11.u32 > 0) {
			// addi r30,r31,12
			var_r30 = (uint32_t)(var_r31 + 12);
		loc_825708F4:
			// lwz r3,0(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
			// lwz r11,4(r11)
			// bctrl
			VCALL(ctx.r3.u32, 1, ctx, base);  // vtable slot 1 (byte +4)
			// stw r28,0(r30)
			PPC_STORE_U32(var_r30 + 0, var_r28);
			// lwz r11,32(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
			// cmplw cr6,r29,r11
			// blt cr6,0x825708f4
			if (var_r29 < ctx.r11.u32) goto loc_825708F4;
		}
	loc_82570920:
		// lwz r3,48(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 48);
		// bl 0x8256c788
		util_C788(ctx, base);
		// li r4,1
		ctx.r4.s64 = 1;
		// addi r3,r31,148
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 148;
		// bl 0x825867fc
		__imp__XMsgCancelIORequest(ctx, base);
		// lwz r3,176(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 176);
		// cmplwi r3,0
		// beq 0x82570950
		if (ctx.r3.u32 != 0) {
			// lis r4,24714
			ctx.r4.s64 = 1619656704;
			// ori r4,r4,8194
			ctx.r4.u64 = ctx.r4.u64 | 8194;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r28,176(r31)
			PPC_STORE_U32(var_r31 + 176, var_r28);
		}
	loc_82570950:
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r4,r4,32779
		ctx.r4.u64 = ctx.r4.u64 | 32779;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_82570960:
	return;
}

__attribute__((alias("__imp__xam_0968"))) PPC_WEAK_FUNC(xam_0968);
PPC_FUNC_IMPL(__imp__xam_0968) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t ea{};
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// bl 0x82570258
	xam_0258(ctx, base);
	// addi r28,r31,8
	var_r28 = (uint32_t)(var_r31 + 8);
	// li r4,15
	ctx.r4.s64 = 15;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// mr r5,r28
	ctx.r5.u64 = var_r28;
	// bl 0x8258681c
	__imp__XamVoiceCreate(ctx, base);
	// mr. r29,r3
	var_r29 = ctx.r3.u32;
	// blt 0x825709f8
	if ((int32_t)var_r29 >= 0) {
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// lwz r3,4(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4);
		// bl 0x82574e80
		xam_4E80_w(ctx, base);
		// lis r11,2
		ctx.r11.s64 = 131072;
		// mr r29,r3
		var_r29 = ctx.r3.u32;
		// stw r30,0(r31)
		PPC_STORE_U32(var_r31 + 0, var_r30);
		// ori r11,r11,25604
		ctx.r11.u64 = ctx.r11.u64 | 25604;
		// li r8,1
		ctx.r8.s64 = 1;
		// addi r7,r31,72
		ctx.r7.s64 = (int64_t)(int32_t)var_r31 + 72;
		// stw r11,196(r31)
		PPC_STORE_U32(var_r31 + 196, ctx.r11.u32);
	loc_825709C4:
		// mfmsr r9
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.r9.u64 = PPC_CHECK_GLOBAL_LOCK();
		// mtmsrd r13,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_ENTER_GLOBAL_LOCK();
		// lwarx r10,0,r7
		ea = ctx.r7.u32;
		ctx.reserved.u32 = *(uint32_t*)PPC_RAW_ADDR(ea);
		ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
		// stwcx. r8,0,r7
		ea = ctx.r7.u32;
		ctx.cr0.lt = 0;
		ctx.cr0.gt = 0;
		ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(PPC_RAW_ADDR(ea)), ctx.reserved.s32, __builtin_bswap32(ctx.r8.s32));
		ctx.cr0.so = ctx.xer.so;
		// mtmsrd r9,1
		std::atomic_thread_fence(std::memory_order_seq_cst);
		ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
		PPC_LEAVE_GLOBAL_LOCK();
		// bne 0x825709c4
		if (!ctx.cr0.eq) goto loc_825709C4;
		// lis r11,-32254
		// addi r3,r31,84
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 84;
		// addi r4,r11,11204
		ctx.r4.s64 = ctx.r11.s64 + 11204;
		// li r5,54
		ctx.r5.s64 = 54;
		// bl 0x82434100
		memcpy(ctx, base);
		// cmpwi cr6,r29,0
		// bge cr6,0x82570a10
		if ((int32_t)var_r29 >= 0) {
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
	}
loc_825709F8:
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(var_r28 + 0);
	// cmplwi r3,0
	// beq 0x82570a10
	if (ctx.r3.u32 != 0) {
		// bl 0x825867ec
		__imp__XamVoiceClose(ctx, base);
		// li r11,0
		ctx.r11.s64 = 0;
		// stw r11,0(r28)
		PPC_STORE_U32(var_r28 + 0, ctx.r11.u32);
	}
loc_82570A10:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	return;
}

__attribute__((alias("__imp__xam_0A20"))) PPC_WEAK_FUNC(xam_0A20);
PPC_FUNC_IMPL(__imp__xam_0A20) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r19 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r18 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r24 = 0;
	PPCRegister temp{};
	// FRAME: size=272, savegprlr_18
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// mr r19,r3
	var_r19 = ctx.r3.u32;
	// ori r4,r4,32779
	ctx.r4.u64 = ctx.r4.u64 | 32779;
	// li r3,200
	ctx.r3.s64 = 200;
	// mr r27,r5
	var_r27 = ctx.r5.u32;
	// mr r18,r6
	var_r18 = ctx.r6.u32;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// li r20,0
	var_r20 = 0;
	// mr. r29,r3
	var_r29 = ctx.r3.u32;
	// bne 0x82570a64
	if ((int32_t)var_r29 == 0) {
	loc_82570A58:
		// lis r22,-32761
		var_r22 = (uint32_t)(-2147024896);
		// ori r22,r22,14
		var_r22 = (uint32_t)(var_r22 | 14);
		// b 0x82570d80
		goto loc_82570D80;
	}
loc_82570A64:
	// lis r11,2
	ctx.r11.s64 = 131072;
	// stw r20,68(r29)
	PPC_STORE_U32(var_r29 + 68, var_r20);
	// addi r31,r29,180
	var_r31 = (uint32_t)(var_r29 + 180);
	// stw r19,144(r29)
	PPC_STORE_U32(var_r29 + 144, var_r19);
	// ori r11,r11,25604
	ctx.r11.u64 = ctx.r11.u64 | 25604;
	// stw r20,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, var_r20);
	// lis r3,-2
	// li r10,0
	ctx.r10.s64 = 0;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r11,196(r29)
	PPC_STORE_U32(var_r29 + 196, ctx.r11.u32);
	// lis r11,-32164
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r8,r11,9836
	ctx.r8.s64 = ctx.r11.s64 + 9836;
	// lbz r11,198(r29)
	ctx.r11.u64 = PPC_LOAD_U8(var_r29 + 198);
	// li r4,255
	ctx.r4.s64 = 255;
	// ori r3,r3,2001
	ctx.r3.u64 = ctx.r3.u64 | 2001;
	// mr r9,r31
	ctx.r9.u64 = var_r31;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32256
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,18992(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 18992);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,184(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r29 + 184, temp.u32);
	// bl 0x825867bc
	__imp__XamUserReadProfileSettings(ctx, base);
	// cmplwi cr6,r3,122
	// beq cr6,0x82570ae4
	if (ctx.r3.u32 != 122) {
		// lis r22,-32768
		var_r22 = (uint32_t)(-2147483648);
		// ori r22,r22,16389
		var_r22 = (uint32_t)(var_r22 | 16389);
		// b 0x82570d80
		goto loc_82570D80;
	}
loc_82570AE4:
	// lis r4,24714
	ctx.r4.s64 = 1619656704;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
	// ori r4,r4,8194
	ctx.r4.u64 = ctx.r4.u64 | 8194;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// cmplwi r3,0
	// stw r3,176(r29)
	PPC_STORE_U32(var_r29 + 176, ctx.r3.u32);
	// beq 0x82570a58
	if (ctx.r3.u32 == 0) goto loc_82570A58;
	// addi r31,r29,48
	var_r31 = (uint32_t)(var_r29 + 48);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,32
	ctx.r4.s64 = 32;
	// li r3,256
	ctx.r3.s64 = 256;
	// mr r7,r31
	ctx.r7.u64 = var_r31;
	// bl 0x8256c8d0
	rage_C8D0(ctx, base);
	// mr. r22,r3
	var_r22 = ctx.r3.u32;
	// blt 0x82570d80
	if ((int32_t)var_r22 >= 0) {
		// addi r8,r29,52
		ctx.r8.s64 = (int64_t)(int32_t)var_r29 + 52;
		// mr r9,r20
		ctx.r9.u64 = var_r20;
	loc_82570B2C:
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r7,8(r11)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// lwz r10,4(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// mullw r11,r7,r9
		ctx.r11.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r9.s32);
		// add r10,r11,r10
		ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
		// addi r11,r10,24
		ctx.r11.s64 = ctx.r10.s64 + 24;
		// stw r10,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
		// stw r20,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r20);
		// lwz r10,4(r8)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
		// cmplwi r10,0
		// beq 0x82570b60
		if (ctx.r10.u32 != 0) {
			// stw r11,4(r10)
			PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r11.u32);
			// b 0x82570b64
		} else {
		loc_82570B60:
			// stw r11,0(r8)
			PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r11.u32);
		}
	loc_82570B64:
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// stw r11,4(r8)
		PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r11.u32);
		// cmplwi cr6,r9,5
		// blt cr6,0x82570b2c
		if (ctx.r9.u32 < 5) goto loc_82570B2C;
		// li r5,24
		ctx.r5.s64 = 24;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,128
		ctx.r3.s64 = ctx.r1.s64 + 128;
		// bl 0x82566898
		util_6898(ctx, base);
		// li r5,12
		ctx.r5.s64 = 12;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,112
		ctx.r3.s64 = ctx.r1.s64 + 112;
		// bl 0x82566898
		util_6898(ctx, base);
		// mr r30,r20
		var_r30 = (uint32_t)(var_r20);
		// cmplwi cr6,r27,0
		// beq cr6,0x82570c28
		if (var_r27 != 0) {
			// addi r31,r29,12
			var_r31 = (uint32_t)(var_r29 + 12);
		loc_82570BA4:
			// cmplwi cr6,r30,2
			// bge cr6,0x82570c28
			if (var_r30 >= 2) goto loc_82570C28;
			// lwz r11,0(r28)
			ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
			// mr r6,r31
			ctx.r6.u64 = var_r31;
			// li r5,0
			ctx.r5.s64 = 0;
			// mr r4,r29
			ctx.r4.u64 = var_r29;
			// mr r3,r19
			ctx.r3.u64 = var_r19;
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// mr. r22,r3
			var_r22 = ctx.r3.u32;
			// blt 0x82570c28
			if ((int32_t)var_r22 < 0) goto loc_82570C28;
			// lwz r3,0(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
			// addi r4,r1,96
			ctx.r4.s64 = ctx.r1.s64 + 96;
			// lwz r11,20(r11)
			// bctrl
			VCALL(ctx.r3.u32, 5, ctx, base);  // vtable slot 5 (byte +20)
			// lwz r10,96(r1)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
			// addi r8,r1,112
			ctx.r8.s64 = ctx.r1.s64 + 112;
			// addi r7,r1,128
			ctx.r7.s64 = ctx.r1.s64 + 128;
			// addi r28,r28,4
			var_r28 = (uint32_t)(var_r28 + 4);
			// lwz r11,12(r10)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
			// rlwinm r9,r11,1,0,30
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// add r9,r9,r30
			ctx.r9.u64 = ctx.r9.u64 + var_r30;
			// addi r30,r30,1
			var_r30 = (uint32_t)(var_r30 + 1);
			// rlwinm r9,r9,2,0,29
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
			// cmplw cr6,r30,r27
			// stwx r10,r11,r8
			PPC_STORE_U32(ctx.r11.u32 + ctx.r8.u32, ctx.r10.u32);
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
			// addi r31,r31,4
			var_r31 = (uint32_t)(var_r31 + 4);
			// stwx r11,r9,r7
			PPC_STORE_U32(ctx.r9.u32 + ctx.r7.u32, ctx.r11.u32);
			// blt cr6,0x82570ba4
			if (var_r30 < var_r27) goto loc_82570BA4;
		}
	loc_82570C28:
		// addi r11,r29,32
		ctx.r11.s64 = (int64_t)(int32_t)var_r29 + 32;
		// cmpwi cr6,r22,0
		// stw r30,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r30);
		// blt cr6,0x82570d80
		if ((int32_t)var_r22 < 0) goto loc_82570D80;
		// mr r25,r20
		var_r25 = (uint32_t)(var_r20);
		// mr r21,r20
		var_r21 = (uint32_t)(var_r20);
		// addi r31,r1,128
		var_r31 = (uint32_t)(ctx.r1.s64 + 128);
		// addi r23,r1,112
		var_r23 = (uint32_t)(ctx.r1.s64 + 112);
		// mr r26,r11
		var_r26 = ctx.r11.u32;
	loc_82570C4C:
		// li r5,8
		ctx.r5.s64 = 8;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,104
		ctx.r3.s64 = ctx.r1.s64 + 104;
		// mr r28,r20
		var_r28 = (uint32_t)(var_r20);
		// bl 0x82566898
		util_6898(ctx, base);
		// addi r30,r1,104
		var_r30 = (uint32_t)(ctx.r1.s64 + 104);
		// mr r24,r31
		var_r24 = (uint32_t)(var_r31);
		// li r27,2
		var_r27 = 2;
	loc_82570C6C:
		// lwz r3,0(r24)
		ctx.r3.u64 = PPC_LOAD_U32(var_r24 + 0);
		// cmplwi r3,0
		// beq 0x82570c9c
		if (ctx.r3.u32 != 0) {
			// lwz r11,0(r3)
  // [ph4a] vtable load collapsed
			// addi r4,r1,96
			ctx.r4.s64 = ctx.r1.s64 + 96;
			// lwz r11,20(r11)
  // [ph4a] slot load collapsed
			// bctrl
			VCALL(ctx.r3.u32, 5, ctx, base);  // pattern-B slot 5 (byte +20)
			// lwz r11,100(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
			// addi r28,r28,1
			var_r28 = (uint32_t)(var_r28 + 1);
			// stw r11,0(r30)
			PPC_STORE_U32(var_r30 + 0, ctx.r11.u32);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
		}
	loc_82570C9C:
		// addic. r27,r27,-1
		ctx.xer.ca = var_r27 > 0;
		var_r27 = (uint32_t)(var_r27 + -1);
		// addi r24,r24,4
		var_r24 = (uint32_t)(var_r24 + 4);
		// bne 0x82570c6c
		if ((int32_t)var_r27 != 0) goto loc_82570C6C;
		// cmplwi cr6,r28,0
		// beq cr6,0x82570d2c
		if (var_r28 != 0) {
			// addi r7,r26,4
			ctx.r7.s64 = (int64_t)(int32_t)var_r26 + 4;
			// lwz r4,0(r23)
			ctx.r4.u64 = PPC_LOAD_U32(var_r23 + 0);
			// addi r6,r1,104
			ctx.r6.s64 = ctx.r1.s64 + 104;
			// li r5,10
			ctx.r5.s64 = 10;
			// mr r3,r19
			ctx.r3.u64 = var_r19;
			// bl 0x8256c500
			msgMsgSink_C500_w(ctx, base);
			// mr. r22,r3
			var_r22 = ctx.r3.u32;
			// blt 0x82570d40
			if ((int32_t)var_r22 < 0) goto loc_82570D40;
			// addi r25,r25,1
			var_r25 = (uint32_t)(var_r25 + 1);
			// addi r26,r26,4
			var_r26 = (uint32_t)(var_r26 + 4);
			// mr r30,r20
			var_r30 = (uint32_t)(var_r20);
			// mr r28,r20
			var_r28 = (uint32_t)(var_r20);
		loc_82570CE0:
			// lwz r3,0(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
			// cmplwi r3,0
			// beq 0x82570d14
			if (ctx.r3.u32 != 0) {
				// lwz r11,0(r3)
  // [ph4a] vtable load collapsed
				// mr r6,r30
				ctx.r6.u64 = var_r30;
				// lwz r5,0(r26)
				ctx.r5.u64 = PPC_LOAD_U32(var_r26 + 0);
				// mr r4,r19
				ctx.r4.u64 = var_r19;
				// lwz r11,0(r11)
  // [ph4a] slot load collapsed
				// bctrl
				VCALL(ctx.r3.u32, 0, ctx, base);  // pattern-B slot 0 (byte +0)
				// mr. r22,r3
				var_r22 = ctx.r3.u32;
				// blt 0x82570d40
				if ((int32_t)var_r22 < 0) goto loc_82570D40;
				// addi r30,r30,1
				var_r30 = (uint32_t)(var_r30 + 1);
			}
		loc_82570D14:
			// addi r28,r28,1
			var_r28 = (uint32_t)(var_r28 + 1);
			// addi r31,r31,4
			var_r31 = (uint32_t)(var_r31 + 4);
			// cmplwi cr6,r28,2
			// blt cr6,0x82570ce0
			if (var_r28 < 2) goto loc_82570CE0;
			// cmpwi cr6,r22,0
			// blt cr6,0x82570d40
			if ((int32_t)var_r22 < 0) goto loc_82570D40;
		}
	loc_82570D2C:
		// addi r21,r21,1
		var_r21 = (uint32_t)(var_r21 + 1);
		// addi r23,r23,4
		var_r23 = (uint32_t)(var_r23 + 4);
		// mr r31,r24
		var_r31 = (uint32_t)(var_r24);
		// cmplwi cr6,r21,3
		// blt cr6,0x82570c4c
		if (var_r21 < 3) goto loc_82570C4C;
	loc_82570D40:
		// cmpwi cr6,r22,0
		// stw r25,44(r29)
		PPC_STORE_U32(var_r29 + 44, var_r25);
		// blt cr6,0x82570d80
		if ((int32_t)var_r22 < 0) goto loc_82570D80;
		// addi r8,r29,4
		ctx.r8.s64 = (int64_t)(int32_t)var_r29 + 4;
		// mr r7,r25
		ctx.r7.u64 = var_r25;
		// addi r6,r29,36
		ctx.r6.s64 = (int64_t)(int32_t)var_r29 + 36;
		// li r5,10
		ctx.r5.s64 = 10;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// mr r3,r19
		ctx.r3.u64 = var_r19;
		// bl 0x82574f18
		msgMsgSink_4F18_w(ctx, base);
		// li r11,4
		ctx.r11.s64 = 4;
		// stw r11,0(r29)
		PPC_STORE_U32(var_r29 + 0, ctx.r11.u32);
		// li r11,2
		ctx.r11.s64 = 2;
		// stw r11,140(r29)
		PPC_STORE_U32(var_r29 + 140, ctx.r11.u32);
		// mr. r22,r3
		var_r22 = ctx.r3.u32;
		// bge 0x82570d8c
		if ((int32_t)var_r22 >= 0) {
			// mr r3,r22
			ctx.r3.u64 = var_r22;
			// stw r29,0(r18)
			PPC_STORE_U32(var_r18 + 0, var_r29);
			return;
		}
	}
loc_82570D80:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// bl 0x82570870
	xam_0870(ctx, base);
	// mr r29,r20
	var_r29 = (uint32_t)(var_r20);
loc_82570D8C:
	// mr r3,r22
	ctx.r3.u64 = var_r22;
	// stw r29,0(r18)
	PPC_STORE_U32(var_r18 + 0, var_r29);
	return;
}

__attribute__((alias("__imp__xam_0DA0_w"))) PPC_WEAK_FUNC(xam_0DA0_w);
PPC_FUNC_IMPL(__imp__xam_0DA0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=192, savegprlr_21
	// mr r25,r3
	var_r25 = ctx.r3.u32;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r24,r25,8
	var_r24 = (uint32_t)(var_r25 + 8);
	// mr r23,r4
	var_r23 = ctx.r4.u32;
	// mr r22,r7
	var_r22 = ctx.r7.u32;
	// lwz r8,4(r25)
	ctx.r8.u64 = PPC_LOAD_U32(var_r25 + 4);
	// li r21,1
	var_r21 = 1;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r10,r24
	ctx.r10.u64 = var_r24;
	// lwz r27,8(r8)
	var_r27 = (uint32_t)(PPC_LOAD_U32(ctx.r8.u32 + 8));
loc_82570DD8:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi r8,0
	// beq 0x82570e14
	if (ctx.r8.u32 != 0) {
		// lwz r6,8(r10)
		ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
		// cmpwi cr6,r6,1
		// bne cr6,0x82570dfc
		if (ctx.r6.s32 == 1) {
			// lwz r8,8(r8)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
			// stw r8,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
			// b 0x82570e00
		} else {
		loc_82570DFC:
			// stw r7,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
		}
	loc_82570E00:
		// lwz r8,0(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmplwi cr6,r8,0
		// beq cr6,0x82570e18
		if (ctx.r8.u32 == 0) goto loc_82570E18;
		// addi r22,r22,1
		var_r22 = (uint32_t)(var_r22 + 1);
		// b 0x82570e18
	} else {
	loc_82570E14:
		// stw r7,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
	}
loc_82570E18:
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82570dd8
	if (ctx.r9.s32 != 0) goto loc_82570DD8;
	// cmplwi cr6,r27,0
	// beq cr6,0x82570f90
	if (var_r27 != 0) {
		// cmplwi cr6,r22,0
		// beq cr6,0x82570f90
		if (var_r22 == 0) {
			// mr r3,r21
			ctx.r3.u64 = var_r21;
			return;
		}
		// mr r21,r7
		var_r21 = ctx.r7.u32;
		// b 0x82570f88
		goto loc_82570F88;
		do {
			// addi r23,r23,-1
			var_r23 = (uint32_t)(var_r23 + -1);
			// cmplwi cr6,r27,0
			// beq cr6,0x82570f90
			// cmplwi cr6,r22,0
			// beq cr6,0x82570f90
			if (var_r22 == 0) {
				// mr r3,r21
				ctx.r3.u64 = var_r21;
				return;
			}
			// lwz r11,0(r27)
			ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
			// addi r9,r1,80
			ctx.r9.s64 = ctx.r1.s64 + 80;
			// li r8,2
			ctx.r8.s64 = 2;
			// lwz r10,12(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// lwz r11,4(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// subf r30,r11,r10
			var_r30 = (uint32_t)(ctx.r10.s64 - ctx.r11.s64);
		loc_82570E6C:
			// lwz r11,0(r9)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
			// cmplwi r11,0
			// beq 0x82570ea0
			if (ctx.r11.u32 != 0) {
				// lwz r10,0(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
				// lwz r7,12(r10)
				ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
				// lwz r10,4(r10)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
				// subf r10,r10,r7
				ctx.r10.s64 = ctx.r7.s64 - ctx.r10.s64;
				// cmplw cr6,r30,r10
				// blt cr6,0x82570ea0
				if (var_r30 < ctx.r10.u32) goto loc_82570EA0;
				// lwz r11,0(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
				// lwz r10,12(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
				// lwz r11,4(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// subf r30,r11,r10
				var_r30 = (uint32_t)(ctx.r10.s64 - ctx.r11.s64);
			}
		loc_82570EA0:
			// addic. r8,r8,-1
			ctx.xer.ca = ctx.r8.u32 > 0;
			ctx.r8.s64 = ctx.r8.s64 + -1;
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// bne 0x82570e6c
			if (ctx.r8.s32 != 0) goto loc_82570E6C;
			// addi r29,r1,80
			var_r29 = (uint32_t)(ctx.r1.s64 + 80);
			// mr r28,r24
			var_r28 = (uint32_t)(var_r24);
			// li r26,2
			var_r26 = 2;
		loc_82570EB8:
			// lwz r31,0(r29)
			var_r31 = (uint32_t)(PPC_LOAD_U32(var_r29 + 0));
			// cmplwi r31,0
			// beq 0x82570f38
			if (var_r31 != 0) {
				// lwz r11,0(r27)
				ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
				// mr r5,r30
				ctx.r5.u64 = var_r30;
				// lwz r10,0(r31)
				ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 0);
				// lwz r9,8(r11)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
				// lwz r11,4(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// add r4,r9,r11
				ctx.r4.u64 = ctx.r9.u64 + ctx.r11.u64;
				// lwz r11,8(r10)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
				// lwz r10,4(r10)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
				// add r3,r11,r10
				ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
				// bl 0x82434100
				memcpy(ctx, base);
				// lwz r11,0(r31)
				ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
				// lwz r9,4(r11)
				ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
				// lwz r10,12(r11)
				ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
				// add r9,r9,r30
				ctx.r9.u64 = ctx.r9.u64 + var_r30;
				// cmplw cr6,r9,r10
				// bge cr6,0x82570f08
				if (ctx.r9.u32 < ctx.r10.u32) {
					// mr r10,r9
					ctx.r10.u64 = ctx.r9.u64;
				}
			loc_82570F08:
				// stw r10,4(r11)
				PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
				// lwz r11,0(r31)
				ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
				// lwz r11,12(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
				// cmplw cr6,r10,r11
				// bne cr6,0x82570f38
				if (ctx.r10.u32 != ctx.r11.u32) goto loc_82570F38;
				// mr r4,r31
				ctx.r4.u64 = var_r31;
				// lwz r3,0(r28)
				ctx.r3.u64 = PPC_LOAD_U32(var_r28 + 0);
				// bl 0x8256c608
				xam_C608_2h(ctx, base);
				// cmplwi r3,0
				// stw r3,0(r29)
				PPC_STORE_U32(var_r29 + 0, ctx.r3.u32);
				// bne 0x82570f38
				if (ctx.r3.u32 != 0) goto loc_82570F38;
				// addi r22,r22,-1
				var_r22 = (uint32_t)(var_r22 + -1);
			}
		loc_82570F38:
			// addic. r26,r26,-1
			ctx.xer.ca = var_r26 > 0;
			var_r26 = (uint32_t)(var_r26 + -1);
			// addi r28,r28,4
			var_r28 = (uint32_t)(var_r28 + 4);
			// addi r29,r29,4
			var_r29 = (uint32_t)(var_r29 + 4);
			// bne 0x82570eb8
			if ((int32_t)var_r26 != 0) goto loc_82570EB8;
			// lwz r11,0(r27)
			ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
			// lwz r9,4(r11)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// lwz r10,12(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// add r9,r9,r30
			ctx.r9.u64 = ctx.r9.u64 + var_r30;
			// cmplw cr6,r9,r10
			// bge cr6,0x82570f64
			if (ctx.r9.u32 < ctx.r10.u32) {
				// mr r10,r9
				ctx.r10.u64 = ctx.r9.u64;
			}
		loc_82570F64:
			// stw r10,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
			// lwz r11,0(r27)
			ctx.r11.u64 = PPC_LOAD_U32(var_r27 + 0);
			// lwz r11,12(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
			// cmplw cr6,r10,r11
			// bne cr6,0x82570f88
			if (ctx.r10.u32 != ctx.r11.u32) goto loc_82570F88;
			// mr r4,r27
			ctx.r4.u64 = var_r27;
			// lwz r3,4(r25)
			ctx.r3.u64 = PPC_LOAD_U32(var_r25 + 4);
			// bl 0x8256c608
			xam_C608_2h(ctx, base);
			// mr r27,r3
			var_r27 = ctx.r3.u32;
			// cmplwi cr6,r23,0
			// bne cr6,0x82570e40
		} while (var_r23 != 0);
	}
loc_82570F90:
	// mr r3,r21
	ctx.r3.u64 = var_r21;
	return;
}

__attribute__((alias("__imp__phBoundCapsule_0FA0_fw"))) PPC_WEAK_FUNC(phBoundCapsule_0FA0_fw);
PPC_FUNC_IMPL(__imp__phBoundCapsule_0FA0_fw) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// FRAME: size=160, manual
	// li r7,2
	ctx.r7.s64 = 2;
	// lis r10,-32256
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// stb r7,128(r1)
	PPC_STORE_U8(ctx.r1.u32 + 128, ctx.r7.u8);
	// li r7,3
	ctx.r7.s64 = 3;
	// lfs f0,15784(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15784);
	ctx.f0.f64 = double(temp.f32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r9,112(r1)
	PPC_STORE_U8(ctx.r1.u32 + 112, ctx.r9.u8);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stb r9,88(r1)
	PPC_STORE_U8(ctx.r1.u32 + 88, ctx.r9.u8);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r8,72(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stb r7,136(r1)
	PPC_STORE_U8(ctx.r1.u32 + 136, ctx.r7.u8);
	// li r7,4
	ctx.r7.s64 = 4;
	// stb r10,120(r1)
	PPC_STORE_U8(ctx.r1.u32 + 120, ctx.r10.u8);
	// stfs f0,132(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stb r10,96(r1)
	PPC_STORE_U8(ctx.r1.u32 + 96, ctx.r10.u8);
	// addi r10,r1,88
	ctx.r10.s64 = ctx.r1.s64 + 88;
	// stfs f0,140(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// cmplwi cr6,r8,0
	// stb r7,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r7.u8);
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// bne cr6,0x82571060
	if (ctx.r8.u32 == 0) {
		// lis r7,-32256
		// addi r8,r1,116
		ctx.r8.s64 = ctx.r1.s64 + 116;
		// addi r9,r11,36
		ctx.r9.s64 = ctx.r11.s64 + 36;
		// li r10,4
		ctx.r10.s64 = 4;
		// lfs f0,15788(r7)
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 15788);
		ctx.f0.f64 = double(temp.f32);
	loc_82571034:
		// lwz r7,0(r9)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// cmplwi cr6,r7,65535
		// bgt cr6,0x82571044
		if (ctx.r7.u32 <= 65535) {
			// stfs f0,0(r8)
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
		}
	loc_82571044:
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// addi r8,r8,8
		ctx.r8.s64 = ctx.r8.s64 + 8;
		// bne 0x82571034
		if (ctx.r10.s32 != 0) goto loc_82571034;
		// addi r4,r1,96
		ctx.r4.s64 = ctx.r1.s64 + 96;
		// lwz r3,68(r11)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
		// bl 0x82460a48
		phBoundCapsule_0A48(ctx, base);
	}
loc_82571060:
	// blr
	return;
}

__attribute__((alias("__imp__phInst_1070_w"))) PPC_WEAK_FUNC(phInst_1070_w);
PPC_FUNC_IMPL(__imp__phInst_1070_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=192, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// li r29,1
	var_r29 = 1;
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// lwz r5,72(r31)
	ctx.r5.u64 = PPC_LOAD_U32(var_r31 + 72);
	// cmplw cr6,r30,r5
	// beq cr6,0x8257116c
	if (var_r30 != ctx.r5.u32) {
		// li r11,4
		ctx.r11.s64 = 4;
		// stb r29,96(r1)
		PPC_STORE_U8(ctx.r1.u32 + 96, (uint8_t)var_r29);
		// li r6,0
		ctx.r6.s64 = 0;
		// lis r7,-32256
		// lis r8,-32256
		// addi r10,r1,116
		ctx.r10.s64 = ctx.r1.s64 + 116;
		// stb r11,80(r1)
		PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r11.u8);
		// addi r11,r1,112
		ctx.r11.s64 = ctx.r1.s64 + 112;
		// stw r6,88(r1)
		PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r6.u32);
		// addi r9,r31,36
		ctx.r9.s64 = (int64_t)(int32_t)var_r31 + 36;
		// lfs f0,15784(r7)
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 15784);
		ctx.f0.f64 = double(temp.f32);
		// lfs f31,15788(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 15788);
		var_f31 = double(temp.f32);
		// stw r11,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
		// addi r11,r1,80
		ctx.r11.s64 = ctx.r1.s64 + 80;
		// stw r11,92(r1)
		PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
		// addi r11,r1,88
		ctx.r11.s64 = ctx.r1.s64 + 88;
		// stw r11,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
		// mr r11,r6
		ctx.r11.u64 = ctx.r6.u64;
	loc_825710E4:
		// lwz r8,0(r9)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// stb r6,-4(r10)
		PPC_STORE_U8(ctx.r10.u32 + -4, ctx.r6.u8);
		// cmplwi cr6,r8,65535
		// stb r11,-3(r10)
		PPC_STORE_U8(ctx.r10.u32 + -3, ctx.r11.u8);
		// bgt cr6,0x82571110
		if (ctx.r8.u32 <= 65535) {
			// lbz r8,64(r31)
			ctx.r8.u64 = PPC_LOAD_U8(var_r31 + 64);
			// slw r7,r29,r11
			ctx.r7.u64 = ctx.r11.u8 & 0x20 ? 0 : (var_r29 << (ctx.r11.u8 & 0x3F));
			// and. r8,r8,r7
			ctx.r8.u64 = ctx.r8.u64 & ctx.r7.u64;
			// bne 0x82571110
			if (ctx.r8.s32 != 0) goto loc_82571110;
			// stfs f31,0(r10)
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(var_f31);
			PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
			// b 0x82571114
		} else {
		loc_82571110:
			// stfs f0,0(r10)
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		}
	loc_82571114:
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// addi r10,r10,8
		ctx.r10.s64 = ctx.r10.s64 + 8;
		// cmplwi cr6,r11,4
		// blt cr6,0x825710e4
		if (ctx.r11.u32 < 4) goto loc_825710E4;
		// cmplwi cr6,r5,0
		// beq cr6,0x82571138
		if (ctx.r5.u32 != 0) {
			// mr r3,r5
			ctx.r3.u64 = ctx.r5.u64;
			// bl 0x824608b8
			phInst_08B8(ctx, base);
		}
	loc_82571138:
		// cmplwi cr6,r30,0
		// stw r30,72(r31)
		PPC_STORE_U32(var_r31 + 72, var_r30);
		// bne cr6,0x8257114c
		if (var_r30 == 0) {
			// lwz r30,76(r31)
			var_r30 = (uint32_t)(PPC_LOAD_U32(var_r31 + 76));
			// b 0x8257115c
		} else {
		loc_8257114C:
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			// bl 0x82460850
			util_0850(ctx, base);
			// stfs f31,116(r1)
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(var_f31);
			PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
			// stb r29,80(r1)
			PPC_STORE_U8(ctx.r1.u32 + 80, (uint8_t)var_r29);
		}
	loc_8257115C:
		// addi r4,r1,96
		ctx.r4.s64 = ctx.r1.s64 + 96;
		// lwz r3,68(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 68);
		// stw r30,88(r1)
		PPC_STORE_U32(ctx.r1.u32 + 88, var_r30);
		// bl 0x824609f0
		phInst_09F0_p28(ctx, base);
	}
loc_8257116C:
	return;
}

__attribute__((alias("__imp__xam_1178_2h"))) PPC_WEAK_FUNC(xam_1178_2h);
PPC_FUNC_IMPL(__imp__xam_1178_2h) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// cmpwi cr6,r11,0
	// beq cr6,0x82571198
	if (ctx.r11.s32 != 0) {
		// lwz r3,76(r3)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 76);
		// b 0x8257119c
	} else {
	loc_82571198:
		// lwz r3,68(r3)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 68);
	}
loc_8257119C:
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// b 0x82460980
	game_0980(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_11A8"))) PPC_WEAK_FUNC(xam_11A8);
PPC_FUNC_IMPL(__imp__xam_11A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// li r29,0
	var_r29 = 0;
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 20);
	// cmplwi cr6,r11,0
	// ble cr6,0x82571200
	if (ctx.r11.u32 > 0) {
		// addi r31,r30,12
		var_r31 = (uint32_t)(var_r30 + 12);
	loc_825711D0:
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r11,24(r11)
		// bctrl
		VCALL(ctx.r3.u32, 6, ctx, base);  // vtable slot 6 (byte +24)
		// cmplw cr6,r28,r3
		// beq cr6,0x8257120c
		if (var_r28 == ctx.r3.u32) {
			// addi r11,r29,3
			ctx.r11.s64 = (int64_t)(int32_t)var_r29 + 3;
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// lwzx r3,r11,r30
			ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r30);
			// b 0x82571204
			return;
		}
		// lwz r11,20(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 20);
		// addi r29,r29,1
		var_r29 = (uint32_t)(var_r29 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// cmplw cr6,r29,r11
		// blt cr6,0x825711d0
		if (var_r29 < ctx.r11.u32) goto loc_825711D0;
	}
loc_82571200:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82571204:
	return;
}

__attribute__((alias("__imp__game_1220"))) PPC_WEAK_FUNC(game_1220);
PPC_FUNC_IMPL(__imp__game_1220) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r29 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=256, savegprlr_24
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// stw r5,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r5.u32);
	// li r11,4
	ctx.r11.s64 = 4;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r28,0
	var_r28 = 0;
	// addi r26,r31,68
	var_r26 = (uint32_t)(var_r31 + 68);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// addi r10,r1,88
	ctx.r10.s64 = ctx.r1.s64 + 88;
	// stb r11,88(r1)
	PPC_STORE_U8(ctx.r1.u32 + 88, ctx.r11.u8);
	// li r30,1
	var_r30 = 1;
	// stb r11,113(r1)
	PPC_STORE_U8(ctx.r1.u32 + 113, ctx.r11.u8);
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// stb r11,121(r1)
	PPC_STORE_U8(ctx.r1.u32 + 121, ctx.r11.u8);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(var_r26 + 0);
	// mr r25,r6
	var_r25 = ctx.r6.u32;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, var_r28);
	// cmplwi r3,0
	ctx.cr0.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stb r30,96(r1)
	PPC_STORE_U8(ctx.r1.u32 + 96, (uint8_t)var_r30);
	// stb r28,112(r1)
	PPC_STORE_U8(ctx.r1.u32 + 112, (uint8_t)var_r28);
	// stb r30,120(r1)
	PPC_STORE_U8(ctx.r1.u32 + 120, (uint8_t)var_r30);
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// lis r10,0
	ctx.r10.s64 = 0;
	// stb r30,122(r1)
	PPC_STORE_U8(ctx.r1.u32 + 122, (uint8_t)var_r30);
	// ori r10,r10,48000
	ctx.r10.u64 = ctx.r10.u64 | 48000;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r11.u32);
	// stw r28,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, var_r28);
	// stw r31,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, var_r31);
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// beq 0x825712b8
	if (!(ctx.cr0.eq)) {
		// bl 0x824608b8
		phInst_08B8(ctx, base);
		// stw r28,0(r26)
		PPC_STORE_U32(var_r26 + 0, var_r28);
	}
loc_825712B8:
	// addi r24,r31,76
	var_r24 = (uint32_t)(var_r31 + 76);
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(var_r24 + 0);
	// cmplwi r3,0
	// beq 0x825712d0
	if (ctx.r3.u32 != 0) {
		// bl 0x824608b8
		phInst_08B8(ctx, base);
		// stw r28,0(r24)
		PPC_STORE_U32(var_r24 + 0, var_r28);
	}
loc_825712D0:
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 72);
	// cmplwi r3,0
	// beq 0x825712e4
	if (ctx.r3.u32 != 0) {
		// bl 0x824608b8
		phInst_08B8(ctx, base);
		// stw r28,72(r31)
		PPC_STORE_U32(var_r31 + 72, var_r28);
	}
loc_825712E4:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 8);
	// mr r11,r28
	ctx.r11.u64 = var_r28;
	// mr r10,r28
	ctx.r10.u64 = var_r28;
	// lwz r9,56(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f31,15788(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
	var_f31 = double(temp.f32);
loc_82571300:
	// addi r9,r10,1
	ctx.r9.s64 = ctx.r10.s64 + 1;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// rlwinm r9,r10,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// addi r5,r1,145
	ctx.r5.s64 = ctx.r1.s64 + 145;
	// addi r4,r1,148
	ctx.r4.s64 = ctx.r1.s64 + 148;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// stbx r8,r9,r6
	PPC_STORE_U8(ctx.r9.u32 + ctx.r6.u32, ctx.r8.u8);
	// cmplwi cr6,r10,4
	// stbx r7,r9,r5
	PPC_STORE_U8(ctx.r9.u32 + ctx.r5.u32, ctx.r7.u8);
	// stfsx f31,r9,r4
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(var_f31);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, temp.u32);
	// blt cr6,0x82571300
	if (ctx.r10.u32 < 4) goto loc_82571300;
	// mr r4,r24
	ctx.r4.u64 = var_r24;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x824612d8
	game_12D8(ctx, base);
	// mr. r29,r3
	var_r29 = ctx.r3.u32;
	// blt 0x82571468
	if ((int32_t)var_r29 >= 0) {
		// lis r10,-32256
		// stb r30,113(r1)
		PPC_STORE_U8(ctx.r1.u32 + 113, (uint8_t)var_r30);
		// stb r28,122(r1)
		PPC_STORE_U8(ctx.r1.u32 + 122, (uint8_t)var_r28);
		// mr r9,r28
		ctx.r9.u64 = var_r28;
		// stw r27,124(r1)
		PPC_STORE_U32(ctx.r1.u32 + 124, var_r27);
		// mr r11,r28
		ctx.r11.u64 = var_r28;
		// lfs f0,15784(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15784);
		ctx.f0.f64 = double(temp.f32);
	loc_82571368:
		// addi r8,r11,9
		ctx.r8.s64 = ctx.r11.s64 + 9;
		// rlwinm r10,r11,3,0,28
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
		// rlwinm r8,r8,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r7,r1,144
		ctx.r7.s64 = ctx.r1.s64 + 144;
		// addi r6,r1,145
		ctx.r6.s64 = ctx.r1.s64 + 145;
		// lwzx r8,r8,r31
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + var_r31);
		// stbx r28,r10,r7
		PPC_STORE_U8(ctx.r10.u32 + ctx.r7.u32, (uint8_t)var_r28);
		// cmplwi cr6,r8,65535
		// stbx r9,r10,r6
		PPC_STORE_U8(ctx.r10.u32 + ctx.r6.u32, ctx.r9.u8);
		// bgt cr6,0x825713ac
		if (ctx.r8.u32 <= 65535) {
			// lbz r9,64(r31)
			ctx.r9.u64 = PPC_LOAD_U8(var_r31 + 64);
			// slw r8,r30,r11
			ctx.r8.u64 = ctx.r11.u8 & 0x20 ? 0 : (var_r30 << (ctx.r11.u8 & 0x3F));
			// and. r9,r9,r8
			ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
			// bne 0x825713ac
			if (ctx.r9.s32 != 0) goto loc_825713AC;
			// addi r9,r1,148
			ctx.r9.s64 = ctx.r1.s64 + 148;
			// stfsx f31,r10,r9
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(var_f31);
			PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, temp.u32);
			// b 0x825713b4
		} else {
		loc_825713AC:
			// addi r9,r1,148
			ctx.r9.s64 = ctx.r1.s64 + 148;
			// stfsx f0,r10,r9
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, temp.u32);
		}
	loc_825713B4:
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// clrlwi r9,r11,24
		ctx.r9.u64 = ctx.r11.u32 & 0xFF;
		// mr r11,r9
		ctx.r11.u64 = ctx.r9.u64;
		// cmplwi cr6,r11,4
		// blt cr6,0x82571368
		if (ctx.r11.u32 < 4) goto loc_82571368;
		// cmplwi cr6,r25,0
		// stw r25,72(r31)
		PPC_STORE_U32(var_r31 + 72, var_r25);
		// bne cr6,0x825713dc
		if (var_r25 == 0) {
			// lwz r25,0(r24)
			var_r25 = (uint32_t)(PPC_LOAD_U32(var_r24 + 0));
			// b 0x825713ec
		} else {
		loc_825713DC:
			// mr r3,r25
			ctx.r3.u64 = var_r25;
			// bl 0x82460850
			util_0850(ctx, base);
			// stfs f31,148(r1)
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(var_f31);
			PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
			// stb r30,88(r1)
			PPC_STORE_U8(ctx.r1.u32 + 88, (uint8_t)var_r30);
		}
	loc_825713EC:
		// mr r4,r26
		ctx.r4.u64 = var_r26;
		// stw r25,80(r1)
		PPC_STORE_U32(ctx.r1.u32 + 80, var_r25);
		// addi r3,r1,112
		ctx.r3.s64 = ctx.r1.s64 + 112;
		// bl 0x824612d8
		game_12D8(ctx, base);
		// mr. r29,r3
		var_r29 = ctx.r3.u32;
		// blt 0x82571468
		if ((int32_t)var_r29 < 0) goto loc_82571468;
		// lwz r11,20(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
		// cmplwi cr6,r11,0
		// ble cr6,0x82571460
		if (ctx.r11.u32 > 0) {
			// mr r30,r28
			var_r30 = (uint32_t)(var_r28);
		loc_82571414:
			// addi r11,r30,3
			ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 3;
			// lwz r4,0(r26)
			ctx.r4.u64 = PPC_LOAD_U32(var_r26 + 0);
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// lwzx r3,r11,r31
			ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
			// lwz r11,32(r11)
			// bctrl
			VCALL(ctx.r3.u32, 8, ctx, base);  // vtable slot 8 (byte +32)
			// mr. r29,r3
			var_r29 = ctx.r3.u32;
			// bge 0x8257144c
			if ((int32_t)var_r29 < 0) {
				// lis r11,-32768
				// ori r11,r11,16385
				ctx.r11.u64 = ctx.r11.u64 | 16385;
				// cmpw cr6,r29,r11
				// bne cr6,0x82571460
				if ((int32_t)var_r29 != ctx.r11.s32) goto loc_82571460;
			}
		loc_8257144C:
			// addi r11,r30,1
			ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 1;
			// lwz r10,20(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 20);
			// clrlwi r30,r11,24
			var_r30 = (uint32_t)(ctx.r11.u32 & 0xFF);
			// cmplw cr6,r30,r10
			// blt cr6,0x82571414
			if (var_r30 < ctx.r10.u32) goto loc_82571414;
		}
	loc_82571460:
		// cmpwi cr6,r29,0
		// bge cr6,0x82571490
		if ((int32_t)var_r29 >= 0) {
			// mr r3,r29
			ctx.r3.u64 = var_r29;
			return;
		}
	}
loc_82571468:
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(var_r26 + 0);
	// cmplwi r3,0
	// beq 0x8257147c
	if (ctx.r3.u32 != 0) {
		// bl 0x824608b8
		phInst_08B8(ctx, base);
		// stw r28,0(r26)
		PPC_STORE_U32(var_r26 + 0, var_r28);
	}
loc_8257147C:
	// lwz r3,0(r24)
	ctx.r3.u64 = PPC_LOAD_U32(var_r24 + 0);
	// cmplwi r3,0
	// beq 0x82571490
	if (ctx.r3.u32 != 0) {
		// bl 0x824608b8
		phInst_08B8(ctx, base);
		// stw r28,0(r24)
		PPC_STORE_U32(var_r24 + 0, var_r28);
	}
loc_82571490:
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	return;
}

__attribute__((alias("__imp__xam_14A0_w"))) PPC_WEAK_FUNC(xam_14A0_w);
PPC_FUNC_IMPL(__imp__xam_14A0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x8257157c
	if (var_r31 != 0) {
		// lwz r11,32(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
		// li r28,0
		var_r28 = 0;
		// mr r29,r28
		var_r29 = (uint32_t)(var_r28);
		// cmplwi cr6,r11,0
		// ble cr6,0x825714f0
		if (ctx.r11.u32 > 0) {
			// addi r30,r31,24
			var_r30 = (uint32_t)(var_r31 + 24);
		loc_825714D0:
			// lwz r3,0(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
			// bl 0x8256c458
			xam_C458_w(ctx, base);
			// stw r28,0(r30)
			PPC_STORE_U32(var_r30 + 0, var_r28);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// lwz r11,32(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
			// cmplw cr6,r29,r11
			// blt cr6,0x825714d0
			if (var_r29 < ctx.r11.u32) goto loc_825714D0;
		}
	loc_825714F0:
		// lwz r11,20(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
		// mr r29,r28
		var_r29 = (uint32_t)(var_r28);
		// cmplwi cr6,r11,0
		// ble cr6,0x82571530
		if (ctx.r11.u32 > 0) {
			// addi r30,r31,12
			var_r30 = (uint32_t)(var_r31 + 12);
		loc_82571504:
			// lwz r3,0(r30)
			ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
			// lwz r11,4(r11)
			// bctrl
			VCALL(ctx.r3.u32, 1, ctx, base);  // vtable slot 1 (byte +4)
			// stw r28,0(r30)
			PPC_STORE_U32(var_r30 + 0, var_r28);
			// lwz r11,20(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
			// cmplw cr6,r29,r11
			// blt cr6,0x82571504
			if (var_r29 < ctx.r11.u32) goto loc_82571504;
		}
	loc_82571530:
		// lwz r3,68(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 68);
		// cmplwi r3,0
		// beq 0x82571544
		if (ctx.r3.u32 != 0) {
			// bl 0x824608b8
			phInst_08B8(ctx, base);
			// stw r28,68(r31)
			PPC_STORE_U32(var_r31 + 68, var_r28);
		}
	loc_82571544:
		// lwz r3,76(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 76);
		// cmplwi r3,0
		// beq 0x82571558
		if (ctx.r3.u32 != 0) {
			// bl 0x824608b8
			phInst_08B8(ctx, base);
			// stw r28,76(r31)
			PPC_STORE_U32(var_r31 + 76, var_r28);
		}
	loc_82571558:
		// lwz r3,72(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 72);
		// cmplwi r3,0
		// beq 0x8257156c
		if (ctx.r3.u32 != 0) {
			// bl 0x824608b8
			phInst_08B8(ctx, base);
			// stw r28,72(r31)
			PPC_STORE_U32(var_r31 + 72, var_r28);
		}
	loc_8257156C:
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// ori r4,r4,32784
		ctx.r4.u64 = ctx.r4.u64 | 32784;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_8257157C:
	return;
}

__attribute__((alias("__imp__xam_1588"))) PPC_WEAK_FUNC(xam_1588);
PPC_FUNC_IMPL(__imp__xam_1588) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r29,0
	var_r29 = 0;
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
	// cmplwi cr6,r11,0
	// ble cr6,0x825715ec
	if (ctx.r11.u32 > 0) {
		// addi r30,r31,24
		var_r30 = (uint32_t)(var_r31 + 24);
	loc_825715AC:
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// addi r7,r1,80
		ctx.r7.s64 = ctx.r1.s64 + 80;
		// addi r6,r1,84
		ctx.r6.s64 = ctx.r1.s64 + 84;
		// ld r4,0(r31)
		ctx.r4.u64 = PPC_LOAD_U64(var_r31 + 0);
		// lwz r3,8(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
		// lwz r5,24(r11)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
		// bl 0x8256e6a8
		xam_E6A8_2hr(ctx, base);
		// lwz r5,80(r1)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// lwz r3,0(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
		// lwz r4,84(r1)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
		// bl 0x8256c200
		xam_C200_2h(ctx, base);
		// lwz r11,32(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
		// addi r29,r29,1
		var_r29 = (uint32_t)(var_r29 + 1);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// cmplw cr6,r29,r11
		// blt cr6,0x825715ac
		if (var_r29 < ctx.r11.u32) goto loc_825715AC;
	}
loc_825715EC:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
	// li r29,0
	var_r29 = 0;
	// cmplwi cr6,r11,0
	// ble cr6,0x82571628
	if (ctx.r11.u32 > 0) {
		// addi r30,r31,12
		var_r30 = (uint32_t)(var_r31 + 12);
	loc_82571600:
		// lwz r3,0(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
		// lwz r11,16(r11)
		// bctrl
		VCALL(ctx.r3.u32, 4, ctx, base);  // vtable slot 4 (byte +16)
		// lwz r11,20(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
		// addi r29,r29,1
		var_r29 = (uint32_t)(var_r29 + 1);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// cmplw cr6,r29,r11
		// blt cr6,0x82571600
		if (var_r29 < ctx.r11.u32) goto loc_82571600;
	}
loc_82571628:
	// li r3,0
	ctx.r3.s64 = 0;
	return;
}

__attribute__((alias("__imp__xam_1638_2h"))) PPC_WEAK_FUNC(xam_1638_2h);
PPC_FUNC_IMPL(__imp__xam_1638_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// lis r28,-32761
	var_r28 = (uint32_t)(-2147024896);
	// mr r27,r3
	var_r27 = ctx.r3.u32;
	// ori r28,r28,87
	var_r28 = (uint32_t)(var_r28 | 87);
	// li r30,0
	var_r30 = 0;
	// cmplwi cr6,r29,0
	// beq cr6,0x825716a0
	if (var_r29 != 0) {
		// mr r31,r4
		var_r31 = ctx.r4.u32;
	loc_82571664:
		// mr r3,r27
		ctx.r3.u64 = var_r27;
		// lwz r4,0(r31)
		ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 0);
		// bl 0x825711a8
		xam_11A8(ctx, base);
		// cmplwi r3,0
		// beq 0x825716a0
		if (ctx.r3.u32 == 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// lwz r11,8(r11)
		// bctrl
		VCALL(ctx.r3.u32, 2, ctx, base);  // vtable slot 2 (byte +8)
		// mr. r28,r3
		var_r28 = ctx.r3.u32;
		// blt 0x825716a0
		if ((int32_t)var_r28 < 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// cmplw cr6,r30,r29
		// blt cr6,0x82571664
		if (var_r30 < var_r29) goto loc_82571664;
	}
loc_825716A0:
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	return;
}

__attribute__((alias("__imp__xam_16B0_2h"))) PPC_WEAK_FUNC(xam_16B0_2h);
PPC_FUNC_IMPL(__imp__xam_16B0_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// lis r28,-32761
	var_r28 = (uint32_t)(-2147024896);
	// mr r27,r3
	var_r27 = ctx.r3.u32;
	// ori r28,r28,87
	var_r28 = (uint32_t)(var_r28 | 87);
	// li r30,0
	var_r30 = 0;
	// cmplwi cr6,r29,0
	// beq cr6,0x82571718
	if (var_r29 != 0) {
		// mr r31,r4
		var_r31 = ctx.r4.u32;
	loc_825716DC:
		// mr r3,r27
		ctx.r3.u64 = var_r27;
		// lwz r4,0(r31)
		ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 0);
		// bl 0x825711a8
		xam_11A8(ctx, base);
		// cmplwi r3,0
		// beq 0x82571718
		if (ctx.r3.u32 == 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// lwz r11,12(r11)
		// bctrl
		VCALL(ctx.r3.u32, 3, ctx, base);  // vtable slot 3 (byte +12)
		// mr. r28,r3
		var_r28 = ctx.r3.u32;
		// blt 0x82571718
		if ((int32_t)var_r28 < 0) {
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			return;
		}
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// cmplw cr6,r30,r29
		// blt cr6,0x825716dc
		if (var_r30 < var_r29) goto loc_825716DC;
	}
loc_82571718:
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	return;
}

__attribute__((alias("__imp__xam_1728_w"))) PPC_WEAK_FUNC(xam_1728_w);
PPC_FUNC_IMPL(__imp__xam_1728_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r27 = 0;
	// FRAME: size=144, savegprlr_26
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r26,r4
	var_r26 = ctx.r4.u32;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// li r5,16
	ctx.r5.s64 = 16;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,36
	ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 36;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r29,r7
	var_r29 = ctx.r7.u32;
	// mr r27,r8
	var_r27 = ctx.r8.u32;
	// bl 0x82566898
	util_6898(ctx, base);
	// cmplwi cr6,r30,0
	// stb r27,64(r31)
	PPC_STORE_U8(var_r31 + 64, (uint8_t)var_r27);
	// bne cr6,0x82571790
	if (var_r30 == 0) {
		// cmplwi cr6,r28,0
		// bne cr6,0x82571790
		if (var_r28 != 0) goto loc_82571790;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82571070
		phInst_1070_w(ctx, base);
		// cmpwi cr6,r3,1
		// bne cr6,0x825717ac
		if (ctx.r3.s32 != 1) goto loc_825717AC;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82570fa0
		phBoundCapsule_0FA0_fw(ctx, base);
		// b 0x825717ac
	} else {
	loc_82571790:
		// mr r6,r29
		ctx.r6.u64 = var_r29;
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82571220
		game_1220(ctx, base);
		// cmpwi r3,0
		// blt 0x825717bc
		if (ctx.r3.s32 < 0) {
			return;
		}
	}
loc_825717AC:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// std r26,0(r31)
	PPC_STORE_U64(var_r31 + 0, var_r26);
	// stw r10,1308(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1308, ctx.r10.u32);
loc_825717BC:
	return;
}

__attribute__((alias("__imp__xam_17C8_w"))) PPC_WEAK_FUNC(xam_17C8_w);
PPC_FUNC_IMPL(__imp__xam_17C8_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, savegprlr_29
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// bl 0x82566898
	util_6898(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
	// li r29,0
	var_r29 = 0;
	// cmplwi cr6,r11,0
	// ble cr6,0x82571820
	if (ctx.r11.u32 > 0) {
		// addi r30,r31,12
		var_r30 = (uint32_t)(var_r31 + 12);
	loc_825717F8:
		// lwz r3,0(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
		// lwz r11,12(r11)
		// bctrl
		VCALL(ctx.r3.u32, 3, ctx, base);  // vtable slot 3 (byte +12)
		// lwz r11,20(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
		// addi r29,r29,1
		var_r29 = (uint32_t)(var_r29 + 1);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// cmplw cr6,r29,r11
		// blt cr6,0x825717f8
		if (var_r29 < ctx.r11.u32) goto loc_825717F8;
	}
loc_82571820:
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 72);
	// cmplwi r3,0
	// beq 0x82571838
	if (ctx.r3.u32 != 0) {
		// bl 0x824608b8
		phInst_08B8(ctx, base);
		// li r11,0
		ctx.r11.s64 = 0;
		// stw r11,72(r31)
		PPC_STORE_U32(var_r31 + 72, ctx.r11.u32);
	}
loc_82571838:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,1308(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1308, ctx.r10.u32);
	return;
}

__attribute__((alias("__imp__xam_1850_2h"))) PPC_WEAK_FUNC(xam_1850_2h);
PPC_FUNC_IMPL(__imp__xam_1850_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=112, savegprlr_29
	// lis r11,-32254
	// lis r31,-32768
	var_r31 = (uint32_t)(-2147483648);
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// ori r31,r31,16389
	var_r31 = (uint32_t)(var_r31 | 16389);
	// lwz r4,10176(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10176);
	// bl 0x825711a8
	xam_11A8(ctx, base);
	// cmplwi r3,0
	// beq 0x82571890
	if (ctx.r3.u32 != 0) {
		// mr r5,r29
		ctx.r5.u64 = var_r29;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// bl 0x8256b428
		xam_B428_w(ctx, base);
		// mr r31,r3
		var_r31 = ctx.r3.u32;
	}
loc_82571890:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	return;
}

__attribute__((alias("__imp__xam_18A0_2h"))) PPC_WEAK_FUNC(xam_18A0_2h);
PPC_FUNC_IMPL(__imp__xam_18A0_2h) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r4,9
	ctx.r11.s64 = ctx.r4.s64 + 9;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r3
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	// cmplw cr6,r5,r10
	// beq cr6,0x825718c4
	if (ctx.r5.u32 != ctx.r10.u32) {
		// stwx r5,r11,r3
		PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, ctx.r5.u32);
		// li r10,1
		ctx.r10.s64 = 1;
		// lwz r11,8(r3)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
		// stw r10,1308(r11)
		PPC_STORE_U32(ctx.r11.u32 + 1308, ctx.r10.u32);
	}
loc_825718C4:
	// b 0x82570fa0
	phBoundCapsule_0FA0_fw(ctx, base);
	return;
}

__attribute__((alias("__imp__atSingleton_18C8"))) PPC_WEAK_FUNC(atSingleton_18C8);
PPC_FUNC_IMPL(__imp__atSingleton_18C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r29,0
	var_r29 = 0;
	// li r28,1
	var_r28 = 1;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
	// stw r29,52(r31)
	PPC_STORE_U32(var_r31 + 52, var_r29);
	// cmplwi cr6,r11,0
	// ble cr6,0x82571928
	if (ctx.r11.u32 > 0) {
		// addi r30,r31,12
		var_r30 = (uint32_t)(var_r31 + 12);
	loc_825718F4:
		// lwz r3,0(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0)/* atSingleton::vtable@+0x0 */;
		// lwz r11,36(r11)
		// bctrl
		VCALL(ctx.r3.u32, 9, ctx, base);  // vtable slot 9 (byte +36)
		// cmpwi cr6,r3,1
		// bne cr6,0x82571914
		if (ctx.r3.s32 == 1) {
			// stw r28,52(r31)
			PPC_STORE_U32(var_r31 + 52, var_r28);
		}
	loc_82571914:
		// lwz r11,20(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
		// addi r29,r29,1
		var_r29 = (uint32_t)(var_r29 + 1);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// cmplw cr6,r29,r11
		// blt cr6,0x825718f4
		if (var_r29 < ctx.r11.u32) goto loc_825718F4;
	}
loc_82571928:
	// lwz r11,52(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 52);
	// cmpwi cr6,r11,0
	// beq cr6,0x82571940
	if (ctx.r11.s32 != 0) {
		// li r11,200
		ctx.r11.s64 = 200;
		// stw r11,56(r31)
		PPC_STORE_U32(var_r31 + 56, ctx.r11.u32);
		// b 0x82571974
	} else {
	loc_82571940:
		// lwz r11,56(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 56);
		// cmpwi cr6,r11,0
		// ble cr6,0x82571974
		if (ctx.r11.s32 <= 0) {
			// bl 0x82566f98
			atSingleton_6F98_g(ctx, base);
			// mr r11,r3
			ctx.r11.u64 = ctx.r3.u64;
			// lwz r3,52(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 52);
			// stw r11,60(r31)
			PPC_STORE_U32(var_r31 + 60, ctx.r11.u32);
			return;
		}
		// lwz r11,60(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 60);
		// cmplwi cr6,r11,0
		// beq cr6,0x82571970
		if (ctx.r11.u32 != 0) {
			// bl 0x82566f98
			atSingleton_6F98_g(ctx, base);
			// lwz r11,60(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 60);
			// lwz r10,56(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 56);
			// subf r11,r3,r11
			ctx.r11.s64 = ctx.r11.s64 - ctx.r3.s64;
			// add r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
			// stw r11,56(r31)
			PPC_STORE_U32(var_r31 + 56, ctx.r11.u32);
		}
	loc_82571970:
		// stw r28,52(r31)
		PPC_STORE_U32(var_r31 + 52, var_r28);
	}
loc_82571974:
	// bl 0x82566f98
	atSingleton_6F98_g(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r3,52(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 52);
	// stw r11,60(r31)
	PPC_STORE_U32(var_r31 + 60, ctx.r11.u32);
	return;
}

__attribute__((alias("__imp__xam_1990_w"))) PPC_WEAK_FUNC(xam_1990_w);
PPC_FUNC_IMPL(__imp__xam_1990_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82566898
	util_6898(ctx, base);
	// lwz r11,32(r28)
	ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 32);
	// li r30,0
	var_r30 = 0;
	// cmplwi cr6,r11,0
	// ble cr6,0x82571a24
	if (ctx.r11.u32 > 0) {
		// addi r31,r28,24
		var_r31 = (uint32_t)(var_r28 + 24);
	loc_825719C8:
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// li r9,0
		ctx.r9.s64 = 0;
		// lwz r10,24(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
		// lwz r29,12(r10)
		var_r29 = (uint32_t)(PPC_LOAD_U32(ctx.r10.u32 + 12));
		// addi r10,r11,16
		ctx.r10.s64 = ctx.r11.s64 + 16;
	loc_825719DC:
		// lwz r8,-8(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + -8);
		// cmplwi cr6,r8,0
		// beq cr6,0x825719f4
		if (ctx.r8.u32 != 0) {
			// lwz r8,0(r10)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			// cmpwi cr6,r8,1
			// beq cr6,0x82571a2c
			if (ctx.r8.s32 == 1) goto loc_82571A2C;
		}
	loc_825719F4:
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// cmplwi cr6,r9,2
		// blt cr6,0x825719dc
		if (ctx.r9.u32 < 2) goto loc_825719DC;
		// li r3,0
		ctx.r3.s64 = 0;
	loc_82571A08:
		// rlwinm r11,r29,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r29 | (var_r29 << 32), 2) & 0xFFFFFFFC;
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// stwx r3,r11,r27
		PPC_STORE_U32(ctx.r11.u32 + var_r27, ctx.r3.u32);
		// lwz r11,32(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 32);
		// cmplw cr6,r30,r11
		// blt cr6,0x825719c8
		if (var_r30 < ctx.r11.u32) goto loc_825719C8;
	}
loc_82571A24:
	return;
loc_82571A2C:
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r3,r11,8
	ctx.r3.s64 = ctx.r11.s64 + 8;
	// bl 0x8256c5e8
	xam_C5E8_gen(ctx, base);
	// b 0x82571a08
	goto loc_82571A08;
}

__attribute__((alias("__imp__msgMsgSink_1A40_w"))) PPC_WEAK_FUNC(msgMsgSink_1A40_w);
PPC_FUNC_IMPL(__imp__msgMsgSink_1A40_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r19 = 0;
	uint32_t var_r18 = 0;
	uint32_t var_r17 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r27 = 0;
	// FRAME: size=272, savegprlr_17
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// mr r20,r3
	var_r20 = ctx.r3.u32;
	// ori r4,r4,32784
	ctx.r4.u64 = ctx.r4.u64 | 32784;
	// li r3,80
	ctx.r3.s64 = 80;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// mr r19,r6
	var_r19 = ctx.r6.u32;
	// mr r18,r7
	var_r18 = ctx.r7.u32;
	// mr r17,r8
	var_r17 = ctx.r8.u32;
	// li r26,0
	var_r26 = 0;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r25,r3
	var_r25 = ctx.r3.u32;
	// bne 0x82571a8c
	if ((int32_t)var_r25 == 0) {
		// lis r26,-32761
		var_r26 = (uint32_t)(-2147024896);
		// ori r26,r26,14
		var_r26 = (uint32_t)(var_r26 | 14);
		// b 0x82571c84
	} else {
	loc_82571A8C:
		// li r5,24
		ctx.r5.s64 = 24;
		// stw r20,8(r25)
		PPC_STORE_U32(var_r25 + 8, var_r20);
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,112
		ctx.r3.s64 = ctx.r1.s64 + 112;
		// bl 0x82566898
		util_6898(ctx, base);
		// li r5,12
		ctx.r5.s64 = 12;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,96
		ctx.r3.s64 = ctx.r1.s64 + 96;
		// bl 0x82566898
		util_6898(ctx, base);
		// li r30,0
		var_r30 = 0;
		// cmplwi cr6,r28,0
		// beq cr6,0x82571b44
		if (var_r28 != 0) {
			// addi r31,r25,12
			var_r31 = (uint32_t)(var_r25 + 12);
		loc_82571AC0:
			// cmplwi cr6,r30,2
			// bge cr6,0x82571b44
			if (var_r30 >= 2) goto loc_82571B44;
			// lwz r11,0(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0)/* msgMsgSink::vtable@+0x0 */;
			// mr r6,r31
			ctx.r6.u64 = var_r31;
			// li r5,1
			ctx.r5.s64 = 1;
			// mr r4,r25
			ctx.r4.u64 = var_r25;
			// mr r3,r20
			ctx.r3.u64 = var_r20;
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// mr. r26,r3
			var_r26 = ctx.r3.u32;
			// blt 0x82571b44
			if ((int32_t)var_r26 < 0) goto loc_82571B44;
			// lwz r3,0(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0)/* msgMsgSink::vtable@+0x0 */;
			// addi r4,r1,80
			ctx.r4.s64 = ctx.r1.s64 + 80;
			// lwz r11,20(r11)
			// bctrl
			VCALL(ctx.r3.u32, 5, ctx, base);  // vtable slot 5 (byte +20)
			// lwz r10,80(r1)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
			// addi r8,r1,96
			ctx.r8.s64 = ctx.r1.s64 + 96;
			// addi r7,r1,112
			ctx.r7.s64 = ctx.r1.s64 + 112;
			// addi r29,r29,4
			var_r29 = (uint32_t)(var_r29 + 4);
			// lwz r11,12(r10)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
			// rlwinm r9,r11,1,0,30
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// add r9,r9,r30
			ctx.r9.u64 = ctx.r9.u64 + var_r30;
			// addi r30,r30,1
			var_r30 = (uint32_t)(var_r30 + 1);
			// rlwinm r9,r9,2,0,29
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
			// cmplw cr6,r30,r28
			// stwx r10,r11,r8
			PPC_STORE_U32(ctx.r11.u32 + ctx.r8.u32, ctx.r10.u32);
			// lwz r11,0(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0)/* msgMsgSink::vtable@+0x0 */;
			// addi r31,r31,4
			var_r31 = (uint32_t)(var_r31 + 4);
			// stwx r11,r9,r7
			PPC_STORE_U32(ctx.r9.u32 + ctx.r7.u32, ctx.r11.u32);
			// blt cr6,0x82571ac0
			if (var_r30 < var_r28) goto loc_82571AC0;
		}
	loc_82571B44:
		// addi r11,r25,20
		ctx.r11.s64 = (int64_t)(int32_t)var_r25 + 20;
		// cmpwi cr6,r26,0
		// stw r30,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r30);
		// blt cr6,0x82571c84
		if ((int32_t)var_r26 < 0) goto loc_82571C84;
		// li r24,0
		var_r24 = 0;
		// li r21,0
		var_r21 = 0;
		// addi r31,r1,112
		var_r31 = (uint32_t)(ctx.r1.s64 + 112);
		// addi r22,r1,96
		var_r22 = (uint32_t)(ctx.r1.s64 + 96);
		// mr r28,r11
		var_r28 = ctx.r11.u32;
	loc_82571B68:
		// li r5,8
		ctx.r5.s64 = 8;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r1,88
		ctx.r3.s64 = ctx.r1.s64 + 88;
		// li r29,0
		var_r29 = 0;
		// bl 0x82566898
		util_6898(ctx, base);
		// addi r30,r1,88
		var_r30 = (uint32_t)(ctx.r1.s64 + 88);
		// mr r23,r31
		var_r23 = (uint32_t)(var_r31);
		// li r27,2
		var_r27 = 2;
	loc_82571B88:
		// lwz r3,0(r23)
		ctx.r3.u64 = PPC_LOAD_U32(var_r23 + 0);
		// cmplwi r3,0
		// beq 0x82571bb8
		if (ctx.r3.u32 != 0) {
			// lwz r11,0(r3)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* msgMsgSink::vtable@+0x0 */;
			// addi r4,r1,80
			ctx.r4.s64 = ctx.r1.s64 + 80;
			// lwz r11,20(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// lwz r11,84(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// stw r11,0(r30)
			PPC_STORE_U32(var_r30 + 0,/* msgMsgSink::vtable@+0x0 */ ctx.r11.u32);
			// addi r30,r30,4
			var_r30 = (uint32_t)(var_r30 + 4);
		}
	loc_82571BB8:
		// addic. r27,r27,-1
		ctx.xer.ca = var_r27 > 0;
		var_r27 = (uint32_t)(var_r27 + -1);
		// addi r23,r23,4
		var_r23 = (uint32_t)(var_r23 + 4);
		// bne 0x82571b88
		if ((int32_t)var_r27 != 0) goto loc_82571B88;
		// cmplwi cr6,r29,0
		// beq cr6,0x82571c48
		if (var_r29 != 0) {
			// addi r7,r28,4
			ctx.r7.s64 = (int64_t)(int32_t)var_r28 + 4;
			// lwz r4,0(r22)
			ctx.r4.u64 = PPC_LOAD_U32(var_r22 + 0);
			// addi r6,r1,88
			ctx.r6.s64 = ctx.r1.s64 + 88;
			// li r5,10
			ctx.r5.s64 = 10;
			// mr r3,r20
			ctx.r3.u64 = var_r20;
			// bl 0x8256c500
			msgMsgSink_C500_w(ctx, base);
			// mr. r26,r3
			var_r26 = ctx.r3.u32;
			// blt 0x82571c5c
			if ((int32_t)var_r26 < 0) goto loc_82571C5C;
			// addi r24,r24,1
			var_r24 = (uint32_t)(var_r24 + 1);
			// addi r28,r28,4
			var_r28 = (uint32_t)(var_r28 + 4);
			// li r30,0
			var_r30 = 0;
			// li r29,0
			var_r29 = 0;
		loc_82571BFC:
			// lwz r3,0(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0)/* msgMsgSink::vtable@+0x0 */;
			// cmplwi r3,0
			// beq 0x82571c30
			if (ctx.r3.u32 != 0) {
				// lwz r11,0(r3)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* msgMsgSink::vtable@+0x0 */;
				// mr r6,r30
				ctx.r6.u64 = var_r30;
				// lwz r5,0(r28)
				ctx.r5.u64 = PPC_LOAD_U32(var_r28 + 0);
				// mr r4,r20
				ctx.r4.u64 = var_r20;
				// lwz r11,0(r11)
				ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
				// bctrl
				PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
				// mr. r26,r3
				var_r26 = ctx.r3.u32;
				// blt 0x82571c5c
				if ((int32_t)var_r26 < 0) goto loc_82571C5C;
				// addi r30,r30,1
				var_r30 = (uint32_t)(var_r30 + 1);
			}
		loc_82571C30:
			// addi r29,r29,1
			var_r29 = (uint32_t)(var_r29 + 1);
			// addi r31,r31,4
			var_r31 = (uint32_t)(var_r31 + 4);
			// cmplwi cr6,r29,2
			// blt cr6,0x82571bfc
			if (var_r29 < 2) goto loc_82571BFC;
			// cmpwi cr6,r26,0
			// blt cr6,0x82571c5c
			if ((int32_t)var_r26 < 0) goto loc_82571C5C;
		}
	loc_82571C48:
		// addi r21,r21,1
		var_r21 = (uint32_t)(var_r21 + 1);
		// addi r22,r22,4
		var_r22 = (uint32_t)(var_r22 + 4);
		// mr r31,r23
		var_r31 = (uint32_t)(var_r23);
		// cmplwi cr6,r21,3
		// blt cr6,0x82571b68
		if (var_r21 < 3) goto loc_82571B68;
	loc_82571C5C:
		// cmpwi cr6,r26,0
		// stw r24,32(r25)
		PPC_STORE_U32(var_r25 + 32, var_r24);
		// blt cr6,0x82571c84
		if ((int32_t)var_r26 < 0) goto loc_82571C84;
		// li r6,0
		ctx.r6.s64 = 0;
		// mr r5,r18
		ctx.r5.u64 = var_r18;
		// mr r4,r19
		ctx.r4.u64 = var_r19;
		// mr r3,r25
		ctx.r3.u64 = var_r25;
		// bl 0x82571220
		game_1220(ctx, base);
		// mr. r26,r3
		var_r26 = ctx.r3.u32;
		// bge 0x82571c90
		if ((int32_t)var_r26 >= 0) {
			// mr r3,r26
			ctx.r3.u64 = var_r26;
			// stw r25,0(r17)
			PPC_STORE_U32(var_r17 + 0, var_r25);
			return;
		}
	}
loc_82571C84:
	// mr r3,r25
	ctx.r3.u64 = var_r25;
	// bl 0x825714a0
	xam_14A0_w(ctx, base);
	// li r25,0
	var_r25 = 0;
loc_82571C90:
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// stw r25,0(r17)
	PPC_STORE_U32(var_r17 + 0, var_r25);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_1CA0_p39"))) PPC_WEAK_FUNC(phBoundCapsule_1CA0_p39);
PPC_FUNC_IMPL(__imp__phBoundCapsule_1CA0_p39) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=144, savegprlr_29
	// li r10,0
	ctx.r10.s64 = 0;
	// sth r7,84(r1)
	PPC_STORE_U16(ctx.r1.u32 + 84, ctx.r7.u16);
	// clrlwi r9,r8,16
	ctx.r9.u64 = ctx.r8.u32 & 0xFFFF;
	// stw r5,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r5.u32);
	// lis r11,-32254
	// stw r6,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r6.u32);
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// addi r31,r11,10200
	var_r31 = (uint32_t)(ctx.r11.s64 + 10200);  // lbl_820227D8 @ 0x820227d8
	// stw r10,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, ctx.r10.u32);
	// stw r9,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, ctx.r9.u32);
	// mr r30,r31
	var_r30 = (uint32_t)(var_r31);
loc_82571CDC:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lha r5,0(r30)
	ctx.r5.s64 = int16_t(PPC_LOAD_U16(var_r30 + 0));
	// clrlwi r4,r11,24
	ctx.r4.u64 = ctx.r11.u32 & 0xFF;
	// bl 0x82575040
	phBoundCapsule_5040_p39(ctx, base);
	// addi r30,r30,2
	var_r30 = (uint32_t)(var_r30 + 2);
	// addi r11,r31,34
	ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 34;
	// addi r29,r29,4
	var_r29 = (uint32_t)(var_r29 + 4);
	// cmpw cr6,r30,r11
	// blt cr6,0x82571cdc
	if ((int32_t)var_r30 < ctx.r11.s32) goto loc_82571CDC;
	return;
}

__attribute__((alias("__imp__aud_1D10"))) PPC_WEAK_FUNC(aud_1D10);
PPC_FUNC_IMPL(__imp__aud_1D10) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=144, savegprlr_26
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// addi r28,r29,8
	var_r28 = (uint32_t)(var_r29 + 8);
	// addi r26,r29,4
	var_r26 = (uint32_t)(var_r29 + 4);
	// addi r27,r28,4
	var_r27 = (uint32_t)(var_r28 + 4);
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lfs f1,56(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r30 + 56);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,0(r26)
	temp.u32 = PPC_LOAD_U32(var_r26 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,0(r27)
	temp.u32 = PPC_LOAD_U32(var_r27 + 0);
	ctx.f3.f64 = double(temp.f32);
	// bl 0x82575838
	phBoundCapsule_5838_p39(ctx, base);
	// mr r6,r27
	ctx.r6.u64 = var_r27;
	// stw r3,4(r31)
	PPC_STORE_U32(var_r31 + 4, ctx.r3.u32);
	// mr r5,r26
	ctx.r5.u64 = var_r26;
	// lfs f1,56(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r30 + 56);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x825758b8
	aud_58B8_h(ctx, base);
	// lfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r28 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82575750
	aud_5750(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(var_r31 + 8, ctx.r3.u32);
	// bl 0x825757e8
	aud_57E8_h(ctx, base);
	// stfs f1,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(var_r28 + 0, temp.u32);
	// lfs f1,16(r29)
	temp.u32 = PPC_LOAD_U32(var_r29 + 16);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x825756f8
	aud_56F8_h(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r5,12
	ctx.r5.s64 = 12;
	// addi r4,r31,12
	ctx.r4.s64 = (int64_t)(int32_t)var_r31 + 12;
	// addi r3,r29,20
	ctx.r3.s64 = (int64_t)(int32_t)var_r29 + 20;
	// stw r11,0(r31)
	PPC_STORE_U32(var_r31 + 0, ctx.r11.u32);
	// lfs f1,0(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r27 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82575460
	phBoundCapsule_5460_p39(ctx, base);
	// lfs f0,0(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r27 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,56(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r30 + 56, temp.u32);
	// lfs f0,0(r28)
	temp.u32 = PPC_LOAD_U32(var_r28 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,60(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r30 + 60, temp.u32);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_1DA8_p33"))) PPC_WEAK_FUNC(phBoundCapsule_1DA8_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_1DA8_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=144, savegprlr_26
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// cmplwi cr6,r30,0
	// bne cr6,0x82571dd0
	if (var_r30 == 0) {
	loc_82571DC8:
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82571ec8
		return;
	}
loc_82571DD0:
	// li r28,0
	var_r28 = 0;
	// lis r29,-32161
	var_r29 = (uint32_t)(-2107703296);
	// li r4,88
	ctx.r4.s64 = 88;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r28,0(r30)
	PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ var_r28);
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// beq 0x82571dc8
	if ((int32_t)var_r31 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82571ec8
		return;
	}
	// li r26,1
	var_r26 = 1;
	// stw r31,0(r30)
	PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ var_r31);
	// stw r27,64(r31)
	PPC_STORE_U32(var_r31 + 64, var_r27);
	// li r4,40
	ctx.r4.s64 = 40;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r26,68(r31)
	PPC_STORE_U32(var_r31 + 68, var_r26);
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// mr. r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stw r11,72(r31)
	PPC_STORE_U32(var_r31 + 72, ctx.r11.u32);
	// beq 0x82571dc8
	if (ctx.r11.s32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82571ec8
		return;
	}
	// lis r10,-32256
	// sth r28,28(r11)
	PPC_STORE_U16(ctx.r11.u32 + 28, (uint16_t)var_r28);
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// sth r28,36(r11)
	PPC_STORE_U16(ctx.r11.u32 + 36, (uint16_t)var_r28);
	// li r3,371
	ctx.r3.s64 = 371;
	// lfs f0,15788(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15788);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32256
	// stfs f0,12(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// stfs f0,16(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 16, temp.u32);
	// stfs f0,20(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 20, temp.u32);
	// stfs f0,32(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 32, temp.u32);
	// lfs f31,15784(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15784);
	var_f31 = double(temp.f32);
	// stfs f31,24(r11)
	temp.f32 = float(var_f31);
	PPC_STORE_U32(ctx.r11.u32 + 24, temp.u32);
	// bl 0x82576558
	phBoundCapsule_6558_p33(ctx, base);
	// cmpwi r3,0
	// bne 0x82571dc8
	if (ctx.r3.s32 != 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82571ec8
		return;
	}
	// addi r3,r31,16
	ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 16;
	// stfs f31,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(var_f31);
	PPC_STORE_U32(var_r31 + 8, temp.u32);
	// bl 0x825764e0
	phBoundCapsule_64E0_p33(ctx, base);
	// clrlwi. r11,r3,16
	ctx.r11.u64 = ctx.r3.u32 & 0xFFFF;
	// bne 0x82571dc8
	if (ctx.r11.s32 != 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82571ec8
		return;
	}
	// addi r3,r31,20
	ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 20;
	// bl 0x82575c20
	phBoundCapsule_5C20_p33(ctx, base);
	// clrlwi. r11,r3,16
	ctx.r11.u64 = ctx.r3.u32 & 0xFFFF;
	// bne 0x82571dc8
	if (ctx.r11.s32 != 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82571ec8
		return;
	}
	// addi r3,r31,24
	ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 24;
	// bl 0x82575b20
	phBoundCapsule_5B20_p33(ctx, base);
	// extsh. r11,r3
	ctx.r11.s64 = ctx.r3.s16;
	// bne 0x82571dc8
	if (ctx.r11.s32 != 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82571ec8
		return;
	}
	// lis r11,-32256
	// stfs f31,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(var_f31);
	PPC_STORE_U32(var_r31 + 28, temp.u32);
	// stfs f31,48(r31)
	temp.f32 = float(var_f31);
	PPC_STORE_U32(var_r31 + 48, temp.u32);
	// stw r26,32(r31)
	PPC_STORE_U32(var_r31 + 32, var_r26);
	// stfs f31,56(r31)
	temp.f32 = float(var_f31);
	PPC_STORE_U32(var_r31 + 56, temp.u32);
	// stw r26,40(r31)
	PPC_STORE_U32(var_r31 + 40, var_r26);
	// stw r28,76(r31)
	PPC_STORE_U32(var_r31 + 76, var_r28);
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f0,22092(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22092);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,52(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 52, temp.u32);
	// stfs f0,60(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 60, temp.u32);
loc_82571EC8:
	return;
}

__attribute__((alias("__imp__phBoundCapsule_1ED8_p33"))) PPC_WEAK_FUNC(phBoundCapsule_1ED8_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_1ED8_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// lwz r31,0(r3)
	var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */);
	// cmplwi r31,0
	// beq 0x82571f4c
	if (var_r31 != 0) {
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82579258
		phBoundCapsule_9258_p33(ctx, base);
		// addi r3,r31,16
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 16;
		// bl 0x82575bd0
		phBoundCapsule_5BD0_p33(ctx, base);
		// addi r3,r31,20
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 20;
		// bl 0x82575cc8
		phBoundCapsule_5CC8_p33(ctx, base);
		// addi r3,r31,24
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 24;
		// bl 0x82575bd0
		phBoundCapsule_5BD0_p33(ctx, base);
		// lwz r3,72(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 72);
		// lis r30,-32161
		var_r30 = (uint32_t)(-2107703296);
		// cmplwi r3,0
		// beq 0x82571f3c
		if (ctx.r3.u32 != 0) {
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// li r11,0
			ctx.r11.s64 = 0;
			// stw r11,72(r31)
			PPC_STORE_U32(var_r31 + 72, ctx.r11.u32);
		}
	loc_82571F3C:
		// lwz r11,-22268(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	}
loc_82571F4C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_1F68_2h"))) PPC_WEAK_FUNC(phBoundCapsule_1F68_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_1F68_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// FRAME: size=3344, manual
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// li r5,291
	ctx.r5.s64 = 291;
	// li r4,145
	ctx.r4.s64 = 145;
	// bl 0x825766e8
	phBoundCapsule_66E8_2h(ctx, base);
	// lis r11,-32254
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r11,r11,10240
	ctx.r11.s64 = ctx.r11.s64 + 10240;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r7,145
	ctx.r7.s64 = 145;
	// addi r8,r1,1240
	ctx.r8.s64 = ctx.r1.s64 + 1240;
loc_82571FAC:
	// lfs f13,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f13,0(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f13,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r8,r8,-4
	ctx.r8.s64 = ctx.r8.s64 + -4;
	// bgt 0x82571fac
	if (ctx.cr0.gt) goto loc_82571FAC;
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// li r5,291
	ctx.r5.s64 = 291;
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// bl 0x825769a0
	phBoundCapsule_69A0_2h(ctx, base);
	// lis r11,-32254
	// addi r7,r1,2288
	ctx.r7.s64 = ctx.r1.s64 + 2288;
	// addi r6,r1,1248
	ctx.r6.s64 = ctx.r1.s64 + 1248;
	// li r5,9
	ctx.r5.s64 = 9;
	// li r4,291
	ctx.r4.s64 = 291;
	// lfs f0,10828(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 10828);
	ctx.f0.f64 = double(temp.f32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// bl 0x82576848
	phBoundCapsule_6848_2h(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = var_r31;
	// addi r4,r1,2288
	ctx.r4.s64 = ctx.r1.s64 + 2288;
	// addi r3,r1,1248
	ctx.r3.s64 = ctx.r1.s64 + 1248;
	// bl 0x825762a8
	phBoundCapsule_62A8(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_2050_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_2050_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_2050_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r22 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	double var_f30 = 0.0;
	double var_f28 = 0.0;
	double var_f31 = 0.0;
	double var_f29 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f87c
	ctx.lr = 0x82572058;
	__savegprlr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-1536(r1)
	ea = -1536 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r22,r5
	var_r22 = ctx.r5.u32;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	var_f30 = ctx.f1.f64;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r11,r22,-1
	ctx.r11.s64 = (int64_t)(int32_t)var_r22 + -1;
	// mr r21,r4
	var_r21 = ctx.r4.u32;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f28,f0
	var_f28 = double(float(ctx.f0.f64));
	// fdivs f0,f28,f30
	ctx.f0.f64 = double(float(var_f28 / var_f30));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r29,r11,1
	var_r29 = (uint32_t)(ctx.r11.s64 + 1);  // addr:0x82020001
	// cmpwi cr6,r29,80
	// ble cr6,0x825720ac
	if ((int32_t)var_r29 > 80) {
		// li r29,80
		var_r29 = 80;
	}
loc_825720AC:
	// lis r11,-32256
	// rlwinm r27,r29,2,0,29
	var_r27 = (uint32_t)(__builtin_rotateleft64(var_r29 | (var_r29 << 32), 2) & 0xFFFFFFFC);
	// rlwinm r10,r29,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(var_r29 | (var_r29 << 32), 3) & 0xFFFFFFF8;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// cmpwi cr6,r29,0
	// lfs f31,15784(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	var_f31 = double(temp.f32);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// add r30,r10,r9
	var_r30 = (uint32_t)(ctx.r10.u64 + ctx.r9.u64);
	// add r31,r27,r11
	var_r31 = (uint32_t)(var_r27 + ctx.r11.u64);
	// ble cr6,0x82572130
	if ((int32_t)var_r29 > 0) {
		// addi r11,r1,96
		ctx.r11.s64 = ctx.r1.s64 + 96;
		// mr r28,r30
		var_r28 = (uint32_t)(var_r30);
		// subf r24,r30,r11
		var_r24 = (uint32_t)(ctx.r11.s64 - (int64_t)(int32_t)var_r30);
		// lis r11,-32256
		// subf r23,r30,r31
		var_r23 = var_r31 - var_r30;
		// mr r26,r29
		var_r26 = (uint32_t)(var_r29);
		// lfs f29,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
		var_f29 = double(temp.f32);
	loc_825720F0:
		// fadds f0,f31,f29
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(var_f31 + var_f29));
		// addi r11,r1,80
		ctx.r11.s64 = ctx.r1.s64 + 80;
		// fctiwz f0,f0
		ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
		// stfiwx f0,0,r11
		PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
		// lwz r25,80(r1)
		var_r25 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 80));
		// rlwinm r11,r25,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r25 | (var_r25 << 32), 2) & 0xFFFFFFFC;
		// lfsx f1,r11,r21
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r21);
		ctx.f1.f64 = double(temp.f32);
		// bl 0x82576ef0
		phBoundCapsule_6EF0(ctx, base);
		// stfsx f1,r24,r28
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f1.f64);
		PPC_STORE_U32(var_r24 + var_r28, temp.u32);
		// fmr f0,f31
		ctx.f0.f64 = var_f31;
		// stw r25,0(r28)
		PPC_STORE_U32(var_r28 + 0, var_r25);
		// stfsx f0,r23,r28
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r23 + var_r28, temp.u32);
		// addic. r26,r26,-1
		ctx.xer.ca = var_r26 > 0;
		var_r26 = (uint32_t)(var_r26 + -1);
		// fadds f31,f31,f30
		var_f31 = double(float(var_f31 + var_f30));
		// addi r28,r28,4
		var_r28 = (uint32_t)(var_r28 + 4);
		// bne 0x825720f0
		if ((int32_t)var_r26 != 0) goto loc_825720F0;
	}
loc_82572130:
	// rlwinm r11,r22,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r22 | (var_r22 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r21
	ctx.r11.u64 = ctx.r11.u64 + var_r21;
	// lfs f1,-4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82576ef0
	phBoundCapsule_6EF0(ctx, base);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r29,1
	ctx.r10.s64 = (int64_t)(int32_t)var_r29 + 1;
	// cmpwi cr6,r10,1
	// stfsx f1,r27,r11
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(var_r27 + ctx.r11.u32, temp.u32);
	// stwx r22,r27,r30
	PPC_STORE_U32(var_r27 + var_r30, var_r22);
	// stfsx f28,r27,r31
	temp.f32 = float(var_f28);
	PPC_STORE_U32(var_r27 + var_r31, temp.u32);
	// ble cr6,0x82572200
	if (ctx.r10.s32 > 1) {
		// addi r5,r10,-1
		ctx.r5.s64 = ctx.r10.s64 + -1;
		// lis r10,-32256
		// addi r9,r1,96
		ctx.r9.s64 = ctx.r1.s64 + 96;
		// addi r7,r1,100
		ctx.r7.s64 = ctx.r1.s64 + 100;
		// addi r8,r30,4
		ctx.r8.s64 = (int64_t)(int32_t)var_r30 + 4;
		// mr r11,r31
		ctx.r11.u64 = var_r31;
		// lfs f10,15788(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15788);
		ctx.f10.f64 = double(temp.f32);
		// subf r30,r31,r30
		var_r30 = var_r30 - var_r31;
		// subf r4,r31,r9
		ctx.r4.s64 = ctx.r9.s64 - (int64_t)(int32_t)var_r31;
		// subf r3,r31,r7
		ctx.r3.s64 = ctx.r7.s64 - (int64_t)(int32_t)var_r31;
	loc_82572184:
		// addi r6,r11,4
		ctx.r6.s64 = ctx.r11.s64 + 4;
		// lfs f13,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// lwzx r10,r30,r11
		ctx.r10.u64 = PPC_LOAD_U32(var_r30 + ctx.r11.u32);
		// lwz r7,0(r8)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		// cmpw cr6,r10,r7
		// lfs f0,0(r6)
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// fsubs f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
		// fdivs f11,f10,f0
		ctx.f11.f64 = double(float(ctx.f10.f64 / ctx.f0.f64));
		// bge cr6,0x825721f0
		if (ctx.r10.s32 < ctx.r7.s32) {
			// rlwinm r9,r10,2,0,29
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
			// lfsx f0,r4,r11
			temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r11.u32);
			ctx.f0.f64 = double(temp.f32);
			// lfsx f12,r3,r11
			temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r11.u32);
			ctx.f12.f64 = double(temp.f32);
			// add r11,r9,r21
			ctx.r11.u64 = ctx.r9.u64 + var_r21;
			// fsubs f12,f12,f0
			ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
		loc_825721BC:
			// extsw r9,r10
			ctx.r9.s64 = ctx.r10.s32;
			// addi r10,r10,1
			ctx.r10.s64 = ctx.r10.s64 + 1;
			// cmpw cr6,r10,r7
			ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r7.s32, ctx.xer);
			// std r9,80(r1)
			PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
			// lfd f9,80(r1)
			ctx.fpscr.disableFlushMode();
			ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
			// fcfid f9,f9
			ctx.f9.f64 = double(ctx.f9.s64);
			// frsp f9,f9
			ctx.f9.f64 = double(float(ctx.f9.f64));
			// fsubs f9,f9,f13
			ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
			// fmuls f9,f9,f12
			ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
			// fmadds f9,f9,f11,f0
			ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64 + ctx.f0.f64));
			// stfs f9,0(r11)
			temp.f32 = float(ctx.f9.f64);
			PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
			// addi r11,r11,4
			ctx.r11.s64 = ctx.r11.s64 + 4;
			// blt cr6,0x825721bc
			if (ctx.cr6.lt) goto loc_825721BC;
		}
	loc_825721F0:
		// addic. r5,r5,-1
		ctx.xer.ca = ctx.r5.u32 > 0;
		ctx.r5.s64 = ctx.r5.s64 + -1;
		// mr r11,r6
		ctx.r11.u64 = ctx.r6.u64;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// bne 0x82572184
		if (ctx.r5.s32 != 0) goto loc_82572184;
	}
loc_82572200:
	// addi r1,r1,1536
	ctx.r1.s64 = ctx.r1.s64 + 1536;
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// b 0x8242f8cc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_2210"))) PPC_WEAK_FUNC(phBoundCapsule_2210);
PPC_FUNC_IMPL(__imp__phBoundCapsule_2210) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r26 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=3184, savegprlr_24
	// mr r29,r7
	var_r29 = ctx.r7.u32;
	// mr r25,r3
	var_r25 = ctx.r3.u32;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r28,r8
	var_r28 = ctx.r8.u32;
	// lwz r31,72(r29)
	var_r31 = (uint32_t)(PPC_LOAD_U32(var_r29 + 72));
	// mr r24,r9
	var_r24 = ctx.r9.u32;
	// li r9,100
	ctx.r9.s64 = 100;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// addi r6,r1,1536
	ctx.r6.s64 = ctx.r1.s64 + 1536;
	// addi r5,r1,512
	ctx.r5.s64 = ctx.r1.s64 + 512;
	// addi r30,r27,8
	var_r30 = (uint32_t)(var_r27 + 8);
	// bl 0x82577e58
	phBoundCapsule_7E58_2h(ctx, base);
	// lis r11,-32248
	// lfs f13,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f13.f64 = double(temp.f32);
	// li r9,100
	ctx.r9.s64 = 100;
	// addi r7,r1,512
	ctx.r7.s64 = ctx.r1.s64 + 512;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,1536
	ctx.r4.s64 = ctx.r1.s64 + 1536;
	// lfs f0,-25804(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25804);
	ctx.f0.f64 = double(temp.f32);
	// addi r3,r1,512
	ctx.r3.s64 = ctx.r1.s64 + 512;
	// fdivs f31,f0,f13
	var_f31 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// fmr f1,f31
	ctx.f1.f64 = var_f31;
	// bl 0x82577bc0
	SinglesNetworkClient_7BC0(ctx, base);
	// addi r26,r30,4
	var_r26 = (uint32_t)(var_r30 + 4);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,100
	ctx.r10.s64 = 100;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// addi r7,r1,1536
	ctx.r7.s64 = ctx.r1.s64 + 1536;
	// mr r5,r30
	ctx.r5.u64 = var_r30;
	// addi r4,r1,512
	ctx.r4.s64 = ctx.r1.s64 + 512;
	// addi r3,r29,8
	ctx.r3.s64 = (int64_t)(int32_t)var_r29 + 8;
	// mr r6,r26
	ctx.r6.u64 = var_r26;
	// bl 0x82577110
	phBoundCapsule_7110_h(ctx, base);
	// li r5,256
	ctx.r5.s64 = 256;
	// addi r4,r1,512
	ctx.r4.s64 = ctx.r1.s64 + 512;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = var_f31;
	// bl 0x82572050
	phBoundCapsule_2050_2hr(ctx, base);
	// lis r11,-32256
	// lfs f12,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lhz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U16(var_r31 + 28);
	// lfs f0,15788(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// fcmpu cr6,f12,f0
	// lfs f31,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
	var_f31 = double(temp.f32);
	// bne cr6,0x825722ec
	if (ctx.f12.f64 == ctx.f0.f64) {
		// extsh. r11,r7
		ctx.r11.s64 = ctx.r7.s16;
		// beq 0x825723e4
		if (ctx.r11.s32 == 0) goto loc_825723E4;
	}
loc_825722EC:
	// lha r6,36(r31)
	ctx.r6.s64 = int16_t(PPC_LOAD_U16(var_r31 + 36));
	// fmr f13,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = var_f31;
	// fmr f0,f31
	ctx.f0.f64 = var_f31;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
loc_82572300:
	// extsw r11,r8
	ctx.r11.s64 = ctx.r8.s32;
	// cmpw cr6,r8,r6
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f11,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// fmuls f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fctiwz f11,f11
	ctx.f11.s64 = (ctx.f11.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f11.f64));
	// stfd f11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f11.u64);
	// lhz r11,102(r1)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 102);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// blt cr6,0x82572364
	if (ctx.r8.s32 >= ctx.r6.s32) {
		// extsh. r11,r11
		ctx.r11.s64 = ctx.r11.s16;
		ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
		// cmpwi cr6,r11,256
		// blt 0x82572358
		if (!(ctx.cr0.lt)) {
			// bge cr6,0x8257235c
		if (ctx.r11.s32 >= 256) goto loc_8257235C;
			// addi r9,r1,1936
			ctx.r9.s64 = ctx.r1.s64 + 1936;
			// rlwinm r5,r11,2,0,29
			ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// add r11,r10,r9
			ctx.r11.u64 = ctx.r10.u64 + ctx.r9.u64;
			// addi r9,r1,512
			ctx.r9.s64 = ctx.r1.s64 + 512;
			// lfsx f11,r5,r9
			temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r9.u32);
			ctx.f11.f64 = double(temp.f32);
			// b 0x82572374
			goto loc_82572374;
		}
	loc_82572358:
		// blt cr6,0x82572364
		if (ctx.cr6.lt) goto loc_82572364;
	loc_8257235C:
		// lfs f11,1532(r1)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1532);
		ctx.f11.f64 = double(temp.f32);
		// b 0x8257236c
	} else {
	loc_82572364:
		// addi r9,r1,512
		ctx.r9.s64 = ctx.r1.s64 + 512;
		// lfsx f11,r10,r9
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
		ctx.f11.f64 = double(temp.f32);
	}
loc_8257236C:
	// addi r11,r1,1936
	ctx.r11.s64 = ctx.r1.s64 + 1936;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
loc_82572374:
	// addi r9,r1,512
	ctx.r9.s64 = ctx.r1.s64 + 512;
	// stfs f11,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// fadds f0,f0,f11
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f11.f64));
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lfsx f11,r10,r9
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	ctx.f11.f64 = double(temp.f32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// fadds f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// cmpwi cr6,r10,1024
	// blt cr6,0x82572300
	if (ctx.r10.s32 < 1024) goto loc_82572300;
	// fsubs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// lis r9,-32256
	// addi r11,r1,1936
	ctx.r11.s64 = ctx.r1.s64 + 1936;
	// li r10,256
	ctx.r10.s64 = 256;
	// lfs f0,22868(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 22868);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_825723B0:
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// fadds f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x825723b0
	if (ctx.r10.s32 != 0) goto loc_825723B0;
	// lis r11,-32161
	// li r5,256
	ctx.r5.s64 = 256;
	// addi r4,r1,1936
	ctx.r4.s64 = ctx.r1.s64 + 1936;
	// addi r3,r1,512
	ctx.r3.s64 = ctx.r1.s64 + 512;
	// lwz r11,-22260(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22260);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
loc_825723E4:
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// addi r6,r1,1536
	ctx.r6.s64 = ctx.r1.s64 + 1536;
	// addi r5,r27,16
	ctx.r5.s64 = (int64_t)(int32_t)var_r27 + 16;
	// li r4,12
	ctx.r4.s64 = 12;
	// addi r3,r1,512
	ctx.r3.s64 = ctx.r1.s64 + 512;
	// bl 0x825776a0
	phBoundCapsule_76A0_2h(ctx, base);
	// addi r5,r27,20
	ctx.r5.s64 = (int64_t)(int32_t)var_r27 + 20;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x825778a8
	phBoundCapsule_78A8_g(ctx, base);
	// addi r6,r1,1936
	ctx.r6.s64 = ctx.r1.s64 + 1936;
	// mr r5,r28
	ctx.r5.u64 = var_r28;
	// addi r4,r24,145
	ctx.r4.s64 = (int64_t)(int32_t)var_r24 + 145;
	// mr r3,r25
	ctx.r3.u64 = var_r25;
	// bl 0x825766e8
	phBoundCapsule_66E8_2h(ctx, base);
	// lis r11,-32256
	// addi r6,r1,1936
	ctx.r6.s64 = ctx.r1.s64 + 1936;
	// mr r4,r28
	ctx.r4.u64 = var_r28;
	// addi r3,r1,1936
	ctx.r3.s64 = ctx.r1.s64 + 1936;
	// lfs f1,16056(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16056);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82576a08
	phBoundCapsule_6A08_2h(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = var_r28;
	// addi r3,r1,1936
	ctx.r3.s64 = ctx.r1.s64 + 1936;
	// bl 0x82576c38
	phBoundCapsule_6C38_2h(ctx, base);
	// lwz r31,3268(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 3268));
	// mr r4,r28
	ctx.r4.u64 = var_r28;
	// lfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f1.f64 = double(temp.f32);
	// mr r6,r31
	ctx.r6.u64 = var_r31;
	// fmr f2,f31
	ctx.f2.f64 = var_f31;
	// addi r3,r1,1936
	ctx.r3.s64 = ctx.r1.s64 + 1936;
	// bl 0x825774b8
	phBoundCapsule_74B8(ctx, base);
	// lfs f5,52(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r29 + 52);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r30)
	temp.u32 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,48(r29)
	temp.u32 = PPC_LOAD_U32(var_r29 + 48);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r26)
	temp.u32 = PPC_LOAD_U32(var_r26 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r31)
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82577038
	phBoundCapsule_7038_2h(ctx, base);
	// stfs f1,0(r26)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(var_r26 + 0, temp.u32);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_2488"))) PPC_WEAK_FUNC(phBoundCapsule_2488);
PPC_FUNC_IMPL(__imp__phBoundCapsule_2488) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f888
	ctx.lr = 0x82572490;
	__savegprlr_24(ctx, base);
	// ld r12,-4096(r1)
	ctx.r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -4096);
	// stwu r1,-4352(r1)
	ea = -4352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// mr r26,r5
	var_r26 = ctx.r5.u32;
	// addi r28,r26,8
	var_r28 = (uint32_t)(var_r26 + 8);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 32);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 40);
	// lwz r29,0(r31)
	var_r29 = (uint32_t)(PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */);
	// lwz r24,72(r31)
	var_r24 = (uint32_t)(PPC_LOAD_U32(var_r31 + 72));
	// and. r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 & ctx.r10.u64;
	// bne 0x825724c4
	if (ctx.r11.s32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572688
	} else {
	loc_825724C4:
		// addi r10,r1,112
		ctx.r10.s64 = ctx.r1.s64 + 112;
		// li r11,160
		ctx.r11.s64 = 160;
	loc_825724CC:
		// lha r9,0(r3)
		ctx.r9.s64 = int16_t(PPC_LOAD_U16(ctx.r3.u32 + 0));
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// addi r3,r3,2
		ctx.r3.s64 = ctx.r3.s64 + 2;
		// std r9,96(r1)
		PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
		// lfd f0,96(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
		// fcfid f0,f0
		ctx.f0.f64 = double(ctx.f0.s64);
		// frsp f0,f0
		ctx.f0.f64 = double(float(ctx.f0.f64));
		// stfs f0,0(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bgt 0x825724cc
		if (ctx.r11.s32 > 0) goto loc_825724CC;
		// addi r6,r1,112
		ctx.r6.s64 = ctx.r1.s64 + 112;
		// li r5,160
		ctx.r5.s64 = 160;
		// li r4,0
		ctx.r4.s64 = 0;
		// mr r3,r29
		ctx.r3.u64 = var_r29;
		// bl 0x825765c8
		phBoundCapsule_65C8_2hr(ctx, base);
		// addi r25,r31,44
		var_r25 = (uint32_t)(var_r31 + 44);
		// mr r3,r29
		ctx.r3.u64 = var_r29;
		// lwz r4,16(r31)
		ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 16);
		// mr r5,r25
		ctx.r5.u64 = var_r25;
		// bl 0x82571f68
		phBoundCapsule_1F68_2h(ctx, base);
		// stfs f1,0(r28)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f1.f64);
		PPC_STORE_U32(var_r28 + 0, temp.u32);
		// lwz r27,24(r31)
		var_r27 = (uint32_t)(PPC_LOAD_U32(var_r31 + 24));
		// bl 0x82576e48
		phBoundCapsule_6E48_2h(ctx, base);
		// mr r30,r3
		var_r30 = ctx.r3.u32;
		// addi r7,r1,112
		ctx.r7.s64 = ctx.r1.s64 + 112;
		// li r5,145
		ctx.r5.s64 = 145;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// mr r3,r27
		ctx.r3.u64 = var_r27;
		// mr r6,r30
		ctx.r6.u64 = var_r30;
		// bl 0x82575918
		phBoundCapsule_5918_2h(ctx, base);
		// mr r27,r3
		var_r27 = ctx.r3.u32;
		// addi r6,r1,112
		ctx.r6.s64 = ctx.r1.s64 + 112;
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// mr r3,r29
		ctx.r3.u64 = var_r29;
		// addi r4,r27,145
		ctx.r4.s64 = (int64_t)(int32_t)var_r27 + 145;
		// bl 0x825766e8
		phBoundCapsule_66E8_2h(ctx, base);
		// lis r11,-32256
		// addi r6,r1,112
		ctx.r6.s64 = ctx.r1.s64 + 112;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// addi r3,r1,112
		ctx.r3.s64 = ctx.r1.s64 + 112;
		// lfs f1,16056(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16056);
		ctx.f1.f64 = double(temp.f32);
		// bl 0x82576a08
		phBoundCapsule_6A08_2h(ctx, base);
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// addi r3,r1,112
		ctx.r3.s64 = ctx.r1.s64 + 112;
		// bl 0x82576c38
		phBoundCapsule_6C38_2h(ctx, base);
		// addi r7,r1,1168
		ctx.r7.s64 = ctx.r1.s64 + 1168;
		// addi r6,r1,2208
		ctx.r6.s64 = ctx.r1.s64 + 2208;
		// li r5,9
		ctx.r5.s64 = 9;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// addi r3,r1,112
		ctx.r3.s64 = ctx.r1.s64 + 112;
		// bl 0x82576848
		phBoundCapsule_6848_2h(ctx, base);
		// addi r11,r1,96
		ctx.r11.s64 = ctx.r1.s64 + 96;
		// addi r10,r1,96
		ctx.r10.s64 = ctx.r1.s64 + 96;
		// mr r9,r27
		ctx.r9.u64 = var_r27;
		// mr r8,r30
		ctx.r8.u64 = var_r30;
		// mr r7,r31
		ctx.r7.u64 = var_r31;
		// mr r6,r26
		ctx.r6.u64 = var_r26;
		// stw r11,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
		// addi r5,r1,1168
		ctx.r5.s64 = ctx.r1.s64 + 1168;
		// addi r4,r1,2208
		ctx.r4.s64 = ctx.r1.s64 + 2208;
		// mr r3,r29
		ctx.r3.u64 = var_r29;
		// bl 0x82572210
		phBoundCapsule_2210(ctx, base);
		// lwz r11,40(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 40);
		// li r8,0
		ctx.r8.s64 = 0;
		// lfs f1,96(r1)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
		ctx.f1.f64 = double(temp.f32);
		// li r5,225
		ctx.r5.s64 = 225;
		// extsh r6,r11
		ctx.r6.s64 = ctx.r11.s16;
		// mr r4,r26
		ctx.r4.u64 = var_r26;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x825782d8
		phBoundCapsule_82D8_2hr_82D8_1(ctx, base);
		// lwz r11,40(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 40);
		// lfs f0,0(r28)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r28 + 0);
		ctx.f0.f64 = double(temp.f32);
		// lwz r3,76(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 76);
		// stfs f0,52(r31)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r31 + 52, temp.u32);
		// lfs f0,4(r28)
		temp.u32 = PPC_LOAD_U32(var_r28 + 4);
		ctx.f0.f64 = double(temp.f32);
		// cmplwi r3,0
		// stfs f0,48(r31)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r31 + 48, temp.u32);
		// stw r11,36(r31)
		PPC_STORE_U32(var_r31 + 36, ctx.r11.u32);
		// beq 0x82572614
		if (ctx.r3.u32 != 0) {
			// lfs f2,4(r28)
			temp.u32 = PPC_LOAD_U32(var_r28 + 4);
			ctx.f2.f64 = double(temp.f32);
			// lfs f1,0(r25)
			temp.u32 = PPC_LOAD_U32(var_r25 + 0);
			ctx.f1.f64 = double(temp.f32);
			// bl 0x82578168
			atSingleton_8168(ctx, base);
		}
	loc_82572614:
		// lwz r11,68(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 68);
		// cmpwi cr6,r11,0
		// beq cr6,0x82572684
		if (ctx.r11.s32 != 0) {
			// lis r11,-32254
			// lfs f0,0(r28)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(var_r28 + 0);
			ctx.f0.f64 = double(temp.f32);
			// lfs f13,20(r24)
			temp.u32 = PPC_LOAD_U32(var_r24 + 20);
			ctx.f13.f64 = double(temp.f32);
			// lfs f10,16(r24)
			temp.u32 = PPC_LOAD_U32(var_r24 + 16);
			ctx.f10.f64 = double(temp.f32);
			// lfs f9,24(r24)
			temp.u32 = PPC_LOAD_U32(var_r24 + 24);
			ctx.f9.f64 = double(temp.f32);
			// lfs f11,12(r24)
			temp.u32 = PPC_LOAD_U32(var_r24 + 12);
			ctx.f11.f64 = double(temp.f32);
			// lfs f12,10824(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 10824);
			ctx.f12.f64 = double(temp.f32);
			// lis r11,-32256
			// fdivs f0,f12,f0
			ctx.f0.f64 = double(float(ctx.f12.f64 / ctx.f0.f64));
			// lfs f8,4(r28)
			temp.u32 = PPC_LOAD_U32(var_r28 + 4);
			ctx.f8.f64 = double(temp.f32);
			// fmuls f11,f11,f8
			ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f8.f64));
			// fmuls f0,f0,f13
			ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
			// lfs f13,27328(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27328);
			ctx.f13.f64 = double(temp.f32);
			// fmadds f0,f0,f10,f9
			ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64 + ctx.f9.f64));
			// fcmpu cr6,f0,f13
			// bge cr6,0x82572664
			if (ctx.f0.f64 < ctx.f13.f64) {
				// fmr f0,f13
				ctx.f0.f64 = ctx.f13.f64;
			}
		loc_82572664:
			// lis r11,-32256
			ctx.r11.s64 = -2113929216;
			// lfs f13,27352(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27352);  /* glob:lbl_82006AD8 @ 0x82006ad8 */
			ctx.f13.f64 = double(temp.f32);
			// fcmpu cr6,f0,f13
			// ble cr6,0x82572678
			if (ctx.f0.f64 > ctx.f13.f64) {
				// fmr f0,f13
				ctx.f0.f64 = ctx.f13.f64;
			}
		loc_82572678:
			// fdivs f0,f12,f0
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = double(float(ctx.f12.f64 / ctx.f0.f64));
			// stfs f11,4(r28)
			temp.f32 = float(ctx.f11.f64);
			PPC_STORE_U32(var_r28 + 4, temp.u32);
			// stfs f0,0(r28)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(var_r28 + 0, temp.u32);
		}
	loc_82572684:
		// li r3,0
		ctx.r3.s64 = 0;
	}
loc_82572688:
	// addi r1,r1,4352
	ctx.r1.s64 = ctx.r1.s64 + 4352;
	// b 0x8242f8d8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_2690_h"))) PPC_WEAK_FUNC(phBoundCapsule_2690_h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_2690_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	double var_f27 = 0.0;
	double var_f28 = 0.0;
	double var_f31 = 0.0;
	double var_f30 = 0.0;
	double var_f29 = 0.0;
	double var_f26 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f894
	ctx.lr = 0x82572698;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82436610
	__savefpr_26(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// lfs f27,112(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	var_f27 = double(temp.f32);
	// mr r29,r6
	var_r29 = ctx.r6.u32;
	// lfs f28,108(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 108);
	var_f28 = double(temp.f32);
	// lfs f31,44(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	var_f31 = double(temp.f32);
	// mr r27,r5
	var_r27 = ctx.r5.u32;
	// lfs f30,60(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	var_f30 = double(temp.f32);
	// addi r31,r29,8
	var_r31 = (uint32_t)(var_r29 + 8);
	// lfs f29,48(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	var_f29 = double(temp.f32);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4)/* phBoundCapsule::flags@+0x4 */;
	// lfs f26,64(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	var_f26 = double(temp.f32);
	// rlwinm r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,8
	// blt cr6,0x825726e4
	if (ctx.r11.s32 >= 8) {
		// li r11,0
		ctx.r11.s64 = 0;
	}
loc_825726E4:
	// lis r9,-32254
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r28,r9,10832
	var_r28 = (uint32_t)(ctx.r9.s64 + 10832);  // lbl_82022A50 @ 0x82022a50
	// cmpwi cr6,r10,0
	// lfsx f0,r11,r28
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r28);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,4(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 4,/* phBoundCapsule::flags@+0x4 */ temp.u32);
	// bne cr6,0x82572708
	if (ctx.r10.s32 == 0) {
		// stfs f27,4(r29)
		temp.f32 = float(var_f27);
		PPC_STORE_U32(var_r29 + 4,/* phBoundCapsule::flags@+0x4 */ temp.u32);
		// b 0x8257270c
	} else {
	loc_82572708:
		// stfs f0,4(r29)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r29 + 4,/* phBoundCapsule::flags@+0x4 */ temp.u32);
	}
loc_8257270C:
	// lis r11,-32254
	// lwa r10,8(r30)
	ctx.r10.s64 = int32_t(PPC_LOAD_U32(var_r30 + 8));
	// lfs f0,11200(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11200);
	ctx.f0.f64 = double(temp.f32);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lis r11,-32254
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,11196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11196);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// bl 0x82432478
	aud_2478(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f0,10824(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 10824);  /* glob:lbl_82022A48 @ 0x82022a48 */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	// fdivs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// fmuls f13,f13,f30
	ctx.f13.f64 = double(float(ctx.f13.f64 * var_f30));
	// fmadds f13,f13,f31,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * var_f31 + var_f29));
	// fdivs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// lfs f13,22700(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22700);  /* glob:0x820258ac */
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// fcmpu cr6,f0,f13
	// bge cr6,0x82572770
	if (ctx.f0.f64 < ctx.f13.f64) {
		// stfs f13,0(r31)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	}
loc_82572770:
	// lis r11,-32254
	// lfs f13,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,11192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11192);  /* glob:lbl_82022BB8 @ 0x82022bb8 */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	// ble cr6,0x82572788
	if (ctx.f13.f64 > ctx.f0.f64) {
		// stfs f0,0(r31)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	}
loc_82572788:
	// lis r11,-32254
	// lfs f13,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r31)
	temp.u32 = PPC_LOAD_U32(var_r31 + 4)/* phBoundCapsule::flags@+0x4 */;
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,11188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11188);  /* glob:lbl_82022BB4 @ 0x82022bb4 */
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f28,f0
	ctx.f0.f64 = double(float(var_f28 * ctx.f0.f64));
	// fcmpu cr6,f13,f0
	// bgt cr6,0x825727d4
	if (ctx.f13.f64 <= ctx.f0.f64) {
		// bso cr6,0x825727d4
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x825727A4, "bso");
		// lis r11,-32255
		ctx.r11.s64 = -2113863680;
		// lfs f0,21604(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21604);  /* glob:lbl_82015464 @ 0x82015464 */
		ctx.f0.f64 = double(temp.f32);
		// fmuls f0,f28,f0
		ctx.f0.f64 = double(float(var_f28 * ctx.f0.f64));
		// fcmpu cr6,f13,f0
		// blt cr6,0x825727d4
		if (ctx.f13.f64 < ctx.f0.f64) goto loc_825727D4;
		// bso cr6,0x825727d4
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x825727BC, "bso");
		// fadds f13,f13,f28
		ctx.f13.f64 = double(float(ctx.f13.f64 + var_f28));
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f0,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
		ctx.f0.f64 = double(temp.f32);
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// b 0x82572830
	} else {
	loc_825727D4:
		// fcmpu cr6,f27,f12
		ctx.fpscr.disableFlushMode();
		// ble cr6,0x825727e8
		if (var_f27 > ctx.f12.f64) {
			// fmr f0,f28
			ctx.f0.f64 = var_f28;
			// fmr f12,f27
			ctx.f12.f64 = var_f27;
			// b 0x825727ec
		} else {
		loc_825727E8:
			// fmr f0,f13
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = ctx.f13.f64;
		}
	loc_825727EC:
		// lis r11,-32248
		ctx.r11.s64 = -2113404928;
		// lfs f11,-25668(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25668);  /* glob:lbl_82079BBC @ 0x82079bbc */
		ctx.f11.f64 = double(temp.f32);
		// fcmpu cr6,f0,f11
		// bge cr6,0x82572830
		if (ctx.f0.f64 >= ctx.f11.f64) goto loc_82572830;
		// fmuls f11,f12,f0
		ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f12,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
		ctx.f12.f64 = double(temp.f32);
		// lis r11,-32256
		// fmuls f11,f11,f12
		ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
		// lfs f12,15788(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
		ctx.f12.f64 = double(temp.f32);
		// fcmpu cr6,f11,f12
		// bge cr6,0x82572830
		if (ctx.f11.f64 >= ctx.f12.f64) goto loc_82572830;
		// fcmpu cr6,f13,f28
		// ble cr6,0x8257282c
		if (ctx.f13.f64 > var_f28) {
			// fmr f0,f13
			ctx.f0.f64 = ctx.f13.f64;
			// b 0x82572830
		} else {
		loc_8257282C:
			// fmr f0,f28
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = var_f28;
		}
	}
loc_82572830:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// stfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// cmpwi cr6,r11,64
	// blt cr6,0x82572844
	if (ctx.r11.s32 >= 64) {
		// li r11,0
		ctx.r11.s64 = 0;
	}
loc_82572844:
	// addi r10,r28,32
	ctx.r10.s64 = (int64_t)(int32_t)var_r28 + 32;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r7,r27
	ctx.r7.u64 = var_r27;
	// li r5,12
	ctx.r5.s64 = 12;
	// addi r4,r29,20
	ctx.r4.s64 = (int64_t)(int32_t)var_r29 + 20;
	// addi r3,r30,12
	ctx.r3.s64 = (int64_t)(int32_t)var_r30 + 12;
	// lfsx f0,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,16(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r29 + 16, temp.u32);
	// lfs f1,4(r31)
	temp.u32 = PPC_LOAD_U32(var_r31 + 4)/* phBoundCapsule::flags@+0x4 */;
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82578468
	phBoundCapsule_8468_2hr(ctx, base);
	// lfs f0,4(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + 4)/* phBoundCapsule::flags@+0x4 */;
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f26
	ctx.f0.f64 = double(float(ctx.f0.f64 * var_f26));
	// stfs f0,4(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 4,/* phBoundCapsule::flags@+0x4 */ temp.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x8243665c
	__restfpr_26(ctx, base);
	// b 0x8242f8e4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_2888_h"))) PPC_WEAK_FUNC(phBoundCapsule_2888_h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_2888_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r22 = 0;
	PPCRegister temp{};
	// FRAME: size=400, savegprlr_20
	// mr r30,r8
	var_r30 = ctx.r8.u32;
	// sth r7,116(r1)
	PPC_STORE_U16(ctx.r1.u32 + 116, ctx.r7.u16);
	// mr r29,r9
	var_r29 = ctx.r9.u32;
	// stw r6,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r6.u32);
	// li r27,0
	var_r27 = 0;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lis r11,-32254
	// lhz r24,0(r30)
	var_r24 = (uint32_t)(PPC_LOAD_U16(var_r30 + 0));
	// mr r21,r4
	var_r21 = ctx.r4.u32;
	// lbz r23,0(r29)
	var_r23 = (uint32_t)(PPC_LOAD_U8(var_r29 + 0));
	// mr r26,r5
	var_r26 = ctx.r5.u32;
	// mr r25,r10
	var_r25 = ctx.r10.u32;
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, var_r27);
	// lwz r20,4(r31)
	var_r20 = (uint32_t)(PPC_LOAD_U32(var_r31 + 4)/* phBoundCapsule::flags@+0x4 */);
	// mr r28,r27
	var_r28 = (uint32_t)(var_r27);
	// stw r30,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, var_r30);
	// addi r22,r11,11120
	var_r22 = (uint32_t)(ctx.r11.s64 + 11120);  // lbl_82022B70 @ 0x82022b70
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, var_r29);
loc_825728DC:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwzx r5,r28,r22
	ctx.r5.u64 = PPC_LOAD_U32(var_r28 + var_r22);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82578c08
	phBoundCapsule_8C08_2h(ctx, base);
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// addi r10,r1,224
	ctx.r10.s64 = ctx.r1.s64 + 224;
	// stwx r11,r28,r10
	PPC_STORE_U32(var_r28 + ctx.r10.u32, ctx.r11.u32);
	// addi r28,r28,4
	var_r28 = (uint32_t)(var_r28 + 4);
	// cmpwi cr6,r28,68
	// blt cr6,0x825728dc
	if ((int32_t)var_r28 < 68) goto loc_825728DC;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// mr r5,r20
	ctx.r5.u64 = var_r20;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x82572690
	phBoundCapsule_2690_h(ctx, base);
	// lhz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 92);
	// cmplwi cr6,r11,1
	// bne cr6,0x82572948
	if (ctx.r11.u32 == 1) {
		// mr r9,r25
		ctx.r9.u64 = var_r25;
		// lwz r10,484(r1)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 484);
		// addi r3,r1,164
		ctx.r3.s64 = ctx.r1.s64 + 164;
		// lhz r8,58(r31)
		ctx.r8.u64 = PPC_LOAD_U16(var_r31 + 58);
		// lhz r7,56(r31)
		ctx.r7.u64 = PPC_LOAD_U16(var_r31 + 56);
		// lfs f2,52(r31)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r31 + 52);
		ctx.f2.f64 = double(temp.f32);
		// lwz r5,4(r31)
		ctx.r5.u64 = PPC_LOAD_U32(var_r31 + 4)/* phBoundCapsule::flags@+0x4 */;
		// lfs f1,160(r1)
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
		ctx.f1.f64 = double(temp.f32);
		// bl 0x82578790
		phBoundCapsule_8790_h(ctx, base);
	}
loc_82572948:
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// mr r5,r21
	ctx.r5.u64 = var_r21;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x825786e8
	phBoundCapsule_86E8_fw(ctx, base);
	// li r11,80
	ctx.r11.s64 = 80;
	// lfs f0,160(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f0.f64 = double(temp.f32);
	// lis r28,-32161
	var_r28 = (uint32_t)(-2107703296);
	// sth r11,0(r26)
	PPC_STORE_U16(var_r26 + 0, ctx.r11.u16);
	// lwz r11,492(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 492);
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// lhz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 92);
	// cmplwi cr6,r11,0
	// bne cr6,0x825729a4
	if (ctx.r11.u32 == 0) {
		// li r11,1
		ctx.r11.s64 = 1;
		// li r5,8
		ctx.r5.s64 = 8;
		// addi r4,r1,152
		ctx.r4.s64 = ctx.r1.s64 + 152;
		// addi r3,r31,108
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 108;
		// sth r11,92(r31)
		PPC_STORE_U16(var_r31 + 92, ctx.r11.u16);
		// lwz r11,-22260(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + -22260);
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// b 0x82572a48
	} else {
	loc_825729A4:
		// lwz r9,84(r1)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
		// sth r27,92(r31)
		PPC_STORE_U16(var_r31 + 92, (uint16_t)var_r27);
		// addi r11,r9,-1
		ctx.r11.s64 = ctx.r9.s64 + -1;
		// sth r24,0(r30)
		PPC_STORE_U16(var_r30 + 0, (uint16_t)var_r24);
		// stb r23,0(r29)
		PPC_STORE_U8(var_r29 + 0, (uint8_t)var_r23);
		// extsw r11,r11
		ctx.r11.s64 = ctx.r11.s32;
		// std r11,88(r1)
		PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
		// lhz r11,94(r31)
		ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 94);
		// cmplwi cr6,r11,1
		// lis r11,-32256
		// lfd f0,88(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
		// fcfid f0,f0
		ctx.f0.f64 = double(ctx.f0.s64);
		// frsp f13,f0
		ctx.f13.f64 = double(float(ctx.f0.f64));
		// lfs f0,15788(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
		ctx.f0.f64 = double(temp.f32);
		// fdivs f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
		// bne cr6,0x82572a48
		if (ctx.r11.u32 != 1) goto loc_82572A48;
		// mr r11,r27
		ctx.r11.u64 = var_r27;
		// sth r27,94(r31)
		PPC_STORE_U16(var_r31 + 94, (uint16_t)var_r27);
		// cmpwi cr6,r9,0
		// ble cr6,0x82572a48
		if (ctx.r9.s32 <= 0) goto loc_82572A48;
		// mr r10,r21
		ctx.r10.u64 = var_r21;
	loc_825729F8:
		// lha r8,0(r10)
		ctx.r8.s64 = int16_t(PPC_LOAD_U16(ctx.r10.u32 + 0));
		// extsw r7,r11
		ctx.r7.s64 = ctx.r11.s32;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// cmpw cr6,r11,r9
		ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
		// std r8,96(r1)
		PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r8.u64);
		// std r7,88(r1)
		PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r7.u64);
		// lfd f12,96(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
		// lfd f13,88(r1)
		ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
		// fcfid f12,f12
		ctx.f12.f64 = double(ctx.f12.s64);
		// fcfid f13,f13
		ctx.f13.f64 = double(ctx.f13.s64);
		// frsp f12,f12
		ctx.f12.f64 = double(float(ctx.f12.f64));
		// frsp f13,f13
		ctx.f13.f64 = double(float(ctx.f13.f64));
		// fmuls f13,f12,f13
		ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
		// fmuls f13,f13,f0
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// fctiwz f13,f13
		ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
		// stfd f13,104(r1)
		PPC_STORE_U64(ctx.r1.u32 + 104, ctx.f13.u64);
		// lhz r8,110(r1)
		ctx.r8.u64 = PPC_LOAD_U16(ctx.r1.u32 + 110);
		// sth r8,0(r10)
		PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r8.u16);
		// addi r10,r10,2
		ctx.r10.s64 = ctx.r10.s64 + 2;
		// blt cr6,0x825729f8
		if (ctx.cr6.lt) goto loc_825729F8;
	}
loc_82572A48:
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 12);
	// li r5,260
	ctx.r5.s64 = 260;
	// lwz r11,-22260(r28)
	ctx.r11.u64 = PPC_LOAD_U32(var_r28 + -22260);
	// addi r4,r20,2056
	ctx.r4.s64 = (int64_t)(int32_t)var_r20 + 2056;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 16);
	// li r5,260
	ctx.r5.s64 = 260;
	// lwz r11,-22260(r28)
	ctx.r11.u64 = PPC_LOAD_U32(var_r28 + -22260);
	// addi r4,r20,2316
	ctx.r4.s64 = (int64_t)(int32_t)var_r20 + 2316;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_2A80_p33"))) PPC_WEAK_FUNC(phBoundCapsule_2A80_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_2A80_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=128, savegprlr_28
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// cmplwi cr6,r28,0
	// bne cr6,0x82572aa0
	if (var_r28 == 0) {
	loc_82572A98:
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572c48
		return;
	}
loc_82572AA0:
	// li r30,0
	var_r30 = 0;
	// lis r29,-32161
	var_r29 = (uint32_t)(-2107703296);
	// li r4,116
	ctx.r4.s64 = 116;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r30,0(r28)
	PPC_STORE_U32(var_r28 + 0, var_r30);
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// beq 0x82572a98
	if ((int32_t)var_r31 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572c48
		return;
	}
	// lis r11,-32256
	// stw r31,0(r28)
	PPC_STORE_U32(var_r28 + 0, var_r31);
	// li r10,100
	ctx.r10.s64 = 100;
	// stw r30,0(r31)
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ var_r30);
	// stw r30,88(r31)
	PPC_STORE_U32(var_r31 + 88, var_r30);
	// li r4,4
	ctx.r4.s64 = 4;
	// sth r30,56(r31)
	PPC_STORE_U16(var_r31 + 56, (uint16_t)var_r30);
	// li r3,644
	ctx.r3.s64 = 644;
	// sth r30,58(r31)
	PPC_STORE_U16(var_r31 + 58, (uint16_t)var_r30);
	// lfs f0,15788(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	// stfs f0,28(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 28, temp.u32);
	// stw r30,84(r31)
	PPC_STORE_U32(var_r31 + 84, var_r30);
	// stfs f0,40(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 40, temp.u32);
	// sth r30,94(r31)
	PPC_STORE_U16(var_r31 + 94, (uint16_t)var_r30);
	// stfs f0,44(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 44, temp.u32);
	// sth r10,96(r31)
	PPC_STORE_U16(var_r31 + 96, ctx.r10.u16);
	// stfs f0,52(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 52, temp.u32);
	// stw r30,4(r31)
	PPC_STORE_U32(var_r31 + 4,/* phBoundCapsule::flags@+0x4 */ var_r30);
	// lfs f12,22448(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22448);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	// stfs f12,32(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(var_r31 + 32, temp.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(var_r31 + 8, var_r30);
	// stfs f0,60(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 60, temp.u32);
	// stw r30,12(r31)
	PPC_STORE_U32(var_r31 + 12, var_r30);
	// stfs f0,64(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 64, temp.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(var_r31 + 16, var_r30);
	// stfs f0,68(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 68, temp.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(var_r31 + 20, var_r30);
	// lfs f13,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32248
	// stfs f13,36(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(var_r31 + 36, temp.u32);
	// stw r30,24(r31)
	PPC_STORE_U32(var_r31 + 24, var_r30);
	// stfs f13,48(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(var_r31 + 48, temp.u32);
	// stfs f0,72(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 72, temp.u32);
	// stfs f13,80(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(var_r31 + 80, temp.u32);
	// lfs f11,-24380(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24380);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32256
	// stfs f11,76(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(var_r31 + 76, temp.u32);
	// lfs f10,22092(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22092);
	ctx.f10.f64 = double(temp.f32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stfs f10,108(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(var_r31 + 108, temp.u32);
	// sth r11,92(r31)
	PPC_STORE_U16(var_r31 + 92, ctx.r11.u16);
	// stw r11,104(r31)
	PPC_STORE_U32(var_r31 + 104, ctx.r11.u32);
	// stw r11,100(r31)
	PPC_STORE_U32(var_r31 + 100, ctx.r11.u32);
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmplwi r3,0
	// stw r3,4(r31)
	PPC_STORE_U32(var_r31 + 4,/* phBoundCapsule::flags@+0x4 */ ctx.r3.u32);
	// beq 0x82572a98
	if (ctx.r3.u32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572c48
		return;
	}
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,80
	ctx.r3.s64 = 80;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmplwi r3,0
	// stw r3,8(r31)
	PPC_STORE_U32(var_r31 + 8, ctx.r3.u32);
	// beq 0x82572a98
	if (ctx.r3.u32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572c48
		return;
	}
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,65
	ctx.r3.s64 = 65;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmplwi r3,0
	// stw r3,12(r31)
	PPC_STORE_U32(var_r31 + 12, ctx.r3.u32);
	// beq 0x82572a98
	if (ctx.r3.u32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572c48
		return;
	}
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,65
	ctx.r3.s64 = 65;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmplwi r3,0
	// stw r3,16(r31)
	PPC_STORE_U32(var_r31 + 16, ctx.r3.u32);
	// beq 0x82572a98
	if (ctx.r3.u32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572c48
		return;
	}
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,102
	ctx.r3.s64 = 102;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmplwi r3,0
	// stw r3,20(r31)
	PPC_STORE_U32(var_r31 + 20, ctx.r3.u32);
	// beq 0x82572a98
	if (ctx.r3.u32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572c48
		return;
	}
	// lwz r11,-22272(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22272);
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,104
	ctx.r3.s64 = 104;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmplwi r3,0
	// stw r3,24(r31)
	PPC_STORE_U32(var_r31 + 24, ctx.r3.u32);
	// beq 0x82572a98
	if (ctx.r3.u32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82572c48
		return;
	}
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x825791d8
	phBoundCapsule_91D8_p33(ctx, base);
	// cntlzw r11,r3
	ctx.r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = ctx.r11.u64 ^ 1;
loc_82572C48:
	return;
}

__attribute__((alias("__imp__phBoundCapsule_2C50_p33"))) PPC_WEAK_FUNC(phBoundCapsule_2C50_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_2C50_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, savegprlr_29
	// lwz r31,0(r3)
	var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */);
	// cmplwi r31,0
	// beq 0x82572d30
	if (var_r31 != 0) {
		// lwz r3,4(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4)/* phBoundCapsule::flags@+0x4 */;
		// li r29,0
		var_r29 = 0;
		// lis r30,-32161
		var_r30 = (uint32_t)(-2107703296);
		// cmplwi r3,0
		// beq 0x82572c8c
		if (ctx.r3.u32 != 0) {
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// stw r29,4(r31)
			PPC_STORE_U32(var_r31 + 4,/* phBoundCapsule::flags@+0x4 */ var_r29);
		}
	loc_82572C8C:
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82579258
		phBoundCapsule_9258_p33(ctx, base);
		// lwz r3,12(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 12);
		// cmplwi r3,0
		// beq 0x82572cb0
		if (ctx.r3.u32 != 0) {
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// stw r29,12(r31)
			PPC_STORE_U32(var_r31 + 12, var_r29);
		}
	loc_82572CB0:
		// lwz r3,16(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 16);
		// cmplwi r3,0
		// beq 0x82572ccc
		if (ctx.r3.u32 != 0) {
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// stw r29,16(r31)
			PPC_STORE_U32(var_r31 + 16, var_r29);
		}
	loc_82572CCC:
		// lwz r3,20(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 20);
		// cmplwi r3,0
		// beq 0x82572ce8
		if (ctx.r3.u32 != 0) {
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// stw r29,20(r31)
			PPC_STORE_U32(var_r31 + 20, var_r29);
		}
	loc_82572CE8:
		// lwz r3,24(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 24);
		// cmplwi r3,0
		// beq 0x82572d04
		if (ctx.r3.u32 != 0) {
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// stw r29,24(r31)
			PPC_STORE_U32(var_r31 + 24, var_r29);
		}
	loc_82572D04:
		// lwz r3,8(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
		// cmplwi r3,0
		// beq 0x82572d20
		if (ctx.r3.u32 != 0) {
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// stw r29,8(r31)
			PPC_STORE_U32(var_r31 + 8, var_r29);
		}
	loc_82572D20:
		// lwz r11,-22268(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	}
loc_82572D30:
	// li r3,0
	ctx.r3.s64 = 0;
	return;
}

__attribute__((alias("__imp__phBoundCapsule_2D40_fw"))) PPC_WEAK_FUNC(phBoundCapsule_2D40_fw);
PPC_FUNC_IMPL(__imp__phBoundCapsule_2D40_fw) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	double var_f30 = 0.0;
	double var_f28 = 0.0;
	double var_f29 = 0.0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f88c
	ctx.lr = 0x82572D48;
	__savegprlr_25(ctx, base);
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-2608(r1)
	ea = -2608 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	var_f30 = ctx.f1.f64;
	// lis r31,-32161
	var_r31 = (uint32_t)(-2107703296);
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// fmr f28,f2
	var_f28 = ctx.f2.f64;
	// srawi r27,r5,1
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x1) != 0);
	var_r27 = (uint32_t)(ctx.r5.s32 >> 1);
	// fmr f29,f3
	var_f29 = ctx.f3.f64;
	// mr r26,r6
	var_r26 = ctx.r6.u32;
	// mr r25,r8
	var_r25 = ctx.r8.u32;
	// lwz r11,-22264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + -22264);
	// mr r29,r9
	var_r29 = ctx.r9.u32;
	// mr r28,r10
	var_r28 = ctx.r10.u32;
	// li r5,1028
	ctx.r5.s64 = 1028;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,432
	ctx.r3.s64 = ctx.r1.s64 + 432;
	// fmr f31,f30
	var_f31 = var_f30;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// lwz r11,-22264(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + -22264);
	// li r5,1028
	ctx.r5.s64 = 1028;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,1472
	ctx.r3.s64 = ctx.r1.s64 + 1472;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmpwi cr6,r30,0
	// ble cr6,0x82572e50
	if ((int32_t)var_r30 > 0) {
		// lis r5,-32256
		// lis r6,-32164
		// lis r8,-32164
		// lis r9,-32254
		// mr r11,r29
		ctx.r11.u64 = var_r29;
		// lfs f0,27200(r5)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 27200);
		ctx.f0.f64 = double(temp.f32);
		// subf r4,r29,r28
		ctx.r4.s64 = (int64_t)(int32_t)var_r28 - (int64_t)(int32_t)var_r29;
		// lwz r6,10076(r6)
		ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 10076);
		// mr r10,r30
		ctx.r10.u64 = var_r30;
		// lwz r7,10080(r8)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 10080);
		// lfs f12,24912(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 24912);
		ctx.f12.f64 = double(temp.f32);
	loc_82572DE4:
		// fadds f10,f31,f0
		ctx.fpscr.disableFlushMode();
		ctx.f10.f64 = double(float(var_f31 + ctx.f0.f64));
		// lfs f11,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// addi r9,r1,84
		ctx.r9.s64 = ctx.r1.s64 + 84;
		// fmadds f11,f11,f12,f0
		ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 + ctx.f0.f64));
		// lfsx f13,r4,r11
		temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r11.u32);
		ctx.f13.f64 = double(temp.f32);
		// addi r5,r1,432
		ctx.r5.s64 = ctx.r1.s64 + 432;
		// fmuls f13,f13,f0
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// addi r3,r1,1472
		ctx.r3.s64 = ctx.r1.s64 + 1472;
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
		// fadds f31,f31,f30
		var_f31 = double(float(var_f31 + var_f30));
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fctiwz f10,f10
		ctx.f10.s64 = (ctx.f10.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f10.f64));
		// stfiwx f10,0,r9
		PPC_STORE_U32(ctx.r9.u32, ctx.f10.u32);
		// addi r8,r1,80
		ctx.r8.s64 = ctx.r1.s64 + 80;
		// fctiwz f11,f11
		ctx.f11.s64 = (ctx.f11.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f11.f64));
		// lwz r9,84(r1)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
		// rlwinm r9,r9,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// stfiwx f11,0,r8
		PPC_STORE_U32(ctx.r8.u32, ctx.f11.u32);
		// lwz r8,80(r1)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// rlwinm r8,r8,2,22,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0x3FC;
		// lfsx f11,r8,r7
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
		ctx.f11.f64 = double(temp.f32);
		// fmuls f11,f11,f13
		ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
		// stfsx f11,r9,r5
		temp.f32 = float(ctx.f11.f64);
		PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, temp.u32);
		// lfsx f11,r8,r6
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r6.u32);
		ctx.f11.f64 = double(temp.f32);
		// fmuls f13,f11,f13
		ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
		// stfsx f13,r9,r3
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, temp.u32);
		// bne 0x82572de4
		if (!ctx.cr0.eq) goto loc_82572DE4;
	}
loc_82572E50:
	// li r5,512
	ctx.r5.s64 = 512;
	// addi r4,r1,1472
	ctx.r4.s64 = ctx.r1.s64 + 1472;
	// addi r3,r1,432
	ctx.r3.s64 = ctx.r1.s64 + 432;
	// bl 0x82576808
	phBoundCapsule_6808(ctx, base);
	// lis r10,-32256
	// lis r11,-32256
	// cmpwi cr6,r27,0
	// lfs f12,15788(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15788);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f13.f64 = double(temp.f32);
	// ble cr6,0x82572e94
	if ((int32_t)var_r27 > 0) {
		// extsw r11,r27
		ctx.r11.s64 = (int32_t)var_r27;
		// std r11,88(r1)
		PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
		// lfd f0,88(r1)
		ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
		// fcfid f0,f0
		ctx.f0.f64 = double(ctx.f0.s64);
		// frsp f0,f0
		ctx.f0.f64 = double(float(ctx.f0.f64));
		// fdivs f0,f12,f0
		ctx.f0.f64 = double(float(ctx.f12.f64 / ctx.f0.f64));
		// b 0x82572e98
	} else {
	loc_82572E94:
		// fmr f0,f13
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = ctx.f13.f64;
	}
loc_82572E98:
	// mr r8,r25
	ctx.r8.u64 = var_r25;
	// addi r10,r1,1296
	ctx.r10.s64 = ctx.r1.s64 + 1296;
	// addi r9,r1,2336
	ctx.r9.s64 = ctx.r1.s64 + 2336;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// li r11,40
	ctx.r11.s64 = 40;
loc_82572EAC:
	// lfs f11,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// fmuls f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f9,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fadds f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f8,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lfs f7,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// fmadds f11,f9,f10,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f10.f64 + ctx.f11.f64));
	// stfs f11,0(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fmuls f11,f8,f13
	ctx.f11.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// fadds f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
	// fmadds f11,f7,f10,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f10.f64 + ctx.f11.f64));
	// stfs f11,0(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x82572eac
	if (!ctx.cr0.eq) goto loc_82572EAC;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,22448(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22448);  /* glob:lbl_820157B0 @ 0x820157b0 */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f29,f0
	// beq cr6,0x8257302c
	if (var_f29 != ctx.f0.f64) {
		// lis r11,-32248
		// addi r10,r1,88
		ctx.r10.s64 = ctx.r1.s64 + 88;
		// addi r8,r1,80
		ctx.r8.s64 = ctx.r1.s64 + 80;
		// addi r9,r1,96
		ctx.r9.s64 = ctx.r1.s64 + 96;
		// addi r7,r1,80
		ctx.r7.s64 = ctx.r1.s64 + 80;
		// lfs f0,-25892(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25892);  /* glob:0x82009adc */
		ctx.f0.f64 = double(temp.f32);
		// addi r11,r1,84
		ctx.r11.s64 = ctx.r1.s64 + 84;
		// stfs f0,80(r1)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
		// addi r6,r1,84
		ctx.r6.s64 = ctx.r1.s64 + 84;
		// stfs f0,84(r1)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
		// addi r5,r1,88
		ctx.r5.s64 = ctx.r1.s64 + 88;
		// stfs f0,96(r1)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
		// addi r4,r1,80
		ctx.r4.s64 = ctx.r1.s64 + 80;
		// stfs f0,88(r1)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
		// addi r3,r1,96
		ctx.r3.s64 = ctx.r1.s64 + 96;
		// lvlx v0,0,r10
		temp.u32 = ctx.r10.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// addi r10,r1,96
		ctx.r10.s64 = ctx.r1.s64 + 96;
		// lvlx v7,0,r8
		temp.u32 = ctx.r8.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v7.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// addi r31,r1,88
		var_r31 = (uint32_t)(ctx.r1.s64 + 88);
		// addi r8,r1,84
		ctx.r8.s64 = ctx.r1.s64 + 84;
		// lvlx v8,0,r9
		temp.u32 = ctx.r9.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v8.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// lvlx v13,0,r11
		temp.u32 = ctx.r11.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v13.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// vrlimi128 v0,v8,4,3
		simde_mm_store_ps(ctx.v0.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v0.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v8.f32), 57), 4));
		// stfs f28,88(r1)
		temp.f32 = float(var_f28);
		PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
		// vrlimi128 v13,v7,4,3
		simde_mm_store_ps(ctx.v13.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v13.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v7.f32), 57), 4));
		// stfs f28,96(r1)
		temp.f32 = float(var_f28);
		PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
		// mr r11,r26
		ctx.r11.u64 = var_r26;
		// stfs f28,84(r1)
		temp.f32 = float(var_f28);
		PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
		// addi r9,r1,112
		ctx.r9.s64 = ctx.r1.s64 + 112;
		// stfs f28,80(r1)
		temp.f32 = float(var_f28);
		PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
		// lvlx v11,0,r10
		temp.u32 = ctx.r10.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v11.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// vrlimi128 v0,v13,3,2
		simde_mm_store_ps(ctx.v0.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v0.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v13.f32), 78), 3));
		// lvlx v12,0,r7
		temp.u32 = ctx.r7.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v12.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// li r10,20
		ctx.r10.s64 = 20;
		// lvlx v6,0,r6
		temp.u32 = ctx.r6.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v6.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// lvlx v5,0,r5
		temp.u32 = ctx.r5.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v5.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// vrlimi128 v12,v6,4,3
		simde_mm_store_ps(ctx.v12.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v12.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v6.f32), 57), 4));
		// stfs f29,88(r1)
		temp.f32 = float(var_f29);
		PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
		// vrlimi128 v11,v5,4,3
		simde_mm_store_ps(ctx.v11.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v11.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v5.f32), 57), 4));
		// stfs f29,96(r1)
		temp.f32 = float(var_f29);
		PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
		// stfs f29,84(r1)
		temp.f32 = float(var_f29);
		PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
		// stfs f29,80(r1)
		temp.f32 = float(var_f29);
		PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
		// lvlx v10,0,r4
		temp.u32 = ctx.r4.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v10.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// vrlimi128 v12,v11,3,2
		simde_mm_store_ps(ctx.v12.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v12.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v11.f32), 78), 3));
		// lvlx v9,0,r3
		temp.u32 = ctx.r3.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v9.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// lvlx v4,0,r8
		temp.u32 = ctx.r8.u32;
		simde_mm_store_si128((simde__m128i*)ctx.v4.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// lvlx v3,0,r31
		temp.u32 = var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v3.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// vrlimi128 v10,v4,4,3
		simde_mm_store_ps(ctx.v10.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v10.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v4.f32), 57), 4));
		// vrlimi128 v9,v3,4,3
		simde_mm_store_ps(ctx.v9.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v9.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v3.f32), 57), 4));
		// vrlimi128 v10,v9,3,2
		simde_mm_store_ps(ctx.v10.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v10.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v9.f32), 78), 3));
	loc_82572FE4:
		// lvx128 v13,r0,r9
		ea = (ctx.r9.u32) & ~0xF;
		simde_mm_store_si128((simde__m128i*)ctx.v13.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
		// mr r8,r11
		ctx.r8.u64 = ctx.r11.u64;
		// vmulfp128 v13,v13,v12
		ctx.fpscr.enableFlushMode();
		simde_mm_store_ps(ctx.v13.f32, simde_mm_mul_ps(simde_mm_load_ps(ctx.v13.f32), simde_mm_load_ps(ctx.v12.f32)));
		// mr r7,r11
		ctx.r7.u64 = ctx.r11.u64;
		// li r6,4
		ctx.r6.s64 = 4;
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
		// addi r9,r9,16
		ctx.r9.s64 = ctx.r9.s64 + 16;
		// addi r11,r11,8
		ctx.r11.s64 = ctx.r11.s64 + 8;
		// vmulfp128 v13,v13,v0
		simde_mm_store_ps(ctx.v13.f32, simde_mm_mul_ps(simde_mm_load_ps(ctx.v13.f32), simde_mm_load_ps(ctx.v0.f32)));
		// vmulfp128 v13,v13,v10
		simde_mm_store_ps(ctx.v13.f32, simde_mm_mul_ps(simde_mm_load_ps(ctx.v13.f32), simde_mm_load_ps(ctx.v10.f32)));
		// vctsxs v13,v13,0
		simde_mm_store_si128((simde__m128i*)ctx.v13.s32, simde_mm_vctsxs(simde_mm_load_ps(ctx.v13.f32)));
		// vpkswss v13,v13,v13
		simde_mm_store_si128((simde__m128i*)ctx.v13.s16, simde_mm_packs_epi32(simde_mm_load_si128((simde__m128i*)ctx.v13.s32), simde_mm_load_si128((simde__m128i*)ctx.v13.s32)));
		// vspltw v11,v13,0
		simde_mm_store_si128((simde__m128i*)ctx.v11.u32, simde_mm_shuffle_epi32(simde_mm_load_si128((simde__m128i*)ctx.v13.u32), 0xFF));
		// vspltw v13,v13,1
		simde_mm_store_si128((simde__m128i*)ctx.v13.u32, simde_mm_shuffle_epi32(simde_mm_load_si128((simde__m128i*)ctx.v13.u32), 0xAA));
		// stvewx v11,r0,r8
		ea = (ctx.r8.u32) & ~0x3;
		PPC_STORE_U32(ea, ctx.v11.u32[3 - ((ea & 0xF) >> 2)]);
		// stvewx v13,r7,r6
		ea = (ctx.r7.u32 + ctx.r6.u32) & ~0x3;
		PPC_STORE_U32(ea, ctx.v13.u32[3 - ((ea & 0xF) >> 2)]);
		// bne 0x82572fe4
		if (!ctx.cr0.eq) goto loc_82572FE4;
		// b 0x82573070
	} else {
	loc_8257302C:
		// mr r11,r26
		ctx.r11.u64 = var_r26;
		// addi r9,r1,112
		ctx.r9.s64 = ctx.r1.s64 + 112;
		// li r10,20
		ctx.r10.s64 = 20;
	loc_82573038:
		// lvx128 v0,r0,r9
		ea = (ctx.r9.u32) & ~0xF;
		simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
		// mr r8,r11
		ctx.r8.u64 = ctx.r11.u64;
		// vctsxs v0,v0,0
		ctx.fpscr.enableFlushMode();
		simde_mm_store_si128((simde__m128i*)ctx.v0.s32, simde_mm_vctsxs(simde_mm_load_ps(ctx.v0.f32)));
		// mr r7,r11
		ctx.r7.u64 = ctx.r11.u64;
		// li r6,4
		ctx.r6.s64 = 4;
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// addi r9,r9,16
		ctx.r9.s64 = ctx.r9.s64 + 16;
		// addi r11,r11,8
		ctx.r11.s64 = ctx.r11.s64 + 8;
		// vpkswss v0,v0,v0
		simde_mm_store_si128((simde__m128i*)ctx.v0.s16, simde_mm_packs_epi32(simde_mm_load_si128((simde__m128i*)ctx.v0.s32), simde_mm_load_si128((simde__m128i*)ctx.v0.s32)));
		// vspltw v13,v0,0
		simde_mm_store_si128((simde__m128i*)ctx.v13.u32, simde_mm_shuffle_epi32(simde_mm_load_si128((simde__m128i*)ctx.v0.u32), 0xFF));
		// vspltw v0,v0,1
		simde_mm_store_si128((simde__m128i*)ctx.v0.u32, simde_mm_shuffle_epi32(simde_mm_load_si128((simde__m128i*)ctx.v0.u32), 0xAA));
		// stvewx v13,r0,r8
		ea = (ctx.r8.u32) & ~0x3;
		PPC_STORE_U32(ea, ctx.v13.u32[3 - ((ea & 0xF) >> 2)]);
		// stvewx v0,r7,r6
		ea = (ctx.r7.u32 + ctx.r6.u32) & ~0x3;
		PPC_STORE_U32(ea, ctx.v0.u32[3 - ((ea & 0xF) >> 2)]);
		// bne 0x82573038
		if (ctx.r10.s32 != 0) goto loc_82573038;
	}
loc_82573070:
	// addi r10,r1,432
	ctx.r10.s64 = ctx.r1.s64 + 432;
	// addi r9,r1,1472
	ctx.r9.s64 = ctx.r1.s64 + 1472;
	// mr r8,r25
	ctx.r8.u64 = var_r25;
	// li r11,40
	ctx.r11.s64 = 40;
loc_82573080:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// lfs f0,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stfs f0,0(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bne 0x82573080
	if (ctx.r11.s32 != 0) goto loc_82573080;
	// addi r1,r1,2608
	ctx.r1.s64 = ctx.r1.s64 + 2608;
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// b 0x8242f8dc
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_30B8_w"))) PPC_WEAK_FUNC(xam_30B8_w);
PPC_FUNC_IMPL(__imp__xam_30B8_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r20 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r21 = 0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f878
	ctx.lr = 0x825730C0;
	__savegprlr_20(ctx, base);
	// addi r20,r6,8
	var_r20 = (uint32_t)(ctx.r6.s64 + 8);  // addr:0x825c0008
	// lhz r9,26(r6)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r6.u32 + 26);
	// lhz r11,0(r20)
	ctx.r11.u64 = PPC_LOAD_U16(var_r20 + 0);
	// extsh r10,r11
	ctx.r10.s64 = ctx.r11.s16;
	// extsh r11,r9
	ctx.r11.s64 = ctx.r9.s16;
	// srawi r8,r10,15
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFF) != 0);
	ctx.r8.s64 = ctx.r10.s32 >> 15;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// cmpwi cr6,r8,0
	// bne cr6,0x825730ec
	if (ctx.r8.s32 == 0) {
		// srawi r10,r10,2
		ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
		ctx.r10.s64 = ctx.r10.s32 >> 2;
		// b 0x825730f8
	} else {
	loc_825730EC:
		// srawi r7,r10,2
		ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
		ctx.r7.s64 = ctx.r10.s32 >> 2;
		// neg r10,r7
		ctx.r10.s64 = static_cast<int64_t>(-ctx.r7.u64);
		// clrlwi r10,r10,19
		ctx.r10.u64 = ctx.r10.u32 & 0x1FFF;
	}
loc_825730F8:
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmpwi cr6,r10,0
	// subfic r9,r9,32
	ctx.xer.ca = ctx.r9.u32 <= 32;
	ctx.r9.s64 = 32 - ctx.r9.s64;
	// bne cr6,0x82573110
	if (ctx.r10.s32 == 0) {
		// li r10,32
		ctx.r10.s64 = 32;
		// b 0x82573118
	} else {
	loc_82573110:
		// rlwinm r7,r10,6,0,25
		ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
		// sraw r10,r7,r9
		temp.u32 = ctx.r9.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r7.s32 < 0) & (((ctx.r7.s32 >> temp.u32) << temp.u32) != ctx.r7.s32);
		ctx.r10.s64 = ctx.r7.s32 >> temp.u32;
	}
loc_82573118:
	// srawi r7,r11,10
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FF) != 0);
	ctx.r7.s64 = ctx.r11.s32 >> 10;
	// srawi r31,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	var_r31 = (uint32_t)(ctx.r11.s32 >> 6);
	// clrlwi r30,r11,26
	var_r30 = (uint32_t)(ctx.r11.u32 & 0x3F);
	// clrlwi r11,r31,28
	ctx.r11.u64 = var_r31 & 0xF;
	// mullw r10,r30,r10
	ctx.r10.s64 = int64_t((int32_t)var_r30) * int64_t(ctx.r10.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// clrlwi r9,r7,31
	ctx.r9.u64 = ctx.r7.u32 & 0x1;
	// addi r7,r10,48
	ctx.r7.s64 = ctx.r10.s64 + 48;
	// cmpwi cr6,r11,26
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// rlwinm r10,r7,3,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFF80;
	// bgt cr6,0x82573154
	if (ctx.r11.s32 <= 26) {
		// subfic r11,r11,26
		ctx.xer.ca = ctx.r11.u32 <= 26;
		ctx.r11.s64 = 26 - ctx.r11.s64;
		// sraw r10,r10,r11
		temp.u32 = ctx.r11.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
		// b 0x82573160
	} else {
	loc_82573154:
		// addi r8,r11,-26
		ctx.r8.s64 = ctx.r11.s64 + -26;
		// slw r7,r10,r8
		ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
		// clrlwi r10,r7,17
		ctx.r10.u64 = ctx.r7.u32 & 0x7FFF;
	}
loc_82573160:
	// lhz r8,10(r6)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r6.u32 + 10);
	// xori r11,r9,1
	ctx.r11.u64 = ctx.r9.u64 ^ 1;
	// neg r7,r10
	ctx.r7.s64 = static_cast<int64_t>(-ctx.r10.u64);
	// lhz r31,28(r6)
	var_r31 = (uint32_t)(PPC_LOAD_U16(ctx.r6.u32 + 28));
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// extsh r9,r8
	ctx.r9.s64 = ctx.r8.s16;
	// andc r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// and r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 & ctx.r11.u64;
	// srawi r8,r9,15
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7FFF) != 0);
	ctx.r8.s64 = ctx.r9.s32 >> 15;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// extsh r11,r31
	ctx.r11.s64 = (int16_t)var_r31;
	// extsh r27,r10
	var_r27 = (uint32_t)(ctx.r10.s16);
	// cmpwi cr6,r8,0
	// bne cr6,0x825731a4
	if (ctx.r8.s32 == 0) {
		// srawi r10,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r10.s64 = ctx.r9.s32 >> 2;
		// b 0x825731b0
	} else {
	loc_825731A4:
		// srawi r9,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r9.s32 >> 2;
		// neg r7,r9
		ctx.r7.s64 = static_cast<int64_t>(-ctx.r9.u64);
		// clrlwi r10,r7,19
		ctx.r10.u64 = ctx.r7.u32 & 0x1FFF;
	}
loc_825731B0:
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmpwi cr6,r10,0
	// subfic r9,r9,32
	ctx.xer.ca = ctx.r9.u32 <= 32;
	ctx.r9.s64 = 32 - ctx.r9.s64;
	// bne cr6,0x825731c8
	if (ctx.r10.s32 == 0) {
		// li r10,32
		ctx.r10.s64 = 32;
		// b 0x825731d0
	} else {
	loc_825731C8:
		// rlwinm r10,r10,6,0,25
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
		// sraw r10,r10,r9
		temp.u32 = ctx.r9.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
	}
loc_825731D0:
	// srawi r7,r11,10
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FF) != 0);
	ctx.r7.s64 = ctx.r11.s32 >> 10;
	// srawi r31,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	var_r31 = (uint32_t)(ctx.r11.s32 >> 6);
	// clrlwi r30,r11,26
	var_r30 = (uint32_t)(ctx.r11.u32 & 0x3F);
	// clrlwi r11,r31,28
	ctx.r11.u64 = var_r31 & 0xF;
	// mullw r10,r30,r10
	ctx.r10.s64 = int64_t((int32_t)var_r30) * int64_t(ctx.r10.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// clrlwi r9,r7,31
	ctx.r9.u64 = ctx.r7.u32 & 0x1;
	// addi r7,r10,48
	ctx.r7.s64 = ctx.r10.s64 + 48;
	// cmpwi cr6,r11,26
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// rlwinm r10,r7,3,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFF80;
	// bgt cr6,0x8257320c
	if (ctx.r11.s32 <= 26) {
		// subfic r11,r11,26
		ctx.xer.ca = ctx.r11.u32 <= 26;
		ctx.r11.s64 = 26 - ctx.r11.s64;
		// sraw r10,r10,r11
		temp.u32 = ctx.r11.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
		// b 0x82573218
	} else {
	loc_8257320C:
		// addi r8,r11,-26
		ctx.r8.s64 = ctx.r11.s64 + -26;
		// slw r7,r10,r8
		ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
		// clrlwi r10,r7,17
		ctx.r10.u64 = ctx.r7.u32 & 0x7FFF;
	}
loc_82573218:
	// lhz r8,12(r6)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r6.u32 + 12);
	// xori r11,r9,1
	ctx.r11.u64 = ctx.r9.u64 ^ 1;
	// neg r7,r10
	ctx.r7.s64 = static_cast<int64_t>(-ctx.r10.u64);
	// lhz r31,30(r6)
	var_r31 = (uint32_t)(PPC_LOAD_U16(ctx.r6.u32 + 30));
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// extsh r9,r8
	ctx.r9.s64 = ctx.r8.s16;
	// andc r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// and r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 & ctx.r11.u64;
	// srawi r8,r9,15
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7FFF) != 0);
	ctx.r8.s64 = ctx.r9.s32 >> 15;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// extsh r11,r31
	ctx.r11.s64 = (int16_t)var_r31;
	// extsh r28,r10
	var_r28 = (uint32_t)(ctx.r10.s16);
	// cmpwi cr6,r8,0
	// bne cr6,0x8257325c
	if (ctx.r8.s32 == 0) {
		// srawi r10,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r10.s64 = ctx.r9.s32 >> 2;
		// b 0x82573268
	} else {
	loc_8257325C:
		// srawi r9,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r9.s32 >> 2;
		// neg r7,r9
		ctx.r7.s64 = static_cast<int64_t>(-ctx.r9.u64);
		// clrlwi r10,r7,19
		ctx.r10.u64 = ctx.r7.u32 & 0x1FFF;
	}
loc_82573268:
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmpwi cr6,r10,0
	// subfic r9,r9,32
	ctx.xer.ca = ctx.r9.u32 <= 32;
	ctx.r9.s64 = 32 - ctx.r9.s64;
	// bne cr6,0x82573280
	if (ctx.r10.s32 == 0) {
		// li r10,32
		ctx.r10.s64 = 32;
		// b 0x82573288
	} else {
	loc_82573280:
		// rlwinm r10,r10,6,0,25
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
		// sraw r10,r10,r9
		temp.u32 = ctx.r9.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
	}
loc_82573288:
	// srawi r7,r11,10
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FF) != 0);
	ctx.r7.s64 = ctx.r11.s32 >> 10;
	// srawi r31,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	var_r31 = (uint32_t)(ctx.r11.s32 >> 6);
	// clrlwi r30,r11,26
	var_r30 = (uint32_t)(ctx.r11.u32 & 0x3F);
	// clrlwi r11,r31,28
	ctx.r11.u64 = var_r31 & 0xF;
	// mullw r10,r30,r10
	ctx.r10.s64 = int64_t((int32_t)var_r30) * int64_t(ctx.r10.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// clrlwi r9,r7,31
	ctx.r9.u64 = ctx.r7.u32 & 0x1;
	// addi r7,r10,48
	ctx.r7.s64 = ctx.r10.s64 + 48;
	// cmpwi cr6,r11,26
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// rlwinm r10,r7,3,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFF80;
	// bgt cr6,0x825732c4
	if (ctx.r11.s32 <= 26) {
		// subfic r11,r11,26
		ctx.xer.ca = ctx.r11.u32 <= 26;
		ctx.r11.s64 = 26 - ctx.r11.s64;
		// sraw r10,r10,r11
		temp.u32 = ctx.r11.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
		// b 0x825732d0
	} else {
	loc_825732C4:
		// addi r8,r11,-26
		ctx.r8.s64 = ctx.r11.s64 + -26;
		// slw r7,r10,r8
		ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
		// clrlwi r10,r7,17
		ctx.r10.u64 = ctx.r7.u32 & 0x7FFF;
	}
loc_825732D0:
	// lhz r8,14(r6)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r6.u32 + 14);
	// xori r11,r9,1
	ctx.r11.u64 = ctx.r9.u64 ^ 1;
	// neg r7,r10
	ctx.r7.s64 = static_cast<int64_t>(-ctx.r10.u64);
	// lhz r31,32(r6)
	var_r31 = (uint32_t)(PPC_LOAD_U16(ctx.r6.u32 + 32));
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// extsh r9,r8
	ctx.r9.s64 = ctx.r8.s16;
	// andc r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// and r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 & ctx.r11.u64;
	// srawi r8,r9,15
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7FFF) != 0);
	ctx.r8.s64 = ctx.r9.s32 >> 15;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// extsh r11,r31
	ctx.r11.s64 = (int16_t)var_r31;
	// extsh r29,r10
	var_r29 = (uint32_t)(ctx.r10.s16);
	// cmpwi cr6,r8,0
	// bne cr6,0x82573314
	if (ctx.r8.s32 == 0) {
		// srawi r10,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r10.s64 = ctx.r9.s32 >> 2;
		// b 0x82573320
	} else {
	loc_82573314:
		// srawi r9,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r9.s32 >> 2;
		// neg r7,r9
		ctx.r7.s64 = static_cast<int64_t>(-ctx.r9.u64);
		// clrlwi r10,r7,19
		ctx.r10.u64 = ctx.r7.u32 & 0x1FFF;
	}
loc_82573320:
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmpwi cr6,r10,0
	// subfic r9,r9,32
	ctx.xer.ca = ctx.r9.u32 <= 32;
	ctx.r9.s64 = 32 - ctx.r9.s64;
	// bne cr6,0x82573338
	if (ctx.r10.s32 == 0) {
		// li r10,32
		ctx.r10.s64 = 32;
		// b 0x82573340
	} else {
	loc_82573338:
		// rlwinm r10,r10,6,0,25
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
		// sraw r10,r10,r9
		temp.u32 = ctx.r9.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
	}
loc_82573340:
	// srawi r7,r11,10
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FF) != 0);
	ctx.r7.s64 = ctx.r11.s32 >> 10;
	// srawi r31,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	var_r31 = (uint32_t)(ctx.r11.s32 >> 6);
	// clrlwi r30,r11,26
	var_r30 = (uint32_t)(ctx.r11.u32 & 0x3F);
	// clrlwi r11,r31,28
	ctx.r11.u64 = var_r31 & 0xF;
	// mullw r10,r30,r10
	ctx.r10.s64 = int64_t((int32_t)var_r30) * int64_t(ctx.r10.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// clrlwi r9,r7,31
	ctx.r9.u64 = ctx.r7.u32 & 0x1;
	// addi r7,r10,48
	ctx.r7.s64 = ctx.r10.s64 + 48;
	// cmpwi cr6,r11,26
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// rlwinm r10,r7,3,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFF80;
	// bgt cr6,0x8257337c
	if (ctx.r11.s32 <= 26) {
		// subfic r11,r11,26
		ctx.xer.ca = ctx.r11.u32 <= 26;
		ctx.r11.s64 = 26 - ctx.r11.s64;
		// sraw r10,r10,r11
		temp.u32 = ctx.r11.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
		// b 0x82573388
	} else {
	loc_8257337C:
		// addi r8,r11,-26
		ctx.r8.s64 = ctx.r11.s64 + -26;
		// slw r7,r10,r8
		ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
		// clrlwi r10,r7,17
		ctx.r10.u64 = ctx.r7.u32 & 0x7FFF;
	}
loc_82573388:
	// lhz r8,16(r6)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r6.u32 + 16);
	// xori r11,r9,1
	ctx.r11.u64 = ctx.r9.u64 ^ 1;
	// neg r7,r10
	ctx.r7.s64 = static_cast<int64_t>(-ctx.r10.u64);
	// lhz r31,34(r6)
	var_r31 = (uint32_t)(PPC_LOAD_U16(ctx.r6.u32 + 34));
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// extsh r9,r8
	ctx.r9.s64 = ctx.r8.s16;
	// andc r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// and r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 & ctx.r11.u64;
	// srawi r8,r9,15
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7FFF) != 0);
	ctx.r8.s64 = ctx.r9.s32 >> 15;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// extsh r11,r31
	ctx.r11.s64 = (int16_t)var_r31;
	// extsh r30,r10
	var_r30 = (uint32_t)(ctx.r10.s16);
	// cmpwi cr6,r8,0
	// bne cr6,0x825733cc
	if (ctx.r8.s32 == 0) {
		// srawi r10,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r10.s64 = ctx.r9.s32 >> 2;
		// b 0x825733d8
	} else {
	loc_825733CC:
		// srawi r9,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r9.s32 >> 2;
		// neg r7,r9
		ctx.r7.s64 = static_cast<int64_t>(-ctx.r9.u64);
		// clrlwi r10,r7,19
		ctx.r10.u64 = ctx.r7.u32 & 0x1FFF;
	}
loc_825733D8:
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmpwi cr6,r10,0
	// subfic r9,r9,32
	ctx.xer.ca = ctx.r9.u32 <= 32;
	ctx.r9.s64 = 32 - ctx.r9.s64;
	// bne cr6,0x825733f0
	if (ctx.r10.s32 == 0) {
		// li r10,32
		ctx.r10.s64 = 32;
		// b 0x825733f8
	} else {
	loc_825733F0:
		// rlwinm r10,r10,6,0,25
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
		// sraw r10,r10,r9
		temp.u32 = ctx.r9.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
	}
loc_825733F8:
	// srawi r7,r11,10
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FF) != 0);
	ctx.r7.s64 = ctx.r11.s32 >> 10;
	// srawi r31,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	var_r31 = (uint32_t)(ctx.r11.s32 >> 6);
	// clrlwi r26,r11,26
	var_r26 = (uint32_t)(ctx.r11.u32 & 0x3F);
	// clrlwi r11,r31,28
	ctx.r11.u64 = var_r31 & 0xF;
	// mullw r10,r26,r10
	ctx.r10.s64 = int64_t((int32_t)var_r26) * int64_t(ctx.r10.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// clrlwi r9,r7,31
	ctx.r9.u64 = ctx.r7.u32 & 0x1;
	// addi r7,r10,48
	ctx.r7.s64 = ctx.r10.s64 + 48;
	// cmpwi cr6,r11,26
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// rlwinm r10,r7,3,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFF80;
	// bgt cr6,0x82573434
	if (ctx.r11.s32 <= 26) {
		// subfic r11,r11,26
		ctx.xer.ca = ctx.r11.u32 <= 26;
		ctx.r11.s64 = 26 - ctx.r11.s64;
		// sraw r10,r10,r11
		temp.u32 = ctx.r11.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
		// b 0x82573440
	} else {
	loc_82573434:
		// addi r8,r11,-26
		ctx.r8.s64 = ctx.r11.s64 + -26;
		// slw r7,r10,r8
		ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
		// clrlwi r10,r7,17
		ctx.r10.u64 = ctx.r7.u32 & 0x7FFF;
	}
loc_82573440:
	// lhz r8,18(r6)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r6.u32 + 18);
	// xori r11,r9,1
	ctx.r11.u64 = ctx.r9.u64 ^ 1;
	// neg r7,r10
	ctx.r7.s64 = static_cast<int64_t>(-ctx.r10.u64);
	// lhz r31,36(r6)
	var_r31 = (uint32_t)(PPC_LOAD_U16(ctx.r6.u32 + 36));
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// extsh r9,r8
	ctx.r9.s64 = ctx.r8.s16;
	// andc r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// and r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 & ctx.r11.u64;
	// srawi r8,r9,15
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7FFF) != 0);
	ctx.r8.s64 = ctx.r9.s32 >> 15;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// extsh r11,r31
	ctx.r11.s64 = (int16_t)var_r31;
	// extsh r31,r10
	var_r31 = (uint32_t)(ctx.r10.s16);
	// cmpwi cr6,r8,0
	// bne cr6,0x82573484
	if (ctx.r8.s32 == 0) {
		// srawi r10,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r10.s64 = ctx.r9.s32 >> 2;
		// b 0x82573490
	} else {
	loc_82573484:
		// srawi r9,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r9.s32 >> 2;
		// neg r7,r9
		ctx.r7.s64 = static_cast<int64_t>(-ctx.r9.u64);
		// clrlwi r10,r7,19
		ctx.r10.u64 = ctx.r7.u32 & 0x1FFF;
	}
loc_82573490:
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmpwi cr6,r10,0
	// subfic r7,r9,32
	ctx.xer.ca = ctx.r9.u32 <= 32;
	ctx.r7.s64 = 32 - ctx.r9.s64;
	// bne cr6,0x825734a8
	if (ctx.r10.s32 == 0) {
		// li r9,32
		ctx.r9.s64 = 32;
		// b 0x825734b0
	} else {
	loc_825734A8:
		// rlwinm r10,r10,6,0,25
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
		// sraw r9,r10,r7
		temp.u32 = ctx.r7.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r9.s64 = ctx.r10.s32 >> temp.u32;
	}
loc_825734B0:
	// srawi r26,r11,10
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FF) != 0);
	var_r26 = (uint32_t)(ctx.r11.s32 >> 10);
	// srawi r10,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 6;
	// clrlwi r11,r11,26
	ctx.r11.u64 = ctx.r11.u32 & 0x3F;
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// mullw r11,r11,r9
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// clrlwi r9,r26,31
	ctx.r9.u64 = var_r26 & 0x1;
	// addi r7,r11,48
	ctx.r7.s64 = ctx.r11.s64 + 48;
	// xor r11,r9,r8
	ctx.r11.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// cmpwi cr6,r10,26
	// rlwinm r9,r7,3,0,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFF80;
	// bgt cr6,0x825734ec
	if (ctx.r10.s32 <= 26) {
		// subfic r10,r10,26
		ctx.xer.ca = ctx.r10.u32 <= 26;
		ctx.r10.s64 = 26 - ctx.r10.s64;
		// sraw r10,r9,r10
		temp.u32 = ctx.r10.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r9.s32 < 0) & (((ctx.r9.s32 >> temp.u32) << temp.u32) != ctx.r9.s32);
		ctx.r10.s64 = ctx.r9.s32 >> temp.u32;
		// b 0x825734f8
	} else {
	loc_825734EC:
		// addi r8,r10,-26
		ctx.r8.s64 = ctx.r10.s64 + -26;
		// slw r7,r9,r8
		ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
		// clrlwi r10,r7,17
		ctx.r10.u64 = ctx.r7.u32 & 0x7FFF;
	}
loc_825734F8:
	// extsh r8,r31
	ctx.r8.s64 = (int16_t)var_r31;
	// lhz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r6.u32 + 0);
	// extsh r31,r30
	var_r31 = (uint32_t)((int16_t)var_r30);
	// extsh r7,r29
	ctx.r7.s64 = (int16_t)var_r29;
	// add r8,r8,r31
	ctx.r8.u64 = ctx.r8.u64 + var_r31;
	// extsh r31,r28
	var_r31 = (uint32_t)((int16_t)var_r28);
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// xori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 ^ 1;
	// extsh r7,r27
	ctx.r7.s64 = (int16_t)var_r27;
	// add r8,r8,r31
	ctx.r8.u64 = ctx.r8.u64 + var_r31;
	// lhz r31,42(r6)
	var_r31 = (uint32_t)(PPC_LOAD_U16(ctx.r6.u32 + 42));
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// neg r26,r10
	var_r26 = (uint32_t)(static_cast<int64_t>(-ctx.r10.u64));
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// and r7,r26,r11
	ctx.r7.u64 = var_r26 & ctx.r11.u64;
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// clrlwi r10,r7,16
	ctx.r10.u64 = ctx.r7.u32 & 0xFFFF;
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// or r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
	// srawi r7,r9,15
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7FFF) != 0);
	ctx.r7.s64 = ctx.r9.s32 >> 15;
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
	// clrlwi r10,r7,31
	ctx.r10.u64 = ctx.r7.u32 & 0x1;
	// extsh r7,r31
	ctx.r7.s64 = (int16_t)var_r31;
	// extsh r30,r11
	var_r30 = (uint32_t)(ctx.r11.s16);
	// cmpwi cr6,r10,0
	// bne cr6,0x82573568
	if (ctx.r10.s32 == 0) {
		// srawi r11,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r11.s64 = ctx.r9.s32 >> 2;
		// b 0x82573574
	} else {
	loc_82573568:
		// srawi r9,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r9.s32 >> 2;
		// neg r8,r9
		ctx.r8.s64 = static_cast<int64_t>(-ctx.r9.u64);
		// clrlwi r11,r8,19
		ctx.r11.u64 = ctx.r8.u32 & 0x1FFF;
	}
loc_82573574:
	// cntlzw r9,r11
	ctx.r9.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// cmpwi cr6,r11,0
	// subfic r8,r9,32
	ctx.xer.ca = ctx.r9.u32 <= 32;
	ctx.r8.s64 = 32 - ctx.r9.s64;
	// bne cr6,0x8257358c
	if (ctx.r11.s32 == 0) {
		// li r9,32
		ctx.r9.s64 = 32;
		// b 0x82573594
	} else {
	loc_8257358C:
		// rlwinm r11,r11,6,0,25
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
		// sraw r9,r11,r8
		temp.u32 = ctx.r8.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r11.s32 < 0) & (((ctx.r11.s32 >> temp.u32) << temp.u32) != ctx.r11.s32);
		ctx.r9.s64 = ctx.r11.s32 >> temp.u32;
	}
loc_82573594:
	// srawi r29,r7,10
	ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x3FF) != 0);
	var_r29 = (uint32_t)(ctx.r7.s32 >> 10);
	// srawi r11,r7,6
	ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r7.s32 >> 6;
	// clrlwi r7,r7,26
	ctx.r7.u64 = ctx.r7.u32 & 0x3F;
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// mullw r9,r7,r9
	ctx.r9.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r9.s32);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// clrlwi r8,r29,31
	ctx.r8.u64 = var_r29 & 0x1;
	// addi r7,r9,48
	ctx.r7.s64 = ctx.r9.s64 + 48;
	// xor r9,r8,r10
	ctx.r9.u64 = ctx.r8.u64 ^ ctx.r10.u64;
	// cmpwi cr6,r11,26
	// rlwinm r10,r7,3,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFF80;
	// bgt cr6,0x825735d0
	if (ctx.r11.s32 <= 26) {
		// subfic r11,r11,26
		ctx.xer.ca = ctx.r11.u32 <= 26;
		ctx.r11.s64 = 26 - ctx.r11.s64;
		// sraw r10,r10,r11
		temp.u32 = ctx.r11.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
		// b 0x825735dc
	} else {
	loc_825735D0:
		// addi r8,r11,-26
		ctx.r8.s64 = ctx.r11.s64 + -26;
		// slw r7,r10,r8
		ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
		// clrlwi r10,r7,17
		ctx.r10.u64 = ctx.r7.u32 & 0x7FFF;
	}
loc_825735DC:
	// xori r11,r9,1
	ctx.r11.u64 = ctx.r9.u64 ^ 1;
	// lhz r7,2(r6)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r6.u32 + 2);
	// neg r8,r10
	ctx.r8.s64 = static_cast<int64_t>(-ctx.r10.u64);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// extsh r9,r7
	ctx.r9.s64 = ctx.r7.s16;
	// lhz r7,44(r6)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r6.u32 + 44);
	// and r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 & ctx.r11.u64;
	// andc r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// extsh r11,r7
	ctx.r11.s64 = ctx.r7.s16;
	// or r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 | ctx.r10.u64;
	// srawi r10,r9,15
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x7FFF) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 15;
	// extsh r7,r8
	ctx.r7.s64 = ctx.r8.s16;
	// clrlwi r8,r10,31
	ctx.r8.u64 = ctx.r10.u32 & 0x1;
	// cmpwi cr6,r8,0
	// bne cr6,0x82573620
	if (ctx.r8.s32 == 0) {
		// srawi r10,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r10.s64 = ctx.r9.s32 >> 2;
		// b 0x8257362c
	} else {
	loc_82573620:
		// srawi r9,r9,2
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r9.s32 >> 2;
		// neg r10,r9
		ctx.r10.s64 = static_cast<int64_t>(-ctx.r9.u64);
		// clrlwi r10,r10,19
		ctx.r10.u64 = ctx.r10.u32 & 0x1FFF;
	}
loc_8257362C:
	// cntlzw r9,r10
	ctx.r9.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cmpwi cr6,r10,0
	// subfic r9,r9,32
	ctx.xer.ca = ctx.r9.u32 <= 32;
	ctx.r9.s64 = 32 - ctx.r9.s64;
	// bne cr6,0x82573644
	if (ctx.r10.s32 == 0) {
		// li r10,32
		ctx.r10.s64 = 32;
		// b 0x8257364c
	} else {
	loc_82573644:
		// rlwinm r10,r10,6,0,25
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
		// sraw r10,r10,r9
		temp.u32 = ctx.r9.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
	}
loc_8257364C:
	// srawi r29,r11,10
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3FF) != 0);
	var_r29 = (uint32_t)(ctx.r11.s32 >> 10);
	// srawi r28,r11,6
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3F) != 0);
	var_r28 = (uint32_t)(ctx.r11.s32 >> 6);
	// clrlwi r27,r11,26
	var_r27 = (uint32_t)(ctx.r11.u32 & 0x3F);
	// clrlwi r11,r28,28
	ctx.r11.u64 = var_r28 & 0xF;
	// mullw r10,r27,r10
	ctx.r10.s64 = int64_t((int32_t)var_r27) * int64_t(ctx.r10.s32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// clrlwi r9,r29,31
	ctx.r9.u64 = var_r29 & 0x1;
	// addi r10,r10,48
	ctx.r10.s64 = ctx.r10.s64 + 48;
	// cmpwi cr6,r11,26
	// xor r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 ^ ctx.r8.u64;
	// rlwinm r10,r10,3,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFF80;
	// bgt cr6,0x82573688
	if (ctx.r11.s32 <= 26) {
		// subfic r8,r11,26
		ctx.xer.ca = ctx.r11.u32 <= 26;
		ctx.r8.s64 = 26 - ctx.r11.s64;
		// sraw r10,r10,r8
		temp.u32 = ctx.r8.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
		// b 0x82573694
	} else {
	loc_82573688:
		// addi r11,r11,-26
		ctx.r11.s64 = ctx.r11.s64 + -26;
		// slw r10,r10,r11
		ctx.r10.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r11.u8 & 0x3F));
		// clrlwi r10,r10,17
		ctx.r10.u64 = ctx.r10.u32 & 0x7FFF;
	}
loc_82573694:
	// xori r11,r9,1
	ctx.r11.u64 = ctx.r9.u64 ^ 1;
	// sth r31,44(r6)
	PPC_STORE_U16(ctx.r6.u32 + 44, (uint16_t)var_r31);
	// neg r29,r10
	var_r29 = (uint32_t)(static_cast<int64_t>(-ctx.r10.u64));
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// extsh r9,r7
	ctx.r9.s64 = ctx.r7.s16;
	// and r7,r29,r11
	ctx.r7.u64 = var_r29 & ctx.r11.u64;
	// extsh r8,r30
	ctx.r8.s64 = (int16_t)var_r30;
	// andc r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 & ~ctx.r11.u64;
	// clrlwi r7,r7,16
	ctx.r7.u64 = ctx.r7.u32 & 0xFFFF;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// extsh r8,r30
	ctx.r8.s64 = (int16_t)var_r30;
	// or r11,r7,r11
	ctx.r11.u64 = ctx.r7.u64 | ctx.r11.u64;
	// srawi r23,r8,1
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x1) != 0);
	var_r23 = (uint32_t)(ctx.r8.s32 >> 1);
	// lhz r8,4(r6)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r6.u32 + 4);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + ctx.r11.u64;
	// extsh r10,r8
	ctx.r10.s64 = ctx.r8.s16;
	// extsh r7,r9
	ctx.r7.s64 = ctx.r9.s16;
	// cmpwi cr6,r10,256
	// srawi r24,r7,1
	ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x1) != 0);
	var_r24 = (uint32_t)(ctx.r7.s32 >> 1);
	// li r11,1
	ctx.r11.s64 = 1;
	// blt cr6,0x825736ec
	if (ctx.r10.s32 >= 256) {
		// li r11,0
		ctx.r11.s64 = 0;
	}
loc_825736EC:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	// beq cr6,0x82573704
	if (ctx.r11.u32 != 0) {
		// extsh r10,r8
		ctx.r10.s64 = ctx.r8.s16;
		// srawi r9,r10,2
		ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r10.s32 >> 2;
		// b 0x82573708
	} else {
	loc_82573704:
		// li r9,64
		ctx.r9.s64 = 64;
	}
loc_82573708:
	// lhz r26,50(r6)
	var_r26 = (uint32_t)(PPC_LOAD_U16(ctx.r6.u32 + 50));
	// lhz r7,52(r6)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r6.u32 + 52);
	// subf r10,r26,r7
	ctx.r10.s64 = ctx.r7.s64 - (int64_t)(int32_t)var_r26;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r11,0
	// bge cr6,0x8257372c
	if (ctx.r11.s32 < 0) {
		// neg r8,r11
		ctx.r8.s64 = static_cast<int64_t>(-ctx.r11.u64);
		// extsh r10,r8
		ctx.r10.s64 = ctx.r8.s16;
	}
loc_8257372C:
	// extsh r7,r10
	ctx.r7.s64 = ctx.r10.s16;
	// extsh r10,r9
	ctx.r10.s64 = ctx.r9.s16;
	// cmpwi cr6,r11,0
	// mullw r9,r7,r10
	ctx.r9.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r10.s32);
	// srawi r11,r9,6
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3F) != 0);
	ctx.r11.s64 = ctx.r9.s32 >> 6;
	// bge cr6,0x82573750
	if (ctx.r11.s32 < 0) {
		// subf r7,r11,r26
		ctx.r7.s64 = (int64_t)(int32_t)var_r26 - ctx.r11.s64;
		// extsh r29,r7
		var_r29 = (uint32_t)(ctx.r7.s16);
		// b 0x82573758
	} else {
	loc_82573750:
		// add r11,r26,r11
		ctx.r11.u64 = var_r26 + ctx.r11.u64;
		// extsh r29,r11
		var_r29 = (uint32_t)(ctx.r11.s16);
	}
loc_82573758:
	// cmpwi cr6,r3,0
	// beq cr6,0x82573768
	if (ctx.r3.s32 != 0) {
		// mr r11,r4
		ctx.r11.u64 = ctx.r4.u64;
		// b 0x825739f4
	} else {
	loc_82573768:
		// subf r8,r24,r4
		ctx.r8.s64 = ctx.r4.s64 - (int64_t)(int32_t)var_r24;
		// extsh r11,r8
		ctx.r11.s64 = ctx.r8.s16;
		// mr r7,r11
		ctx.r7.u64 = ctx.r11.u64;
		// cmpwi cr6,r7,0
		// bge cr6,0x82573788
		if (ctx.r7.s32 < 0) {
			// neg r4,r7
			ctx.r4.s64 = static_cast<int64_t>(-ctx.r7.u64);
			// extsh r8,r4
			ctx.r8.s64 = ctx.r4.s16;
			// b 0x8257378c
		} else {
		loc_82573788:
			// mr r8,r11
			ctx.r8.u64 = ctx.r11.u64;
		}
	loc_8257378C:
		// extsh r9,r8
		ctx.r9.s64 = ctx.r8.s16;
		// ori r11,r9,1
		ctx.r11.u64 = ctx.r9.u64 | 1;
		// extsh r10,r11
		ctx.r10.s64 = ctx.r11.s16;
		// mr r11,r10
		ctx.r11.u64 = ctx.r10.u64;
		// rlwinm r10,r10,17,31,31
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
		// rlwinm r4,r11,18,31,31
		ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x1;
		// xor r4,r4,r10
		ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
		// cmplwi cr6,r4,0
		// beq cr6,0x825737b8
		if (ctx.r4.u32 != 0) {
			// li r11,15
			ctx.r11.s64 = 15;
			// b 0x82573908
		} else {
		loc_825737B8:
			// rlwinm r4,r11,19,31,31
			ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 19) & 0x1;
			// xor r4,r4,r10
			ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
			// cmplwi cr6,r4,0
			// beq cr6,0x825737d0
			if (ctx.r4.u32 != 0) {
				// li r11,14
				ctx.r11.s64 = 14;
				// b 0x82573908
			} else {
			loc_825737D0:
				// rlwinm r4,r11,20,31,31
				ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 20) & 0x1;
				// xor r4,r4,r10
				ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
				// cmplwi cr6,r4,0
				// beq cr6,0x825737e8
				if (ctx.r4.u32 != 0) {
					// li r11,13
					ctx.r11.s64 = 13;
					// b 0x82573908
				} else {
				loc_825737E8:
					// rlwinm r4,r11,21,31,31
					ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1;
					// xor r4,r4,r10
					ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
					// cmplwi cr6,r4,0
					// beq cr6,0x82573800
					if (ctx.r4.u32 != 0) {
						// li r11,12
						ctx.r11.s64 = 12;
						// b 0x82573908
					} else {
					loc_82573800:
						// rlwinm r4,r11,22,31,31
						ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 22) & 0x1;
						// xor r4,r4,r10
						ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
						// cmplwi cr6,r4,0
						// beq cr6,0x82573818
						if (ctx.r4.u32 != 0) {
							// li r11,11
							ctx.r11.s64 = 11;
							// b 0x82573908
						} else {
						loc_82573818:
							// rlwinm r4,r11,23,31,31
							ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 23) & 0x1;
							// xor r4,r4,r10
							ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
							// cmplwi cr6,r4,0
							// beq cr6,0x82573830
							if (ctx.r4.u32 != 0) {
								// li r11,10
								ctx.r11.s64 = 10;
								// b 0x82573908
							} else {
							loc_82573830:
								// rlwinm r4,r11,24,31,31
								ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0x1;
								// xor r4,r4,r10
								ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
								// cmplwi cr6,r4,0
								// beq cr6,0x82573848
								if (ctx.r4.u32 != 0) {
									// li r11,9
									ctx.r11.s64 = 9;
									// b 0x82573908
								} else {
								loc_82573848:
									// rlwinm r4,r11,25,31,31
									ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 25) & 0x1;
									// xor r4,r4,r10
									ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
									// cmplwi cr6,r4,0
									// beq cr6,0x82573860
									if (ctx.r4.u32 != 0) {
										// li r11,8
										ctx.r11.s64 = 8;
										// b 0x82573908
									} else {
									loc_82573860:
										// rlwinm r4,r11,26,31,31
										ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x1;
										// xor r4,r4,r10
										ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
										// cmplwi cr6,r4,0
										// beq cr6,0x82573878
										if (ctx.r4.u32 != 0) {
											// li r11,7
											ctx.r11.s64 = 7;
											// b 0x82573908
										} else {
										loc_82573878:
											// rlwinm r4,r11,27,31,31
											ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
											// xor r4,r4,r10
											ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
											// cmplwi cr6,r4,0
											// beq cr6,0x82573890
											if (ctx.r4.u32 != 0) {
												// li r11,6
												ctx.r11.s64 = 6;
												// b 0x82573908
											} else {
											loc_82573890:
												// rlwinm r4,r11,28,31,31
												ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0x1;
												// xor r4,r4,r10
												ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
												// cmplwi cr6,r4,0
												// beq cr6,0x825738a8
												if (ctx.r4.u32 != 0) {
													// li r11,5
													ctx.r11.s64 = 5;
													// b 0x82573908
												} else {
												loc_825738A8:
													// rlwinm r4,r11,29,31,31
													ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1;
													// xor r4,r4,r10
													ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
													// cmplwi cr6,r4,0
													// beq cr6,0x825738c0
													if (ctx.r4.u32 != 0) {
														// li r11,4
														ctx.r11.s64 = 4;
														// b 0x82573908
													} else {
													loc_825738C0:
														// rlwinm r4,r11,30,31,31
														ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x1;
														// xor r4,r4,r10
														ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
														// cmplwi cr6,r4,0
														// beq cr6,0x825738d8
														if (ctx.r4.u32 == 0) goto loc_825738D8;
														// li r11,3
														ctx.r11.s64 = 3;
														// b 0x82573908
														goto loc_82573908;
													loc_825738D8:
														// rlwinm r4,r11,31,31,31
														ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
														// xor r4,r4,r10
														ctx.r4.u64 = ctx.r4.u64 ^ ctx.r10.u64;
														// cmplwi cr6,r4,0
														// beq cr6,0x825738f0
														if (ctx.r4.u32 == 0) goto loc_825738F0;
														// li r11,2
														ctx.r11.s64 = 2;
														// b 0x82573908
														goto loc_82573908;
													loc_825738F0:
														// clrlwi r11,r11,31
														ctx.r11.u64 = ctx.r11.u32 & 0x1;
														// xor r10,r11,r10
														ctx.r10.u64 = ctx.r11.u64 ^ ctx.r10.u64;
														// li r11,1
														ctx.r11.s64 = 1;
														// cmplwi cr6,r10,0
														// bne cr6,0x82573908
														if (ctx.r10.u32 != 0) goto loc_82573908;
														// li r11,0
														ctx.r11.s64 = 0;
													}
												}
											}
										}
									}
								}
							}
						}
					}
				}
			}
		}
	loc_82573908:
		// addi r4,r11,-1
		ctx.r4.s64 = ctx.r11.s64 + -1;
		// extsh r10,r4
		ctx.r10.s64 = ctx.r4.s16;
		// subfic r11,r10,7
		ctx.xer.ca = ctx.r10.u32 <= 7;
		ctx.r11.s64 = 7 - ctx.r10.s64;
		// extsh r11,r11
		ctx.r11.s64 = ctx.r11.s16;
		// cmpwi cr6,r11,0
		// bge cr6,0x82573934
		if (ctx.r11.s32 < 0) {
			// neg r9,r11
			ctx.r9.s64 = static_cast<int64_t>(-ctx.r11.u64);
			// extsh r11,r8
			ctx.r11.s64 = ctx.r8.s16;
			// extsh r4,r9
			ctx.r4.s64 = ctx.r9.s16;
			// sraw r11,r11,r4
			temp.u32 = ctx.r4.u32 & 0x3F;
			if (temp.u32 > 0x1F) temp.u32 = 0x1F;
			ctx.xer.ca = (ctx.r11.s32 < 0) & (((ctx.r11.s32 >> temp.u32) << temp.u32) != ctx.r11.s32);
			ctx.r11.s64 = ctx.r11.s32 >> temp.u32;
			// b 0x8257393c
		} else {
		loc_82573934:
			// slw r9,r9,r11
			ctx.r9.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r11.u8 & 0x3F));
			// extsh r11,r9
			ctx.r11.s64 = ctx.r9.s16;
		}
	loc_8257393C:
		// rlwinm r8,r10,7,0,24
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0xFFFFFF80;
		// extsh r4,r29
		ctx.r4.s64 = (int16_t)var_r29;
		// extsh r10,r8
		ctx.r10.s64 = ctx.r8.s16;
		// srawi r9,r4,2
		ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x3) != 0);
		ctx.r9.s64 = ctx.r4.s32 >> 2;
		// mr r8,r11
		ctx.r8.u64 = ctx.r11.u64;
		// subf r11,r9,r10
		ctx.r11.s64 = ctx.r10.s64 - ctx.r9.s64;
		// clrlwi r10,r8,25
		ctx.r10.u64 = ctx.r8.u32 & 0x7F;
		// add r11,r11,r10
		ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
		// extsh r11,r11
		ctx.r11.s64 = ctx.r11.s16;
		// cmpwi cr6,r11,-124
		// bge cr6,0x82573970
		if (ctx.r11.s32 < -124) {
			// li r11,15
			ctx.r11.s64 = 15;
			// b 0x825739d8
		} else {
		loc_82573970:
			// cmpwi cr6,r11,80
			// blt cr6,0x825739d4
			if (ctx.r11.s32 >= 80) {
				// cmpwi cr6,r11,178
				// bge cr6,0x82573988
				if (ctx.r11.s32 < 178) {
					// li r11,2
					ctx.r11.s64 = 2;
					// b 0x825739d8
					goto loc_825739D8;
				}
			loc_82573988:
				// cmpwi cr6,r11,246
				// bge cr6,0x82573998
				if (ctx.r11.s32 < 246) {
					// li r11,3
					ctx.r11.s64 = 3;
					// b 0x825739d8
					goto loc_825739D8;
				}
			loc_82573998:
				// cmpwi cr6,r11,300
				// bge cr6,0x825739a8
				if (ctx.r11.s32 < 300) {
					// li r11,4
					ctx.r11.s64 = 4;
					// b 0x825739d8
					goto loc_825739D8;
				}
			loc_825739A8:
				// cmpwi cr6,r11,349
				// bge cr6,0x825739b8
				if (ctx.r11.s32 < 349) {
					// li r11,5
					ctx.r11.s64 = 5;
					// b 0x825739d8
					goto loc_825739D8;
				}
			loc_825739B8:
				// cmpwi cr6,r11,400
				// bge cr6,0x825739c8
				if (ctx.r11.s32 < 400) {
					// li r11,6
					ctx.r11.s64 = 6;
					// b 0x825739d8
					goto loc_825739D8;
				}
			loc_825739C8:
				// cmpwi cr6,r11,2048
				// li r11,7
				ctx.r11.s64 = 7;
				// blt cr6,0x825739d8
				if (ctx.r11.s32 < 2048) goto loc_825739D8;
			}
		loc_825739D4:
			// li r11,1
			ctx.r11.s64 = 1;
		}
	loc_825739D8:
		// cmpwi cr6,r7,0
		// bge cr6,0x825739f4
		if (ctx.r7.s32 >= 0) goto loc_825739F4;
		// extsh r10,r11
		ctx.r10.s64 = ctx.r11.s16;
		// cmpwi cr6,r10,15
		// beq cr6,0x825739f4
		if (ctx.r10.s32 == 15) goto loc_825739F4;
		// not r7,r10
		ctx.r7.u64 = ~ctx.r10.u64;
		// clrlwi r11,r7,28
		ctx.r11.u64 = ctx.r7.u32 & 0xF;
	}
loc_825739F4:
	// extsh r27,r11
	var_r27 = (uint32_t)(ctx.r11.s16);
	// srawi. r28,r27,3
	ctx.xer.ca = ((int32_t)var_r27 < 0) & ((var_r27 & 0x7) != 0);
	var_r28 = (uint32_t)((int32_t)var_r27 >> 3);
	// beq 0x82573a08
	if ((int32_t)var_r28 != 0) {
		// xori r4,r27,15
		ctx.r4.u64 = var_r27 ^ 15;
		// extsh r11,r4
		ctx.r11.s64 = ctx.r4.s16;
	}
loc_82573A08:
	// extsh r10,r11
	ctx.r10.s64 = ctx.r11.s16;
	// lis r11,-32164
	// rlwinm r22,r10,1,0,30
	var_r22 = (uint32_t)(__builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE);
	// addi r11,r11,9896
	ctx.r11.s64 = ctx.r11.s64 + 9896;
	// extsh r9,r29
	ctx.r9.s64 = (int16_t)var_r29;
	// srawi r10,r9,2
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 2;
	// lhzx r11,r22,r11
	ctx.r11.u64 = PPC_LOAD_U16(var_r22 + ctx.r11.u32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// extsh r8,r11
	ctx.r8.s64 = ctx.r11.s16;
	// extsh r9,r11
	ctx.r9.s64 = ctx.r11.s16;
	// srawi r11,r8,7
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x7F) != 0);
	ctx.r11.s64 = ctx.r8.s32 >> 7;
	// clrlwi r10,r9,25
	ctx.r10.u64 = ctx.r9.u32 & 0x7F;
	// clrlwi r11,r11,28
	ctx.r11.u64 = ctx.r11.u32 & 0xF;
	// addi r7,r10,128
	ctx.r7.s64 = ctx.r10.s64 + 128;
	// addi r11,r11,-7
	ctx.r11.s64 = ctx.r11.s64 + -7;
	// extsh r10,r7
	ctx.r10.s64 = ctx.r7.s16;
	// extsh r11,r11
	ctx.r11.s64 = ctx.r11.s16;
	// cmpwi cr6,r11,0
	// bge cr6,0x82573a68
	if (ctx.r11.s32 < 0) {
		// neg r8,r11
		ctx.r8.s64 = static_cast<int64_t>(-ctx.r11.u64);
		// extsh r4,r10
		ctx.r4.s64 = ctx.r10.s16;
		// extsh r7,r8
		ctx.r7.s64 = ctx.r8.s16;
		// sraw r11,r4,r7
		temp.u32 = ctx.r7.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r4.s32 < 0) & (((ctx.r4.s32 >> temp.u32) << temp.u32) != ctx.r4.s32);
		ctx.r11.s64 = ctx.r4.s32 >> temp.u32;
		// b 0x82573a74
	} else {
	loc_82573A68:
		// extsh r10,r10
		ctx.r10.s64 = ctx.r10.s16;
		// slw r8,r10,r11
		ctx.r8.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r11.u8 & 0x3F));
		// extsh r11,r8
		ctx.r11.s64 = ctx.r8.s16;
	}
loc_82573A74:
	// cmpwi cr6,r9,0
	// li r31,0
	var_r31 = 0;
	// blt cr6,0x82573a84
	if (ctx.r9.s32 >= 0) {
		// mr r31,r11
		var_r31 = ctx.r11.u32;
	}
loc_82573A84:
	// extsh r7,r26
	ctx.r7.s64 = (int16_t)var_r26;
	// extsh r4,r26
	ctx.r4.s64 = (int16_t)var_r26;
	// srawi r11,r7,9
	ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x1FF) != 0);
	ctx.r11.s64 = ctx.r7.s32 >> 9;
	// srawi r10,r4,4
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0xF) != 0);
	ctx.r10.s64 = ctx.r4.s32 >> 4;
	// extsh r11,r11
	ctx.r11.s64 = ctx.r11.s16;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// cmpwi cr6,r11,0
	// addi r9,r10,32
	ctx.r9.s64 = ctx.r10.s64 + 32;
	// extsh r10,r9
	ctx.r10.s64 = ctx.r9.s16;
	// bge cr6,0x82573ac0
	if (ctx.r11.s32 < 0) {
		// neg r8,r11
		ctx.r8.s64 = static_cast<int64_t>(-ctx.r11.u64);
		// extsh r4,r10
		ctx.r4.s64 = ctx.r10.s16;
		// extsh r7,r8
		ctx.r7.s64 = ctx.r8.s16;
		// sraw r10,r4,r7
		temp.u32 = ctx.r7.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r4.s32 < 0) & (((ctx.r4.s32 >> temp.u32) << temp.u32) != ctx.r4.s32);
		ctx.r10.s64 = ctx.r4.s32 >> temp.u32;
		// b 0x82573acc
	} else {
	loc_82573AC0:
		// extsh r10,r10
		ctx.r10.s64 = ctx.r10.s16;
		// slw r9,r10,r11
		ctx.r9.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r11.u8 & 0x3F));
		// extsh r10,r9
		ctx.r10.s64 = ctx.r9.s16;
	}
loc_82573ACC:
	// cmpwi cr6,r11,8
	// li r11,15872
	ctx.r11.s64 = 15872;
	// bgt cr6,0x82573adc
	if (ctx.r11.s32 <= 8) {
		// mr r11,r10
		ctx.r11.u64 = ctx.r10.u64;
	}
loc_82573ADC:
	// extsh r11,r11
	ctx.r11.s64 = ctx.r11.s16;
	// extsh r30,r31
	var_r30 = (uint32_t)((int16_t)var_r31);
	// srawi r10,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 1;
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srawi r7,r8,1
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x1) != 0);
	ctx.r7.s64 = ctx.r8.s32 >> 1;
	// extsh r11,r7
	ctx.r11.s64 = ctx.r7.s16;
	// cmpw cr6,r30,r11
	// ble cr6,0x82573b0c
	if ((int32_t)var_r30 > ctx.r11.s32) {
		// lhz r10,46(r6)
		ctx.r10.u64 = PPC_LOAD_U16(ctx.r6.u32 + 46);
		// li r25,-1
		var_r25 = (uint32_t)(-1);
		// cmplwi cr6,r10,1
		// beq cr6,0x82573b10
		if (ctx.r10.u32 == 1) goto loc_82573B10;
	}
loc_82573B0C:
	// li r25,0
	var_r25 = 0;
loc_82573B10:
	// lis r11,-32164
	// extsh r21,r29
	var_r21 = (uint32_t)((int16_t)var_r29);
	// addi r11,r11,9944
	ctx.r11.s64 = ctx.r11.s64 + 9944;
	// lhzx r9,r22,r11
	ctx.r9.u64 = PPC_LOAD_U16(var_r22 + ctx.r11.u32);
	// extsh r8,r9
	ctx.r8.s64 = ctx.r9.s16;
	// rlwinm r7,r8,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r4,r21,r7
	ctx.r4.s64 = ctx.r7.s64 - (int64_t)(int32_t)var_r21;
	// srawi r11,r4,5
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x1F) != 0);
	ctx.r11.s64 = ctx.r4.s32 >> 5;
	// add r11,r21,r11
	ctx.r11.u64 = var_r21 + ctx.r11.u64;
	// extsh r9,r11
	ctx.r9.s64 = ctx.r11.s16;
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
	// cmpwi cr6,r11,544
	// bge cr6,0x82573b4c
	if (ctx.r11.s32 < 544) {
		// li r9,544
		ctx.r9.s64 = 544;
		// b 0x82573b58
	} else {
	loc_82573B4C:
		// cmpwi cr6,r11,5120
		// blt cr6,0x82573b58
		if (ctx.r11.s32 < 5120) goto loc_82573B58;
		// li r9,5120
		ctx.r9.s64 = 5120;
	}
loc_82573B58:
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// sth r9,52(r6)
	PPC_STORE_U16(ctx.r6.u32 + 52, ctx.r9.u16);
	// lhz r9,48(r6)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r6.u32 + 48);
	// extsh r10,r26
	ctx.r10.s64 = (int16_t)var_r26;
	// rlwinm r8,r30,18,31,31
	ctx.r8.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 18) & 0x1;
	// rlwinm r11,r31,17,31,31
	ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 17) & 0x1;
	// rlwinm r10,r10,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// xor r4,r8,r11
	ctx.r4.u64 = ctx.r8.u64 ^ ctx.r11.u64;
	// add r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// neg r4,r8
	ctx.r4.s64 = static_cast<int64_t>(-ctx.r8.u64);
	// srawi r8,r4,6
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x3F) != 0);
	ctx.r8.s64 = ctx.r4.s32 >> 6;
	// add r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 + ctx.r8.u64;
	// extsh r8,r8
	ctx.r8.s64 = ctx.r8.s16;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// clrlwi r4,r10,26
	ctx.r4.u64 = ctx.r10.u32 & 0x3F;
	// srawi r10,r10,6
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3F) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 6;
	// sth r4,48(r6)
	PPC_STORE_U16(ctx.r6.u32 + 48, ctx.r4.u16);
	// sth r10,50(r6)
	PPC_STORE_U16(ctx.r6.u32 + 50, ctx.r10.u16);
	// beq cr6,0x82573bb8
	if (!(ctx.cr6.eq)) {
		// li r11,15
		ctx.r11.s64 = 15;
		// b 0x82573d08
	} else {
	loc_82573BB8:
		// rlwinm r8,r30,19,31,31
		ctx.r8.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 19) & 0x1;
		// xor r7,r8,r11
		ctx.r7.u64 = ctx.r8.u64 ^ ctx.r11.u64;
		// cmplwi cr6,r7,0
		// beq cr6,0x82573bd0
		if (ctx.r7.u32 != 0) {
			// li r11,14
			ctx.r11.s64 = 14;
			// b 0x82573d08
		} else {
		loc_82573BD0:
			// rlwinm r4,r30,20,31,31
			ctx.r4.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 20) & 0x1;
			// xor r10,r4,r11
			ctx.r10.u64 = ctx.r4.u64 ^ ctx.r11.u64;
			// cmplwi cr6,r10,0
			// beq cr6,0x82573be8
			if (ctx.r10.u32 != 0) {
				// li r11,13
				ctx.r11.s64 = 13;
				// b 0x82573d08
			} else {
			loc_82573BE8:
				// rlwinm r9,r30,21,31,31
				ctx.r9.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 21) & 0x1;
				// xor r8,r9,r11
				ctx.r8.u64 = ctx.r9.u64 ^ ctx.r11.u64;
				// cmplwi cr6,r8,0
				// beq cr6,0x82573c00
				if (ctx.r8.u32 != 0) {
					// li r11,12
					ctx.r11.s64 = 12;
					// b 0x82573d08
				} else {
				loc_82573C00:
					// rlwinm r7,r30,22,31,31
					ctx.r7.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 22) & 0x1;
					// xor r4,r7,r11
					ctx.r4.u64 = ctx.r7.u64 ^ ctx.r11.u64;
					// cmplwi cr6,r4,0
					// beq cr6,0x82573c18
					if (ctx.r4.u32 != 0) {
						// li r11,11
						ctx.r11.s64 = 11;
						// b 0x82573d08
					} else {
					loc_82573C18:
						// rlwinm r10,r30,23,31,31
						ctx.r10.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 23) & 0x1;
						// xor r9,r10,r11
						ctx.r9.u64 = ctx.r10.u64 ^ ctx.r11.u64;
						// cmplwi cr6,r9,0
						// beq cr6,0x82573c30
						if (ctx.r9.u32 != 0) {
							// li r11,10
							ctx.r11.s64 = 10;
							// b 0x82573d08
						} else {
						loc_82573C30:
							// rlwinm r8,r30,24,31,31
							ctx.r8.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 24) & 0x1;
							// xor r7,r8,r11
							ctx.r7.u64 = ctx.r8.u64 ^ ctx.r11.u64;
							// cmplwi cr6,r7,0
							// beq cr6,0x82573c48
							if (ctx.r7.u32 != 0) {
								// li r11,9
								ctx.r11.s64 = 9;
								// b 0x82573d08
							} else {
							loc_82573C48:
								// rlwinm r4,r30,25,31,31
								ctx.r4.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 25) & 0x1;
								// xor r10,r4,r11
								ctx.r10.u64 = ctx.r4.u64 ^ ctx.r11.u64;
								// cmplwi cr6,r10,0
								// beq cr6,0x82573c60
								if (ctx.r10.u32 != 0) {
									// li r11,8
									ctx.r11.s64 = 8;
									// b 0x82573d08
								} else {
								loc_82573C60:
									// rlwinm r9,r30,26,31,31
									ctx.r9.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 26) & 0x1;
									// xor r8,r9,r11
									ctx.r8.u64 = ctx.r9.u64 ^ ctx.r11.u64;
									// cmplwi cr6,r8,0
									// beq cr6,0x82573c78
									if (ctx.r8.u32 != 0) {
										// li r11,7
										ctx.r11.s64 = 7;
										// b 0x82573d08
									} else {
									loc_82573C78:
										// rlwinm r7,r30,27,31,31
										ctx.r7.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 27) & 0x1;
										// xor r4,r7,r11
										ctx.r4.u64 = ctx.r7.u64 ^ ctx.r11.u64;
										// cmplwi cr6,r4,0
										// beq cr6,0x82573c90
										if (ctx.r4.u32 != 0) {
											// li r11,6
											ctx.r11.s64 = 6;
											// b 0x82573d08
										} else {
										loc_82573C90:
											// rlwinm r10,r30,28,31,31
											ctx.r10.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 28) & 0x1;
											// xor r9,r10,r11
											ctx.r9.u64 = ctx.r10.u64 ^ ctx.r11.u64;
											// cmplwi cr6,r9,0
											// beq cr6,0x82573ca8
											if (ctx.r9.u32 != 0) {
												// li r11,5
												ctx.r11.s64 = 5;
												// b 0x82573d08
											} else {
											loc_82573CA8:
												// rlwinm r8,r30,29,31,31
												ctx.r8.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 29) & 0x1;
												// xor r7,r8,r11
												ctx.r7.u64 = ctx.r8.u64 ^ ctx.r11.u64;
												// cmplwi cr6,r7,0
												// beq cr6,0x82573cc0
												if (ctx.r7.u32 != 0) {
													// li r11,4
													ctx.r11.s64 = 4;
													// b 0x82573d08
												} else {
												loc_82573CC0:
													// rlwinm r4,r30,30,31,31
													ctx.r4.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 30) & 0x1;
													// xor r10,r4,r11
													ctx.r10.u64 = ctx.r4.u64 ^ ctx.r11.u64;
													// cmplwi cr6,r10,0
													// beq cr6,0x82573cd8
													if (ctx.r10.u32 != 0) {
														// li r11,3
														ctx.r11.s64 = 3;
														// b 0x82573d08
													} else {
													loc_82573CD8:
														// rlwinm r9,r30,31,31,31
														ctx.r9.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 31) & 0x1;
														// xor r8,r9,r11
														ctx.r8.u64 = ctx.r9.u64 ^ ctx.r11.u64;
														// cmplwi cr6,r8,0
														// beq cr6,0x82573cf0
														if (ctx.r8.u32 == 0) goto loc_82573CF0;
														// li r11,2
														ctx.r11.s64 = 2;
														// b 0x82573d08
														goto loc_82573D08;
													loc_82573CF0:
														// clrlwi r7,r30,31
														ctx.r7.u64 = var_r30 & 0x1;
														// xor r4,r7,r11
														ctx.r4.u64 = ctx.r7.u64 ^ ctx.r11.u64;
														// li r11,1
														ctx.r11.s64 = 1;
														// cmplwi cr6,r4,0
														// bne cr6,0x82573d08
														if (ctx.r4.u32 != 0) goto loc_82573D08;
														// li r11,0
														ctx.r11.s64 = 0;
													}
												}
											}
										}
									}
								}
							}
						}
					}
				}
			}
		}
	}
loc_82573D08:
	// extsh r4,r11
	ctx.r4.s64 = ctx.r11.s16;
	// subfic r11,r4,6
	ctx.xer.ca = ctx.r4.u32 <= 6;
	ctx.r11.s64 = 6 - ctx.r4.s64;
	// extsh r11,r11
	ctx.r11.s64 = ctx.r11.s16;
	// cmpwi cr6,r11,0
	// bge cr6,0x82573d30
	if (ctx.r11.s32 < 0) {
		// neg r10,r11
		ctx.r10.s64 = static_cast<int64_t>(-ctx.r11.u64);
		// extsh r8,r31
		ctx.r8.s64 = (int16_t)var_r31;
		// extsh r9,r10
		ctx.r9.s64 = ctx.r10.s16;
		// sraw r11,r8,r9
		temp.u32 = ctx.r9.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r8.s32 < 0) & (((ctx.r8.s32 >> temp.u32) << temp.u32) != ctx.r8.s32);
		ctx.r11.s64 = ctx.r8.s32 >> temp.u32;
		// b 0x82573d38
	} else {
	loc_82573D30:
		// slw r7,r30,r11
		ctx.r7.u64 = ctx.r11.u8 & 0x20 ? 0 : (var_r30 << (ctx.r11.u8 & 0x3F));
		// extsh r11,r7
		ctx.r11.s64 = ctx.r7.s16;
	}
loc_82573D38:
	// ori r10,r11,32
	ctx.r10.u64 = ctx.r11.u64 | 32;
	// cmpwi cr6,r28,0
	// extsh r9,r10
	ctx.r9.s64 = ctx.r10.s16;
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x82573d50
	if ((int32_t)var_r28 == 0) {
		// li r11,0
		ctx.r11.s64 = 0;
	}
loc_82573D50:
	// clrlwi r8,r11,24
	ctx.r8.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r8,0
	// beq cr6,0x82573d6c
	if (ctx.r8.u32 != 0) {
		// subf r8,r30,r23
		ctx.r8.s64 = (int64_t)(int32_t)var_r23 - (int64_t)(int32_t)var_r30;
		// subf r7,r30,r24
		ctx.r7.s64 = (int64_t)(int32_t)var_r24 - (int64_t)(int32_t)var_r30;
		// li r10,-1024
		// b 0x82573d78
	} else {
	loc_82573D6C:
		// add r8,r23,r30
		ctx.r8.u64 = var_r23 + var_r30;
		// add r7,r24,r30
		ctx.r7.u64 = var_r24 + var_r30;
		// li r10,0
		ctx.r10.s64 = 0;
	}
loc_82573D78:
	// extsh r31,r10
	var_r31 = (uint32_t)(ctx.r10.s16);
	// rlwinm r10,r4,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 6) & 0xFFFFFFC0;
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// extsh r29,r8
	var_r29 = (uint32_t)(ctx.r8.s16);
	// extsh r8,r7
	ctx.r8.s64 = ctx.r7.s16;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// extsh r7,r8
	ctx.r7.s64 = ctx.r8.s16;
	// add r4,r10,r31
	ctx.r4.u64 = ctx.r10.u64 + var_r31;
	// addi r10,r7,-8191
	ctx.r10.s64 = ctx.r7.s64 + -8191;
	// extsh r28,r4
	var_r28 = (uint32_t)(ctx.r4.s16);
	// srawi r10,r10,16
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFFFF) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 16;
	// xori r11,r3,1
	ctx.r11.u64 = ctx.r3.u64 ^ 1;
	// not r9,r10
	ctx.r9.u64 = ~ctx.r10.u64;
	// and r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 & ctx.r7.u64;
	// clrlwi r4,r9,19
	ctx.r4.u64 = ctx.r9.u32 & 0x1FFF;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// or r10,r4,r10
	ctx.r10.u64 = ctx.r4.u64 | ctx.r10.u64;
	// andc r3,r27,r11
	ctx.r3.u64 = var_r27 & ~ctx.r11.u64;
	// addi r9,r10,8192
	ctx.r9.s64 = ctx.r10.s64 + 8192;
	// cmpwi cr6,r7,0
	// srawi r9,r9,16
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0xFFFF) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 16;
	// rlwinm r4,r9,0,0,18
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFE000;
	// andc r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r9.u64;
	// or r9,r10,r4
	ctx.r9.u64 = ctx.r10.u64 | ctx.r4.u64;
	// and r4,r9,r11
	ctx.r4.u64 = ctx.r9.u64 & ctx.r11.u64;
	// or r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 | ctx.r3.u64;
	// sth r3,0(r5)
	PPC_STORE_U16(ctx.r5.u32 + 0, ctx.r3.u16);
	// bge cr6,0x82573df0
	if (ctx.r7.s32 < 0) {
		// neg r10,r7
		ctx.r10.s64 = static_cast<int64_t>(-ctx.r7.u64);
		// extsh r8,r10
		ctx.r8.s64 = ctx.r10.s16;
	}
loc_82573DF0:
	// extsh r10,r8
	ctx.r10.s64 = ctx.r8.s16;
	// rlwinm r11,r8,17,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 17) & 0x1;
	// rlwinm r9,r10,18,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x1;
	// xor r5,r9,r11
	ctx.r5.u64 = ctx.r9.u64 ^ ctx.r11.u64;
	// cmplwi cr6,r5,0
	// beq cr6,0x82573e10
	if (ctx.r5.u32 != 0) {
		// li r11,15
		ctx.r11.s64 = 15;
		// b 0x82573f60
	} else {
	loc_82573E10:
		// rlwinm r4,r10,19,31,31
		ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0x1;
		// xor r3,r4,r11
		ctx.r3.u64 = ctx.r4.u64 ^ ctx.r11.u64;
		// cmplwi cr6,r3,0
		// beq cr6,0x82573e28
		if (ctx.r3.u32 != 0) {
			// li r11,14
			ctx.r11.s64 = 14;
			// b 0x82573f60
		} else {
		loc_82573E28:
			// rlwinm r9,r10,20,31,31
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x1;
			// xor r5,r9,r11
			ctx.r5.u64 = ctx.r9.u64 ^ ctx.r11.u64;
			// cmplwi cr6,r5,0
			// beq cr6,0x82573e40
			if (ctx.r5.u32 != 0) {
				// li r11,13
				ctx.r11.s64 = 13;
				// b 0x82573f60
			} else {
			loc_82573E40:
				// rlwinm r4,r10,21,31,31
				ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 21) & 0x1;
				// xor r3,r4,r11
				ctx.r3.u64 = ctx.r4.u64 ^ ctx.r11.u64;
				// cmplwi cr6,r3,0
				// beq cr6,0x82573e58
				if (ctx.r3.u32 != 0) {
					// li r11,12
					ctx.r11.s64 = 12;
					// b 0x82573f60
				} else {
				loc_82573E58:
					// rlwinm r9,r10,22,31,31
					ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 22) & 0x1;
					// xor r5,r9,r11
					ctx.r5.u64 = ctx.r9.u64 ^ ctx.r11.u64;
					// cmplwi cr6,r5,0
					// beq cr6,0x82573e70
					if (ctx.r5.u32 != 0) {
						// li r11,11
						ctx.r11.s64 = 11;
						// b 0x82573f60
					} else {
					loc_82573E70:
						// rlwinm r4,r10,23,31,31
						ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x1;
						// xor r3,r4,r11
						ctx.r3.u64 = ctx.r4.u64 ^ ctx.r11.u64;
						// cmplwi cr6,r3,0
						// beq cr6,0x82573e88
						if (ctx.r3.u32 != 0) {
							// li r11,10
							ctx.r11.s64 = 10;
							// b 0x82573f60
						} else {
						loc_82573E88:
							// rlwinm r9,r10,24,31,31
							ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x1;
							// xor r5,r9,r11
							ctx.r5.u64 = ctx.r9.u64 ^ ctx.r11.u64;
							// cmplwi cr6,r5,0
							// beq cr6,0x82573ea0
							if (ctx.r5.u32 != 0) {
								// li r11,9
								ctx.r11.s64 = 9;
								// b 0x82573f60
							} else {
							loc_82573EA0:
								// rlwinm r4,r10,25,31,31
								ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x1;
								// xor r3,r4,r11
								ctx.r3.u64 = ctx.r4.u64 ^ ctx.r11.u64;
								// cmplwi cr6,r3,0
								// beq cr6,0x82573eb8
								if (ctx.r3.u32 != 0) {
									// li r11,8
									ctx.r11.s64 = 8;
									// b 0x82573f60
								} else {
								loc_82573EB8:
									// rlwinm r9,r10,26,31,31
									ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x1;
									// xor r5,r9,r11
									ctx.r5.u64 = ctx.r9.u64 ^ ctx.r11.u64;
									// cmplwi cr6,r5,0
									// beq cr6,0x82573ed0
									if (ctx.r5.u32 != 0) {
										// li r11,7
										ctx.r11.s64 = 7;
										// b 0x82573f60
									} else {
									loc_82573ED0:
										// rlwinm r4,r10,27,31,31
										ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
										// xor r3,r4,r11
										ctx.r3.u64 = ctx.r4.u64 ^ ctx.r11.u64;
										// cmplwi cr6,r3,0
										// beq cr6,0x82573ee8
										if (ctx.r3.u32 != 0) {
											// li r11,6
											ctx.r11.s64 = 6;
											// b 0x82573f60
										} else {
										loc_82573EE8:
											// rlwinm r9,r10,28,31,31
											ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x1;
											// xor r5,r9,r11
											ctx.r5.u64 = ctx.r9.u64 ^ ctx.r11.u64;
											// cmplwi cr6,r5,0
											// beq cr6,0x82573f00
											if (ctx.r5.u32 != 0) {
												// li r11,5
												ctx.r11.s64 = 5;
												// b 0x82573f60
											} else {
											loc_82573F00:
												// rlwinm r4,r10,29,31,31
												ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1;
												// xor r3,r4,r11
												ctx.r3.u64 = ctx.r4.u64 ^ ctx.r11.u64;
												// cmplwi cr6,r3,0
												// beq cr6,0x82573f18
												if (ctx.r3.u32 != 0) {
													// li r11,4
													ctx.r11.s64 = 4;
													// b 0x82573f60
												} else {
												loc_82573F18:
													// rlwinm r9,r10,30,31,31
													ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x1;
													// xor r5,r9,r11
													ctx.r5.u64 = ctx.r9.u64 ^ ctx.r11.u64;
													// cmplwi cr6,r5,0
													// beq cr6,0x82573f30
													if (ctx.r5.u32 != 0) {
														// li r11,3
														ctx.r11.s64 = 3;
														// b 0x82573f60
													} else {
													loc_82573F30:
														// rlwinm r4,r10,31,31,31
														ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
														// xor r3,r4,r11
														ctx.r3.u64 = ctx.r4.u64 ^ ctx.r11.u64;
														// cmplwi cr6,r3,0
														// beq cr6,0x82573f48
														if (ctx.r3.u32 == 0) goto loc_82573F48;
														// li r11,2
														ctx.r11.s64 = 2;
														// b 0x82573f60
														goto loc_82573F60;
													loc_82573F48:
														// clrlwi r9,r10,31
														ctx.r9.u64 = ctx.r10.u32 & 0x1;
														// xor r5,r9,r11
														ctx.r5.u64 = ctx.r9.u64 ^ ctx.r11.u64;
														// li r11,1
														ctx.r11.s64 = 1;
														// cmplwi cr6,r5,0
														// bne cr6,0x82573f60
														if (ctx.r5.u32 != 0) goto loc_82573F60;
														// li r11,0
														ctx.r11.s64 = 0;
													}
												}
											}
										}
									}
								}
							}
						}
					}
				}
			}
		}
	}
loc_82573F60:
	// extsh r9,r11
	ctx.r9.s64 = ctx.r11.s16;
	// subfic r4,r9,6
	ctx.xer.ca = ctx.r9.u32 <= 6;
	ctx.r4.s64 = 6 - ctx.r9.s64;
	// extsh r11,r4
	ctx.r11.s64 = ctx.r4.s16;
	// cmpwi cr6,r11,0
	// bge cr6,0x82573f88
	if (ctx.r11.s32 < 0) {
		// neg r3,r11
		ctx.r3.s64 = static_cast<int64_t>(-ctx.r11.u64);
		// extsh r10,r8
		ctx.r10.s64 = ctx.r8.s16;
		// extsh r11,r3
		ctx.r11.s64 = ctx.r3.s16;
		// sraw r11,r10,r11
		temp.u32 = ctx.r11.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
		ctx.r11.s64 = ctx.r10.s32 >> temp.u32;
		// b 0x82573f90
	} else {
	loc_82573F88:
		// slw r8,r10,r11
		ctx.r8.u64 = ctx.r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r11.u8 & 0x3F));
		// extsh r11,r8
		ctx.r11.s64 = ctx.r8.s16;
	}
loc_82573F90:
	// ori r4,r11,32
	ctx.r4.u64 = ctx.r11.u64 | 32;
	// cmpwi cr6,r7,0
	// extsh r8,r4
	ctx.r8.s64 = ctx.r4.s16;
	// li r11,1
	ctx.r11.s64 = 1;
	// blt cr6,0x82573fa8
	if (ctx.r7.s32 >= 0) {
		// li r11,0
		ctx.r11.s64 = 0;
	}
loc_82573FA8:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// li r10,-1024
	// cmplwi cr6,r3,0
	// bne cr6,0x82573fbc
	if (ctx.r3.u32 == 0) {
		// li r10,0
		ctx.r10.s64 = 0;
	}
loc_82573FBC:
	// rlwinm r11,r9,6,0,25
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0xFFFFFFC0;
	// extsh r9,r10
	ctx.r9.s64 = ctx.r10.s16;
	// cmpwi cr6,r30,0
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// sth r11,42(r6)
	PPC_STORE_U16(ctx.r6.u32 + 42, ctx.r11.u16);
	// li r11,0
	ctx.r11.s64 = 0;
	// beq cr6,0x82573fe0
	if ((int32_t)var_r30 != 0) {
		// li r11,128
		ctx.r11.s64 = 128;
	}
loc_82573FE0:
	// extsh r9,r25
	ctx.r9.s64 = (int16_t)var_r25;
	// extsh r7,r11
	ctx.r7.s64 = ctx.r11.s16;
	// not r8,r9
	ctx.r8.u64 = ~ctx.r9.u64;
	// mr r11,r20
	ctx.r11.u64 = var_r20;
	// extsh r30,r8
	var_r30 = (uint32_t)(ctx.r8.s16);
	// li r9,6
	ctx.r9.s64 = 6;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
loc_82573FFC:
	// lhz r5,18(r11)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r11.u32 + 18);
	// lhz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// extsh r4,r5
	ctx.r4.s64 = ctx.r5.s16;
	// extsh r5,r8
	ctx.r5.s64 = ctx.r8.s16;
	// xor r10,r4,r31
	ctx.r10.u64 = ctx.r4.u64 ^ var_r31;
	// cmpwi cr6,r10,0
	// srawi r10,r5,8
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0xFF) != 0);
	ctx.r10.s64 = ctx.r5.s32 >> 8;
	// bge cr6,0x82574028
	if (ctx.r10.s32 < 0) {
		// add r4,r10,r7
		ctx.r4.u64 = ctx.r10.u64 + ctx.r7.u64;
		// extsh r10,r4
		ctx.r10.s64 = ctx.r4.s16;
		// b 0x82574030
	} else {
	loc_82574028:
		// subf r5,r7,r10
		ctx.r5.s64 = ctx.r10.s64 - ctx.r7.s64;
		// extsh r10,r5
		ctx.r10.s64 = ctx.r5.s16;
	}
loc_82574030:
	// extsh r4,r10
	ctx.r4.s64 = ctx.r10.s16;
	// extsh r10,r8
	ctx.r10.s64 = ctx.r8.s16;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// subf r8,r4,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r4.s64;
	// cmplwi cr6,r9,0
	// and r5,r8,r3
	ctx.r5.u64 = ctx.r8.u64 & ctx.r3.u64;
	// sth r5,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r5.u16);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// bne cr6,0x82573ffc
	if (ctx.r9.u32 != 0) goto loc_82573FFC;
	// lhz r11,26(r6)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r6.u32 + 26);
	// extsh r4,r29
	ctx.r4.s64 = (int16_t)var_r29;
	// lhz r9,30(r6)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r6.u32 + 30);
	// lhz r8,32(r6)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r6.u32 + 32);
	// lhz r10,28(r6)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r6.u32 + 28);
	// lhz r31,40(r6)
	var_r31 = (uint32_t)(PPC_LOAD_U16(ctx.r6.u32 + 40));
	// sth r11,28(r6)
	PPC_STORE_U16(ctx.r6.u32 + 28, ctx.r11.u16);
	// lhz r11,38(r6)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r6.u32 + 38);
	// xor r5,r31,r29
	ctx.r5.u64 = var_r31 ^ var_r29;
	// lhz r7,34(r6)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r6.u32 + 34);
	// sth r9,32(r6)
	PPC_STORE_U16(ctx.r6.u32 + 32, ctx.r9.u16);
	// xor r9,r11,r4
	ctx.r9.u64 = ctx.r11.u64 ^ ctx.r4.u64;
	// sth r8,34(r6)
	PPC_STORE_U16(ctx.r6.u32 + 34, ctx.r8.u16);
	// extsh r8,r5
	ctx.r8.s64 = ctx.r5.s16;
	// sth r10,30(r6)
	PPC_STORE_U16(ctx.r6.u32 + 30, ctx.r10.u16);
	// extsh r10,r9
	ctx.r10.s64 = ctx.r9.s16;
	// sth r28,26(r6)
	PPC_STORE_U16(ctx.r6.u32 + 26, (uint16_t)var_r28);
	// cmpwi cr6,r8,0
	// sth r29,38(r6)
	PPC_STORE_U16(ctx.r6.u32 + 38, (uint16_t)var_r29);
	// li r9,-4096
	// sth r7,36(r6)
	PPC_STORE_U16(ctx.r6.u32 + 36, ctx.r7.u16);
	// sth r11,40(r6)
	PPC_STORE_U16(ctx.r6.u32 + 40, ctx.r11.u16);
	// blt cr6,0x825740b4
	if (ctx.r8.s32 >= 0) {
		// li r9,4096
		ctx.r9.s64 = 4096;
	}
loc_825740B4:
	// lhz r5,0(r6)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r6.u32 + 0);
	// li r11,-8191
	// extsh r7,r5
	ctx.r7.s64 = ctx.r5.s16;
	// cmpwi cr6,r7,-8191
	// blt cr6,0x825740cc
	if (ctx.r7.s32 >= -8191) {
		// mr r11,r5
		ctx.r11.u64 = ctx.r5.u64;
	}
loc_825740CC:
	// extsh r8,r11
	ctx.r8.s64 = ctx.r11.s16;
	// cmpwi cr6,r8,8191
	// blt cr6,0x825740dc
	if (ctx.r8.s32 >= 8191) {
		// li r11,8191
		ctx.r11.s64 = 8191;
	}
loc_825740DC:
	// extsh r8,r10
	ctx.r8.s64 = ctx.r10.s16;
	// cmpwi cr6,r8,0
	// bge cr6,0x825740f4
	if (ctx.r8.s32 < 0) {
		// add r7,r11,r9
		ctx.r7.u64 = ctx.r11.u64 + ctx.r9.u64;
		// extsh r11,r7
		ctx.r11.s64 = ctx.r7.s16;
		// b 0x825740fc
	} else {
	loc_825740F4:
		// subf r9,r11,r9
		ctx.r9.s64 = ctx.r9.s64 - ctx.r11.s64;
		// extsh r11,r9
		ctx.r11.s64 = ctx.r9.s16;
	}
loc_825740FC:
	// cmpwi cr6,r4,0
	// bne cr6,0x82574110
	if (ctx.r4.s32 == 0) {
		// li r10,0
		ctx.r10.s64 = 0;
		// li r9,0
		ctx.r9.s64 = 0;
		// b 0x8257411c
	} else {
	loc_82574110:
		// extsh r7,r11
		ctx.r7.s64 = ctx.r11.s16;
		// li r9,192
		ctx.r9.s64 = 192;
		// srawi r10,r7,5
		ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x1F) != 0);
		ctx.r10.s64 = ctx.r7.s32 >> 5;
	}
loc_8257411C:
	// lhz r11,2(r6)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r6.u32 + 2);
	// extsh r4,r11
	ctx.r4.s64 = ctx.r11.s16;
	// srawi r7,r4,7
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x7F) != 0);
	ctx.r7.s64 = ctx.r4.s32 >> 7;
	// subf r11,r7,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r7.s64;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// extsh r4,r11
	ctx.r4.s64 = ctx.r11.s16;
	// cmpwi cr6,r4,-12288
	// bge cr6,0x82574140
	if (ctx.r4.s32 < -12288) {
		// li r11,-12288
	}
loc_82574140:
	// extsh r10,r11
	ctx.r10.s64 = ctx.r11.s16;
	// cmpwi cr6,r10,12288
	// blt cr6,0x82574150
	if (ctx.r10.s32 >= 12288) {
		// li r11,12288
		ctx.r11.s64 = 12288;
	}
loc_82574150:
	// extsh r7,r11
	ctx.r7.s64 = ctx.r11.s16;
	// cmpwi cr6,r8,0
	// and r8,r7,r3
	ctx.r8.u64 = ctx.r7.u64 & ctx.r3.u64;
	// extsh r4,r5
	ctx.r4.s64 = ctx.r5.s16;
	// srawi r11,r4,8
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0xFF) != 0);
	ctx.r11.s64 = ctx.r4.s32 >> 8;
	// sth r8,2(r6)
	PPC_STORE_U16(ctx.r6.u32 + 2, ctx.r8.u16);
	// bge cr6,0x82574178
	if (ctx.r8.s32 < 0) {
		// add r9,r11,r9
		ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
		// extsh r11,r9
		ctx.r11.s64 = ctx.r9.s16;
		// b 0x82574180
	} else {
	loc_82574178:
		// subf r11,r9,r11
		ctx.r11.s64 = ctx.r11.s64 - ctx.r9.s64;
		// extsh r11,r11
		ctx.r11.s64 = ctx.r11.s16;
	}
loc_82574180:
	// subfic r10,r7,15360
	ctx.xer.ca = ctx.r7.u32 <= 15360;
	ctx.r10.s64 = 15360 - ctx.r7.s64;
	// subf r4,r11,r5
	ctx.r4.s64 = ctx.r5.s64 - ctx.r11.s64;
	// extsh r8,r10
	ctx.r8.s64 = ctx.r10.s16;
	// extsh r11,r4
	ctx.r11.s64 = ctx.r4.s16;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// neg r4,r9
	ctx.r4.s64 = static_cast<int64_t>(-ctx.r9.u64);
	// extsh r10,r4
	ctx.r10.s64 = ctx.r4.s16;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// cmpw cr6,r5,r4
	// bge cr6,0x825741b0
	if (ctx.r5.s32 < ctx.r4.s32) {
		// mr r11,r10
		ctx.r11.u64 = ctx.r10.u64;
	}
loc_825741B0:
	// extsh r10,r11
	ctx.r10.s64 = ctx.r11.s16;
	// cmpw cr6,r10,r9
	// bge cr6,0x825741c0
	if (ctx.r10.s32 < ctx.r9.s32) {
		// mr r8,r11
		ctx.r8.u64 = ctx.r11.u64;
	}
loc_825741C0:
	// and r8,r8,r3
	ctx.r8.u64 = ctx.r8.u64 & ctx.r3.u64;
	// cmpwi cr6,r7,-11776
	// li r11,1
	ctx.r11.s64 = 1;
	// sth r8,0(r6)
	PPC_STORE_U16(ctx.r6.u32 + 0, ctx.r8.u16);
	// blt cr6,0x825741d8
	if (ctx.r7.s32 >= -11776) {
		// li r11,0
		ctx.r11.s64 = 0;
	}
loc_825741D8:
	// extsh r8,r11
	ctx.r8.s64 = ctx.r11.s16;
	// lhz r10,20(r6)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r6.u32 + 20);
	// lis r11,-32164
	// and r5,r8,r3
	ctx.r5.u64 = ctx.r8.u64 & ctx.r3.u64;
	// addi r9,r11,9928
	ctx.r9.s64 = ctx.r11.s64 + 9928;
	// lhz r11,22(r6)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r6.u32 + 22);
	// sth r5,46(r6)
	PPC_STORE_U16(ctx.r6.u32 + 46, ctx.r5.u16);
	// lhzx r9,r22,r9
	ctx.r9.u64 = PPC_LOAD_U16(var_r22 + ctx.r9.u32);
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// subf r4,r11,r9
	ctx.r4.s64 = ctx.r9.s64 - ctx.r11.s64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// extsh r7,r4
	ctx.r7.s64 = ctx.r4.s16;
	// subf r5,r10,r9
	ctx.r5.s64 = ctx.r9.s64 - ctx.r10.s64;
	// srawi r9,r7,5
	ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x1F) != 0);
	ctx.r9.s64 = ctx.r7.s32 >> 5;
	// extsh r4,r5
	ctx.r4.s64 = ctx.r5.s16;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// srawi r9,r4,7
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x7F) != 0);
	ctx.r9.s64 = ctx.r4.s32 >> 7;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// extsh r9,r11
	ctx.r9.s64 = ctx.r11.s16;
	// sth r11,22(r6)
	PPC_STORE_U16(ctx.r6.u32 + 22, ctx.r11.u16);
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r4,r10,r7
	ctx.r4.s64 = ctx.r7.s64 - ctx.r10.s64;
	// sth r10,20(r6)
	PPC_STORE_U16(ctx.r6.u32 + 20, ctx.r10.u16);
	// extsh r11,r4
	ctx.r11.s64 = ctx.r4.s16;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// cmpwi cr6,r9,0
	// bge cr6,0x8257424c
	if (ctx.r9.s32 < 0) {
		// neg r11,r9
		ctx.r11.s64 = static_cast<int64_t>(-ctx.r9.u64);
		// extsh r11,r11
		ctx.r11.s64 = ctx.r11.s16;
	}
loc_8257424C:
	// rlwinm r7,r10,29,19,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFF;
	// extsh r9,r11
	ctx.r9.s64 = ctx.r11.s16;
	// cmpw cr6,r9,r7
	// bge cr6,0x82574264
	if (ctx.r9.s32 < ctx.r7.s32) {
		// cmpwi cr6,r21,1536
		// bge cr6,0x8257426c
		if ((int32_t)var_r21 >= 1536) goto loc_8257426C;
	}
loc_82574264:
	// li r10,512
	ctx.r10.s64 = 512;
	// b 0x8257427c
	goto loc_8257427C;
loc_8257426C:
	// cmpwi cr6,r8,0
	// li r10,512
	ctx.r10.s64 = 512;
	// bne cr6,0x8257427c
	if (ctx.r8.s32 == 0) {
		// li r10,0
		ctx.r10.s64 = 0;
	}
loc_8257427C:
	// lhz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r6.u32 + 4);
	// not r4,r3
	ctx.r4.u64 = ~ctx.r3.u64;
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// rlwinm r3,r4,0,23,23
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x100;
	// extsh r8,r9
	ctx.r8.s64 = ctx.r9.s16;
	// srawi r10,r8,4
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0xF) != 0);
	ctx.r10.s64 = ctx.r8.s32 >> 4;
	// add r7,r10,r11
	ctx.r7.u64 = ctx.r10.u64 + ctx.r11.u64;
	// and r5,r7,r30
	ctx.r5.u64 = ctx.r7.u64 & var_r30;
	// or r4,r5,r3
	ctx.r4.u64 = ctx.r5.u64 | ctx.r3.u64;
	// sth r4,4(r6)
	PPC_STORE_U16(ctx.r6.u32 + 4, ctx.r4.u16);
	// b 0x8242f8c8
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__msgMsgSink_42A8_w"))) PPC_WEAK_FUNC(msgMsgSink_42A8_w);
PPC_FUNC_IMPL(__imp__msgMsgSink_42A8_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=144, savegprlr_25
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r29,0
	var_r29 = 0;
	// mr r26,r29
	var_r26 = (uint32_t)(var_r29);
	// mr r25,r29
	var_r25 = (uint32_t)(var_r29);
	// lwz r8,136(r31)
	ctx.r8.u64 = PPC_LOAD_U32(var_r31 + 136);
	// lwz r30,12(r31)
	var_r30 = (uint32_t)(PPC_LOAD_U32(var_r31 + 12));
	// cmplwi r8,0
	// beq 0x82574300
	if (ctx.r8.u32 != 0) {
		// rotlwi r9,r8,0
		ctx.r9.u64 = ctx.r8.u32;
		// addi r11,r31,80
		ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 80;
	loc_825742DC:
		// lwz r10,0(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// lwz r10,24(r10)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
		// lwz r10,24(r10)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
		// cmplw cr6,r26,r10
		// bgt cr6,0x825742f4
		if (var_r26 <= ctx.r10.u32) {
			// mr r26,r10
			var_r26 = ctx.r10.u32;
		}
	loc_825742F4:
		// addic. r9,r9,-1
		ctx.xer.ca = ctx.r9.u32 > 0;
		ctx.r9.s64 = ctx.r9.s64 + -1;
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x825742dc
		if (ctx.r9.s32 != 0) goto loc_825742DC;
	}
loc_82574300:
	// cmplwi cr6,r8,0
	// beq cr6,0x82574340
	if (ctx.r8.u32 != 0) {
		// lwz r9,136(r31)
		ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 136);
		// addi r10,r31,80
		ctx.r10.s64 = (int64_t)(int32_t)var_r31 + 80;
	loc_82574310:
		// lwz r11,0(r10)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// lwz r11,24(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
		// lwz r11,20(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
		// divwu r8,r26,r11
		ctx.r8.u32 = ctx.r11.u32 ? var_r26 / ctx.r11.u32 : 0;
		// twllei r11,0
		if (ctx.r11.s32 == 0 || ctx.r11.u32 < 0u) __builtin_trap();
		// mullw r8,r8,r11
		ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
		// subf. r8,r8,r26
		ctx.r8.s64 = (int64_t)(int32_t)var_r26 - ctx.r8.s64;
		// beq 0x82574334
		if (ctx.r8.s32 != 0) {
			// mullw r26,r11,r26
			var_r26 = (uint32_t)(int64_t(ctx.r11.s32) * int64_t((int32_t)var_r26));
		}
	loc_82574334:
		// addic. r9,r9,-1
		ctx.xer.ca = ctx.r9.u32 > 0;
		ctx.r9.s64 = ctx.r9.s64 + -1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bne 0x82574310
		if (ctx.r9.s32 != 0) goto loc_82574310;
	}
loc_82574340:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
	// mullw r27,r26,r30
	var_r27 = (uint32_t)(int64_t((int32_t)var_r26) * int64_t((int32_t)var_r30));
	// cmplwi r11,0
	// bne 0x8257441c
	if (ctx.r11.u32 == 0) {
		// lis r4,24714
		ctx.r4.s64 = 1619656704;
		// mr r3,r27
		ctx.r3.u64 = var_r27;
		// ori r4,r4,8194
		ctx.r4.u64 = ctx.r4.u64 | 8194;
		// bl 0x820c01b8
		rage_01B8(ctx, base);
		// mr r11,r3
		ctx.r11.u64 = ctx.r3.u64;
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mulli r3,r30,28
		ctx.r3.s64 = static_cast<int64_t>(var_r30 * static_cast<uint64_t>(28));
		// stw r11,8(r31)
		PPC_STORE_U32(var_r31 + 8, ctx.r11.u32);
		// ori r4,r4,9
		ctx.r4.u64 = ctx.r4.u64 | 9;
		// bl 0x820c01b8
		rage_01B8(ctx, base);
		// mr r11,r3
		ctx.r11.u64 = ctx.r3.u64;
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// rlwinm r3,r30,3,0,28
		ctx.r3.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 3) & 0xFFFFFFF8;
		// ori r4,r4,3
		ctx.r4.u64 = ctx.r4.u64 | 3;
		// stw r11,132(r31)
		PPC_STORE_U32(var_r31 + 132, ctx.r11.u32);
		// bl 0x820c01b8
		rage_01B8(ctx, base);
		// lwz r11,8(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 8);
		// stw r3,96(r31)
		PPC_STORE_U32(var_r31 + 96, ctx.r3.u32);
		// cmplwi r11,0
		// beq 0x825743b4
		if (ctx.r11.u32 != 0) {
			// lwz r10,132(r31)
			ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 132);
			// cmplwi cr6,r10,0
			// beq cr6,0x825743b4
			if (ctx.r10.u32 == 0) goto loc_825743B4;
			// cmplwi cr6,r3,0
			// bne cr6,0x8257441c
			if (ctx.r3.u32 != 0) goto loc_8257441C;
		}
	loc_825743B4:
		// lwz r3,96(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 96);
		// lis r25,-32761
		var_r25 = (uint32_t)(-2147024896);
		// ori r25,r25,14
		var_r25 = (uint32_t)(var_r25 | 14);
		// cmplwi r3,0
		// beq 0x825743d8
		if (ctx.r3.u32 != 0) {
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// ori r4,r4,3
			ctx.r4.u64 = ctx.r4.u64 | 3;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r29,96(r31)
			PPC_STORE_U32(var_r31 + 96, var_r29);
		}
	loc_825743D8:
		// lwz r3,132(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 132);
		// cmplwi r3,0
		// beq 0x825743f4
		if (ctx.r3.u32 != 0) {
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// ori r4,r4,9
			ctx.r4.u64 = ctx.r4.u64 | 9;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r29,132(r31)
			PPC_STORE_U32(var_r31 + 132, var_r29);
		}
	loc_825743F4:
		// lwz r3,8(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
		// cmplwi r3,0
		// beq 0x82574410
		if (ctx.r3.u32 == 0) {
			// mr r3,r25
			ctx.r3.u64 = var_r25;
			return;
		}
		// lis r4,24714
		ctx.r4.s64 = 1619656704;
		// ori r4,r4,8194
		ctx.r4.u64 = ctx.r4.u64 | 8194;
		// bl 0x820c02d0
		_locale_register(ctx, base);
		// stw r29,8(r31)
		PPC_STORE_U32(var_r31 + 8, var_r29);
	loc_82574410:
		// mr r3,r25
		ctx.r3.u64 = var_r25;
		return;
	}
loc_8257441C:
	// mr r5,r27
	ctx.r5.u64 = var_r27;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x82566898
	util_6898(ctx, base);
	// mulli r29,r30,28
	var_r29 = (uint32_t)(static_cast<int64_t>(var_r30 * static_cast<uint64_t>(28)));
	// lwz r3,132(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 132);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = var_r29;
	// bl 0x82566898
	util_6898(ctx, base);
	// rlwinm r28,r30,3,0,28
	var_r28 = (uint32_t)(__builtin_rotateleft64(var_r30 | (var_r30 << 32), 3) & 0xFFFFFFF8);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,96(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 96);
	// mr r5,r28
	ctx.r5.u64 = var_r28;
	// bl 0x82566898
	util_6898(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 8);
	// lwz r11,132(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 132);
	// cmplwi cr6,r30,0
	// lwz r9,96(r31)
	ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 96);
	// add r10,r10,r27
	ctx.r10.u64 = ctx.r10.u64 + var_r27;
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + var_r29;
	// add r9,r9,r28
	ctx.r9.u64 = ctx.r9.u64 + var_r28;
	// beq cr6,0x82574410
	if (var_r30 == 0) {
		// mr r3,r25
		ctx.r3.u64 = var_r25;
		return;
	}
loc_82574474:
	// addi r11,r11,-28
	ctx.r11.s64 = ctx.r11.s64 + -28;
	// subf r10,r26,r10
	ctx.r10.s64 = ctx.r10.s64 - (int64_t)(int32_t)var_r26;
	// addi r9,r9,-8
	ctx.r9.s64 = ctx.r9.s64 + -8;
	// addic. r30,r30,-1
	ctx.xer.ca = var_r30 > 0;
	var_r30 = (uint32_t)(var_r30 + -1);
	// stw r26,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, var_r26);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r11.u32);
	// bne 0x82574474
	if ((int32_t)var_r30 != 0) goto loc_82574474;
	// b 0x82574410
	// mr r3,r25
	ctx.r3.u64 = var_r25;
	return;
}

__attribute__((alias("__imp__xam_4498_wrh"))) PPC_WEAK_FUNC(xam_4498_wrh);
PPC_FUNC_IMPL(__imp__xam_4498_wrh) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	PPCRegister temp{};
	// FRAME: size=160, savegprlr_24
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lwz r11,12(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// li r26,0
	var_r26 = 0;
	// lwz r29,8(r4)
	var_r29 = (uint32_t)(PPC_LOAD_U32(ctx.r4.u32 + 8));
	// addi r30,r31,144
	var_r30 = (uint32_t)(var_r31 + 144);
	// mr r28,r26
	var_r28 = (uint32_t)(var_r26);
	// rlwinm r27,r11,31,1,31
	var_r27 = (uint32_t)(__builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF);
	// lwz r10,0(r31)
  // [ph4a] vtable load collapsed
	// lwz r24,0(r30)
	var_r24 = (uint32_t)(PPC_LOAD_U32(var_r30 + 0));
	// lwz r10,40(r10)
  // [ph4a] slot load collapsed
	// cmplwi r10,0
	// beq 0x825744f4
	if (ctx.r10.u32 != 0) {
		// lwz r9,4(r31)
		ctx.r9.u64 = PPC_LOAD_U32(var_r31 + 4);
		// mr r6,r30
		ctx.r6.u64 = var_r30;
		// mr r5,r11
		ctx.r5.u64 = ctx.r11.u64;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// lwz r3,0(r9)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// bctrl
		VCALL(var_r31, 10, ctx, base);  // pattern-B slot 10 (byte +40)
		// mr r5,r26
		ctx.r5.u64 = var_r26;
	}
loc_825744F4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
	// li r25,16000
	var_r25 = 16000;
	// lwz r11,32(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// cmpwi cr6,r11,0
	// bne cr6,0x825745c0
	if (ctx.r11.s32 == 0) {
		// cmpwi cr6,r5,1
		// beq cr6,0x8257456c
		if (ctx.r5.s32 != 1) {
			// lwz r11,4(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 4);
			// lwz r11,196(r11)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 196);
			// clrlwi. r11,r11,31
			ctx.r11.u64 = ctx.r11.u32 & 0x1;
			// bne 0x8257456c
			if (ctx.r11.s32 != 0) goto loc_8257456C;
			// cmplwi cr6,r27,0
			// beq cr6,0x8257454c
			if (var_r27 != 0) {
				// mr r11,r27
				ctx.r11.u64 = var_r27;
			loc_8257452C:
				// lha r10,0(r29)
				ctx.r10.s64 = int16_t(PPC_LOAD_U16(var_r29 + 0));
				// addic. r11,r11,-1
				ctx.xer.ca = ctx.r11.u32 > 0;
				ctx.r11.s64 = ctx.r11.s64 + -1;
				// addi r29,r29,2
				var_r29 = (uint32_t)(var_r29 + 2);
				// srawi r9,r10,31
				ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFFF) != 0);
				ctx.r9.s64 = ctx.r10.s32 >> 31;
				// xor r10,r10,r9
				ctx.r10.u64 = ctx.r10.u64 ^ ctx.r9.u64;
				// subf r10,r9,r10
				ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
				// add r28,r10,r28
				var_r28 = (uint32_t)(ctx.r10.u64 + var_r28);
				// bne 0x8257452c
				if (ctx.r11.s32 != 0) goto loc_8257452C;
			}
		loc_8257454C:
			// lwz r11,148(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 148);
			// divwu r10,r28,r27
			ctx.r10.u32 = var_r27 ? var_r28 / var_r27 : 0;
			// twllei r27,0
			if ((int32_t)var_r27 == 0 || var_r27 < 0u) __builtin_trap();
			// subfc r11,r10,r11
			ctx.xer.ca = ctx.r11.u32 >= ctx.r10.u32;
			ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
			// subfe r11,r11,r11
			temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
			ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
			ctx.xer.ca = temp.u8;
			// clrlwi r11,r11,31
			ctx.r11.u64 = ctx.r11.u32 & 0x1;
			// stw r11,0(r30)
			PPC_STORE_U32(var_r30 + 0, ctx.r11.u32);
			// b 0x82574570
		} else {
		loc_8257456C:
			// stw r26,0(r30)
			PPC_STORE_U32(var_r30 + 0, var_r26);
		}
	loc_82574570:
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmpwi cr6,r11,1
		// bne cr6,0x82574590
		if (ctx.r11.s32 == 1) {
			// li r11,500
			ctx.r11.s64 = 500;
			// li r10,300
			ctx.r10.s64 = 300;
			// stw r11,152(r31)
			PPC_STORE_U32(var_r31 + 152, ctx.r11.u32);
			// stw r10,148(r31)
			PPC_STORE_U32(var_r31 + 148, ctx.r10.u32);
			// b 0x825745c0
		} else {
		loc_82574590:
			// lwz r11,152(r31)
			ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 152);
			// cmpwi r11,0
			// ble 0x825745b8
			if (ctx.r11.s32 > 0) {
				// mulli r10,r27,1000
				ctx.r10.s64 = static_cast<int64_t>(var_r27 * static_cast<uint64_t>(1000));
				// divwu r10,r10,r25
				ctx.r10.u32 = var_r25 ? ctx.r10.u32 / var_r25 : 0;
				// li r9,1
				ctx.r9.s64 = 1;
				// subf r11,r10,r11
				ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
				// stw r9,0(r30)
				PPC_STORE_U32(var_r30 + 0, ctx.r9.u32);
				// stw r11,152(r31)
				PPC_STORE_U32(var_r31 + 152, ctx.r11.u32);
				// b 0x825745c0
			} else {
			loc_825745B8:
				// li r11,600
				ctx.r11.s64 = 600;
				// stw r11,148(r31)
				PPC_STORE_U32(var_r31 + 148, ctx.r11.u32);
			}
		}
	}
loc_825745C0:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
	// cmpwi cr6,r11,1
	// bne cr6,0x825745d4
	if (ctx.r11.s32 == 1) {
		// cmpwi cr6,r24,0
		// beq cr6,0x825745e0
		if ((int32_t)var_r24 == 0) goto loc_825745E0;
	}
loc_825745D4:
	// lwz r11,156(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 156);
	// cmplwi cr6,r11,30000
	// ble cr6,0x82574604
	if (ctx.r11.u32 > 30000) {
	loc_825745E0:
		// lis r11,-32254
		// stw r26,156(r31)
		PPC_STORE_U32(var_r31 + 156, var_r26);
		// addi r3,r31,24
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 24;
		// addi r4,r11,11204
		ctx.r4.s64 = ctx.r11.s64 + 11204;
		// lbz r11,140(r31)
		ctx.r11.u64 = PPC_LOAD_U8(var_r31 + 140);
		// li r5,54
		ctx.r5.s64 = 54;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// stb r11,140(r31)
		PPC_STORE_U8(var_r31 + 140, ctx.r11.u8);
		// bl 0x82434100
		memcpy(ctx, base);
	}
loc_82574604:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 0);
	// cmpwi cr6,r3,1
	// bne cr6,0x82574624
	if (ctx.r3.s32 == 1) {
		// mulli r11,r27,1000
		ctx.r11.s64 = static_cast<int64_t>(var_r27 * static_cast<uint64_t>(1000));
		// lwz r10,156(r31)
		ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 156);
		// divwu r11,r11,r25
		ctx.r11.u32 = var_r25 ? ctx.r11.u32 / var_r25 : 0;
		// add r11,r11,r10
		ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
		// stw r11,156(r31)
		PPC_STORE_U32(var_r31 + 156, ctx.r11.u32);
	}
loc_82574624:
	return;
}

__attribute__((alias("__imp__xam_4630"))) PPC_WEAK_FUNC(xam_4630);
PPC_FUNC_IMPL(__imp__xam_4630) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=112, savegprlr_29
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// lis r3,-32768
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// lwz r31,0(r29)
	var_r31 = (uint32_t)(PPC_LOAD_U32(var_r29 + 0));
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 20);
	// cmpwi cr6,r11,0
	// bne cr6,0x82574668
	if (ctx.r11.s32 == 0) {
		// lwz r11,12(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 12);
		// rlwinm r11,r11,30,2,31
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
		// stw r11,12(r31)
		PPC_STORE_U32(var_r31 + 12, ctx.r11.u32);
	}
loc_82574668:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
	// lwz r11,140(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 140);
	// stw r11,20(r31)
	PPC_STORE_U32(var_r31 + 20, ctx.r11.u32);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r11,0
	// beq cr6,0x825746a4
	if (ctx.r11.u32 != 0) {
		// lwz r11,4(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
		// lwz r10,196(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 196);
		// rlwinm. r10,r10,0,12,15
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF0000;
		// beq 0x825746a4
		if (ctx.r10.s32 == 0) goto loc_825746A4;
		// mr r5,r31
		ctx.r5.u64 = var_r31;
		// lwz r3,8(r11)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// li r4,1
		ctx.r4.s64 = 1;
		// bl 0x8258680c
		__imp__XamVoiceSubmitPacket(ctx, base);
	}
loc_825746A4:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4);
	// lwz r11,8(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r11,0
	// beq cr6,0x825746bc
	if (ctx.r11.u32 != 0) {
		// cmpwi cr6,r3,0
		// bge cr6,0x825746d0
		if (ctx.r3.s32 >= 0) goto loc_825746D0;
	}
loc_825746BC:
	// lis r10,-16384
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 12);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r11,4(r31)
	PPC_STORE_U32(var_r31 + 4, ctx.r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(var_r31 + 0, ctx.r10.u32);
loc_825746D0:
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r30,116
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 116;
	// stw r10,4(r29)
	PPC_STORE_U32(var_r29 + 4, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi r10,0
	// beq 0x825746f0
	if (ctx.r10.u32 != 0) {
		// stw r29,4(r10)
		PPC_STORE_U32(ctx.r10.u32 + 4, var_r29);
		// b 0x825746f4
	} else {
	loc_825746F0:
		// stw r29,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r29);
	}
loc_825746F4:
	// stw r29,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, var_r29);
	return;
}

__attribute__((alias("__imp__xam_4700_2h"))) PPC_WEAK_FUNC(xam_4700_2h);
PPC_FUNC_IMPL(__imp__xam_4700_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// mr r31,r5
	var_r31 = ctx.r5.u32;
	// addi r11,r29,20
	ctx.r11.s64 = (int64_t)(int32_t)var_r29 + 20;
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r28,0(r31)
	var_r28 = (uint32_t)(PPC_LOAD_U32(var_r31 + 0));
	// mr r5,r28
	ctx.r5.u64 = var_r28;
	// lwzx r3,r11,r30
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r30);
	// bl 0x8256c1d8
	xam_C1D8_w(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi r3,0
	// bge 0x8257474c
	if (ctx.r3.s32 < 0) {
		// lwz r11,12(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 12);
		// stw r10,0(r28)
		PPC_STORE_U32(var_r28 + 0, ctx.r10.u32);
		// stw r11,4(r28)
		PPC_STORE_U32(var_r28 + 4, ctx.r11.u32);
	}
loc_8257474C:
	// rlwinm r11,r29,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(var_r29 | (var_r29 << 32), 3) & 0xFFFFFFF8;
	// stw r10,4(r31)
	PPC_STORE_U32(var_r31 + 4, ctx.r10.u32);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + var_r30;
	// addi r11,r11,100
	ctx.r11.s64 = ctx.r11.s64 + 100;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi r10,0
	// beq 0x82574770
	if (ctx.r10.u32 != 0) {
		// stw r31,4(r10)
		PPC_STORE_U32(ctx.r10.u32 + 4, var_r31);
		// b 0x82574774
	} else {
	loc_82574770:
		// stw r31,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
	}
loc_82574774:
	// stw r31,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, var_r31);
	return;
}

__attribute__((alias("__imp__xam_4780"))) PPC_WEAK_FUNC(xam_4780);
PPC_FUNC_IMPL(__imp__xam_4780) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=128, savegprlr_27
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// li r27,0
	var_r27 = 0;
	// mr r28,r27
	var_r28 = (uint32_t)(var_r27);
	// lwz r11,136(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 136);
	// cmplwi cr6,r11,0
	// ble cr6,0x82574804
	if (ctx.r11.u32 > 0) {
		// addi r31,r30,100
		var_r31 = (uint32_t)(var_r30 + 100);
		// addi r29,r30,80
		var_r29 = (uint32_t)(var_r30 + 80);
	loc_825747AC:
		// li r6,0
		ctx.r6.s64 = 0;
		// lwz r3,0(r29)
		ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 0);
		// li r5,0
		ctx.r5.s64 = 0;
		// li r4,0
		ctx.r4.s64 = 0;
		// bl 0x8256c328
		xam_C328_fw(ctx, base);
	loc_825747C0:
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// cmplwi r11,0
		// beq 0x825747ec
		if (ctx.r11.u32 == 0) goto loc_825747EC;
		// lwz r10,4(r31)
		ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 4);
		// cmplw cr6,r11,r10
		// bne cr6,0x825747dc
		if (ctx.r11.u32 == ctx.r10.u32) {
			// stw r27,4(r31)
			PPC_STORE_U32(var_r31 + 4, var_r27);
		}
	loc_825747DC:
		// lwz r10,4(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// stw r10,0(r31)
		PPC_STORE_U32(var_r31 + 0, ctx.r10.u32);
		// stw r27,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r27);
		// b 0x825747c0
		goto loc_825747C0;
	loc_825747EC:
		// lwz r11,136(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 136);
		// addi r28,r28,1
		var_r28 = (uint32_t)(var_r28 + 1);
		// addi r29,r29,4
		var_r29 = (uint32_t)(var_r29 + 4);
		// addi r31,r31,8
		var_r31 = (uint32_t)(var_r31 + 8);
		// cmplw cr6,r28,r11
		// blt cr6,0x825747ac
		if (var_r28 < ctx.r11.u32) goto loc_825747AC;
	}
loc_82574804:
	// addi r11,r30,116
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 116;
loc_82574808:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi r10,0
	// beq 0x82574834
	if (ctx.r10.u32 == 0) {
		return;
	}
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r10,r9
	// bne cr6,0x82574824
	if (ctx.r10.u32 == ctx.r9.u32) {
		// stw r27,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, var_r27);
	}
loc_82574824:
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// stw r27,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, var_r27);
	// b 0x82574808
	goto loc_82574808;
}

__attribute__((alias("__imp__xam_4840_h"))) PPC_WEAK_FUNC(xam_4840_h);
PPC_FUNC_IMPL(__imp__xam_4840_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r15 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r14 = 0;
	uint32_t var_r16 = 0;
	uint32_t var_r17 = 0;
	uint32_t var_r19 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r18 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r22 = 0;
	PPCRegister temp{};
	// FRAME: size=240, savegprlr_14
	// li r15,0
	var_r15 = 0;
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// mr r14,r15
	var_r14 = (uint32_t)(var_r15);
	// mr r16,r15
	var_r16 = (uint32_t)(var_r15);
	// mr r17,r15
	var_r17 = (uint32_t)(var_r15);
	// bl 0x82566f98
	atSingleton_6F98_g(ctx, base);
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 16);
	// mr r19,r3
	var_r19 = ctx.r3.u32;
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 20);
	// addi r20,r28,116
	var_r20 = (uint32_t)(var_r28 + 116);
	// cmplw cr6,r19,r11
	ctx.cr6.compare<uint32_t>(var_r19, ctx.r11.u32, ctx.xer);
	// subf r11,r11,r19
	ctx.r11.s64 = (int64_t)(int32_t)var_r19 - ctx.r11.s64;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r21,0(r20)
	var_r21 = (uint32_t)(PPC_LOAD_U32(var_r20 + 0));
	// cmplwi r21,0
	// stw r11,20(r28)
	PPC_STORE_U32(var_r28 + 20, ctx.r11.u32);
	// beq 0x82574bd8
	if (var_r21 != 0) {
		// lis r11,-32164
		ctx.r11.s64 = -2107899904;
		// addi r18,r11,10088
		var_r18 = (uint32_t)(ctx.r11.s64 + 10088);  // lbl_825C2768 @ 0x825c2768
	loc_82574898:
		// lwz r29,0(r21)
		var_r29 = (uint32_t)(PPC_LOAD_U32(var_r21 + 0));
		// lwz r11,0(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 0);
		// cmpwi cr6,r11,259
		// beq cr6,0x82574bd8
		if (ctx.r11.s32 == 259) goto loc_82574BD8;
		// lwz r10,24(r29)
		ctx.r10.u64 = PPC_LOAD_U32(var_r29 + 24);
		// cmplwi cr6,r10,0
		// bne cr6,0x82574bd8
		if (ctx.r10.u32 != 0) goto loc_82574BD8;
		// lwz r10,12(r28)
		ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 12);
		// cmplw cr6,r16,r10
		// bge cr6,0x82574bd8
		if (var_r16 >= ctx.r10.u32) goto loc_82574BD8;
		// lwz r10,20(r28)
		ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 20);
		// cmpwi cr6,r10,20
		// blt cr6,0x82574bd8
		if (ctx.r10.s32 < 20) goto loc_82574BD8;
		// cmpwi cr6,r11,0
		// lwz r11,20(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 20);
		// beq cr6,0x82574918
		if (ctx.r11.s32 != 0) {
			// cmpwi cr6,r11,1
			// beq cr6,0x825748e8
			if (ctx.r11.s32 != 1) {
				// cmpwi cr6,r11,2
				// bne cr6,0x825748f8
				if (ctx.r11.s32 != 2) goto loc_825748F8;
			}
		loc_825748E8:
			// lwz r11,12(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 12);
			// stw r15,20(r29)
			PPC_STORE_U32(var_r29 + 20, var_r15);
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// stw r11,12(r29)
			PPC_STORE_U32(var_r29 + 12, ctx.r11.u32);
		loc_825748F8:
			// li r4,0
			ctx.r4.s64 = 0;
			// lwz r3,8(r29)
			ctx.r3.u64 = PPC_LOAD_U32(var_r29 + 8);
			// lwz r5,12(r29)
			ctx.r5.u64 = PPC_LOAD_U32(var_r29 + 12);
			// bl 0x82566898
			util_6898(ctx, base);
			// lwz r11,12(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 12);
			// li r17,1
			var_r17 = 1;
			// stw r15,0(r29)
			PPC_STORE_U32(var_r29 + 0, var_r15);
			// b 0x82574ab8
		} else {
		loc_82574918:
			// cmpwi cr6,r11,1
			// bne cr6,0x82574a5c
			if (ctx.r11.s32 == 1) {
				// lwz r11,12(r29)
				ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 12);
				// addi r23,r28,24
				var_r23 = (uint32_t)(var_r28 + 24);
				// lwz r30,8(r29)
				var_r30 = (uint32_t)(PPC_LOAD_U32(var_r29 + 8));
				// rlwinm r11,r11,1,0,30
				ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
				// mr r4,r30
				ctx.r4.u64 = var_r30;
				// srawi r11,r11,2
				ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
				ctx.r11.s64 = ctx.r11.s32 >> 2;
				// addze r31,r11
				temp.s64 = ctx.r11.s64 + ctx.xer.ca;
				ctx.xer.ca = temp.u32 < ctx.r11.u32;
				var_r31 = (uint32_t)(temp.s64);
				// mulli r11,r31,3
				ctx.r11.s64 = static_cast<int64_t>(var_r31 * static_cast<uint64_t>(3));
				// add r27,r11,r30
				var_r27 = (uint32_t)(ctx.r11.u64 + var_r30);
				// mr r5,r31
				ctx.r5.u64 = var_r31;
				// mr r3,r27
				ctx.r3.u64 = var_r27;
				// bl 0x82434100
				memcpy(ctx, base);
				// mulli r11,r31,7
				ctx.r11.s64 = static_cast<int64_t>(var_r31 * static_cast<uint64_t>(7));
				// add r24,r11,r30
				var_r24 = (uint32_t)(ctx.r11.u64 + var_r30);
				// mr r5,r31
				ctx.r5.u64 = var_r31;
				// add r4,r31,r30
				ctx.r4.u64 = var_r31 + var_r30;
				// mr r3,r24
				ctx.r3.u64 = var_r24;
				// bl 0x82434100
				memcpy(ctx, base);
				// mr r26,r30
				var_r26 = (uint32_t)(var_r30);
				// rlwinm. r25,r31,1,0,30
				var_r25 = (uint32_t)(__builtin_rotateleft64(var_r31 | (var_r31 << 32), 1) & 0xFFFFFFFE);
				// ble 0x825749dc
				if ((int32_t)var_r25 > 0) {
					// addi r11,r25,-1
					ctx.r11.s64 = (int64_t)(int32_t)var_r25 + -1;
					// rlwinm r11,r11,31,1,31
					ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
					// addi r22,r11,1
					var_r22 = (uint32_t)(ctx.r11.s64 + 1);  // addr:0x825c0001
				loc_82574980:
					// lbz r11,0(r27)
					ctx.r11.u64 = PPC_LOAD_U8(var_r27 + 0);
					// mr r6,r23
					ctx.r6.u64 = var_r23;
					// mr r5,r26
					ctx.r5.u64 = var_r26;
					// li r3,1
					ctx.r3.s64 = 1;
					// clrlwi r4,r11,28
					ctx.r4.u64 = ctx.r11.u32 & 0xF;
					// bl 0x825730b8
					xam_30B8_w(ctx, base);
					// mr r6,r23
					ctx.r6.u64 = var_r23;
					// li r3,1
					ctx.r3.s64 = 1;
					// lha r11,0(r26)
					ctx.r11.s64 = int16_t(PPC_LOAD_U16(var_r26 + 0));
					// rlwinm r11,r11,2,0,29
					ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
					// sth r11,0(r26)
					PPC_STORE_U16(var_r26 + 0, ctx.r11.u16);
					// addi r26,r26,2
					var_r26 = (uint32_t)(var_r26 + 2);
					// lbz r11,0(r27)
					ctx.r11.u64 = PPC_LOAD_U8(var_r27 + 0);
					// mr r5,r26
					ctx.r5.u64 = var_r26;
					// rlwinm r4,r11,28,4,31
					ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
					// bl 0x825730b8
					xam_30B8_w(ctx, base);
					// addic. r22,r22,-1
					ctx.xer.ca = var_r22 > 0;
					var_r22 = (uint32_t)(var_r22 + -1);
					// addi r27,r27,1
					var_r27 = (uint32_t)(var_r27 + 1);
					// lha r11,0(r26)
					ctx.r11.s64 = int16_t(PPC_LOAD_U16(var_r26 + 0));
					// rlwinm r11,r11,2,0,29
					ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
					// sth r11,0(r26)
					PPC_STORE_U16(var_r26 + 0, ctx.r11.u16);
					// addi r26,r26,2
					var_r26 = (uint32_t)(var_r26 + 2);
					// bne 0x82574980
					if ((int32_t)var_r22 != 0) goto loc_82574980;
				}
			loc_825749DC:
				// rlwinm r11,r31,2,0,29
				ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
				// mr r27,r24
				var_r27 = (uint32_t)(var_r24);
				// add r31,r11,r30
				var_r31 = (uint32_t)(ctx.r11.u64 + var_r30);
				// cmpwi cr6,r25,0
				// ble cr6,0x82574aa8
				if ((int32_t)var_r25 <= 0) goto loc_82574AA8;
				// addi r11,r25,-1
				ctx.r11.s64 = (int64_t)(int32_t)var_r25 + -1;
				// rlwinm r11,r11,31,1,31
				ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
				// addi r30,r11,1
				var_r30 = (uint32_t)(ctx.r11.s64 + 1);  // addr:0x825c0001
			loc_825749FC:
				// lbz r11,0(r27)
				ctx.r11.u64 = PPC_LOAD_U8(var_r27 + 0);
				// mr r6,r23
				ctx.r6.u64 = var_r23;
				// mr r5,r31
				ctx.r5.u64 = var_r31;
				// li r3,1
				ctx.r3.s64 = 1;
				// clrlwi r4,r11,28
				ctx.r4.u64 = ctx.r11.u32 & 0xF;
				// bl 0x825730b8
				xam_30B8_w(ctx, base);
				// mr r6,r23
				ctx.r6.u64 = var_r23;
				// li r3,1
				ctx.r3.s64 = 1;
				// lha r11,0(r31)
				ctx.r11.s64 = int16_t(PPC_LOAD_U16(var_r31 + 0));
				// rlwinm r11,r11,2,0,29
				ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
				// sth r11,0(r31)
				PPC_STORE_U16(var_r31 + 0, ctx.r11.u16);
				// addi r31,r31,2
				var_r31 = (uint32_t)(var_r31 + 2);
				// lbz r11,0(r27)
				ctx.r11.u64 = PPC_LOAD_U8(var_r27 + 0);
				// mr r5,r31
				ctx.r5.u64 = var_r31;
				// rlwinm r4,r11,28,4,31
				ctx.r4.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 28) & 0xFFFFFFF;
				// bl 0x825730b8
				xam_30B8_w(ctx, base);
				// addic. r30,r30,-1
				ctx.xer.ca = var_r30 > 0;
				var_r30 = (uint32_t)(var_r30 + -1);
				// addi r27,r27,1
				var_r27 = (uint32_t)(var_r27 + 1);
				// lha r11,0(r31)
				ctx.r11.s64 = int16_t(PPC_LOAD_U16(var_r31 + 0));
				// rlwinm r11,r11,2,0,29
				ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
				// sth r11,0(r31)
				PPC_STORE_U16(var_r31 + 0, ctx.r11.u16);
				// addi r31,r31,2
				var_r31 = (uint32_t)(var_r31 + 2);
				// bne 0x825749fc
				if ((int32_t)var_r30 != 0) goto loc_825749FC;
				// b 0x82574aa8
			} else {
			loc_82574A5C:
				// cmpwi cr6,r11,2
				// bne cr6,0x82574abc
				if (ctx.r11.s32 != 2) goto loc_82574ABC;
				// lwz r11,12(r29)
				ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 12);
				// lwz r9,8(r29)
				ctx.r9.u64 = PPC_LOAD_U32(var_r29 + 8);
				// rlwinm r8,r11,2,0,29
				ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
				// add r10,r9,r11
				ctx.r10.u64 = ctx.r9.u64 + ctx.r11.u64;
				// add r9,r8,r9
				ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
				// cmplwi r11,0
				// beq 0x82574aa8
			while (!ctx.cr0.eq) {
				loc_82574A80:
					// addi r10,r10,-1
					ctx.r10.s64 = ctx.r10.s64 + -1;
					// addi r9,r9,-2
					ctx.r9.s64 = ctx.r9.s64 + -2;
					// addic. r11,r11,-1
					ctx.xer.ca = ctx.r11.u32 > 0;
					ctx.r11.s64 = ctx.r11.s64 + -1;
					ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
					// lbz r8,0(r10)
					ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
					// rotlwi r8,r8,1
					ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 1);
					// lhzx r8,r8,r18
					ctx.r8.u64 = PPC_LOAD_U16(ctx.r8.u32 + var_r18);
					// sth r8,0(r9)
					PPC_STORE_U16(ctx.r9.u32 + 0, ctx.r8.u16);
					// addi r9,r9,-2
					ctx.r9.s64 = ctx.r9.s64 + -2;
					// sth r8,0(r9)
					PPC_STORE_U16(ctx.r9.u32 + 0, ctx.r8.u16);
					// bne 0x82574a80
			}
			}
		loc_82574AA8:
			// lwz r11,12(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 12);
			// stw r15,20(r29)
			PPC_STORE_U32(var_r29 + 20, var_r15);
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// stw r11,12(r29)
			PPC_STORE_U32(var_r29 + 12, ctx.r11.u32);
		}
	loc_82574AB8:
		// stw r11,4(r29)
		PPC_STORE_U32(var_r29 + 4, ctx.r11.u32);
	loc_82574ABC:
		// mr r5,r17
		ctx.r5.u64 = var_r17;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// mr r3,r28
		ctx.r3.u64 = var_r28;
		// bl 0x82574498
		xam_4498_wrh(ctx, base);
		// lwz r11,144(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 144);
		// cmpwi cr6,r11,1
		// bne cr6,0x82574b70
		if (ctx.r11.s32 == 1) {
			// lwz r11,136(r28)
			ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 136);
			// mr r27,r15
			var_r27 = (uint32_t)(var_r15);
			// cmplwi cr6,r11,0
			// ble cr6,0x82574b70
			if (ctx.r11.u32 <= 0) goto loc_82574B70;
			// addi r26,r28,88
			var_r26 = (uint32_t)(var_r28 + 88);
		loc_82574AEC:
			// lwz r11,132(r28)
			ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 132);
			// li r9,28
			ctx.r9.s64 = 28;
			// lwz r10,12(r28)
			ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 12);
			// subf r11,r11,r29
			ctx.r11.s64 = (int64_t)(int32_t)var_r29 - ctx.r11.s64;
			// divw r11,r11,r9
			ctx.r11.s32 = ctx.r9.s32 ? ctx.r11.s32 / ctx.r9.s32 : 0;
			// cmplw cr6,r11,r10
			// blt cr6,0x82574b10
			if (ctx.r11.u32 >= ctx.r10.u32) {
				// mr r30,r15
				var_r30 = (uint32_t)(var_r15);
				// b 0x82574b1c
			} else {
			loc_82574B10:
				// lwz r10,0(r26)
				ctx.r10.u64 = PPC_LOAD_U32(var_r26 + 0);
				// rlwinm r11,r11,3,0,28
				ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
				// add r30,r11,r10
				var_r30 = (uint32_t)(ctx.r11.u64 + ctx.r10.u64);
			}
		loc_82574B1C:
			// lwz r31,0(r30)
			var_r31 = (uint32_t)(PPC_LOAD_U32(var_r30 + 0));
			// li r5,24
			ctx.r5.s64 = 24;
			// li r4,0
			ctx.r4.s64 = 0;
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bl 0x82566898
			util_6898(ctx, base);
			// lwz r11,8(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 8);
			// mr r5,r30
			ctx.r5.u64 = var_r30;
			// mr r4,r27
			ctx.r4.u64 = var_r27;
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			// stw r11,8(r31)
			PPC_STORE_U32(var_r31 + 8, ctx.r11.u32);
			// lwz r11,12(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 12);
			// stw r11,12(r31)
			PPC_STORE_U32(var_r31 + 12, ctx.r11.u32);
			// bl 0x82574700
			xam_4700_2h(ctx, base);
			// lwz r11,24(r29)
			ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 24);
			// addi r27,r27,1
			var_r27 = (uint32_t)(var_r27 + 1);
			// addi r26,r26,4
			var_r26 = (uint32_t)(var_r26 + 4);
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// stw r11,24(r29)
			PPC_STORE_U32(var_r29 + 24, ctx.r11.u32);
			// lwz r11,136(r28)
			ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 136);
			// cmplw cr6,r27,r11
			// blt cr6,0x82574aec
			if (var_r27 < ctx.r11.u32) goto loc_82574AEC;
		}
	loc_82574B70:
		// lwz r11,0(r20)
		ctx.r11.u64 = PPC_LOAD_U32(var_r20 + 0);
		// cmplwi r11,0
		// beq 0x82574b98
		if (ctx.r11.u32 != 0) {
			// lwz r10,4(r20)
			ctx.r10.u64 = PPC_LOAD_U32(var_r20 + 4);
			// cmplw cr6,r11,r10
			// bne cr6,0x82574b8c
			if (ctx.r11.u32 == ctx.r10.u32) {
				// stw r15,4(r20)
				PPC_STORE_U32(var_r20 + 4, var_r15);
			}
		loc_82574B8C:
			// lwz r10,4(r11)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
			// stw r10,0(r20)
			PPC_STORE_U32(var_r20 + 0, ctx.r10.u32);
			// stw r15,4(r11)
			PPC_STORE_U32(ctx.r11.u32 + 4, var_r15);
		}
	loc_82574B98:
		// lwz r11,24(r29)
		ctx.r11.u64 = PPC_LOAD_U32(var_r29 + 24);
		// cmplwi cr6,r11,0
		// bne cr6,0x82574bb0
		if (ctx.r11.u32 == 0) {
			// mr r4,r21
			ctx.r4.u64 = var_r21;
			// mr r3,r28
			ctx.r3.u64 = var_r28;
			// bl 0x82574630
			xam_4630(ctx, base);
		}
	loc_82574BB0:
		// lwz r11,20(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 20);
		// addi r16,r16,1
		var_r16 = (uint32_t)(var_r16 + 1);
		// stw r19,16(r28)
		PPC_STORE_U32(var_r28 + 16, var_r19);
		// addic. r11,r11,-20
		ctx.xer.ca = ctx.r11.u32 > 19;
		ctx.r11.s64 = ctx.r11.s64 + -20;
		// stw r11,20(r28)
		PPC_STORE_U32(var_r28 + 20, ctx.r11.u32);
		// bge 0x82574bcc
		if (ctx.r11.s32 < 0) {
			// stw r15,20(r28)
			PPC_STORE_U32(var_r28 + 20, var_r15);
		}
	loc_82574BCC:
		// lwz r21,0(r20)
		var_r21 = (uint32_t)(PPC_LOAD_U32(var_r20 + 0));
		// cmplwi r21,0
		// bne 0x82574898
		if (var_r21 != 0) goto loc_82574898;
	}
loc_82574BD8:
	// lwz r11,136(r28)
	ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 136);
	// mr r30,r15
	var_r30 = (uint32_t)(var_r15);
	// cmplwi cr6,r11,0
	// ble cr6,0x82574c80
	if (ctx.r11.u32 > 0) {
		// addi r31,r28,80
		var_r31 = (uint32_t)(var_r28 + 80);
	loc_82574BEC:
		// lwz r3,0(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
		// lwz r10,4(r28)
		ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 4);
		// lwz r11,0(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
		// lwz r9,24(r3)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
		// lwz r10,0(r10)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// mulli r10,r10,3
		ctx.r10.s64 = static_cast<int64_t>(ctx.r10.u64 * static_cast<uint64_t>(3));
		// lwz r9,12(r9)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
		// add r10,r10,r9
		ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
		// addi r9,r10,344
		ctx.r9.s64 = ctx.r10.s64 + 344;
		// addi r10,r10,332
		ctx.r10.s64 = ctx.r10.s64 + 332;
		// rlwinm r9,r9,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// rlwinm r10,r10,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// lwzx r4,r9,r11
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
		// lwzx r5,r10,r11
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
		// bl 0x8256c200
		xam_C200_2h(ctx, base);
		// lwz r11,0(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0);
		// mr r14,r3
		var_r14 = ctx.r3.u32;
		// mr r10,r15
		ctx.r10.u64 = var_r15;
		// addi r11,r11,16
		ctx.r11.s64 = ctx.r11.s64 + 16;
	loc_82574C38:
		// lwz r9,-8(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
		// cmplwi cr6,r9,0
		// beq cr6,0x82574c50
		if (ctx.r9.u32 != 0) {
			// lwz r9,0(r11)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			// cmpwi cr6,r9,1
			// beq cr6,0x82574c64
			if (ctx.r9.s32 == 1) goto loc_82574C64;
		}
	loc_82574C50:
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// cmplwi cr6,r10,2
		// blt cr6,0x82574c38
		if (ctx.r10.u32 < 2) goto loc_82574C38;
		// stw r15,144(r28)
		PPC_STORE_U32(var_r28 + 144, var_r15);
	loc_82574C64:
		// lwz r11,136(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 136);
		// addi r30,r30,1
		var_r30 = (uint32_t)(var_r30 + 1);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// cmplw cr6,r30,r11
		// blt cr6,0x82574bec
		if (var_r30 < ctx.r11.u32) goto loc_82574BEC;
		// cmpwi cr6,r14,0
		// blt cr6,0x82574d74
		if ((int32_t)var_r14 < 0) {
			// mr r3,r14
			ctx.r3.u64 = var_r14;
			return;
		}
	}
loc_82574C80:
	// lwz r11,136(r28)
	ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 136);
	// mr r31,r15
	var_r31 = (uint32_t)(var_r15);
	// cmplwi cr6,r11,0
	// ble cr6,0x82574d74
	if (ctx.r11.u32 > 0) {
		// li r29,24
		var_r29 = 24;
		// li r27,28
		var_r27 = 28;
	loc_82574C98:
		// rlwinm r11,r31,3,0,28
		ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 3) & 0xFFFFFFF8;
		// add r11,r11,r28
		ctx.r11.u64 = ctx.r11.u64 + var_r28;
		// addi r30,r11,100
		var_r30 = (uint32_t)(ctx.r11.s64 + 100);  // addr:0x825c0064
	loc_82574CA4:
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmplwi r11,0
		// beq 0x82574d64
		if (ctx.r11.u32 == 0) goto loc_82574D64;
		// lwz r8,0(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmplwi cr6,r31,2
		// bne cr6,0x82574ccc
		if (var_r31 == 2) {
			// lwz r11,132(r28)
			ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 132);
			// subf r11,r11,r8
			ctx.r11.s64 = ctx.r8.s64 - ctx.r11.s64;
			// divw r11,r11,r27
			ctx.r11.s32 = (int32_t)var_r27 ? ctx.r11.s32 / (int32_t)var_r27 : 0;
			// b 0x82574ce0
		} else {
		loc_82574CCC:
			// addi r11,r31,31
			ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 31;
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// lwzx r11,r11,r28
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + var_r28);
			// subf r11,r11,r8
			ctx.r11.s64 = ctx.r8.s64 - ctx.r11.s64;
			// divw r11,r11,r29
			ctx.r11.s32 = (int32_t)var_r29 ? ctx.r11.s32 / (int32_t)var_r29 : 0;
		}
	loc_82574CE0:
		// lwz r10,12(r28)
		ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 12);
		// cmplw cr6,r11,r10
		// blt cr6,0x82574cf4
		if (ctx.r11.u32 >= ctx.r10.u32) {
			// mr r11,r15
			ctx.r11.u64 = var_r15;
			// b 0x82574d00
		} else {
		loc_82574CF4:
			// lwz r10,96(r28)
			ctx.r10.u64 = PPC_LOAD_U32(var_r28 + 96);
			// rlwinm r11,r11,3,0,28
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
			// add r11,r11,r10
			ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
		}
	loc_82574D00:
		// lwz r10,0(r8)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		// lwz r9,0(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// cmpwi cr6,r10,259
		// beq cr6,0x82574d64
		if (ctx.r10.s32 == 259) goto loc_82574D64;
		// lwz r10,24(r9)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
		// cmplwi cr6,r10,0
		// beq cr6,0x82574d64
		if (ctx.r10.u32 == 0) goto loc_82574D64;
		// lwz r10,0(r30)
		ctx.r10.u64 = PPC_LOAD_U32(var_r30 + 0);
		// cmplwi r10,0
		// beq 0x82574d44
		if (ctx.r10.u32 != 0) {
			// lwz r8,4(r30)
			ctx.r8.u64 = PPC_LOAD_U32(var_r30 + 4);
			// cmplw cr6,r10,r8
			// bne cr6,0x82574d38
			if (ctx.r10.u32 == ctx.r8.u32) {
				// stw r15,4(r30)
				PPC_STORE_U32(var_r30 + 4, var_r15);
			}
		loc_82574D38:
			// lwz r8,4(r10)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
			// stw r8,0(r30)
			PPC_STORE_U32(var_r30 + 0, ctx.r8.u32);
			// stw r15,4(r10)
			PPC_STORE_U32(ctx.r10.u32 + 4, var_r15);
		}
	loc_82574D44:
		// lwz r10,24(r9)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// stw r10,24(r9)
		PPC_STORE_U32(ctx.r9.u32 + 24, ctx.r10.u32);
		// bne 0x82574ca4
		if (ctx.r10.s32 != 0) goto loc_82574CA4;
		// mr r4,r11
		ctx.r4.u64 = ctx.r11.u64;
		// mr r3,r28
		ctx.r3.u64 = var_r28;
		// bl 0x82574630
		xam_4630(ctx, base);
		// b 0x82574ca4
		goto loc_82574CA4;
	loc_82574D64:
		// lwz r11,136(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 136);
		// addi r31,r31,1
		var_r31 = (uint32_t)(var_r31 + 1);
		// cmplw cr6,r31,r11
		// blt cr6,0x82574c98
		if (var_r31 < ctx.r11.u32) goto loc_82574C98;
	}
loc_82574D74:
	// mr r3,r14
	ctx.r3.u64 = var_r14;
	return;
}

__attribute__((alias("__imp__xam_4D80_w"))) PPC_WEAK_FUNC(xam_4D80_w);
PPC_FUNC_IMPL(__imp__xam_4D80_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// cmplwi cr6,r30,0
	// beq cr6,0x82574e74
	if (var_r30 != 0) {
		// lwz r11,136(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 136);
		// li r29,0
		var_r29 = 0;
		// mr r28,r29
		var_r28 = (uint32_t)(var_r29);
		// cmplwi cr6,r11,0
		// ble cr6,0x82574e10
		if (ctx.r11.u32 > 0) {
			// addi r31,r30,124
			var_r31 = (uint32_t)(var_r30 + 124);
		loc_82574DB0:
			// li r6,0
			ctx.r6.s64 = 0;
			// lwz r3,-44(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + -44);
			// li r5,0
			ctx.r5.s64 = 0;
			// li r4,0
			ctx.r4.s64 = 0;
			// bl 0x8256c328
			xam_C328_fw(ctx, base);
			// lwz r3,0(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0);
			// cmplwi r3,0
			// beq 0x82574de0
			if (ctx.r3.u32 != 0) {
				// lis r4,24970
				ctx.r4.s64 = 1636433920;
				// ori r4,r4,9
				ctx.r4.u64 = ctx.r4.u64 | 9;
				// bl 0x820c02d0
				_locale_register(ctx, base);
				// stw r29,0(r31)
				PPC_STORE_U32(var_r31 + 0, var_r29);
			}
		loc_82574DE0:
			// lwz r3,-36(r31)
			ctx.r3.u64 = PPC_LOAD_U32(var_r31 + -36);
			// cmplwi r3,0
			// beq 0x82574dfc
			if (ctx.r3.u32 != 0) {
				// lis r4,24970
				ctx.r4.s64 = 1636433920;
				// ori r4,r4,3
				ctx.r4.u64 = ctx.r4.u64 | 3;
				// bl 0x820c02d0
				_locale_register(ctx, base);
				// stw r29,-36(r31)
				PPC_STORE_U32(var_r31 + -36, var_r29);
			}
		loc_82574DFC:
			// lwz r11,136(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 136);
			// addi r28,r28,1
			var_r28 = (uint32_t)(var_r28 + 1);
			// addi r31,r31,4
			var_r31 = (uint32_t)(var_r31 + 4);
			// cmplw cr6,r28,r11
			// blt cr6,0x82574db0
			if (var_r28 < ctx.r11.u32) goto loc_82574DB0;
		}
	loc_82574E10:
		// lwz r3,96(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 96);
		// cmplwi r3,0
		// beq 0x82574e2c
		if (ctx.r3.u32 != 0) {
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// ori r4,r4,3
			ctx.r4.u64 = ctx.r4.u64 | 3;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r29,96(r30)
			PPC_STORE_U32(var_r30 + 96, var_r29);
		}
	loc_82574E2C:
		// lwz r3,132(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 132);
		// cmplwi r3,0
		// beq 0x82574e48
		if (ctx.r3.u32 != 0) {
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// ori r4,r4,9
			ctx.r4.u64 = ctx.r4.u64 | 9;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r29,132(r30)
			PPC_STORE_U32(var_r30 + 132, var_r29);
		}
	loc_82574E48:
		// lwz r3,8(r30)
		ctx.r3.u64 = PPC_LOAD_U32(var_r30 + 8);
		// cmplwi r3,0
		// beq 0x82574e64
		if (ctx.r3.u32 != 0) {
			// lis r4,24714
			ctx.r4.s64 = 1619656704;
			// ori r4,r4,8194
			ctx.r4.u64 = ctx.r4.u64 | 8194;
			// bl 0x820c02d0
			_locale_register(ctx, base);
			// stw r29,8(r30)
			PPC_STORE_U32(var_r30 + 8, var_r29);
		}
	loc_82574E64:
		// lis r4,24970
		ctx.r4.s64 = 1636433920;
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// ori r4,r4,32781
		ctx.r4.u64 = ctx.r4.u64 | 32781;
		// bl 0x820c02d0
		_locale_register(ctx, base);
	}
loc_82574E74:
	return;
}

__attribute__((alias("__imp__xam_4E80_w"))) PPC_WEAK_FUNC(xam_4E80_w);
PPC_FUNC_IMPL(__imp__xam_4E80_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	// FRAME: size=112, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lwz r30,12(r31)
	var_r30 = (uint32_t)(PPC_LOAD_U32(var_r31 + 12));
	// bl 0x82574780
	xam_4780(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x825742a8
	msgMsgSink_42A8_w(ctx, base);
	// li r29,0
	var_r29 = 0;
	// b 0x82574edc
	goto loc_82574EDC;
	do {
		// lwz r11,12(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 12);
		// addi r30,r30,-1
		var_r30 = (uint32_t)(var_r30 + -1);
		// subf r10,r30,r11
		ctx.r10.s64 = ctx.r11.s64 - (int64_t)(int32_t)var_r30;
		// addi r10,r10,-1
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// cmplw cr6,r10,r11
		// blt cr6,0x82574ec8
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// b 0x82574ed4
		goto loc_82574ED4;
	loc_82574EC8:
		// lwz r11,96(r31)
		ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 96);
		// rlwinm r10,r10,3,0,28
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
		// add r4,r11,r10
		ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	loc_82574ED4:
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82574630
		xam_4630(ctx, base);
		// cmplwi cr6,r30,0
		// bne cr6,0x82574ea8
	} while (var_r30 != 0);
	// li r11,600
	ctx.r11.s64 = 600;
	// stb r29,140(r31)
	PPC_STORE_U8(var_r31 + 140, (uint8_t)var_r29);
	// stw r29,144(r31)
	PPC_STORE_U32(var_r31 + 144, var_r29);
	// stw r29,152(r31)
	PPC_STORE_U32(var_r31 + 152, var_r29);
	// stw r29,156(r31)
	PPC_STORE_U32(var_r31 + 156, var_r29);
	// stw r11,148(r31)
	PPC_STORE_U32(var_r31 + 148, ctx.r11.u32);
	// bl 0x82566f98
	atSingleton_6F98_g(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,16(r31)
	PPC_STORE_U32(var_r31 + 16, ctx.r11.u32);
	return;
}

__attribute__((alias("__imp__msgMsgSink_4F18_w"))) PPC_WEAK_FUNC(msgMsgSink_4F18_w);
PPC_FUNC_IMPL(__imp__msgMsgSink_4F18_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=144, savegprlr_25
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// lis r4,24970
	ctx.r4.s64 = 1636433920;
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// ori r4,r4,32781
	ctx.r4.u64 = ctx.r4.u64 | 32781;
	// li r3,160
	ctx.r3.s64 = 160;
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// mr r26,r6
	var_r26 = ctx.r6.u32;
	// mr r30,r7
	var_r30 = ctx.r7.u32;
	// mr r25,r8
	var_r25 = ctx.r8.u32;
	// bl 0x820c01b8
	rage_01B8(ctx, base);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// beq 0x82575034
	if ((int32_t)var_r31 != 0) {
		// rlwinm r5,r30,2,0,29
		ctx.r5.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
		// stw r28,12(r31)
		PPC_STORE_U32(var_r31 + 12, var_r28);
		// mr r4,r26
		ctx.r4.u64 = var_r26;
		// stw r30,136(r31)
		PPC_STORE_U32(var_r31 + 136, var_r30);
		// addi r3,r31,80
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 80;
		// stw r29,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* msgMsgSink::vtable@+0x0 */ var_r29);
		// stw r27,4(r31)
		PPC_STORE_U32(var_r31 + 4,/* msgMsgSink::flags@+0x4 */ var_r27);
		// bl 0x82434100
		memcpy(ctx, base);
		// cmplwi cr6,r30,0
		// beq cr6,0x82575008
		if (var_r30 != 0) {
			// addi r11,r30,22
			ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 22;
			// mulli r27,r28,24
			var_r27 = (uint32_t)(static_cast<int64_t>(var_r28 * static_cast<uint64_t>(24)));
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// add r29,r11,r31
			var_r29 = (uint32_t)(ctx.r11.u64 + var_r31);
		loc_82574F8C:
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// mr r3,r27
			ctx.r3.u64 = var_r27;
			// ori r4,r4,9
			ctx.r4.u64 = ctx.r4.u64 | 9;
			// addi r30,r30,-1
			var_r30 = (uint32_t)(var_r30 + -1);
			// addi r29,r29,-4
			var_r29 = (uint32_t)(var_r29 + -4);
			// bl 0x820c01b8
			rage_01B8(ctx, base);
			// cmplwi r3,0
			// stw r3,36(r29)
			PPC_STORE_U32(var_r29 + 36, ctx.r3.u32);
			// beq 0x82575034
			if (ctx.r3.u32 == 0) goto loc_82575034;
			// lis r4,24970
			ctx.r4.s64 = 1636433920;
			// rlwinm r3,r28,3,0,28
			ctx.r3.u64 = __builtin_rotateleft64(var_r28 | (var_r28 << 32), 3) & 0xFFFFFFF8;
			// ori r4,r4,3
			ctx.r4.u64 = ctx.r4.u64 | 3;
			// bl 0x820c01b8
			rage_01B8(ctx, base);
			// cmplwi r3,0
			// stw r3,0(r29)
			PPC_STORE_U32(var_r29 + 0,/* msgMsgSink::vtable@+0x0 */ ctx.r3.u32);
			// beq 0x82575034
			if (ctx.r3.u32 == 0) goto loc_82575034;
			// cmplwi cr6,r28,0
			// beq cr6,0x82575000
			if (var_r28 != 0) {
				// li r9,0
				ctx.r9.s64 = 0;
				// li r10,0
				ctx.r10.s64 = 0;
				// mr r11,r28
				ctx.r11.u64 = var_r28;
			loc_82574FE0:
				// lwz r8,36(r29)
				ctx.r8.u64 = PPC_LOAD_U32(var_r29 + 36);
				// addic. r11,r11,-1
				ctx.xer.ca = ctx.r11.u32 > 0;
				ctx.r11.s64 = ctx.r11.s64 + -1;
				// lwz r7,0(r29)
				ctx.r7.u64 = PPC_LOAD_U32(var_r29 + 0)/* msgMsgSink::vtable@+0x0 */;
				// add r8,r8,r10
				ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
				// addi r10,r10,24
				ctx.r10.s64 = ctx.r10.s64 + 24;
				// stwx r8,r9,r7
				PPC_STORE_U32(ctx.r9.u32 + ctx.r7.u32, ctx.r8.u32);
				// addi r9,r9,8
				ctx.r9.s64 = ctx.r9.s64 + 8;
				// bne 0x82574fe0
				if (ctx.r11.s32 != 0) goto loc_82574FE0;
			}
		loc_82575000:
			// cmplwi cr6,r30,0
			// bne cr6,0x82574f8c
			if (var_r30 != 0) goto loc_82574F8C;
		}
	loc_82575008:
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x825742a8
		msgMsgSink_42A8_w(ctx, base);
		// mr. r30,r3
		var_r30 = ctx.r3.u32;
		// bge 0x82575024
		if ((int32_t)var_r30 < 0) {
		loc_82575018:
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bl 0x82574d80
			xam_4D80_w(ctx, base);
			// li r31,0
			var_r31 = 0;
		}
	loc_82575024:
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// stw r31,0(r25)
		PPC_STORE_U32(var_r25 + 0, var_r31);
		return;
	}
loc_82575034:
	// lis r30,-32761
	var_r30 = (uint32_t)(-2147024896);
	// ori r30,r30,14
	var_r30 = (uint32_t)(var_r30 | 14);
	// b 0x82575018
	goto loc_82575018;
}

__attribute__((alias("__imp__phBoundCapsule_5040_p39"))) PPC_WEAK_FUNC(phBoundCapsule_5040_p39);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5040_p39) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, var_r31);
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// extsh r6,r4
	ctx.r6.s64 = ctx.r4.s16;
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// lhz r7,4(r3)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r3.u32 + 4);
	// lhz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// lbz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// cmplwi r4,0
	// bne 0x82575074
	if (ctx.r4.u32 == 0) {
		// stb r6,0(r9)
		PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r6.u8);
		// b 0x8257508c
	} else {
	loc_82575074:
		// lbz r8,0(r11)
		ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
		// extsh r4,r6
		ctx.r4.s64 = ctx.r6.s16;
		// lbz r31,0(r9)
		var_r31 = (uint32_t)(PPC_LOAD_U8(ctx.r9.u32 + 0));
		// slw r8,r4,r8
		ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r4.u32 << (ctx.r8.u8 & 0x3F));
		// or r8,r8,r31
		ctx.r8.u64 = ctx.r8.u64 | var_r31;
		// stb r8,0(r9)
		PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r8.u8);
	}
loc_8257508C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r8,r8,r5
	ctx.r8.u64 = ctx.r8.u64 + ctx.r5.u64;
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r8,8
	// stb r8,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r8.u8);
	// ble cr6,0x82575100
	if (ctx.r8.u32 > 8) {
		// lhz r8,0(r10)
		ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
		// clrlwi r7,r7,16
		ctx.r7.u64 = ctx.r7.u32 & 0xFFFF;
		// addi r4,r8,1
		ctx.r4.s64 = ctx.r8.s64 + 1;
		// addi r8,r9,1
		ctx.r8.s64 = ctx.r9.s64 + 1;
		// clrlwi r9,r4,16
		ctx.r9.u64 = ctx.r4.u32 & 0xFFFF;
		// mr r4,r9
		ctx.r4.u64 = ctx.r9.u64;
		// cmplw cr6,r4,r7
		// sth r9,0(r10)
		PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r9.u16);
		// blt cr6,0x825750d4
		if (ctx.r4.u32 >= ctx.r7.u32) {
			// li r9,0
			ctx.r9.s64 = 0;
			// sth r9,0(r10)
			PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r9.u16);
			// lwz r8,0(r3)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
		}
	loc_825750D4:
		// lbz r10,0(r11)
		ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
		// extsh r9,r6
		ctx.r9.s64 = ctx.r6.s16;
		// subf r10,r10,r5
		ctx.r10.s64 = ctx.r5.s64 - ctx.r10.s64;
		// addi r10,r10,8
		ctx.r10.s64 = ctx.r10.s64 + 8;
		// extsh r10,r10
		ctx.r10.s64 = ctx.r10.s16;
		// sraw r10,r9,r10
		temp.u32 = ctx.r10.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = (ctx.r9.s32 < 0) & (((ctx.r9.s32 >> temp.u32) << temp.u32) != ctx.r9.s32);
		ctx.r10.s64 = ctx.r9.s32 >> temp.u32;
		// stb r10,0(r8)
		PPC_STORE_U8(ctx.r8.u32 + 0, ctx.r10.u8);
		// lbz r10,0(r11)
		ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
		// addi r10,r10,248
		ctx.r10.s64 = ctx.r10.s64 + 248;
		// stb r10,0(r11)
		PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
		// b 0x82575138
	} else {
	loc_82575100:
		// clrlwi r9,r8,24
		ctx.r9.u64 = ctx.r8.u32 & 0xFF;
		// cmplwi cr6,r9,8
		// bne cr6,0x82575138
		if (ctx.r9.u32 != 8) {
			// ld r31,-8(r1)
			var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
			// blr
			return;
		}
		// li r9,0
		ctx.r9.s64 = 0;
		// clrlwi r8,r7,16
		ctx.r8.u64 = ctx.r7.u32 & 0xFFFF;
		// stb r9,0(r11)
		PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
		// lhz r11,0(r10)
		ctx.r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// clrlwi r11,r11,16
		ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
		// mr r7,r11
		ctx.r7.u64 = ctx.r11.u64;
		// cmplw cr6,r7,r8
		// sth r11,0(r10)
		PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r11.u16);
		// blt cr6,0x82575138
		if (ctx.r7.u32 < ctx.r8.u32) {
			// ld r31,-8(r1)
			var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
			// blr
			return;
		}
		// sth r9,0(r10)
		PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r9.u16);
	}
loc_82575138:
	// ld r31,-8(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
	// blr
	return;
}

__attribute__((alias("__imp__aud_5140_h"))) PPC_WEAK_FUNC(aud_5140_h);
PPC_FUNC_IMPL(__imp__aud_5140_h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cmpw cr6,r5,r4
	// blt cr6,0x8257514c
	if (ctx.r5.s32 >= ctx.r4.s32) {
		// li r5,0
		ctx.r5.s64 = 0;
	}
loc_8257514C:
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f1,r11,r3
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5158_p39"))) PPC_WEAK_FUNC(phBoundCapsule_5158_p39);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5158_p39) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32254
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r5,0
	// lfs f0,16808(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16808);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,-16(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -16, temp.u32);
	// blelr cr6
	if (ctx.r5.s32 <= 0) return;
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lwz r9,-16(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
loc_82575184:
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r4,4
	ctx.r11.s64 = ctx.r4.s64 + 4;
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// addi r4,r11,4
	ctx.r4.s64 = ctx.r11.s64 + 4;
	// lfs f10,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f13,f0,f0
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fsubs f0,f10,f11
	ctx.f0.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fmadds f0,f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f13.f64));
	// stfs f0,-16(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -16, temp.u32);
	// lwz r11,-16(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// cmpw cr6,r11,r9
	// bge cr6,0x825751bc
	if (ctx.r11.s32 < ctx.r9.s32) {
		// mr r9,r11
		ctx.r9.u64 = ctx.r11.u64;
		// mr r3,r10
		ctx.r3.u64 = ctx.r10.u64;
	}
loc_825751BC:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r10,r5
	// blt cr6,0x82575184
	if (ctx.r10.s32 < ctx.r5.s32) goto loc_82575184;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_51D0_p39"))) PPC_WEAK_FUNC(phBoundCapsule_51D0_p39);
PPC_FUNC_IMPL(__imp__phBoundCapsule_51D0_p39) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r23 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	PPCRegister temp{};
	// FRAME: size=192, savegprlr_22
	// lis r11,-32254
	// mr r23,r3
	var_r23 = ctx.r3.u32;
	// mr r27,r4
	var_r27 = ctx.r4.u32;
	// mr r24,r9
	var_r24 = ctx.r9.u32;
	// mr r22,r10
	var_r22 = ctx.r10.u32;
	// lfs f4,16812(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16812);
	ctx.f4.f64 = double(temp.f32);
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// cmpwi cr6,r5,0
	// ble cr6,0x82575248
	if (ctx.r5.s32 > 0) {
		// rlwinm r11,r5,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
		// lis r4,32639
		ctx.r4.s64 = 2139029504;
		// addi r9,r1,80
		ctx.r9.s64 = ctx.r1.s64 + 80;
		// ori r4,r4,65518
		ctx.r4.u64 = ctx.r4.u64 | 65518;
		// rlwinm. r10,r11,30,2,31
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
		// beq 0x82575228
		if (ctx.r10.s32 != 0) {
			// mtctr r10
			ctx.ctr.u64 = ctx.r10.u64;
		loc_8257521C:
			// stw r4,0(r9)
			PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r4.u32);
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// bdnz 0x8257521c
			--ctx.ctr.u64;
			if (ctx.ctr.u32 != 0) goto loc_8257521C;
		}
	loc_82575228:
		// rlwinm. r11,r11,30,2,31
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
		// addi r10,r1,88
		ctx.r10.s64 = ctx.r1.s64 + 88;
		// li r9,0
		ctx.r9.s64 = 0;
		// beq 0x82575248
		if (ctx.r11.s32 == 0) goto loc_82575248;
		// mtctr r11
		ctx.ctr.u64 = ctx.r11.u64;
	loc_8257523C:
		// stw r9,0(r10)
		PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bdnz 0x8257523c
		--ctx.ctr.u64;
		if (ctx.ctr.u32 != 0) goto loc_8257523C;
	}
loc_82575248:
	// li r9,0
	ctx.r9.s64 = 0;
	// cmpwi cr6,r6,0
	// ble cr6,0x825752f8
	if (ctx.r6.s32 > 0) {
		// rlwinm r11,r5,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
		// lfs f12,0(r27)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r27 + 0);
		ctx.f12.f64 = double(temp.f32);
		// addi r10,r1,80
		ctx.r10.s64 = ctx.r1.s64 + 80;
		// lfs f11,4(r27)
		temp.u32 = PPC_LOAD_U32(var_r27 + 4);
		ctx.f11.f64 = double(temp.f32);
		// add r4,r11,r10
		ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	loc_82575268:
		// lfs f0,0(r3)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f0.f64 = double(temp.f32);
		// fsubs f0,f12,f0
		ctx.f0.f64 = double(float(ctx.f12.f64 - ctx.f0.f64));
		// lfs f10,4(r3)
		temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4)/* phBoundCapsule::flags@+0x4 */;
		ctx.f10.f64 = double(temp.f32);
		// lfs f9,-4(r4)
		temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -4);
		ctx.f9.f64 = double(temp.f32);
		// addi r3,r3,8
		ctx.r3.s64 = ctx.r3.s64 + 8;
		// fmuls f13,f0,f0
		ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
		// fsubs f0,f11,f10
		ctx.f0.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
		// fmadds f0,f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f13.f64));
		// fcmpu cr6,f0,f9
		// bge cr6,0x825752ec
		if (ctx.f0.f64 < ctx.f9.f64) {
			// addic. r11,r5,-1
			ctx.xer.ca = ctx.r5.u32 > 0;
			ctx.r11.s64 = ctx.r5.s64 + -1;
			// ble 0x825752d8
			if (ctx.r11.s32 > 0) {
				// rlwinm r10,r11,2,0,29
				ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
				// addi r10,r10,-4
				ctx.r10.s64 = ctx.r10.s64 + -4;
			loc_825752A0:
				// addi r31,r1,80
				var_r31 = (uint32_t)(ctx.r1.s64 + 80);
				// lfsx f13,r10,r31
				ctx.fpscr.disableFlushMode();
				temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + var_r31);
				ctx.f13.f64 = double(temp.f32);
				// fcmpu cr6,f0,f13
				// bgt cr6,0x825752d8
				if (ctx.f0.f64 > ctx.f13.f64) goto loc_825752D8;
				// bso cr6,0x825752d8
				// UNIMPLEMENTED: bso
				PPC_UNIMPLEMENTED(0x825752B0, "bso");
				// addi r31,r1,88
				var_r31 = (uint32_t)(ctx.r1.s64 + 88);
				// addi r30,r1,84
				var_r30 = (uint32_t)(ctx.r1.s64 + 84);
				// addi r29,r1,92
				var_r29 = (uint32_t)(ctx.r1.s64 + 92);
				// addic. r11,r11,-1
				ctx.xer.ca = ctx.r11.u32 > 0;
				ctx.r11.s64 = ctx.r11.s64 + -1;
				// lwzx r31,r10,r31
				var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r10.u32 + var_r31));
				// stfsx f13,r10,r30
				temp.f32 = float(ctx.f13.f64);
				PPC_STORE_U32(ctx.r10.u32 + var_r30, temp.u32);
				// stwx r31,r10,r29
				PPC_STORE_U32(ctx.r10.u32 + var_r29, var_r31);
				// addi r10,r10,-4
				ctx.r10.s64 = ctx.r10.s64 + -4;
				// bgt 0x825752a0
				if (ctx.r11.s32 > 0) goto loc_825752A0;
			}
		loc_825752D8:
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// addi r10,r1,80
			ctx.r10.s64 = ctx.r1.s64 + 80;
			// addi r31,r1,88
			var_r31 = (uint32_t)(ctx.r1.s64 + 88);
			// stfsx f0,r11,r10
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, temp.u32);
			// stwx r9,r11,r31
			PPC_STORE_U32(ctx.r11.u32 + var_r31, ctx.r9.u32);
		}
	loc_825752EC:
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// cmpw cr6,r9,r6
		// blt cr6,0x82575268
		if (ctx.r9.s32 < ctx.r6.s32) goto loc_82575268;
	}
loc_825752F8:
	// cmpwi cr6,r5,0
	// ble cr6,0x8257543c
	if (ctx.r5.s32 > 0) {
		// lis r11,-32256
		// lwz r28,284(r1)
		var_r28 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 284));
		// addi r26,r1,88
		var_r26 = (uint32_t)(ctx.r1.s64 + 88);
		// mr r25,r5
		var_r25 = ctx.r5.u32;
		// lfs f5,15788(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
		ctx.f5.f64 = double(temp.f32);
	loc_82575314:
		// lwz r29,0(r26)
		var_r29 = (uint32_t)(PPC_LOAD_U32(var_r26 + 0));
		// mr r11,r29
		ctx.r11.u64 = var_r29;
		// cmplw cr6,r29,r6
		// blt cr6,0x82575328
		if (var_r29 >= ctx.r6.u32) {
			// li r11,0
			ctx.r11.s64 = 0;
		}
	loc_82575328:
		// rlwinm r11,r11,3,0,28
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
		// lfs f8,4(r27)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r27 + 4);
		ctx.f8.f64 = double(temp.f32);
		// lfs f9,0(r27)
		temp.u32 = PPC_LOAD_U32(var_r27 + 0);
		ctx.f9.f64 = double(temp.f32);
		// rlwinm r10,r29,3,0,28
		ctx.r10.u64 = __builtin_rotateleft64(var_r29 | (var_r29 << 32), 3) & 0xFFFFFFF8;
		// add r11,r11,r7
		ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
		// add r31,r10,r8
		var_r31 = (uint32_t)(ctx.r10.u64 + ctx.r8.u64);
		// li r10,0
		ctx.r10.s64 = 0;
		// cmpwi cr6,r28,0
		ctx.cr6.compare<int32_t>((int32_t)var_r28, 0, ctx.xer);
		// lfs f6,4(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		ctx.f6.f64 = double(temp.f32);
		// lfs f7,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f7.f64 = double(temp.f32);
		// fsubs f13,f8,f6
		ctx.f13.f64 = double(float(ctx.f8.f64 - ctx.f6.f64));
		// fsubs f0,f9,f7
		ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f7.f64));
		// lfs f12,4(r31)
		temp.u32 = PPC_LOAD_U32(var_r31 + 4)/* phBoundCapsule::flags@+0x4 */;
		ctx.f12.f64 = double(temp.f32);
		// lfs f11,0(r31)
		temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f11.f64 = double(temp.f32);
		// fmuls f10,f12,f13
		ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
		// fmuls f12,f12,f0
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
		// fmadds f0,f11,f0,f10
		ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f10.f64));
		// stfs f0,96(r1)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
		// fmsubs f0,f11,f13,f12
		ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f12.f64));
		// stfs f0,100(r1)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
		// ble cr6,0x8257539c
		if (ctx.cr6.gt) {
			// lwz r11,292(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
		loc_82575380:
			// lwz r9,0(r11)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			// cmpw cr6,r9,r29
			// beq cr6,0x82575454
			if (ctx.r9.s32 == (int32_t)var_r29) goto loc_82575454;
			// addi r10,r10,1
			ctx.r10.s64 = ctx.r10.s64 + 1;
			// addi r11,r11,4
			ctx.r11.s64 = ctx.r11.s64 + 4;
			// cmpw cr6,r10,r28
			// blt cr6,0x82575380
			if (ctx.r10.s32 < (int32_t)var_r28) goto loc_82575380;
		}
	loc_8257539C:
		// mr r30,r22
		var_r30 = (uint32_t)(var_r22);
	loc_825753A0:
		// mr r5,r24
		ctx.r5.u64 = var_r24;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// addi r3,r1,96
		ctx.r3.s64 = ctx.r1.s64 + 96;
		// bl 0x82575158
		phBoundCapsule_5158_p39(ctx, base);
		// mr r11,r3
		ctx.r11.u64 = ctx.r3.u64;
		// cmplw cr6,r3,r24
		// blt cr6,0x825753c0
		if (ctx.r3.u32 >= var_r24) {
			// li r11,0
			ctx.r11.s64 = 0;
		}
	loc_825753C0:
		// lfs f13,4(r31)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r31 + 4)/* phBoundCapsule::flags@+0x4 */;
		ctx.f13.f64 = double(temp.f32);
		// rlwinm r11,r11,3,0,28
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
		// fmuls f10,f13,f13
		ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
		// lfs f0,0(r31)
		temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f0.f64 = double(temp.f32);
		// add r11,r11,r30
		ctx.r11.u64 = ctx.r11.u64 + var_r30;
		// lfs f11,4(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		ctx.f11.f64 = double(temp.f32);
		// fmuls f3,f13,f11
		ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
		// lfs f12,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fmuls f11,f0,f11
		ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
		// fmadds f10,f0,f0,f10
		ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f10.f64));
		// fmsubs f3,f0,f12,f3
		ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f12.f64 - ctx.f3.f64));
		// fmadds f12,f13,f12,f11
		ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
		// fdivs f0,f5,f10
		ctx.f0.f64 = double(float(ctx.f5.f64 / ctx.f10.f64));
		// fmuls f13,f3,f0
		ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
		// fmuls f12,f12,f0
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
		// fadds f13,f13,f7
		ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
		// fadds f12,f12,f6
		ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f6.f64));
		// fsubs f0,f9,f13
		ctx.f0.f64 = double(float(ctx.f9.f64 - ctx.f13.f64));
		// fmuls f11,f0,f0
		ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
		// fsubs f0,f8,f12
		ctx.f0.f64 = double(float(ctx.f8.f64 - ctx.f12.f64));
		// fmadds f0,f0,f0,f11
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f11.f64));
		// fcmpu cr6,f0,f4
		// bge cr6,0x82575430
		if (ctx.f0.f64 < ctx.f4.f64) {
			// stfs f13,80(r1)
			temp.f32 = float(ctx.f13.f64);
			PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
			// fmr f4,f0
			ctx.f4.f64 = ctx.f0.f64;
			// stfs f12,84(r1)
			temp.f32 = float(ctx.f12.f64);
			PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
			// stw r29,0(r23)
			PPC_STORE_U32(var_r23 + 0, var_r29);
			// stw r3,4(r23)
			PPC_STORE_U32(var_r23 + 4, ctx.r3.u32);
		}
	loc_82575430:
		// addic. r25,r25,-1
		ctx.xer.ca = var_r25 > 0;
		var_r25 = (uint32_t)(var_r25 + -1);
		// addi r26,r26,4
		var_r26 = (uint32_t)(var_r26 + 4);
		// bne 0x82575314
		if ((int32_t)var_r25 != 0) goto loc_82575314;
	}
loc_8257543C:
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r27 + 0, temp.u32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,4(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r27 + 4, temp.u32);
	return;
loc_82575454:
	// lwz r30,276(r1)
	var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 276));
	// b 0x825753a0
	goto loc_825753A0;
}

__attribute__((alias("__imp__phBoundCapsule_5460_p39"))) PPC_WEAK_FUNC(phBoundCapsule_5460_p39);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5460_p39) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r19 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r18 = 0;
	uint32_t var_r17 = 0;
	uint32_t var_r16 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=336, savegprlr_16
	// lis r11,-32255
	// lis r10,-32164
	// mr r19,r3
	var_r19 = ctx.r3.u32;
	// mr r20,r5
	var_r20 = ctx.r5.u32;
	// addi r23,r10,9960
	var_r23 = (uint32_t)(ctx.r10.s64 + 9960);  // lbl_825C26E8 @ 0x825c26e8
	// lfs f0,21604(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21604);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	// fcmpu cr6,f1,f0
	// addi r11,r11,11264
	ctx.r11.s64 = ctx.r11.s64 + 11264;
	// ble cr6,0x825754a8
	if (ctx.f1.f64 > ctx.f0.f64) {
		// addi r10,r11,1644
		ctx.r10.s64 = ctx.r11.s64 + 1644;
		// mr r21,r11
		var_r21 = ctx.r11.u32;
		// mr r9,r23
		ctx.r9.u64 = var_r23;
		// b 0x825754b4
	} else {
	loc_825754A8:
		// addi r21,r11,48
		var_r21 = (uint32_t)(ctx.r11.s64 + 48);  // addr:0x82020030
		// addi r9,r23,24
		ctx.r9.s64 = (int64_t)(int32_t)var_r23 + 24;
		// addi r10,r11,2744
		ctx.r10.s64 = ctx.r11.s64 + 2744;
	}
loc_825754B4:
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
	// addi r8,r11,4324
	ctx.r8.s64 = ctx.r11.s64 + 4324;
	// addi r10,r11,3600
	ctx.r10.s64 = ctx.r11.s64 + 3600;
	// addi r11,r11,4984
	ctx.r11.s64 = ctx.r11.s64 + 4984;
	// cmpwi cr6,r20,0
	// stw r8,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r8.u32);
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r11.u32);
	// ble cr6,0x82575508
	if ((int32_t)var_r20 > 0) {
		// addi r10,r1,144
		ctx.r10.s64 = ctx.r1.s64 + 144;
		// mr r11,r21
		ctx.r11.u64 = var_r21;
		// subf r7,r21,r10
		ctx.r7.s64 = ctx.r10.s64 - (int64_t)(int32_t)var_r21;
		// subf r8,r21,r19
		ctx.r8.s64 = (int64_t)(int32_t)var_r19 - (int64_t)(int32_t)var_r21;
		// mr r10,r20
		ctx.r10.u64 = var_r20;
	loc_825754EC:
		// lfsx f0,r8,r11
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r11.u32);
		ctx.f0.f64 = double(temp.f32);
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// lfs f13,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fsubs f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
		// stfsx f0,r7,r11
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r7.u32 + ctx.r11.u32, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x825754ec
		if (ctx.r10.s32 != 0) goto loc_825754EC;
	}
loc_82575508:
	// addi r11,r23,48
	ctx.r11.s64 = (int64_t)(int32_t)var_r23 + 48;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r30,r11,-16
	var_r30 = (uint32_t)(ctx.r11.s64 + -16);  // addr:0x8201fff0
	// lis r11,-32256
	// li r24,0
	var_r24 = 0;
	// li r25,0
	var_r25 = 0;
	// li r27,0
	var_r27 = 0;
	// addi r31,r1,144
	var_r31 = (uint32_t)(ctx.r1.s64 + 144);
	// lfs f31,15784(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	var_f31 = double(temp.f32);
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r28,r1,128
	var_r28 = (uint32_t)(ctx.r1.s64 + 128);
	// addi r26,r1,148
	var_r26 = (uint32_t)(ctx.r1.s64 + 148);
	// subf r22,r10,r9
	var_r22 = (uint32_t)(ctx.r9.s64 - ctx.r10.s64);
loc_8257553C:
	// lwzx r11,r22,r28
	ctx.r11.u64 = PPC_LOAD_U32(var_r22 + var_r28);
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// li r8,2
	ctx.r8.s64 = 2;
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
loc_82575550:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = var_f31;
	// cmpwi cr6,r27,0
	// ble cr6,0x8257557c
	if ((int32_t)var_r27 > 0) {
		// addi r11,r1,144
		ctx.r11.s64 = ctx.r1.s64 + 144;
		// mr r9,r24
		ctx.r9.u64 = var_r24;
	loc_82575564:
		// lfsx f13,r10,r11
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
		ctx.f13.f64 = double(temp.f32);
		// addic. r9,r9,-1
		ctx.xer.ca = ctx.r9.u32 > 0;
		ctx.r9.s64 = ctx.r9.s64 + -1;
		// lfs f12,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fmadds f0,f13,f12,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f0.f64));
		// bne 0x82575564
		if (ctx.r9.s32 != 0) goto loc_82575564;
	}
loc_8257557C:
	// stfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// add r10,r27,r10
	ctx.r10.u64 = var_r27 + ctx.r10.u64;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// bne 0x82575550
	if (ctx.r8.s32 != 0) goto loc_82575550;
	// lfs f0,0(r31)
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// cmpwi cr6,r25,4
	ctx.cr6.compare<int32_t>((int32_t)var_r25, 4, ctx.xer);
	// lfs f13,0(r26)
	temp.u32 = PPC_LOAD_U32(var_r26 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f2,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f2.f64));
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// stfs f13,0(r26)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(var_r26 + 0, temp.u32);
	// bge cr6,0x825755fc
	if (ctx.cr6.lt) {
		// lwz r11,0(r28)
		ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 0);
		// li r5,2
		ctx.r5.s64 = 2;
		// mr r4,r31
		ctx.r4.u64 = var_r31;
		// mr r3,r29
		ctx.r3.u64 = var_r29;
		// lwz r18,28(r11)
		var_r18 = (uint32_t)(PPC_LOAD_U32(ctx.r11.u32 + 28));
		// lwz r17,24(r11)
		var_r17 = (uint32_t)(PPC_LOAD_U32(ctx.r11.u32 + 24));
		// lwz r16,20(r11)
		var_r16 = (uint32_t)(PPC_LOAD_U32(ctx.r11.u32 + 20));
		// lwz r10,16(r11)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
		// lwz r9,12(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
		// lwz r8,8(r11)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		// lwz r7,4(r11)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// lwz r6,0(r11)
		ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// stw r18,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r18);
		// stw r17,92(r1)
		PPC_STORE_U32(ctx.r1.u32 + 92, var_r17);
		// stw r16,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, var_r16);
		// bl 0x825751d0
		phBoundCapsule_51D0_p39(ctx, base);
		// b 0x82575650
	} else {
	loc_825755FC:
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// lwz r5,0(r11)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// lwz r4,4(r11)
		ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// bl 0x82575158
		phBoundCapsule_5158_p39(ctx, base);
		// li r11,0
		ctx.r11.s64 = 0;
		// stw r3,0(r29)
		PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r3.u32);
		// mr r10,r3
		ctx.r10.u64 = ctx.r3.u64;
		// stw r11,4(r29)
		PPC_STORE_U32(var_r29 + 4,/* phBoundCapsule::flags@+0x4 */ ctx.r11.u32);
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
		// lwz r9,0(r11)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		// lwz r11,4(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		// cmplw cr6,r10,r9
		// blt cr6,0x82575638
		if (ctx.r10.u32 >= ctx.r9.u32) {
			// li r10,0
			ctx.r10.s64 = 0;
		}
	loc_82575638:
		// rlwinm r10,r10,3,0,28
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
		// add r11,r10,r11
		ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
		// lfs f0,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// lfs f13,4(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		ctx.f13.f64 = double(temp.f32);
		// stfs f0,0(r31)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
		// stfs f13,4(r31)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(var_r31 + 4,/* phBoundCapsule::flags@+0x4 */ temp.u32);
	}
loc_82575650:
	// addi r11,r31,4
	ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 4;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// addi r6,r23,48
	ctx.r6.s64 = (int64_t)(int32_t)var_r23 + 48;
	// fadds f0,f0,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f2.f64));
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// addi r10,r24,1
	ctx.r10.s64 = (int64_t)(int32_t)var_r24 + 1;
	// addi r9,r27,4
	ctx.r9.s64 = (int64_t)(int32_t)var_r27 + 4;
	// addi r8,r26,4
	ctx.r8.s64 = (int64_t)(int32_t)var_r26 + 4;
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r7,r29,4
	ctx.r7.s64 = (int64_t)(int32_t)var_r29 + 4;
	// addi r30,r30,4
	var_r30 = (uint32_t)(var_r30 + 4);
	// fadds f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// addi r6,r6,8
	ctx.r6.s64 = ctx.r6.s64 + 8;
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r25,r25,1
	var_r25 = (uint32_t)(var_r25 + 1);
	// addi r28,r28,4
	var_r28 = (uint32_t)(var_r28 + 4);
	// addi r24,r10,1
	var_r24 = (uint32_t)(ctx.r10.s64 + 1);  // addr:0x825c0001
	// addi r27,r9,4
	var_r27 = (uint32_t)(ctx.r9.s64 + 4);  // addr:0x82020004
	// addi r26,r8,4
	var_r26 = (uint32_t)(ctx.r8.s64 + 4);  // addr:0x825c0004
	// addi r29,r7,4
	var_r29 = (uint32_t)(ctx.r7.s64 + 4);  // addr:0x82000004
	// addi r31,r11,4
	var_r31 = (uint32_t)(ctx.r11.s64 + 4);  // addr:0x82000004
	// cmpw cr6,r30,r6
	// blt cr6,0x8257553c
	if ((int32_t)var_r30 < ctx.r6.s32) goto loc_8257553C;
	// cmpwi cr6,r20,0
	// ble cr6,0x825756e8
	if ((int32_t)var_r20 > 0) {
		// addi r10,r1,144
		ctx.r10.s64 = ctx.r1.s64 + 144;
		// addi r8,r1,144
		ctx.r8.s64 = ctx.r1.s64 + 144;
		// subf r9,r10,r21
		ctx.r9.s64 = (int64_t)(int32_t)var_r21 - ctx.r10.s64;
		// addi r11,r1,144
		ctx.r11.s64 = ctx.r1.s64 + 144;
		// subf r8,r8,r19
		ctx.r8.s64 = (int64_t)(int32_t)var_r19 - ctx.r8.s64;
		// mr r10,r20
		ctx.r10.u64 = var_r20;
	loc_825756CC:
		// lfsx f0,r11,r9
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
		ctx.f0.f64 = double(temp.f32);
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// lfs f13,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fadds f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// stfsx f0,r11,r8
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + ctx.r8.u32, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x825756cc
		if (ctx.r10.s32 != 0) goto loc_825756CC;
	}
loc_825756E8:
	return;
}

__attribute__((alias("__imp__aud_56F8_h"))) PPC_WEAK_FUNC(aud_56F8_h);
PPC_FUNC_IMPL(__imp__aud_56F8_h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32254
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r11,r11,16816
	ctx.r11.s64 = ctx.r11.s64 + 16816;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// fmuls f13,f0,f0
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
loc_82575718:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 - ctx.f0.f64));
	// fmuls f0,f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fcmpu cr6,f0,f13
	// bge cr6,0x82575734
	if (ctx.f0.f64 < ctx.f13.f64) {
		// fmr f13,f0
		ctx.f13.f64 = ctx.f0.f64;
		// mr r3,r9
		ctx.r3.u64 = ctx.r9.u64;
	}
loc_82575734:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r8,r11,256
	ctx.r8.s64 = ctx.r11.s64 + 256;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r10,r8
	// blt cr6,0x82575718
	if (ctx.r10.s32 < ctx.r8.s32) goto loc_82575718;
	// blr
	return;
}

__attribute__((alias("__imp__aud_5750"))) PPC_WEAK_FUNC(aud_5750);
PPC_FUNC_IMPL(__imp__aud_5750) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// FRAME: size=96, manual
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,22700(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22700);  /* glob:lbl_820058AC @ 0x820058ac */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	// bgt cr6,0x82575770
	if (ctx.f1.f64 <= ctx.f0.f64) {
		// fmr f1,f0
		ctx.f1.f64 = ctx.f0.f64;
	}
loc_82575770:
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f0,11192(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11192);  /* glob:lbl_82022BB8 @ 0x82022bb8 */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	// ble cr6,0x82575784
	if (ctx.f1.f64 > ctx.f0.f64) {
		// fmr f1,f0
		ctx.f1.f64 = ctx.f0.f64;
	}
loc_82575784:
	// bl 0x82432458
	aud_2458(ctx, base);
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfd f0,17080(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 17080);  /* glob:lbl_820242B8 @ 0x820242b8 */
	// lis r11,-32254
	// fsub f0,f0,f1
	ctx.f0.f64 = ctx.f0.f64 - ctx.f1.f64;
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,17072(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17072);  /* glob:lbl_820242B0 @ 0x820242b0 */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:0x82023da8 */
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// fcmpu cr6,f0,f13
	// lfs f13,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// ble cr6,0x825757c8
	if (ctx.f0.f64 > ctx.f13.f64) {
		// fadds f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// b 0x825757cc
	} else {
	loc_825757C8:
		// fsubs f0,f0,f13
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	}
loc_825757CC:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// blr
	return;
}

__attribute__((alias("__imp__aud_57E8_h"))) PPC_WEAK_FUNC(aud_57E8_h);
PPC_FUNC_IMPL(__imp__aud_57E8_h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// FRAME: size=96, manual
	// extsw r10,r3
	ctx.r10.s64 = ctx.r3.s32;
	// lis r11,-32254
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfs f0,11200(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11200);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,11196(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11196);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// bl 0x82432478
	aud_2478(ctx, base);
	// frsp f1,f1
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5838_p39"))) PPC_WEAK_FUNC(phBoundCapsule_5838_p39);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5838_p39) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32254
	// fmuls f13,f3,f3
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r11,r11,17088
	ctx.r11.s64 = ctx.r11.s64 + 17088;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
loc_82575854:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f3,f0
	ctx.f0.f64 = double(float(ctx.f3.f64 - ctx.f0.f64));
	// fmuls f0,f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fcmpu cr6,f0,f13
	// bge cr6,0x82575870
	if (ctx.f0.f64 < ctx.f13.f64) {
		// fmr f13,f0
		ctx.f13.f64 = ctx.f0.f64;
		// mr r8,r9
		ctx.r8.u64 = ctx.r9.u64;
	}
loc_82575870:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r6,r11,32
	ctx.r6.s64 = ctx.r11.s64 + 32;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpw cr6,r10,r6
	// blt cr6,0x82575854
	if (ctx.r10.s32 < ctx.r6.s32) goto loc_82575854;
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// fsubs f0,f1,f2
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64 - ctx.f2.f64));
	// lfsx f13,r10,r11
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f2.f64));
	// fmuls f0,f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fcmpu cr6,f13,f0
	// bge cr6,0x825758a8
	if (ctx.f13.f64 < ctx.f0.f64) {
		// li r7,1
		ctx.r7.s64 = 1;
	}
loc_825758A8:
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r8
	ctx.r3.u64 = ctx.r11.u64 + ctx.r8.u64;
	// blr
	return;
}

__attribute__((alias("__imp__aud_58B8_h"))) PPC_WEAK_FUNC(aud_58B8_h);
PPC_FUNC_IMPL(__imp__aud_58B8_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=128, savegprlr_29
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// fmr f31,f1
	var_f31 = ctx.f1.f64;
	// lis r10,-32254
	// rlwinm r31,r11,0,28,28
	var_r31 = (uint32_t)(__builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x8);
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// addi r3,r10,17088
	ctx.r3.s64 = ctx.r10.s64 + 17088;
	// li r4,8
	ctx.r4.s64 = 8;
	// subf r5,r31,r11
	ctx.r5.s64 = ctx.r11.s64 - (int64_t)(int32_t)var_r31;
	// mr r30,r6
	var_r30 = ctx.r6.u32;
	// bl 0x82575140
	aud_5140_h(ctx, base);
	// stfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(var_r30 + 0, temp.u32);
	// cmpwi cr6,r31,0
	// bne cr6,0x82575904
	if ((int32_t)var_r31 == 0) {
		// stfs f31,0(r29)
		temp.f32 = float(var_f31);
		PPC_STORE_U32(var_r29 + 0, temp.u32);
		// b 0x82575908
	} else {
	loc_82575904:
		// stfs f1,0(r29)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f1.f64);
		PPC_STORE_U32(var_r29 + 0, temp.u32);
	}
loc_82575908:
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5918_2h"))) PPC_WEAK_FUNC(phBoundCapsule_5918_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5918_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r26 = 0;
	double var_f27 = 0.0;
	double var_f29 = 0.0;
	double var_f28 = 0.0;
	double var_f26 = 0.0;
	double var_f31 = 0.0;
	double var_f30 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f888
	ctx.lr = 0x82575920;
	__savegprlr_24(ctx, base);
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x82436610
	__savefpr_26(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r27,r5
	var_r27 = ctx.r5.u32;
	// addi r28,r31,16
	var_r28 = (uint32_t)(var_r31 + 16);
	// mr r29,r7
	var_r29 = ctx.r7.u32;
	// lfs f27,15788(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
	var_f27 = double(temp.f32);
	// lis r11,-32248
	// lwz r30,40(r31)
	var_r30 = (uint32_t)(PPC_LOAD_U32(var_r31 + 40));
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r24,r6
	var_r24 = ctx.r6.u32;
	// lfs f29,32(r31)
	temp.u32 = PPC_LOAD_U32(var_r31 + 32);
	var_f29 = double(temp.f32);
	// mr r6,r29
	ctx.r6.u64 = var_r29;
	// lfs f28,36(r31)
	temp.u32 = PPC_LOAD_U32(var_r31 + 36);
	var_f28 = double(temp.f32);
	// li r5,161
	ctx.r5.s64 = 161;
	// lfs f26,-25000(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25000);
	var_f26 = double(temp.f32);
	// lwz r11,44(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 44);
	// mr r4,r27
	ctx.r4.u64 = var_r27;
	// addi r25,r11,-150
	var_r25 = (uint32_t)(ctx.r11.s64 + -150);  // addr:0x8207ff6a
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
	// li r26,0
	var_r26 = 0;
	// lfsx f31,r11,r31
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
	var_f31 = double(temp.f32);
	// lfsx f30,r11,r28
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r28);
	var_f30 = double(temp.f32);
	// bl 0x825766e8
	phBoundCapsule_66E8_2h(ctx, base);
	// lis r9,-32254
	// lis r11,-32254
	// li r10,0
	ctx.r10.s64 = 0;
	// lfs f12,17128(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 17128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,17124(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17124);
	ctx.f11.f64 = double(temp.f32);
loc_8257599C:
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r29 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// fmuls f10,f31,f12
	ctx.f10.f64 = double(float(var_f31 * ctx.f12.f64));
	// fmuls f13,f0,f11
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfs f9,4(r29)
	temp.u32 = PPC_LOAD_U32(var_r29 + 4)/* phBoundCapsule::flags@+0x4 */;
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f30,f12
	ctx.f8.f64 = double(float(var_f30 * ctx.f12.f64));
	// addi r11,r30,1
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 1;
	// cmpw cr6,r10,r25
	ctx.cr6.compare<int32_t>(ctx.r10.s32, (int32_t)var_r25, ctx.xer);
	// srawi r9,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r9.s64 = ctx.r11.s32 >> 2;
	// addze r9,r9
	temp.s64 = ctx.r9.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r9.s64 = temp.s64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r30,r9,r11
	var_r30 = (uint32_t)(ctx.r11.s64 - ctx.r9.s64);
	// fmadds f31,f0,f13,f10
	var_f31 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f10.f64));
	// fmadds f30,f9,f13,f8
	var_f30 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f8.f64));
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r11,r31
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r31);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f10,r11,r28
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r28);
	ctx.f10.f64 = double(temp.f32);
	// stfsx f31,r11,r31
	temp.f32 = float(var_f31);
	PPC_STORE_U32(ctx.r11.u32 + var_r31, temp.u32);
	// stfsx f30,r11,r28
	temp.f32 = float(var_f30);
	PPC_STORE_U32(ctx.r11.u32 + var_r28, temp.u32);
	// fmuls f9,f28,f31
	ctx.f9.f64 = double(float(var_f28 * var_f31));
	// fadds f8,f29,f31
	ctx.f8.f64 = double(float(var_f29 + var_f31));
	// fadds f7,f28,f30
	ctx.f7.f64 = double(float(var_f28 + var_f30));
	// fmuls f0,f29,f31
	ctx.f0.f64 = double(float(var_f29 * var_f31));
	// fmsubs f9,f29,f30,f9
	ctx.f9.f64 = double(float(var_f29 * var_f30 - ctx.f9.f64));
	// fsubs f29,f8,f13
	var_f29 = double(float(ctx.f8.f64 - ctx.f13.f64));
	// fsubs f28,f7,f10
	var_f28 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fabs f13,f9
	ctx.f13.u64 = ctx.f9.u64 & ~0x8000000000000000;
	// blt cr6,0x82575a34
	if (!(ctx.cr6.lt)) {
		// fmuls f10,f13,f27
		ctx.f10.f64 = double(float(ctx.f13.f64 * var_f27));
		// stfs f10,80(r1)
		temp.f32 = float(ctx.f10.f64);
		PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
		// fmuls f10,f0,f26
		ctx.f10.f64 = double(float(ctx.f0.f64 * var_f26));
		// stfs f10,88(r1)
		temp.f32 = float(ctx.f10.f64);
		PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
		// lwz r9,88(r1)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// cmpw cr6,r11,r9
		// ble cr6,0x82575a34
		if (ctx.r11.s32 <= ctx.r9.s32) goto loc_82575A34;
		// fmr f27,f0
		var_f27 = ctx.f0.f64;
		// mr r26,r10
		var_r26 = ctx.r10.u32;
		// fmr f26,f13
		var_f26 = ctx.f13.f64;
	}
loc_82575A34:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r29,r29,8
	var_r29 = (uint32_t)(var_r29 + 8);
	// cmpwi cr6,r10,160
	// blt cr6,0x8257599c
	if (ctx.r10.s32 < 160) goto loc_8257599C;
	// lis r11,-32254
	// stfs f29,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(var_f29);
	PPC_STORE_U32(var_r31 + 32, temp.u32);
	// stfs f28,36(r31)
	temp.f32 = float(var_f28);
	PPC_STORE_U32(var_r31 + 36, temp.u32);
	// cmpwi cr6,r26,80
	// stw r26,44(r31)
	PPC_STORE_U32(var_r31 + 44, var_r26);
	// stw r30,40(r31)
	PPC_STORE_U32(var_r31 + 40, var_r30);
	// lfs f0,17120(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17120);
	ctx.f0.f64 = double(temp.f32);
	// srawi r11,r24,1
	ctx.xer.ca = ((int32_t)var_r24 < 0) & ((var_r24 & 0x1) != 0);
	ctx.r11.s64 = (int32_t)var_r24 >> 1;
	// subf r11,r11,r27
	ctx.r11.s64 = (int64_t)(int32_t)var_r27 - ctx.r11.s64;
	// ble cr6,0x82575ac8
	if ((int32_t)var_r26 > 80) {
		// extsw r11,r11
		ctx.r11.s64 = ctx.r11.s32;
		// subfic r9,r26,160
		ctx.xer.ca = var_r26 <= 160;
		ctx.r9.s64 = 160 - (int64_t)(int32_t)var_r26;
		// addi r10,r1,88
		ctx.r10.s64 = ctx.r1.s64 + 88;
		// extsw r9,r9
		ctx.r9.s64 = ctx.r9.s32;
		// std r11,80(r1)
		PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
		// lis r11,-32256
		// std r9,88(r1)
		PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
		// lfd f13,88(r1)
		ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
		// fcfid f13,f13
		ctx.f13.f64 = double(ctx.f13.s64);
		// frsp f13,f13
		ctx.f13.f64 = double(float(ctx.f13.f64));
		// lfd f12,80(r1)
		ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
		// fcfid f12,f12
		ctx.f12.f64 = double(ctx.f12.s64);
		// frsp f12,f12
		ctx.f12.f64 = double(float(ctx.f12.f64));
		// fmuls f12,f12,f13
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
		// lfs f13,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
		ctx.f13.f64 = double(temp.f32);
		// fmadds f0,f12,f0,f13
		ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
		// fctiwz f0,f0
		ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
		// stfiwx f0,0,r10
		PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
		// lwz r3,88(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
		// cmpwi cr6,r3,40
		// ble cr6,0x82575b0c
		if (ctx.r3.s32 <= 40) {
			// addi r1,r1,224
			ctx.r1.s64 = ctx.r1.s64 + 224;
			// addi r12,r1,-72
			ctx.r12.s64 = ctx.r1.s64 + -72;
			// bl 0x8243665c
			__restfpr_26(ctx, base);
			// b 0x8242f8d8
			__restgprlr_24(ctx, base);
			return;
		}
		// li r3,40
		ctx.r3.s64 = 40;
		// b 0x82575b0c
	} else {
	loc_82575AC8:
		// mullw r11,r11,r26
		ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t((int32_t)var_r26);
		// extsw r11,r11
		ctx.r11.s64 = ctx.r11.s32;
		// addi r10,r1,80
		ctx.r10.s64 = ctx.r1.s64 + 80;
		// std r11,88(r1)
		PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
		// lfd f13,88(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
		// fcfid f13,f13
		ctx.f13.f64 = double(ctx.f13.s64);
		// lis r11,-32256
		// frsp f12,f13
		ctx.f12.f64 = double(float(ctx.f13.f64));
		// lfs f13,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
		ctx.f13.f64 = double(temp.f32);
		// fmadds f0,f12,f0,f13
		ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
		// fctiwz f0,f0
		ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
		// stfiwx f0,0,r10
		PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// neg r3,r11
		ctx.r3.s64 = static_cast<int64_t>(-ctx.r11.u64);
		// cmpwi cr6,r3,-40
		// bge cr6,0x82575b0c
		if (ctx.r3.s32 >= -40) {
			// addi r1,r1,224
			ctx.r1.s64 = ctx.r1.s64 + 224;
			// addi r12,r1,-72
			ctx.r12.s64 = ctx.r1.s64 + -72;
			// bl 0x8243665c
			__restfpr_26(ctx, base);
			// b 0x8242f8d8
			__restgprlr_24(ctx, base);
			return;
		}
		// li r3,-40
	}
loc_82575B0C:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// addi r12,r1,-72
	ctx.r12.s64 = ctx.r1.s64 + -72;
	// bl 0x8243665c
	__restfpr_26(ctx, base);
	// b 0x8242f8d8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5B20_p33"))) PPC_WEAK_FUNC(phBoundCapsule_5B20_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5B20_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=112, manual
	// lis r11,-32161
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// li r4,48
	ctx.r4.s64 = 48;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,-22272(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22272);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// stw r31,0(r30)
	PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ var_r31);
	// bne 0x82575b64
	if ((int32_t)var_r31 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82575bb8
	} else {
	loc_82575B64:
		// lis r11,-32256
		// lis r30,-32161
		var_r30 = (uint32_t)(-2107703296);
		// li r5,16
		ctx.r5.s64 = 16;
		// li r4,0
		ctx.r4.s64 = 0;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// lfs f0,15784(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
		ctx.f0.f64 = double(temp.f32);
		// li r11,0
		ctx.r11.s64 = 0;
		// stfs f0,32(r31)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r31 + 32, temp.u32);
		// stfs f0,36(r31)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r31 + 36, temp.u32);
		// stw r11,44(r31)
		PPC_STORE_U32(var_r31 + 44, ctx.r11.u32);
		// stw r11,40(r31)
		PPC_STORE_U32(var_r31 + 40, ctx.r11.u32);
		// lwz r11,-22264(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22264);
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// lwz r11,-22264(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22264);
		// li r5,16
		ctx.r5.s64 = 16;
		// li r4,0
		ctx.r4.s64 = 0;
		// addi r3,r31,16
		ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 16;
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// li r3,0
		ctx.r3.s64 = 0;
	}
loc_82575BB8:
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5BD0_p33"))) PPC_WEAK_FUNC(phBoundCapsule_5BD0_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5BD0_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// cmplwi r3,0
	// beq 0x82575c08
	if (ctx.r3.u32 != 0) {
		// lis r11,-32161
		ctx.r11.s64 = -2107703296;
		// lwz r11,-22268(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22268);
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// stw r11,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
	}
loc_82575C08:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5C20_p33"))) PPC_WEAK_FUNC(phBoundCapsule_5C20_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5C20_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=112, savegprlr_29
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// cmplwi cr6,r29,0
	// bne cr6,0x82575c40
	if (var_r29 == 0) {
	loc_82575C38:
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82575cc0
		return;
	}
loc_82575C40:
	// li r11,0
	ctx.r11.s64 = 0;
	// lis r30,-32161
	var_r30 = (uint32_t)(-2107703296);
	// li r4,12
	ctx.r4.s64 = 12;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r29)
	PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
	// lwz r11,-22272(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22272);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// mr. r31,r3
	var_r31 = ctx.r3.u32;
	// beq 0x82575c38
	if ((int32_t)var_r31 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82575cc0
		return;
	}
	// stw r31,0(r29)
	PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ var_r31);
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r11,-22272(r30)
	ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22272);
	// li r3,13
	ctx.r3.s64 = 13;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmplwi r3,0
	// stw r3,8(r31)
	PPC_STORE_U32(var_r31 + 8, ctx.r3.u32);
	// beq 0x82575c38
	if (ctx.r3.u32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82575cc0
		return;
	}
	// lis r11,-32256
	// lis r10,-32161
	// li r5,52
	ctx.r5.s64 = 52;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f0,27352(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27352);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// lfs f13,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(var_r31 + 4,/* phBoundCapsule::flags@+0x4 */ temp.u32);
	// lwz r11,-22264(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22264);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82575CC0:
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5CC8_p33"))) PPC_WEAK_FUNC(phBoundCapsule_5CC8_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5CC8_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// lwz r31,0(r3)
	var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */);
	// cmplwi r31,0
	// beq 0x82575d1c
	if (var_r31 != 0) {
		// lwz r3,8(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
		// lis r30,-32161
		var_r30 = (uint32_t)(-2107703296);
		// cmplwi r3,0
		// beq 0x82575d0c
		if (ctx.r3.u32 != 0) {
			// lwz r11,-22268(r30)
			ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// li r11,0
			ctx.r11.s64 = 0;
			// stw r11,8(r31)
			PPC_STORE_U32(var_r31 + 8, ctx.r11.u32);
		}
	loc_82575D0C:
		// lwz r11,-22268(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + -22268);
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	}
loc_82575D1C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5D38_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_5D38_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5D38_2hr) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r10,-32256
	// addic. r11,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r11.s64 = ctx.r4.s64 + -1;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lfs f0,15784(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15784);
	ctx.f0.f64 = double(temp.f32);
	// fmr f12,f0
	ctx.f12.f64 = ctx.f0.f64;
	// blt 0x82575d6c
	if (ctx.r11.s32 >= 0) {
		// rlwinm r10,r11,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// add r10,r10,r3
		ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	loc_82575D58:
		// lfs f13,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addic. r9,r9,-1
		ctx.xer.ca = ctx.r9.u32 > 0;
		ctx.r9.s64 = ctx.r9.s64 + -1;
		// fadds f12,f13,f12
		ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
		// addi r10,r10,-4
		ctx.r10.s64 = ctx.r10.s64 + -4;
		// bge 0x82575d58
		if (ctx.r9.s32 >= 0) goto loc_82575D58;
	}
loc_82575D6C:
	// lis r10,-32256
	// cmpwi cr6,r11,0
	// lfs f13,27204(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27204);
	ctx.f13.f64 = double(temp.f32);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// blt cr6,0x82575dac
	if (ctx.r11.s32 >= 0) {
		// rlwinm r11,r11,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// add r11,r11,r3
		ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	loc_82575D8C:
		// lfs f12,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fadds f0,f12,f0
		ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
		// fcmpu cr6,f0,f13
		// bso cr6,0x82575da0
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x82575D98, "bso");
		// bge cr6,0x82575dac
		if (ctx.f0.f64 >= ctx.f13.f64) {
			// addi r3,r10,2
			ctx.r3.s64 = ctx.r10.s64 + 2;
			// cmpwi cr6,r3,76
			// bgelr cr6
			if (ctx.r3.s32 >= 76) return;
			// li r3,76
			ctx.r3.s64 = 76;
			// blr
			return;
		}
	loc_82575DA0:
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// addi r11,r11,-4
		ctx.r11.s64 = ctx.r11.s64 + -4;
		// bge 0x82575d8c
		if (ctx.r10.s32 >= 0) goto loc_82575D8C;
	}
loc_82575DAC:
	// addi r3,r10,2
	ctx.r3.s64 = ctx.r10.s64 + 2;
	// cmpwi cr6,r3,76
	// bgelr cr6
	if (ctx.r3.s32 >= 76) return;
	// li r3,76
	ctx.r3.s64 = 76;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5DC0_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_5DC0_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5DC0_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=688, savegprlr_27
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// addi r6,r4,1
	ctx.r6.s64 = ctx.r4.s64 + 1;
	// mr r27,r5
	var_r27 = ctx.r5.u32;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r31,r1,368
	var_r31 = (uint32_t)(ctx.r1.s64 + 368);
	// li r9,0
	ctx.r9.s64 = 0;
	// srawi. r10,r6,1
	ctx.xer.ca = (ctx.r6.s32 < 0) & ((ctx.r6.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r6.s32 >> 1;
	// ble 0x82575e20
	if (ctx.r10.s32 > 0) {
		// mr r8,r3
		ctx.r8.u64 = ctx.r3.u64;
		// mr r7,r10
		ctx.r7.u64 = ctx.r10.u64;
		// mr r9,r10
		ctx.r9.u64 = ctx.r10.u64;
	loc_82575DFC:
		// lfs f0,0(r8)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addic. r7,r7,-1
		ctx.xer.ca = ctx.r7.u32 > 0;
		ctx.r7.s64 = ctx.r7.s64 + -1;
		// lfs f13,4(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 4);
		ctx.f13.f64 = double(temp.f32);
		// addi r8,r8,8
		ctx.r8.s64 = ctx.r8.s64 + 8;
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// stfs f13,0(r31)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// bne 0x82575dfc
		if (ctx.r7.s32 != 0) goto loc_82575DFC;
	}
loc_82575E20:
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r10,r6
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f31,15784(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
	var_f31 = double(temp.f32);
	// beq cr6,0x82575e50
	if (ctx.r10.s32 != ctx.r6.s32) {
		// rlwinm r10,r9,3,0,28
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
		// stfs f31,0(r31)
		temp.f32 = float(var_f31);
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// lfsx f0,r10,r3
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
		ctx.f0.f64 = double(temp.f32);
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
	}
loc_82575E50:
	// subfic r10,r9,65
	ctx.xer.ca = ctx.r9.u32 <= 65;
	ctx.r10.s64 = 65 - ctx.r9.s64;
	// lis r29,-32161
	var_r29 = (uint32_t)(-2107703296);
	// rlwinm r30,r10,2,0,29
	var_r30 = (uint32_t)(__builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = var_r30;
	// lwz r11,-22264(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22264);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// lwz r11,-22264(r29)
	ctx.r11.u64 = PPC_LOAD_U32(var_r29 + -22264);
	// mr r5,r30
	ctx.r5.u64 = var_r30;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// li r5,128
	ctx.r5.s64 = 128;
	// addi r4,r1,368
	ctx.r4.s64 = ctx.r1.s64 + 368;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x825767c8
	phBoundCapsule_67C8(ctx, base);
	// extsw r11,r28
	ctx.r11.s64 = (int32_t)var_r28;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32248
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,-24420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24420);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	// fdivs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// lfs f0,-23892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -23892);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// fcmpu cr6,f0,f31
	// ble cr6,0x82575ee4
	if (ctx.f0.f64 > var_f31) {
		// fadds f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// b 0x82575ee8
	} else {
	loc_82575EE4:
		// fsubs f0,f0,f13
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	}
loc_82575EE8:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addic. r11,r28,-1
	ctx.xer.ca = var_r28 > 0;
	ctx.r11.s64 = (int64_t)(int32_t)var_r28 + -1;
	// li r7,0
	ctx.r7.s64 = 0;
	// ble 0x82575f40
	if (ctx.r11.s32 > 0) {
		// mr r9,r27
		ctx.r9.u64 = var_r27;
		// li r10,16384
		ctx.r10.s64 = 16384;
		// mr r7,r11
		ctx.r7.u64 = ctx.r11.u64;
	loc_82575F0C:
		// srawi r8,r10,15
		ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFF) != 0);
		ctx.r8.s64 = ctx.r10.s32 >> 15;
		// addi r5,r1,96
		ctx.r5.s64 = ctx.r1.s64 + 96;
		// rlwinm r8,r8,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r4,r1,368
		ctx.r4.s64 = ctx.r1.s64 + 368;
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
		// add r10,r10,r6
		ctx.r10.u64 = ctx.r10.u64 + ctx.r6.u64;
		// lfsx f13,r8,r5
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r5.u32);
		ctx.f13.f64 = double(temp.f32);
		// fmuls f13,f13,f13
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
		// lfsx f0,r8,r4
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
		ctx.f0.f64 = double(temp.f32);
		// fmadds f0,f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f13.f64));
		// stfs f0,0(r9)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// bne 0x82575f0c
		if (!ctx.cr0.eq) goto loc_82575F0C;
	}
loc_82575F40:
	// mullw r11,r6,r7
	ctx.r11.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r7.s32);
	// addi r11,r11,16384
	ctx.r11.s64 = ctx.r11.s64 + 16384;
	// srawi r11,r11,15
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x7FFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 15;
	// cmpwi cr6,r11,64
	// blt cr6,0x82575f68
	if (ctx.r11.s32 >= 64) {
		// rlwinm r11,r7,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
		// add r11,r11,r27
		ctx.r11.u64 = ctx.r11.u64 + var_r27;
		// lfs f0,-4(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
		ctx.f0.f64 = double(temp.f32);
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// b 0x82575f8c
	} else {
	loc_82575F68:
		// rlwinm r11,r11,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r10,r1,96
		ctx.r10.s64 = ctx.r1.s64 + 96;
		// addi r9,r1,368
		ctx.r9.s64 = ctx.r1.s64 + 368;
		// rlwinm r8,r7,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
		// lfsx f13,r11,r10
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
		ctx.f13.f64 = double(temp.f32);
		// fmuls f13,f13,f13
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
		// lfsx f0,r11,r9
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
		ctx.f0.f64 = double(temp.f32);
		// fmadds f0,f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f13.f64));
		// stfsx f0,r8,r27
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r8.u32 + var_r27, temp.u32);
	}
loc_82575F8C:
	return;
}

__attribute__((alias("__imp__phBoundCapsule_5F98_2h"))) PPC_WEAK_FUNC(phBoundCapsule_5F98_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_5F98_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=656, manual
	// extsw r11,r4
	ctx.r11.s64 = ctx.r4.s32;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// mr r31,r6
	var_r31 = ctx.r6.u32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32254
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,17688(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17688);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f0,-23892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -23892);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f13,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f12,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// fcmpu cr6,f0,f13
	// ble cr6,0x82576004
	if (ctx.f0.f64 > ctx.f13.f64) {
		// fadds f0,f0,f12
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
		// b 0x82576008
	} else {
	loc_82576004:
		// fsubs f0,f0,f12
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	}
loc_82576008:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r11,r1,100
	ctx.r11.s64 = ctx.r1.s64 + 100;
	// addi r9,r8,16384
	ctx.r9.s64 = ctx.r8.s64 + 16384;
	// li r10,63
	ctx.r10.s64 = 63;
loc_82576024:
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// srawi r7,r7,15
	ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x7FFF) != 0);
	ctx.r7.s64 = ctx.r7.s32 >> 15;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f0,r7,r3
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82576024
	if (ctx.r10.s32 != 0) goto loc_82576024;
	// lis r10,-32161
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// li r5,260
	ctx.r5.s64 = 260;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,368
	ctx.r3.s64 = ctx.r1.s64 + 368;
	// lwz r11,-22264(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22264);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// li r5,128
	ctx.r5.s64 = 128;
	// addi r4,r1,368
	ctx.r4.s64 = ctx.r1.s64 + 368;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82576808
	phBoundCapsule_6808(ctx, base);
	// lis r9,-32256
	// addi r6,r31,1
	ctx.r6.s64 = (int64_t)(int32_t)var_r31 + 1;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,368
	ctx.r10.s64 = ctx.r1.s64 + 368;
	// srawi. r7,r6,1
	ctx.xer.ca = (ctx.r6.s32 < 0) & ((ctx.r6.u32 & 0x1) != 0);
	ctx.r7.s64 = ctx.r6.s32 >> 1;
	// lfs f0,27868(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27868);
	ctx.f0.f64 = double(temp.f32);
	// ble 0x825760c8
	if (ctx.r7.s32 > 0) {
		// mr r9,r7
		ctx.r9.u64 = ctx.r7.u64;
	loc_82576098:
		// lfs f13,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addi r8,r30,4
		ctx.r8.s64 = (int64_t)(int32_t)var_r30 + 4;
		// fmuls f13,f13,f0
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// stfs f13,0(r30)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
		// lfs f13,0(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addic. r9,r9,-1
		ctx.xer.ca = ctx.r9.u32 > 0;
		ctx.r9.s64 = ctx.r9.s64 + -1;
		// fmuls f13,f13,f0
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// stfs f13,0(r8)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
		// addi r30,r8,4
		var_r30 = (uint32_t)(ctx.r8.s64 + 4);  // addr:0x825c0004
		// bne 0x82576098
		if (ctx.r9.s32 != 0) goto loc_82576098;
	}
loc_825760C8:
	// rlwinm r10,r7,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r10,r6
	// beq cr6,0x825760e0
	if (ctx.r10.s32 != ctx.r6.s32) {
		// lfs f13,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// stfs f0,0(r30)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	}
loc_825760E0:
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_60F8"))) PPC_WEAK_FUNC(phBoundCapsule_60F8);
PPC_FUNC_IMPL(__imp__phBoundCapsule_60F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=608, savegprlr_27
	// mr r27,r5
	var_r27 = ctx.r5.u32;
	// fmr f31,f1
	var_f31 = ctx.f1.f64;
	// mr r29,r6
	var_r29 = ctx.r6.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r8,r29
	ctx.r8.u64 = var_r29;
	// mr r7,r27
	ctx.r7.u64 = var_r27;
	// li r6,43
	ctx.r6.s64 = 43;
	// li r5,87
	ctx.r5.s64 = 87;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// bl 0x82577d90
	phBoundCapsule_7D90_w(ctx, base);
	// extsw r11,r30
	ctx.r11.s64 = (int32_t)var_r30;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32254
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,17700(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17700);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x824321f0
	util_21F0(ctx, base);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f1.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r31,80(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 80));
	// cmpwi cr6,r31,7
	// ble cr6,0x82576174
	if ((int32_t)var_r31 > 7) {
		// li r31,7
		var_r31 = 7;
	}
loc_82576174:
	// mr r6,r31
	ctx.r6.u64 = var_r31;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	// bl 0x82575f98
	phBoundCapsule_5F98_2h(ctx, base);
	// lis r11,-32254
	// lfs f13,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// lfs f0,17696(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17696);
	ctx.f0.f64 = double(temp.f32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// bl 0x825778f0
	phBoundCapsule_78F0_w(ctx, base);
	// lis r11,-32248
	// mr r5,r31
	ctx.r5.u64 = var_r31;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f1,-24612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24612);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82577fa8
	phBoundCapsule_7FA8_2h(ctx, base);
	// mr r6,r30
	ctx.r6.u64 = var_r30;
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82575dc0
	phBoundCapsule_5DC0_2hr(ctx, base);
	// lis r11,-32255
	// lis r10,-32254
	// lfs f13,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(var_r29 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmpwi cr6,r9,0
	// lfs f0,-27004(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -27004);
	ctx.f0.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f0,17692(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17692);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f31,f0
	ctx.f0.f64 = double(float(var_f31 * ctx.f0.f64));
	// ble cr6,0x8257626c
	if (ctx.r9.s32 > 0) {
		// mr r6,r27
		ctx.r6.u64 = var_r27;
		// mr r7,r27
		ctx.r7.u64 = var_r27;
	loc_82576218:
		// lwz r10,0(r7)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
		// cmpw cr6,r10,r30
		// bge cr6,0x82576258
		if (ctx.r10.s32 < (int32_t)var_r30) {
			// rlwinm r9,r10,2,0,29
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
			// addi r5,r1,192
			ctx.r5.s64 = ctx.r1.s64 + 192;
			// lfsx f12,r9,r28
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + var_r28);
			ctx.f12.f64 = double(temp.f32);
			// lfsx f11,r9,r5
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
			ctx.f11.f64 = double(temp.f32);
			// fmuls f11,f11,f12
			ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
			// fcmpu cr6,f11,f13
			// blt cr6,0x82576258
			if (ctx.f11.f64 < ctx.f13.f64) goto loc_82576258;
			// bso cr6,0x82576258
			// UNIMPLEMENTED: bso
			PPC_UNIMPLEMENTED(0x82576240, "bso");
			// fcmpu cr6,f12,f0
			// ble cr6,0x82576258
			if (ctx.f12.f64 <= ctx.f0.f64) goto loc_82576258;
			// stw r10,0(r6)
			PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// addi r6,r6,4
			ctx.r6.s64 = ctx.r6.s64 + 4;
		}
	loc_82576258:
		// lwz r10,0(r29)
		ctx.r10.u64 = PPC_LOAD_U32(var_r29 + 0)/* phBoundCapsule::vtable@+0x0 */;
		// addi r8,r8,1
		ctx.r8.s64 = ctx.r8.s64 + 1;
		// addi r7,r7,4
		ctx.r7.s64 = ctx.r7.s64 + 4;
		// cmpw cr6,r8,r10
		// blt cr6,0x82576218
		if (ctx.r8.s32 < ctx.r10.s32) goto loc_82576218;
	}
loc_8257626C:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r11,2
	ctx.r8.s64 = ctx.r11.s64 + 2;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// add r9,r10,r27
	ctx.r9.u64 = ctx.r10.u64 + var_r27;
	// li r10,32767
	ctx.r10.s64 = 32767;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// stwx r10,r8,r27
	PPC_STORE_U32(ctx.r8.u32 + var_r27, ctx.r10.u32);
	// stwx r10,r7,r27
	PPC_STORE_U32(ctx.r7.u32 + var_r27, ctx.r10.u32);
	// stw r10,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r10.u32);
	// stw r11,0(r29)
	PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_62A8"))) PPC_WEAK_FUNC(phBoundCapsule_62A8);
PPC_FUNC_IMPL(__imp__phBoundCapsule_62A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=768, savegprlr_27
	// mr r27,r5
	var_r27 = ctx.r5.u32;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// li r5,92
	ctx.r5.s64 = 92;
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// bl 0x825769d0
	phBoundCapsule_69D0_w(ctx, base);
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,92
	ctx.r4.s64 = 92;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82576a30
	phBoundCapsule_6A30(ctx, base);
	// li r4,86
	ctx.r4.s64 = 86;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82575d38
	phBoundCapsule_5D38_2hr(ctx, base);
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// lfs f1,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// addi r5,r1,528
	ctx.r5.s64 = ctx.r1.s64 + 528;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// bl 0x825760f8
	phBoundCapsule_60F8(ctx, base);
	// lis r11,-32256
	// lfs f0,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// ble cr6,0x8257632c
	if (ctx.f0.f64 > ctx.f13.f64) {
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f13,15788(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
		ctx.f13.f64 = double(temp.f32);
		// fdivs f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
		// stfs f0,100(r1)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	}
loc_8257632C:
	// addic. r11,r30,-1
	ctx.xer.ca = var_r30 > 0;
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + -1;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// blt 0x8257636c
	if (ctx.r11.s32 >= 0) {
		// rlwinm r10,r11,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r9,r1,160
		ctx.r9.s64 = ctx.r1.s64 + 160;
		// add r10,r10,r9
		ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	loc_82576344:
		// lfs f13,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// fmuls f13,f0,f13
		ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
		// fsqrts f13,f13
		ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
		// fsqrts f13,f13
		ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
		// fsqrts f13,f13
		ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
		// stfs f13,0(r10)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r10,r10,-4
		ctx.r10.s64 = ctx.r10.s64 + -4;
		// bge 0x82576344
		if (ctx.r11.s32 >= 0) goto loc_82576344;
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	}
loc_8257636C:
	// addi r11,r1,116
	ctx.r11.s64 = ctx.r1.s64 + 116;
	// lfs f1,0(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r27 + 0);
	ctx.f1.f64 = double(temp.f32);
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// lwz r6,120(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// lfs f2,4(r27)
	temp.u32 = PPC_LOAD_U32(var_r27 + 4);
	ctx.f2.f64 = double(temp.f32);
	// addi r5,r1,528
	ctx.r5.s64 = ctx.r1.s64 + 528;
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82579868
	phBoundCapsule_9868_2hr(ctx, base);
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lfs f1,-4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82579498
	phBoundCapsule_9498_2h(ctx, base);
	// addi r31,r31,-1
	var_r31 = (uint32_t)(var_r31 + -1);
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr. r11,r31
	ctx.r11.u64 = var_r31;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// b 0x825763f4
	goto loc_825763F4;
	do {
		// rlwinm r11,r11,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r10,r1,128
		ctx.r10.s64 = ctx.r1.s64 + 128;
		// mr r6,r30
		ctx.r6.u64 = var_r30;
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// lfsx f1,r11,r10
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
		ctx.f1.f64 = double(temp.f32);
		// bl 0x825792a8
		phBoundCapsule_92A8_2h(ctx, base);
		// lwz r11,96(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
		// addi r9,r1,104
		ctx.r9.s64 = ctx.r1.s64 + 104;
		// rlwinm r10,r11,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// stfsx f1,r10,r9
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f1.f64);
		PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, temp.u32);
		// stw r11,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
		// bge 0x825763c4
		} while (ctx.r11.s32 >= 0);
	// lwz r11,116(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmpw cr6,r11,r31
	// bge cr6,0x82576474
	if (ctx.r11.s32 < (int32_t)var_r31) {
		// lis r10,-32254
		// cmpwi cr6,r11,0
		// addi r10,r10,17532
		ctx.r10.s64 = ctx.r10.s64 + 17532;
		// beq cr6,0x82576440
		if (ctx.r11.s32 != 0) {
			// lfs f13,104(r1)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
			ctx.f13.f64 = double(temp.f32);
			// rlwinm r8,r11,2,0,29
			ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// lfs f0,0(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			ctx.f0.f64 = double(temp.f32);
			// addi r7,r1,104
			ctx.r7.s64 = ctx.r1.s64 + 104;
			// fmuls f0,f13,f0
			ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
			// lfsx f13,r8,r7
			temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
			ctx.f13.f64 = double(temp.f32);
			// fcmpu cr6,f13,f0
			// blt cr6,0x825764a4
			if (ctx.f13.f64 < ctx.f0.f64) goto loc_825764A4;
			// bso cr6,0x825764a4
			// UNIMPLEMENTED: bso
			PPC_UNIMPLEMENTED(0x8257643C, "bso");
		}
	loc_82576440:
		// rlwinm r9,r11,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// lfs f0,4(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
		ctx.f0.f64 = double(temp.f32);
		// addi r8,r1,104
		ctx.r8.s64 = ctx.r1.s64 + 104;
		// rlwinm r7,r31,2,0,29
		ctx.r7.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
		// addi r6,r1,104
		ctx.r6.s64 = ctx.r1.s64 + 104;
		// lfsx f13,r9,r8
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
		ctx.f13.f64 = double(temp.f32);
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// lfsx f13,r7,r6
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f13,f0
		// blt cr6,0x8257646c
		if (ctx.f13.f64 >= ctx.f0.f64) {
			// bns cr6,0x825764a0
			// UNIMPLEMENTED: bns
			PPC_UNIMPLEMENTED(0x82576468, "bns");
		}
	loc_8257646C:
		// mr r9,r11
		ctx.r9.u64 = ctx.r11.u64;
		// b 0x825764a4
	} else {
	loc_82576474:
		// lis r11,-32254
		// lfs f13,104(r1)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
		ctx.f13.f64 = double(temp.f32);
		// addi r10,r1,104
		ctx.r10.s64 = ctx.r1.s64 + 104;
		// addi r11,r11,17532
		ctx.r11.s64 = ctx.r11.s64 + 17532;
		// lfs f0,8(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
		ctx.f0.f64 = double(temp.f32);
		// rlwinm r11,r31,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// lfsx f13,r11,r10
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f13,f0
		// blt cr6,0x825764a4
		if (ctx.f13.f64 < ctx.f0.f64) goto loc_825764A4;
		// bso cr6,0x825764a4
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257649C, "bso");
	loc_825764A0:
		// mr r9,r31
		ctx.r9.u64 = var_r31;
	}
loc_825764A4:
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// lfsx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f0,r11,r9
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,4(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r27 + 4, temp.u32);
	// stfs f1,0(r27)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(var_r27 + 0, temp.u32);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_64C8_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_64C8_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_64C8_2hr) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32254
	// li r10,74
	ctx.r10.s64 = 74;
	// addi r11,r11,17184
	ctx.r11.s64 = ctx.r11.s64 + 17184;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_64E0_p33"))) PPC_WEAK_FUNC(phBoundCapsule_64E0_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_64E0_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=96, manual
	// lis r11,-32161
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r4,8
	ctx.r4.s64 = 8;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,-22272(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22272);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// cmplwi r3,0
	// stw r3,0(r31)
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r3.u32);
	// bne 0x82576520
	if (ctx.r3.u32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x82576540
	} else {
	loc_82576520:
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f0,22092(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22092);  /* glob:lbl_8200564C @ 0x8200564c */
		ctx.f0.f64 = double(temp.f32);
		// lis r11,-32256
		// stfs f0,0(r3)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r3.u32 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
		// lwz r10,0(r31)
		ctx.r10.u64 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
		// li r3,0
		ctx.r3.s64 = 0;
		// lfs f0,15784(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
		ctx.f0.f64 = double(temp.f32);
		// stfs f0,4(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	}
loc_82576540:
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6558_p33"))) PPC_WEAK_FUNC(phBoundCapsule_6558_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6558_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// lis r11,-32161
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// li r4,1492
	ctx.r4.s64 = 1492;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,-22272(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22272);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// mr. r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// bne 0x8257659c
	if (ctx.r11.s32 == 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x825765b0
	} else {
	loc_8257659C:
		// li r10,0
		ctx.r10.s64 = 0;
		// stw r11,0(r30)
		PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
		// li r3,0
		ctx.r3.s64 = 0;
		// stw r31,0(r11)
		PPC_STORE_U32(ctx.r11.u32 + 0, var_r31);
		// stw r10,4(r11)
		PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	}
loc_825765B0:
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_65C8_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_65C8_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_65C8_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r25 = 0;
	// FRAME: size=160, savegprlr_23
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// rotlwi r11,r4,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 1);
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// lwz r31,0(r29)
	var_r31 = (uint32_t)(PPC_LOAD_U32(var_r29 + 0)/* phBoundCapsule::vtable@+0x0 */);
	// addi r26,r29,8
	var_r26 = (uint32_t)(var_r29 + 8);
	// lwz r23,4(r29)
	var_r23 = (uint32_t)(PPC_LOAD_U32(var_r29 + 4)/* phBoundCapsule::flags@+0x4 */);
	// divw r10,r4,r31
	ctx.r10.s32 = (int32_t)var_r31 ? ctx.r4.s32 / (int32_t)var_r31 : 0;
	// andc r9,r31,r11
	ctx.r9.u64 = var_r31 & ~ctx.r11.u64;
	// mullw r11,r10,r31
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t((int32_t)var_r31);
	// subf r11,r11,r4
	ctx.r11.s64 = ctx.r4.s64 - ctx.r11.s64;
	// twlgei r9,-1
	if (ctx.r9.s32 == -1 || ctx.r9.u32 > 4294967295u) __builtin_trap();
	// add r11,r11,r23
	ctx.r11.u64 = ctx.r11.u64 + var_r23;
	// twllei r31,0
	if ((int32_t)var_r31 == 0 || var_r31 < 0u) __builtin_trap();
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + var_r31;
	// twllei r31,0
	if ((int32_t)var_r31 == 0 || var_r31 < 0u) __builtin_trap();
	// divw r9,r11,r31
	ctx.r9.s32 = (int32_t)var_r31 ? ctx.r11.s32 / (int32_t)var_r31 : 0;
	// rotlwi r10,r11,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r11.u32, 1);
	// mullw r9,r9,r31
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t((int32_t)var_r31);
	// subf r11,r9,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r9.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// subf r28,r11,r31
	var_r28 = (uint32_t)((int64_t)(int32_t)var_r31 - ctx.r11.s64);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// andc r10,r31,r10
	ctx.r10.u64 = var_r31 & ~ctx.r10.u64;
	// cmpw cr6,r28,r30
	// mr r4,r27
	ctx.r4.u64 = var_r27;
	// twlgei r10,-1
	if (ctx.r10.s32 == -1 || ctx.r10.u32 > 4294967295u) __builtin_trap();
	// add r3,r11,r26
	ctx.r3.u64 = ctx.r11.u64 + var_r26;
	// blt cr6,0x8257665c
	if ((int32_t)var_r28 >= (int32_t)var_r30) {
		// lis r10,-32161
		// rlwinm r5,r30,2,0,29
		ctx.r5.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
		// lwz r11,-22260(r10)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22260);
		// b 0x82576688
	} else {
	loc_8257665C:
		// lis r24,-32161
		var_r24 = (uint32_t)(-2107703296);
		// rlwinm r25,r28,2,0,29
		var_r25 = (uint32_t)(__builtin_rotateleft64(var_r28 | (var_r28 << 32), 2) & 0xFFFFFFFC);
		// mr r5,r25
		ctx.r5.u64 = var_r25;
		// lwz r11,-22260(r24)
		ctx.r11.u64 = PPC_LOAD_U32(var_r24 + -22260);
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// subf r11,r28,r30
		ctx.r11.s64 = (int64_t)(int32_t)var_r30 - (int64_t)(int32_t)var_r28;
		// add r4,r25,r27
		ctx.r4.u64 = var_r25 + var_r27;
		// rlwinm r5,r11,2,0,29
		ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// lwz r11,-22260(r24)
		ctx.r11.u64 = PPC_LOAD_U32(var_r24 + -22260);
		// mr r3,r26
		ctx.r3.u64 = var_r26;
	}
loc_82576688:
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// divw r11,r30,r31
	ctx.r11.s32 = (int32_t)var_r31 ? (int32_t)var_r30 / (int32_t)var_r31 : 0;
	// rotlwi r10,r30,1
	ctx.r10.u64 = __builtin_rotateleft32(var_r30, 1);
	// mullw r11,r11,r31
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t((int32_t)var_r31);
	// subf r11,r11,r30
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 - ctx.r11.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// add r11,r11,r23
	ctx.r11.u64 = ctx.r11.u64 + var_r23;
	// andc r10,r31,r10
	ctx.r10.u64 = var_r31 & ~ctx.r10.u64;
	// add r9,r11,r31
	ctx.r9.u64 = ctx.r11.u64 + var_r31;
	// twlgei r10,-1
	if (ctx.r10.s32 == -1 || ctx.r10.u32 > 4294967295u) __builtin_trap();
	// divw r10,r9,r31
	ctx.r10.s32 = (int32_t)var_r31 ? ctx.r9.s32 / (int32_t)var_r31 : 0;
	// rotlwi r11,r9,1
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// mullw r10,r10,r31
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t((int32_t)var_r31);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// andc r11,r31,r11
	ctx.r11.u64 = var_r31 & ~ctx.r11.u64;
	// twllei r31,0
	if ((int32_t)var_r31 == 0 || var_r31 < 0u) __builtin_trap();
	// twllei r31,0
	if ((int32_t)var_r31 == 0 || var_r31 < 0u) __builtin_trap();
	// twlgei r11,-1
	if (ctx.r11.s32 == -1 || ctx.r11.u32 > 4294967295u) __builtin_trap();
	// stw r10,4(r29)
	PPC_STORE_U32(var_r29 + 4,/* phBoundCapsule::flags@+0x4 */ ctx.r10.u32);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_66E8_2h"))) PPC_WEAK_FUNC(phBoundCapsule_66E8_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_66E8_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	// FRAME: size=144, savegprlr_26
	// mr r31,r5
	var_r31 = ctx.r5.u32;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// mr r29,r6
	var_r29 = ctx.r6.u32;
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4)/* phBoundCapsule::flags@+0x4 */;
	// addi r10,r31,1
	ctx.r10.s64 = (int64_t)(int32_t)var_r31 + 1;
	// twllei r11,0
	if (ctx.r11.s32 == 0 || ctx.r11.u32 < 0u) __builtin_trap();
	// srawi r10,r10,1
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 1;
	// twllei r11,0
	if (ctx.r11.s32 == 0 || ctx.r11.u32 < 0u) __builtin_trap();
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// addi r28,r3,8
	var_r28 = (uint32_t)(ctx.r3.s64 + 8);
	// neg r8,r10
	ctx.r8.s64 = static_cast<int64_t>(-ctx.r10.u64);
	// mr r3,r29
	ctx.r3.u64 = var_r29;
	// rotlwi r10,r8,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r8.u32, 1);
	// divw r7,r8,r11
	ctx.r7.s32 = ctx.r11.s32 ? ctx.r8.s32 / ctx.r11.s32 : 0;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 & ~ctx.r10.u64;
	// mullw r10,r7,r11
	ctx.r10.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r11.s32);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// twlgei r6,-1
	if (ctx.r6.s32 == -1 || ctx.r6.u32 > 4294967295u) __builtin_trap();
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// divw r8,r10,r11
	ctx.r8.s32 = ctx.r11.s32 ? ctx.r10.s32 / ctx.r11.s32 : 0;
	// rotlwi r9,r10,1
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r10.u32, 1);
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// subf r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// subf r30,r10,r11
	var_r30 = (uint32_t)(ctx.r11.s64 - ctx.r10.s64);
	// andc r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 & ~ctx.r9.u64;
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpw cr6,r30,r31
	// twlgei r9,-1
	if (ctx.r9.s32 == -1 || ctx.r9.u32 > 4294967295u) __builtin_trap();
	// add r4,r11,r28
	ctx.r4.u64 = ctx.r11.u64 + var_r28;
	// blt cr6,0x82576788
	if ((int32_t)var_r30 >= (int32_t)var_r31) {
		// lis r9,-32161
		// rlwinm r5,r31,2,0,29
		ctx.r5.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
		// lwz r11,-22260(r9)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22260);
		// b 0x825767b4
	} else {
	loc_82576788:
		// lis r26,-32161
		var_r26 = (uint32_t)(-2107703296);
		// rlwinm r27,r30,2,0,29
		var_r27 = (uint32_t)(__builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC);
		// mr r5,r27
		ctx.r5.u64 = var_r27;
		// lwz r11,-22260(r26)
		ctx.r11.u64 = PPC_LOAD_U32(var_r26 + -22260);
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// subf r11,r30,r31
		ctx.r11.s64 = (int64_t)(int32_t)var_r31 - (int64_t)(int32_t)var_r30;
		// mr r4,r28
		ctx.r4.u64 = var_r28;
		// rlwinm r5,r11,2,0,29
		ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// lwz r11,-22260(r26)
		ctx.r11.u64 = PPC_LOAD_U32(var_r26 + -22260);
		// add r3,r27,r29
		ctx.r3.u64 = var_r27 + var_r29;
	}
loc_825767B4:
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_67C8"))) PPC_WEAK_FUNC(phBoundCapsule_67C8);
PPC_FUNC_IMPL(__imp__phBoundCapsule_67C8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// FRAME: size=112, savegprlr_29
	// srawi r11,r5,1
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r5.s32 >> 1;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addze r29,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	var_r29 = (uint32_t)(temp.s64);
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r5,r29
	ctx.r5.u64 = var_r29;
	// bl 0x82579da0
	phBoundCapsule_9DA0_2h(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = var_r29;
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// bl 0x82579b58
	phBoundCapsule_9B58_w(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6808"))) PPC_WEAK_FUNC(phBoundCapsule_6808);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6808) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// FRAME: size=112, savegprlr_29
	// srawi r11,r5,1
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r5.s32 >> 1;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addze r29,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	var_r29 = (uint32_t)(temp.s64);
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r5,r29
	ctx.r5.u64 = var_r29;
	// bl 0x82579c78
	phBoundCapsule_9C78_2hr_9C78_1(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = var_r29;
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bl 0x82579da0
	phBoundCapsule_9DA0_2h(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6848_2h"))) PPC_WEAK_FUNC(phBoundCapsule_6848_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6848_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=112, savegprlr_29
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// srawi r3,r4,1
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x1) != 0);
	ctx.r3.s64 = ctx.r4.s32 >> 1;
	// srawi. r11,r4,2
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r4.s32 >> 2;
	// mr r30,r6
	var_r30 = ctx.r6.u32;
	// subfic r6,r11,256
	ctx.xer.ca = ctx.r11.u32 <= 256;
	ctx.r6.s64 = 256 - ctx.r11.s64;
	// mr r29,r7
	var_r29 = ctx.r7.u32;
	// slw r5,r10,r5
	ctx.r5.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r5.u8 & 0x3F));
	// rlwinm r10,r6,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r10,r30
	ctx.r8.u64 = ctx.r10.u64 + var_r30;
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + var_r29;
	// ble 0x825768b0
	if (ctx.r11.s32 > 0) {
		// mr r7,r11
		ctx.r7.u64 = ctx.r11.u64;
	loc_82576888:
		// lfs f0,0(r9)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// stfs f0,0(r8)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
		// addic. r7,r7,-1
		ctx.xer.ca = ctx.r7.u32 > 0;
		ctx.r7.s64 = ctx.r7.s64 + -1;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// lfs f0,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// stfs f0,0(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bne 0x82576888
		if (ctx.r7.s32 != 0) goto loc_82576888;
	}
loc_825768B0:
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r10,r30
	ctx.r10.u64 = var_r30;
	// subf r8,r11,r4
	ctx.r8.s64 = ctx.r4.s64 - ctx.r11.s64;
	// mr r11,r29
	ctx.r11.u64 = var_r29;
	// srawi. r7,r8,1
	ctx.xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x1) != 0);
	ctx.r7.s64 = ctx.r8.s32 >> 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// ble 0x825768f8
	if (ctx.r7.s32 > 0) {
		// mr r8,r7
		ctx.r8.u64 = ctx.r7.u64;
	loc_825768D0:
		// lfs f0,0(r9)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// stfs f0,0(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addic. r7,r7,-1
		ctx.xer.ca = ctx.r7.u32 > 0;
		ctx.r7.s64 = ctx.r7.s64 + -1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// lfs f0,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x825768d0
		if (ctx.r7.s32 != 0) goto loc_825768D0;
	}
loc_825768F8:
	// rlwinm r7,r3,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r4,r7
	// beq cr6,0x82576924
	if (ctx.r4.s32 != ctx.r7.s32) {
		// lfs f13,0(r9)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// lis r9,-32256
		// stfs f13,0(r10)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r8,r8,1
		ctx.r8.s64 = ctx.r8.s64 + 1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// lfs f0,15784(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15784);
		ctx.f0.f64 = double(temp.f32);
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
	}
loc_82576924:
	// cmpw cr6,r8,r6
	// bge cr6,0x8257696c
	if (ctx.r8.s32 < ctx.r6.s32) {
		// subf r9,r8,r6
		ctx.r9.s64 = ctx.r6.s64 - ctx.r8.s64;
		// li r7,0
		ctx.r7.s64 = 0;
		// rlwinm r9,r9,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// rlwinm. r8,r9,30,2,31
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
		// beq 0x82576950
		if (ctx.r8.s32 != 0) {
			// mtctr r8
			ctx.ctr.u64 = ctx.r8.u64;
		loc_82576944:
			// stw r7,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
			// addi r11,r11,4
			ctx.r11.s64 = ctx.r11.s64 + 4;
			// bdnz 0x82576944
			--ctx.ctr.u64;
			if (ctx.ctr.u32 != 0) goto loc_82576944;
		}
	loc_82576950:
		// rlwinm. r11,r9,30,2,31
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
		// li r9,0
		ctx.r9.s64 = 0;
		// beq 0x8257696c
		if (ctx.r11.s32 == 0) goto loc_8257696C;
		// mtctr r11
		ctx.ctr.u64 = ctx.r11.u64;
	loc_82576960:
		// stw r9,0(r10)
		PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bdnz 0x82576960
		--ctx.ctr.u64;
		if (ctx.ctr.u32 != 0) goto loc_82576960;
	}
loc_8257696C:
	// srawi r11,r5,1
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x1) != 0);
	ctx.r11.s64 = ctx.r5.s32 >> 1;
	// mr r4,r29
	ctx.r4.u64 = var_r29;
	// addze r31,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	var_r31 = (uint32_t)(temp.s64);
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// mr r5,r31
	ctx.r5.u64 = var_r31;
	// bl 0x82579da0
	phBoundCapsule_9DA0_2h(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = var_r31;
	// mr r4,r29
	ctx.r4.u64 = var_r29;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bl 0x82579b58
	phBoundCapsule_9B58_w(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_69A0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_69A0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_69A0_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	// cmpwi cr6,r5,0
	// lfs f1,15784(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f1.f64 = double(temp.f32);
	// blelr cr6
	if (ctx.r5.s32 <= 0) return;
loc_825769B0:
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// fmadds f1,f0,f13,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f1.f64));
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// bgt 0x825769b0
	if (ctx.r5.s32 > 0) goto loc_825769B0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_69D0_w"))) PPC_WEAK_FUNC(phBoundCapsule_69D0_w);
PPC_FUNC_IMPL(__imp__phBoundCapsule_69D0_w) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cmpwi cr6,r5,0
	// blelr cr6
	if (ctx.r5.s32 <= 0) return;
loc_825769D8:
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f13.f64 = double(temp.f32);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f0,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// fmadds f0,f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f13.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// bgt 0x825769d8
	if (ctx.r5.s32 > 0) goto loc_825769D8;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6A08_2h"))) PPC_WEAK_FUNC(phBoundCapsule_6A08_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6A08_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// cmpwi cr6,r4,0
	// blelr cr6
	if (ctx.r4.s32 <= 0) return;
loc_82576A10:
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// addic. r4,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	// fmuls f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// bgt 0x82576a10
	if (ctx.r4.s32 > 0) goto loc_82576A10;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6A30"))) PPC_WEAK_FUNC(phBoundCapsule_6A30);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6A30) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f89c
	ctx.lr = 0x82576A38;
	__savegprlr_29(ctx, base);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// li r29,0
	var_r29 = 0;
	// li r31,0
	var_r31 = 0;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r30,r11
	var_r30 = ctx.r11.u32;
	// cmpwi r11,0
	// bge 0x82576b58
	if (ctx.r11.s32 < 0) {
		// li r8,2
		ctx.r8.s64 = 2;
		// addi r7,r3,12
		ctx.r7.s64 = ctx.r3.s64 + 12;
	loc_82576A5C:
		// addi r9,r8,3
		ctx.r9.s64 = ctx.r8.s64 + 3;
		// cmpw cr6,r9,r4
		// bgt cr6,0x82576b0c
		if (ctx.r9.s32 > ctx.r4.s32) goto loc_82576B0C;
		// lwz r9,-8(r7)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + -8);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576a7c
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// mr r31,r10
			var_r31 = ctx.r10.u32;
		}
	loc_82576A7C:
		// cmpw cr6,r9,r30
		// bge cr6,0x82576a8c
		if (ctx.r9.s32 < (int32_t)var_r30) {
			// mr r30,r9
			var_r30 = ctx.r9.u32;
			// mr r29,r10
			var_r29 = ctx.r10.u32;
		}
	loc_82576A8C:
		// lwz r9,-4(r7)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + -4);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576aa0
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// mr r31,r8
			var_r31 = ctx.r8.u32;
		}
	loc_82576AA0:
		// cmpw cr6,r9,r30
		// bge cr6,0x82576ab0
		if (ctx.r9.s32 < (int32_t)var_r30) {
			// mr r30,r9
			var_r30 = ctx.r9.u32;
			// mr r29,r8
			var_r29 = ctx.r8.u32;
		}
	loc_82576AB0:
		// lwz r9,0(r7)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576ac4
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// addi r31,r8,1
			var_r31 = (uint32_t)(ctx.r8.s64 + 1);  // addr:0x825c0001
		}
	loc_82576AC4:
		// cmpw cr6,r9,r30
		// bge cr6,0x82576ad4
		if (ctx.r9.s32 < (int32_t)var_r30) {
			// mr r30,r9
			var_r30 = ctx.r9.u32;
			// addi r29,r8,1
			var_r29 = (uint32_t)(ctx.r8.s64 + 1);  // addr:0x825c0001
		}
	loc_82576AD4:
		// lwz r9,4(r7)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576ae8
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// addi r31,r8,2
			var_r31 = (uint32_t)(ctx.r8.s64 + 2);  // addr:0x825c0002
		}
	loc_82576AE8:
		// cmpw cr6,r9,r30
		// bge cr6,0x82576af8
		if (ctx.r9.s32 < (int32_t)var_r30) {
			// mr r30,r9
			var_r30 = ctx.r9.u32;
			// addi r29,r8,2
			var_r29 = (uint32_t)(ctx.r8.s64 + 2);  // addr:0x825c0002
		}
	loc_82576AF8:
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// addi r7,r7,16
		ctx.r7.s64 = ctx.r7.s64 + 16;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// cmpwi cr6,r11,0
		// blt cr6,0x82576a5c
		if (ctx.r11.s32 < 0) goto loc_82576A5C;
	loc_82576B0C:
		// cmpwi cr6,r11,0
		// bge cr6,0x82576b58
		if (ctx.r11.s32 >= 0) goto loc_82576B58;
		// rlwinm r9,r10,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// add r8,r9,r3
		ctx.r8.u64 = ctx.r9.u64 + ctx.r3.u64;
	loc_82576B1C:
		// cmpw cr6,r10,r4
		// bge cr6,0x82576b58
		if (ctx.r10.s32 >= ctx.r4.s32) goto loc_82576B58;
		// lwz r9,0(r8)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576b38
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// mr r31,r10
			var_r31 = ctx.r10.u32;
		}
	loc_82576B38:
		// cmpw cr6,r9,r30
		// bge cr6,0x82576b48
		if (ctx.r9.s32 < (int32_t)var_r30) {
			// mr r30,r9
			var_r30 = ctx.r9.u32;
			// mr r29,r10
			var_r29 = ctx.r10.u32;
		}
	loc_82576B48:
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// cmpwi cr6,r11,0
		// blt cr6,0x82576b1c
		if (ctx.r11.s32 < 0) goto loc_82576B1C;
	}
loc_82576B58:
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// cmpw cr6,r7,r4
	// bgt cr6,0x82576bd4
	if (ctx.r7.s32 <= ctx.r4.s32) {
		// addi r9,r10,2
		ctx.r9.s64 = ctx.r10.s64 + 2;
		// rlwinm r9,r9,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// add r8,r9,r3
		ctx.r8.u64 = ctx.r9.u64 + ctx.r3.u64;
	loc_82576B70:
		// lwz r9,-8(r8)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + -8);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576b84
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// mr r31,r10
			var_r31 = ctx.r10.u32;
		}
	loc_82576B84:
		// lwz r9,-4(r8)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576b98
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// addi r31,r10,1
			var_r31 = (uint32_t)(ctx.r10.s64 + 1);  // addr:0x825f0001
		}
	loc_82576B98:
		// lwz r9,0(r8)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576bac
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// addi r31,r10,2
			var_r31 = (uint32_t)(ctx.r10.s64 + 2);  // addr:0x825f0002
		}
	loc_82576BAC:
		// lwz r9,4(r8)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576bc0
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// addi r31,r10,3
			var_r31 = (uint32_t)(ctx.r10.s64 + 3);  // addr:0x825f0003
		}
	loc_82576BC0:
		// mr r10,r7
		ctx.r10.u64 = ctx.r7.u64;
		// addi r8,r8,16
		ctx.r8.s64 = ctx.r8.s64 + 16;
		// addi r7,r10,4
		ctx.r7.s64 = ctx.r10.s64 + 4;
		// cmpw cr6,r7,r4
		// ble cr6,0x82576b70
		if (ctx.r7.s32 <= ctx.r4.s32) goto loc_82576B70;
	}
loc_82576BD4:
	// cmpw cr6,r10,r4
	// bge cr6,0x82576c08
	if (ctx.r10.s32 < ctx.r4.s32) {
		// rlwinm r9,r10,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// add r8,r9,r3
		ctx.r8.u64 = ctx.r9.u64 + ctx.r3.u64;
	loc_82576BE4:
		// lwz r9,0(r8)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		// cmpw cr6,r9,r11
		// ble cr6,0x82576bf8
		if (ctx.r9.s32 > ctx.r11.s32) {
			// mr r11,r9
			ctx.r11.u64 = ctx.r9.u64;
			// mr r31,r10
			var_r31 = ctx.r10.u32;
		}
	loc_82576BF8:
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// cmpw cr6,r10,r4
		// blt cr6,0x82576be4
		if (ctx.r10.s32 < ctx.r4.s32) goto loc_82576BE4;
	}
loc_82576C08:
	// cmpwi cr6,r11,0
	// stw r11,-48(r1)
	PPC_STORE_U32(ctx.r1.u32 + -48, ctx.r11.u32);
	// bge cr6,0x82576c1c
	if (ctx.r11.s32 < 0) {
		// stw r30,-48(r1)
		PPC_STORE_U32(ctx.r1.u32 + -48, var_r30);
		// blt cr6,0x82576c24
		if (ctx.cr6.lt) goto loc_82576C24;
	}
loc_82576C1C:
	// mr r11,r31
	ctx.r11.u64 = var_r31;
	// b 0x82576c28
	// lfs f0,-48(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	ctx.f0.f64 = double(temp.f32);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// b 0x8242f8ec
	__restgprlr_29(ctx, base);
	return;
loc_82576C24:
	// mr r11,r29
	ctx.r11.u64 = var_r29;
loc_82576C28:
	// lfs f0,-48(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	ctx.f0.f64 = double(temp.f32);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r11.u32);
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// b 0x8242f8ec
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6C38_2h"))) PPC_WEAK_FUNC(phBoundCapsule_6C38_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6C38_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	double var_f29 = 0.0;
	double var_f28 = 0.0;
	double var_f31 = 0.0;
	double var_f30 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f898
	ctx.lr = 0x82576C40;
	__savegprlr_28(ctx, base);
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// extsw r9,r29
	ctx.r9.s64 = (int32_t)var_r29;
	// addi r11,r29,-1
	ctx.r11.s64 = (int64_t)(int32_t)var_r29 + -1;
	// lis r10,-32161
	// extsw r8,r11
	ctx.r8.s64 = ctx.r11.s32;
	// rlwinm r11,r29,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r29 | (var_r29 << 32), 2) & 0xFFFFFFFC;
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// srawi r28,r29,1
	ctx.xer.ca = ((int32_t)var_r29 < 0) & ((var_r29 & 0x1) != 0);
	var_r28 = (uint32_t)((int32_t)var_r29 >> 1);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + var_r31;
	// lwz r10,-22256(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22256);
	// std r8,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r8.u64);
	// addi r30,r11,-4
	var_r30 = (uint32_t)(ctx.r11.s64 + -4);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f29,16056(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16056);  /* glob:lbl_82003EB8 @ 0x82003eb8 */
	var_f29 = double(temp.f32);
	// lis r11,-32255
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,-32048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32048);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32254
	// fdivs f0,f29,f0
	ctx.f0.f64 = double(float(var_f29 / ctx.f0.f64));
	// fdivs f1,f13,f12
	ctx.f1.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// lfs f13,17708(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17708);  /* glob:0x8200452c */
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32254
	// fmuls f28,f0,f13
	var_f28 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,17704(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17704);  /* glob:0x82004528 */
	ctx.f13.f64 = double(temp.f32);
	// fmuls f31,f0,f13
	var_f31 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fmr f30,f28
	var_f30 = var_f28;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r10.u32);
	// fsubs f0,f31,f28
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(var_f31 - var_f28));
	// frsp f13,f1
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lfs f12,0(r31)
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r31,4
	ctx.r11.s64 = (int64_t)(int32_t)var_r31 + 4;
	// addi r10,r30,-4
	ctx.r10.s64 = (int64_t)(int32_t)var_r30 + -4;
	// li r9,2
	ctx.r9.s64 = 2;
	// cmpwi cr6,r28,4
	ctx.cr6.compare<int32_t>((int32_t)var_r28, 4, ctx.xer);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f12,0(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f0,0(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// fmuls f0,f13,f28
	ctx.f0.f64 = double(float(ctx.f13.f64 * var_f28));
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * var_f29));
	// fsubs f12,f31,f0
	ctx.f12.f64 = double(float(var_f31 - ctx.f0.f64));
	// fmuls f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// stfs f11,0(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// fmuls f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// ble cr6,0x82576dc0
	if (ctx.cr6.gt) {
		// li r8,4
		ctx.r8.s64 = 4;
	loc_82576D38:
		// fmsubs f12,f0,f13,f30
		ctx.fpscr.disableFlushMode();
		ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - var_f30));
		// lfs f10,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f10.f64 = double(temp.f32);
		// addi r8,r8,3
		ctx.r8.s64 = ctx.r8.s64 + 3;
		// addi r9,r9,3
		ctx.r9.s64 = ctx.r9.s64 + 3;
		// cmpw cr6,r8,r28
		ctx.cr6.compare<int32_t>(ctx.r8.s32, (int32_t)var_r28, ctx.xer);
		// fsubs f11,f31,f12
		ctx.f11.f64 = double(float(var_f31 - ctx.f12.f64));
		// fmsubs f30,f12,f13,f0
		var_f30 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f0.f64));
		// fmuls f0,f10,f11
		ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// lfs f0,0(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fmuls f0,f0,f11
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
		// stfs f0,0(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// fsubs f11,f31,f30
		ctx.f11.f64 = double(float(var_f31 - var_f30));
		// addi r10,r10,-4
		ctx.r10.s64 = ctx.r10.s64 + -4;
		// fmsubs f0,f13,f30,f12
		ctx.f0.f64 = double(float(ctx.f13.f64 * var_f30 - ctx.f12.f64));
		// lfs f12,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fmuls f12,f12,f11
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
		// stfs f12,0(r11)
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// lfs f12,0(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fmuls f12,f12,f11
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
		// stfs f12,0(r10)
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// fsubs f12,f31,f0
		ctx.f12.f64 = double(float(var_f31 - ctx.f0.f64));
		// addi r10,r10,-4
		ctx.r10.s64 = ctx.r10.s64 + -4;
		// lfs f11,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// fmuls f11,f11,f12
		ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
		// stfs f11,0(r11)
		temp.f32 = float(ctx.f11.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// lfs f11,0(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fmuls f12,f11,f12
		ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
		// stfs f12,0(r10)
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r10,r10,-4
		ctx.r10.s64 = ctx.r10.s64 + -4;
		// blt cr6,0x82576d38
		if (ctx.cr6.lt) goto loc_82576D38;
	}
loc_82576DC0:
	// cmpw cr6,r9,r28
	// bge cr6,0x82576e1c
	if (ctx.r9.s32 < (int32_t)var_r28) {
		// fmsubs f11,f0,f13,f30
		ctx.fpscr.disableFlushMode();
		ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 - var_f30));
		// lfs f10,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f10.f64 = double(temp.f32);
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// cmpw cr6,r9,r28
		// fsubs f12,f31,f11
		ctx.f12.f64 = double(float(var_f31 - ctx.f11.f64));
		// fmuls f10,f10,f12
		ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
		// stfs f10,0(r11)
		temp.f32 = float(ctx.f10.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// lfs f10,0(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f10.f64 = double(temp.f32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fmuls f12,f10,f12
		ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
		// stfs f12,0(r10)
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// bge cr6,0x82576e1c
		if (ctx.r9.s32 >= (int32_t)var_r28) goto loc_82576E1C;
		// fmsubs f0,f11,f13,f0
		ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f13.f64 - ctx.f0.f64));
		// lfs f12,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fsubs f0,f31,f0
		ctx.f0.f64 = double(float(var_f31 - ctx.f0.f64));
		// fmuls f13,f12,f0
		ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
		// stfs f13,0(r11)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// lfs f13,-4(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
		ctx.f13.f64 = double(temp.f32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// stfs f0,-4(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + -4, temp.u32);
	}
loc_82576E1C:
	// clrlwi. r10,r29,31
	ctx.r10.u64 = var_r29 & 0x1;
	// beq 0x82576e34
	if (ctx.r10.s32 != 0) {
		// fadds f0,f31,f28
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(var_f31 + var_f28));
		// lfs f13,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fmuls f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	}
loc_82576E34:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// addi r12,r1,-40
	ctx.r12.s64 = ctx.r1.s64 + -40;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// b 0x8242f8e8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6E48_2h"))) PPC_WEAK_FUNC(phBoundCapsule_6E48_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6E48_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f0,17728(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17728);  /* glob:lbl_82024540 @ 0x82024540 */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	// ble cr6,0x82576e60
	if (ctx.f1.f64 > ctx.f0.f64) {
		// li r3,261
		ctx.r3.s64 = 261;
		// blr
		return;
	}
loc_82576E60:
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f0,17724(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17724);  /* glob:lbl_8202453C @ 0x8202453c */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	// ble cr6,0x82576e78
	if (ctx.f1.f64 > ctx.f0.f64) {
		// li r3,241
		ctx.r3.s64 = 241;
		// blr
		return;
	}
loc_82576E78:
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f0,-24380(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24380);  /* glob:lbl_8207A0C4 @ 0x8207a0c4 */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	// ble cr6,0x82576e90
	if (ctx.f1.f64 > ctx.f0.f64) {
		// li r3,221
		ctx.r3.s64 = 221;
		// blr
		return;
	}
loc_82576E90:
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f0,17720(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17720);  /* glob:lbl_82024538 @ 0x82024538 */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	// ble cr6,0x82576ea8
	if (ctx.f1.f64 > ctx.f0.f64) {
		// li r3,201
		ctx.r3.s64 = 201;
		// blr
		return;
	}
loc_82576EA8:
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f0,-24420(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24420);  /* glob:lbl_8207A09C @ 0x8207a09c */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	// ble cr6,0x82576ec0
	if (ctx.f1.f64 > ctx.f0.f64) {
		// li r3,181
		ctx.r3.s64 = 181;
		// blr
		return;
	}
loc_82576EC0:
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f0,17716(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17716);  /* glob:lbl_82024534 @ 0x82024534 */
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	// bgt cr6,0x82576ee8
	if (ctx.f1.f64 <= ctx.f0.f64) {
		// lis r11,-32248
		ctx.r11.s64 = -2113404928;
		// lfs f0,-25772(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25772);  /* glob:lbl_82079B54 @ 0x82079b54 */
		ctx.f0.f64 = double(temp.f32);
		// fcmpu cr6,f1,f0
		// bgt cr6,0x82576ee8
		if (ctx.f1.f64 > ctx.f0.f64) {
			// li r3,161
			ctx.r3.s64 = 161;
			// blr
			return;
		}
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f0,17712(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17712);  /* glob:lbl_82024530 @ 0x82024530 */
		ctx.f0.f64 = double(temp.f32);
	}
loc_82576EE8:
	// li r3,161
	ctx.r3.s64 = 161;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6EF0"))) PPC_WEAK_FUNC(phBoundCapsule_6EF0);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6EF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// stfs f1,-16(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -16, temp.u32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,16056(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16056);  /* glob:lbl_82003EB8 @ 0x82003eb8 */
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-16(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// clrlwi r10,r11,9
	ctx.r10.u64 = ctx.r11.u32 & 0x7FFFFF;
	// srawi r11,r11,23
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x7FFFFF) != 0);
	ctx.r11.s64 = ctx.r11.s32 >> 23;
	// oris r10,r10,16256
	ctx.r10.u64 = ctx.r10.u64 | 1065353216;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// addi r11,r11,-127
	ctx.r11.s64 = ctx.r11.s64 + -127;
	// stw r10,-16(r1)
	PPC_STORE_U32(ctx.r1.u32 + -16, ctx.r10.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// lfs f11,-16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	ctx.f11.f64 = double(temp.f32);
	// std r11,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r11.u64);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f12,15788(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
	ctx.f12.f64 = double(temp.f32);
	// fmsubs f0,f11,f0,f12
	ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 - ctx.f12.f64));
	// lfd f12,-16(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmadds f1,f0,f13,f12
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_6F50_2h"))) PPC_WEAK_FUNC(phBoundCapsule_6F50_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_6F50_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// fmuls f11,f0,f1
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// lis r10,-32254
	// addi r9,r3,4
	ctx.r9.s64 = ctx.r3.s64 + 4;
	// lfs f6,15788(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
	ctx.f6.f64 = double(temp.f32);
	// lis r11,-32248
	// lfs f3,17748(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17748);
	ctx.f3.f64 = double(temp.f32);
	// fmr f13,f6
	ctx.f13.f64 = ctx.f6.f64;
	// lfs f5,-24660(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24660);
	ctx.f5.f64 = double(temp.f32);
	// lis r11,-32256
	// fadds f0,f11,f5
	ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f5.f64));
	// lfs f12,19100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 19100);  /* glob:lbl_82004A9C @ 0x82004a9c */
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f4,-26560(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -26560);  /* glob:lbl_82009840 @ 0x82009840 */
	ctx.f4.f64 = double(temp.f32);
	// b 0x82576f98
	goto loc_82576F98;
	do {
		// fmuls f0,f0,f4
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
		// fmuls f13,f13,f3
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
		// fcmpu cr6,f0,f12
		ctx.fpscr.disableFlushMode();
		// blt cr6,0x82576f90
		} while (ctx.f0.f64 < ctx.f12.f64);
	// lis r10,-32254
	// addic. r11,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r11.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// lfs f9,17744(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17744);
	ctx.f9.f64 = double(temp.f32);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lfs f8,17740(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17740);  /* glob:lbl_8202454C @ 0x8202454c */
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32254
	// fnmsubs f10,f0,f9,f8
	ctx.f10.f64 = double(float(-(ctx.f0.f64 * ctx.f9.f64 - ctx.f8.f64)));
	// lfs f7,17736(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17736);  /* glob:lbl_82024548 @ 0x82024548 */
	ctx.f7.f64 = double(temp.f32);
	// addi r10,r6,4
	ctx.r10.s64 = ctx.r6.s64 + 4;
	// fmadds f0,f10,f0,f7
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f0.f64 + ctx.f7.f64));
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// blelr
	if (!ctx.cr0.gt) return;
loc_82576FD4:
	// lfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// fmuls f10,f0,f1
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// fcmpu cr6,f10,f11
	// beq cr6,0x82577018
	if (ctx.f10.f64 != ctx.f11.f64) {
		// fadds f0,f10,f5
		ctx.f0.f64 = double(float(ctx.f10.f64 + ctx.f5.f64));
		// fmr f13,f6
		ctx.f13.f64 = ctx.f6.f64;
		// b 0x82577000
		goto loc_82577000;
		do {
			// fmuls f0,f0,f4
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
			// fmuls f13,f13,f3
			ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
			// fcmpu cr6,f0,f12
			ctx.fpscr.disableFlushMode();
			// blt cr6,0x82576ff8
			} while (ctx.f0.f64 < ctx.f12.f64);
		// fnmsubs f11,f0,f9,f8
		ctx.f11.f64 = double(float(-(ctx.f0.f64 * ctx.f9.f64 - ctx.f8.f64)));
		// fmadds f0,f11,f0,f7
		ctx.f0.f64 = double(float(ctx.f11.f64 * ctx.f0.f64 + ctx.f7.f64));
		// fmuls f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
		// b 0x8257701c
	} else {
	loc_82577018:
		// lfs f0,-4(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
		ctx.f0.f64 = double(temp.f32);
	}
loc_8257701C:
	// stfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// fmr f11,f10
	ctx.f11.f64 = ctx.f10.f64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,0
	// bgt cr6,0x82576fd4
	if (ctx.r11.s32 > 0) goto loc_82576FD4;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_7038_2h"))) PPC_WEAK_FUNC(phBoundCapsule_7038_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_7038_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f1.f64;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,18992(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 18992);  /* glob:lbl_82004A30 @ 0x82004a30 */
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// bgt cr6,0x82577058
	if (ctx.f0.f64 <= ctx.f13.f64) {
		// bso cr6,0x82577058
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257704C, "bso");
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f2,15784(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
		ctx.f2.f64 = double(temp.f32);
	}
loc_82577058:
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f13,-25384(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25384);  /* glob:lbl_82079CD8 @ 0x82079cd8 */
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// fcmpu cr6,f0,f13
	// lfs f12,17756(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17756);  /* glob:lbl_8202455C @ 0x8202455c */
	ctx.f12.f64 = double(temp.f32);
	// blt cr6,0x825770a8
	if (ctx.f0.f64 >= ctx.f13.f64) {
		// bso cr6,0x825770a8
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x82577070, "bso");
		// lis r11,-32256
		// fsubs f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
		// lfs f13,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:0x82026a40 */
		ctx.f13.f64 = double(temp.f32);
		// lis r11,-32256
		// fmuls f13,f4,f13
		ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
		// fmuls f11,f13,f0
		ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// lfs f13,15788(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:0x82023dac */
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f11,f13
		// bge cr6,0x8257709c
		if (ctx.f11.f64 < ctx.f13.f64) {
			// fadds f0,f0,f12
			ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
		}
	loc_8257709C:
		// fcmpu cr6,f0,f2
		ctx.fpscr.disableFlushMode();
		// ble cr6,0x825770a8
		if (ctx.f0.f64 <= ctx.f2.f64) goto loc_825770A8;
		// fmr f2,f0
		ctx.f2.f64 = ctx.f0.f64;
	}
loc_825770A8:
	// fcmpu cr6,f3,f2
	ctx.fpscr.disableFlushMode();
	// ble cr6,0x82577108
	if (ctx.f3.f64 > ctx.f2.f64) {
		// fcmpu cr6,f3,f12
		// blt cr6,0x82577108
		if (ctx.f3.f64 < ctx.f12.f64) {
			// fmr f1,f2
			ctx.fpscr.disableFlushMode();
			ctx.f1.f64 = ctx.f2.f64;
			// blr
			return;
		}
		// bso cr6,0x82577108
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x825770B8, "bso");
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f0,11188(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11188);  /* glob:lbl_82022BB4 @ 0x82022bb4 */
		ctx.f0.f64 = double(temp.f32);
		// fmuls f0,f5,f0
		ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
		// fcmpu cr6,f4,f0
		// bge cr6,0x825770fc
		if (ctx.f4.f64 < ctx.f0.f64) {
			// lis r11,-32255
			ctx.r11.s64 = -2113863680;
			// lfs f0,21604(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21604);  /* glob:lbl_82015464 @ 0x82015464 */
			ctx.f0.f64 = double(temp.f32);
			// fmuls f0,f5,f0
			ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
			// fcmpu cr6,f4,f0
			// ble cr6,0x825770fc
			if (ctx.f4.f64 <= ctx.f0.f64) goto loc_825770FC;
			// lis r11,-32255
			ctx.r11.s64 = -2113863680;
			// lfs f0,21628(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21628);  /* glob:lbl_8201547C @ 0x8201547c */
			ctx.f0.f64 = double(temp.f32);
			// lis r11,-32256
			ctx.r11.s64 = -2113929216;
			// lfs f13,27324(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27324);  /* glob:lbl_82006ABC @ 0x82006abc */
			ctx.f13.f64 = double(temp.f32);
			// fmuls f13,f3,f13
			ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
			// fmadds f2,f2,f0,f13
			ctx.f2.f64 = double(float(ctx.f2.f64 * ctx.f0.f64 + ctx.f13.f64));
		}
	loc_825770FC:
		// fcmpu cr6,f2,f12
		ctx.fpscr.disableFlushMode();
		// bge cr6,0x82577108
		if (ctx.f2.f64 >= ctx.f12.f64) {
			// fmr f1,f2
			ctx.fpscr.disableFlushMode();
			ctx.f1.f64 = ctx.f2.f64;
			// blr
			return;
		}
		// fadds f2,f2,f12
		ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f12.f64));
	}
loc_82577108:
	// fmr f1,f2
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f2.f64;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_7110_h"))) PPC_WEAK_FUNC(phBoundCapsule_7110_h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_7110_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	double var_f31 = 0.0;
	double var_f28 = 0.0;
	double var_f29 = 0.0;
	double var_f30 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f884
	ctx.lr = 0x82577118;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-2064(r1)
	ea = -2064 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32254
	// mr r25,r5
	var_r25 = ctx.r5.u32;
	// mr r24,r3
	var_r24 = ctx.r3.u32;
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// mr r23,r6
	var_r23 = ctx.r6.u32;
	// lfs f0,17772(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17772);  /* glob:0x8200456c */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	// lfs f31,0(r25)
	temp.u32 = PPC_LOAD_U32(var_r25 + 0);
	var_f31 = double(temp.f32);
	// mr r31,r7
	var_r31 = ctx.r7.u32;
	// fmuls f0,f31,f0
	ctx.f0.f64 = double(float(var_f31 * ctx.f0.f64));
	// mr r27,r8
	var_r27 = ctx.r8.u32;
	// mr r26,r10
	var_r26 = ctx.r10.u32;
	// lfs f13,-25804(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25804);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	// fdivs f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 / var_f31));
	// lfs f28,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
	var_f28 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// fcmpu cr6,f0,f28
	// lfs f29,15788(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
	var_f29 = double(temp.f32);
	// bso cr6,0x82577178
	// UNIMPLEMENTED: bso
	PPC_UNIMPLEMENTED(0x82577170, "bso");
	// bge cr6,0x8257717c
	if (ctx.f0.f64 < var_f28) {
	loc_82577178:
		// fsubs f0,f0,f29
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 - var_f29));
	}
loc_8257717C:
	// addi r11,r1,84
	ctx.r11.s64 = ctx.r1.s64 + 84;
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r11,5
	// bge cr6,0x82577198
	if (ctx.r11.s32 < 5) {
		// li r11,5
		ctx.r11.s64 = 5;
	}
loc_82577198:
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32248
	// frsp f12,f0
	ctx.f12.f64 = double(float(ctx.f0.f64));
	// lfs f0,-25600(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25600);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f13,17732(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17732);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// ble cr6,0x825771d0
	if (ctx.f0.f64 > ctx.f13.f64) {
		// fmr f0,f13
		ctx.f0.f64 = ctx.f13.f64;
	}
loc_825771D0:
	// lis r11,-32256
	// li r4,0
	ctx.r4.s64 = 0;
	// cmpwi cr6,r9,0
	// lfs f30,27200(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
	var_f30 = double(temp.f32);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// fadds f13,f0,f30
	ctx.f13.f64 = double(float(ctx.f0.f64 + var_f30));
	// stw r4,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r4.u32);
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
	// stfiwx f13,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f13.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r29,r11,1
	var_r29 = (uint32_t)(ctx.r11.s64 + 1);  // addr:0x82000001
	// ble cr6,0x82577220
	while (ctx.r9.s32 < 0) {
	loc_82577200:
		// rlwinm r11,r4,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
		// lfsx f13,r11,r27
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r27);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f13,f0
		// bgt cr6,0x82577220
		if (ctx.f13.f64 > ctx.f0.f64) goto loc_82577220;
		// addi r4,r4,1
		ctx.r4.s64 = ctx.r4.s64 + 1;
		// cmpw cr6,r4,r9
		ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r9.s32, ctx.xer);
		// stw r4,88(r1)
		PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r4.u32);
		// blt cr6,0x82577200
}
loc_82577220:
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// cmpwi cr6,r4,0
	// ble cr6,0x82577358
	if (ctx.r4.s32 > 0) {
		// addi r6,r1,92
		ctx.r6.s64 = ctx.r1.s64 + 92;
		// addi r5,r1,88
		ctx.r5.s64 = ctx.r1.s64 + 88;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82576a30
		phBoundCapsule_6A30(ctx, base);
		// addi r6,r1,80
		ctx.r6.s64 = ctx.r1.s64 + 80;
		// addi r5,r1,88
		ctx.r5.s64 = ctx.r1.s64 + 88;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// mr r3,r28
		ctx.r3.u64 = var_r28;
		// bl 0x82576a30
		phBoundCapsule_6A30(ctx, base);
		// lfs f0,92(r1)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
		ctx.f0.f64 = double(temp.f32);
		// lfs f13,80(r1)
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f0,f13
		// bgt cr6,0x82577268
		if (ctx.f0.f64 <= ctx.f13.f64) {
			// fmr f0,f13
			ctx.f0.f64 = ctx.f13.f64;
			// stfs f0,92(r1)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
		}
	loc_82577268:
		// fcmpu cr6,f0,f28
		ctx.fpscr.disableFlushMode();
		// bne cr6,0x82577278
		if (ctx.f0.f64 == var_f28) {
			// fmr f1,f29
			ctx.f1.f64 = var_f29;
			// b 0x8257727c
		} else {
		loc_82577278:
			// fdivs f1,f29,f0
			ctx.fpscr.disableFlushMode();
			ctx.f1.f64 = double(float(var_f29 / ctx.f0.f64));
		}
	loc_8257727C:
		// mr r6,r31
		ctx.r6.u64 = var_r31;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82576f50
		phBoundCapsule_6F50_2h(ctx, base);
		// addi r6,r1,928
		ctx.r6.s64 = ctx.r1.s64 + 928;
		// mr r4,r29
		ctx.r4.u64 = var_r29;
		// mr r3,r28
		ctx.r3.u64 = var_r28;
		// bl 0x82576f50
		phBoundCapsule_6F50_2h(ctx, base);
		// cmpwi cr6,r30,0
		// ble cr6,0x82577308
		if ((int32_t)var_r30 > 0) {
			// mr r11,r31
			ctx.r11.u64 = var_r31;
			// subf r9,r31,r27
			ctx.r9.s64 = (int64_t)(int32_t)var_r27 - (int64_t)(int32_t)var_r31;
			// mr r10,r30
			ctx.r10.u64 = var_r30;
		loc_825772B0:
			// lfsx f0,r9,r11
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
			ctx.f0.f64 = double(temp.f32);
			// addi r8,r1,100
			ctx.r8.s64 = ctx.r1.s64 + 100;
			// fadds f13,f0,f30
			ctx.f13.f64 = double(float(ctx.f0.f64 + var_f30));
			// addi r7,r1,928
			ctx.r7.s64 = ctx.r1.s64 + 928;
			// stfs f0,80(r1)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
			// lfs f0,0(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			ctx.f0.f64 = double(temp.f32);
			// fctiwz f13,f13
			ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
			// stfiwx f13,0,r8
			PPC_STORE_U32(ctx.r8.u32, ctx.f13.u32);
			// lwz r8,100(r1)
			ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
			// rlwinm r8,r8,2,0,29
			ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
			// lfsx f13,r8,r7
			temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
			ctx.f13.f64 = double(temp.f32);
			// fcmpu cr6,f0,f13
			// bge cr6,0x825772fc
			if (ctx.f0.f64 < ctx.f13.f64) {
				// fdivs f13,f0,f13
				ctx.f13.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
				// fmuls f13,f13,f13
				ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
				// stfs f13,80(r1)
				temp.f32 = float(ctx.f13.f64);
				PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
				// fmuls f13,f13,f13
				ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
				// fmuls f0,f13,f0
				ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
				// stfs f0,0(r11)
				temp.f32 = float(ctx.f0.f64);
				PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
			}
		loc_825772FC:
			// addic. r10,r10,-1
			ctx.xer.ca = ctx.r10.u32 > 0;
			ctx.r10.s64 = ctx.r10.s64 + -1;
			// addi r11,r11,4
			ctx.r11.s64 = ctx.r11.s64 + 4;
			// bne 0x825772b0
			if (ctx.r10.s32 != 0) goto loc_825772B0;
		}
	loc_82577308:
		// lis r11,-32254
		// mr r10,r26
		ctx.r10.u64 = var_r26;
		// addi r9,r1,104
		ctx.r9.s64 = ctx.r1.s64 + 104;
		// addi r8,r1,128
		ctx.r8.s64 = ctx.r1.s64 + 128;
		// addi r7,r1,528
		ctx.r7.s64 = ctx.r1.s64 + 528;
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// lfs f1,17768(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17768);
		ctx.f1.f64 = double(temp.f32);
		// mr r4,r27
		ctx.r4.u64 = var_r27;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x82577fe0
		phBoundCapsule_7FE0_2h(ctx, base);
		// addi r9,r1,96
		ctx.r9.s64 = ctx.r1.s64 + 96;
		// addi r8,r1,84
		ctx.r8.s64 = ctx.r1.s64 + 84;
		// lwz r6,104(r1)
		ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
		// addi r7,r1,112
		ctx.r7.s64 = ctx.r1.s64 + 112;
		// fmr f1,f31
		ctx.fpscr.disableFlushMode();
		ctx.f1.f64 = var_f31;
		// addi r5,r1,128
		ctx.r5.s64 = ctx.r1.s64 + 128;
		// addi r4,r1,528
		ctx.r4.s64 = ctx.r1.s64 + 528;
		// bl 0x8257a0b8
		phBoundCapsule_A0B8_2h(ctx, base);
		// lfs f0,96(r1)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
		ctx.f0.f64 = double(temp.f32);
		// b 0x82577364
	} else {
	loc_82577358:
		// fmr f0,f28
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = var_f28;
		// stfs f31,84(r1)
		temp.f32 = float(var_f31);
		PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
		// stfs f0,96(r1)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	}
loc_82577364:
	// lis r11,-32254
	// lfs f12,0(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r24 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f28
	// lfs f13,17764(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17764);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f31,f12,f30,f13
	var_f31 = double(float(-(ctx.f12.f64 * var_f30 - ctx.f13.f64)));
	// bgt cr6,0x82577388
	if (ctx.f0.f64 <= var_f28) {
		// bso cr6,0x82577388
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257737C, "bso");
		// lis r11,-32248
		ctx.r11.s64 = -2113404928;
		// lfs f0,-25840(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25840);  /* glob:lbl_82079B10 @ 0x82079b10 */
		ctx.f0.f64 = double(temp.f32);
	}
loc_82577388:
	// fcmpu cr6,f0,f29
	ctx.fpscr.disableFlushMode();
	// blt cr6,0x8257739c
	if (ctx.f0.f64 >= var_f29) {
		// bso cr6,0x8257739c
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x82577390, "bso");
		// lis r11,-32248
		ctx.r11.s64 = -2113404928;
		// lfs f0,-25256(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25256);  /* glob:lbl_82079D58 @ 0x82079d58 */
		ctx.f0.f64 = double(temp.f32);
	}
loc_8257739C:
	// fsubs f1,f29,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(var_f29 - ctx.f0.f64));
	// bl 0x82432450
	jumptable_2450(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f0,17752(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17752);  /* glob:lbl_82024558 @ 0x82024558 */
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f0,f31
	// bge cr6,0x825773c4
	if (ctx.f0.f64 < var_f31) {
		// fmr f0,f28
		ctx.f0.f64 = var_f28;
		// b 0x825773e8
	} else {
	loc_825773C4:
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f13,17760(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17760);  /* glob:lbl_82024560 @ 0x82024560 */
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f0,f13
		// ble cr6,0x825773dc
		if (ctx.f0.f64 > ctx.f13.f64) {
			// fmr f0,f29
			ctx.f0.f64 = var_f29;
			// b 0x825773e8
		} else {
		loc_825773DC:
			// fsubs f0,f0,f31
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = double(float(ctx.f0.f64 - var_f31));
			// fsubs f13,f13,f31
			ctx.f13.f64 = double(float(ctx.f13.f64 - var_f31));
			// fdivs f0,f0,f13
			ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
		}
	}
loc_825773E8:
	// lfs f13,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,0(r24)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r24 + 0, temp.u32);
	// stfs f13,0(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(var_r25 + 0, temp.u32);
	// stfs f0,0(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r23 + 0, temp.u32);
	// addi r1,r1,2064
	ctx.r1.s64 = ctx.r1.s64 + 2064;
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// b 0x8242f8d4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_7408_2h"))) PPC_WEAK_FUNC(phBoundCapsule_7408_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_7408_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32254
	// fmr f13,f4
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f4.f64;
	// lfs f0,11188(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11188);  /* glob:lbl_82022BB4 @ 0x82022bb4 */
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// fcmpu cr6,f2,f0
	// bgt cr6,0x82577450
	if (ctx.f2.f64 <= ctx.f0.f64) {
		// bso cr6,0x82577450
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x82577420, "bso");
		// lis r11,-32255
		ctx.r11.s64 = -2113863680;
		// lfs f0,21604(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21604);  /* glob:lbl_82015464 @ 0x82015464 */
		ctx.f0.f64 = double(temp.f32);
		// fmuls f0,f1,f0
		ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
		// fcmpu cr6,f2,f0
		// blt cr6,0x82577450
		if (ctx.f2.f64 < ctx.f0.f64) goto loc_82577450;
		// bso cr6,0x82577450
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x82577438, "bso");
		// fadds f13,f1,f2
		ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f0,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
		ctx.f0.f64 = double(temp.f32);
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// b 0x825774ac
	} else {
	loc_82577450:
		// fcmpu cr6,f3,f13
		ctx.fpscr.disableFlushMode();
		// ble cr6,0x82577464
		if (ctx.f3.f64 > ctx.f13.f64) {
			// fmr f0,f1
			ctx.f0.f64 = ctx.f1.f64;
			// fmr f13,f3
			ctx.f13.f64 = ctx.f3.f64;
			// b 0x82577468
		} else {
		loc_82577464:
			// fmr f0,f2
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = ctx.f2.f64;
		}
	loc_82577468:
		// lis r11,-32248
		ctx.r11.s64 = -2113404928;
		// lfs f12,-25668(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25668);  /* glob:lbl_82079BBC @ 0x82079bbc */
		ctx.f12.f64 = double(temp.f32);
		// fcmpu cr6,f0,f12
		// bge cr6,0x825774ac
		if (ctx.f0.f64 >= ctx.f12.f64) {
			// fmr f1,f0
			ctx.fpscr.disableFlushMode();
			ctx.f1.f64 = ctx.f0.f64;
			// blr
			return;
		}
		// fmuls f12,f13,f0
		ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f13,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
		ctx.f13.f64 = double(temp.f32);
		// lis r11,-32256
		// fmuls f12,f12,f13
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
		// lfs f13,15788(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f12,f13
		// bge cr6,0x825774ac
		if (ctx.f12.f64 >= ctx.f13.f64) {
			// fmr f1,f0
			ctx.fpscr.disableFlushMode();
			ctx.f1.f64 = ctx.f0.f64;
			// blr
			return;
		}
		// fcmpu cr6,f2,f1
		// ble cr6,0x825774a8
		if (ctx.f2.f64 > ctx.f1.f64) {
			// fmr f0,f2
			ctx.f0.f64 = ctx.f2.f64;
			// b 0x825774ac
		} else {
		loc_825774A8:
			// fmr f0,f1
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = ctx.f1.f64;
		}
	}
loc_825774AC:
	// fmr f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f0.f64;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_74B8"))) PPC_WEAK_FUNC(phBoundCapsule_74B8);
PPC_FUNC_IMPL(__imp__phBoundCapsule_74B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	double var_f31 = 0.0;
	double var_f30 = 0.0;
	double var_f29 = 0.0;
	double var_f28 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f884
	ctx.lr = 0x825774C0;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// mr r27,r3
	var_r27 = ctx.r3.u32;
	// mr r25,r4
	var_r25 = ctx.r4.u32;
	// mr r24,r6
	var_r24 = ctx.r6.u32;
	// lfs f0,27200(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f0.f64 = double(temp.f32);
	// fmadds f13,f1,f2,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f2.f64 + ctx.f0.f64));
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
	// stfiwx f13,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f13.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,4
	// ble cr6,0x82577500
	if (ctx.r11.s32 > 4) {
		// li r11,4
		ctx.r11.s64 = 4;
	}
loc_82577500:
	// extsw r11,r11
	ctx.r11.s64 = ctx.r11.s32;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f13,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fsubs f12,f1,f13
	ctx.f12.f64 = double(float(ctx.f1.f64 - ctx.f13.f64));
	// fadds f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
	// fadds f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// fctiwz f13,f12
	ctx.f13.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f12.f64));
	// stfiwx f13,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f13.u32);
	// lwz r30,80(r1)
	var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 80));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// cmpwi cr6,r30,8
	// bge cr6,0x8257754c
	if ((int32_t)var_r30 < 8) {
		// li r30,8
		var_r30 = 8;
	}
loc_8257754C:
	// lwz r23,80(r1)
	var_r23 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 80));
	// cmpwi cr6,r23,160
	// ble cr6,0x8257755c
	if ((int32_t)var_r23 > 160) {
		// li r23,160
		var_r23 = 160;
	}
loc_8257755C:
	// lis r10,-32248
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
	// li r26,0
	var_r26 = 0;
	// li r31,0
	var_r31 = 0;
	// add r28,r11,r27
	var_r28 = (uint32_t)(ctx.r11.u64 + var_r27);
	// lfs f31,-25900(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -25900);
	var_f31 = double(temp.f32);
	// lis r10,-32256
	// subf r29,r30,r25
	var_r29 = var_r25 - var_r30;
	// lfs f30,15784(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15784);
	var_f30 = double(temp.f32);
	// fmr f29,f30
	var_f29 = var_f30;
	// fmr f28,f30
	var_f28 = var_f30;
loc_82577588:
	// mr r5,r29
	ctx.r5.u64 = var_r29;
	// mr r4,r28
	ctx.r4.u64 = var_r28;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x825769a0
	phBoundCapsule_69A0_2h(ctx, base);
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	// ble cr6,0x825775b0
	if (ctx.f1.f64 > var_f31) {
		// fmr f31,f1
		var_f31 = ctx.f1.f64;
		// mr r26,r31
		var_r26 = (uint32_t)(var_r31);
		// fmr f28,f29
		var_f28 = var_f29;
		// b 0x825775c0
	} else {
	loc_825775B0:
		// addi r11,r31,-1
		ctx.r11.s64 = (int64_t)(int32_t)var_r31 + -1;
		// cmpw cr6,r26,r11
		// bne cr6,0x825775c0
		if ((int32_t)var_r26 != ctx.r11.s32) goto loc_825775C0;
		// fmr f30,f1
		ctx.fpscr.disableFlushMode();
		var_f30 = ctx.f1.f64;
	}
loc_825775C0:
	// addi r31,r31,1
	var_r31 = (uint32_t)(var_r31 + 1);
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	var_f29 = ctx.f1.f64;
	// addi r29,r29,-1
	var_r29 = (uint32_t)(var_r29 + -1);
	// add r11,r31,r30
	ctx.r11.u64 = var_r31 + var_r30;
	// addi r28,r28,4
	var_r28 = (uint32_t)(var_r28 + 4);
	// cmpw cr6,r11,r23
	// ble cr6,0x82577588
	if (ctx.r11.s32 <= (int32_t)var_r23) goto loc_82577588;
	// add r31,r26,r30
	var_r31 = (uint32_t)(var_r26 + var_r30);
	// cmpw cr6,r31,r30
	// ble cr6,0x82577620
	if ((int32_t)var_r31 > (int32_t)var_r30) {
		// cmpw cr6,r31,r23
		// bge cr6,0x82577620
		if ((int32_t)var_r31 >= (int32_t)var_r23) goto loc_82577620;
		// mr r6,r24
		ctx.r6.u64 = var_r24;
		// fmr f3,f30
		ctx.f3.f64 = var_f30;
		// fmr f2,f31
		ctx.f2.f64 = var_f31;
		// fmr f1,f28
		ctx.f1.f64 = var_f28;
		// bl 0x82577e08
		phBoundCapsule_7E08_2h(ctx, base);
		// extsw r11,r31
		ctx.r11.s64 = (int32_t)var_r31;
		// std r11,80(r1)
		PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
		// lfd f0,80(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
		// fcfid f0,f0
		ctx.f0.f64 = double(ctx.f0.s64);
		// frsp f0,f0
		ctx.f0.f64 = double(float(ctx.f0.f64));
		// fadds f31,f0,f1
		var_f31 = double(float(ctx.f0.f64 + ctx.f1.f64));
		// b 0x82577638
	} else {
	loc_82577620:
		// extsw r11,r31
		ctx.r11.s64 = (int32_t)var_r31;
		// stfs f31,0(r24)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(var_f31);
		PPC_STORE_U32(var_r24 + 0, temp.u32);
		// std r11,80(r1)
		PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
		// lfd f0,80(r1)
		ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
		// fcfid f0,f0
		ctx.f0.f64 = double(ctx.f0.s64);
		// frsp f31,f0
		var_f31 = double(float(ctx.f0.f64));
	}
loc_82577638:
	// subf r30,r31,r25
	var_r30 = var_r25 - var_r31;
	// mr r4,r27
	ctx.r4.u64 = var_r27;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// mr r5,r30
	ctx.r5.u64 = var_r30;
	// bl 0x825769a0
	phBoundCapsule_69A0_2h(ctx, base);
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
	// mr r5,r30
	ctx.r5.u64 = var_r30;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	var_f30 = ctx.f1.f64;
	// add r4,r11,r27
	ctx.r4.u64 = ctx.r11.u64 + var_r27;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x825769a0
	phBoundCapsule_69A0_2h(ctx, base);
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f0,-25840(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25840);  /* glob:lbl_82079B10 @ 0x82079b10 */
	ctx.f0.f64 = double(temp.f32);
	// fmadds f1,f1,f30,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * var_f30 + ctx.f0.f64));
	// bl 0x824301d0
	phBoundCapsule_01D0_g(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f1.f64;
	// lfs f13,0(r24)
	temp.u32 = PPC_LOAD_U32(var_r24 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmr f1,f31
	ctx.f1.f64 = var_f31;
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fdivs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
	// stfs f0,0(r24)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r24 + 0, temp.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// b 0x8242f8d4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_76A0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_76A0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_76A0_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	uint32_t ea{};
	// FRAME: size=720, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// stw r4,748(r1)
	PPC_STORE_U32(ctx.r1.u32 + 748, ctx.r4.u32);
	// stw r5,756(r1)
	PPC_STORE_U32(ctx.r1.u32 + 756, ctx.r5.u32);
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// stw r6,764(r1)
	PPC_STORE_U32(ctx.r1.u32 + 764, ctx.r6.u32);
	// stw r7,772(r1)
	PPC_STORE_U32(ctx.r1.u32 + 772, ctx.r7.u32);
	// stw r31,740(r1)
	PPC_STORE_U32(ctx.r1.u32 + 740, var_r31);
	// bl 0x8257a310
	phBoundCapsule_A310_wrh(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// b 0x825776e8
	goto loc_825776E8;
	do {
		// lwz r31,740(r1)
		var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 740));
		// addi r9,r11,4
		ctx.r9.s64 = ctx.r11.s64 + 4;
		// rlwinm r8,r11,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// rlwinm r9,r9,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r6,r11,20
		ctx.r6.s64 = ctx.r11.s64 + 20;
		// addi r7,r11,16
		ctx.r7.s64 = ctx.r11.s64 + 16;
		// rlwinm r10,r10,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// lvlx v0,r8,r31
		temp.u32 = ctx.r8.u32 + var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// rlwinm r8,r6,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
		// lvlx v12,r9,r31
		temp.u32 = ctx.r9.u32 + var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v12.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// addi r9,r11,8
		ctx.r9.s64 = ctx.r11.s64 + 8;
		// rlwinm r7,r7,2,0,29
		ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
		// vrlimi128 v0,v12,4,3
		simde_mm_store_ps(ctx.v0.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v0.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v12.f32), 57), 4));
		// rlwinm r9,r9,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r6,r11,24
		ctx.r6.s64 = ctx.r11.s64 + 24;
		// lvlx v11,r8,r31
		temp.u32 = ctx.r8.u32 + var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v11.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// addi r8,r11,12
		ctx.r8.s64 = ctx.r11.s64 + 12;
		// addi r11,r11,28
		ctx.r11.s64 = ctx.r11.s64 + 28;
		// rlwinm r8,r8,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
		// lvlx v13,r7,r31
		temp.u32 = ctx.r7.u32 + var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v13.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// lvlx v10,r9,r31
		temp.u32 = ctx.r9.u32 + var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v10.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// rlwinm r7,r6,2,0,29
		ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
		// vrlimi128 v0,v10,2,2
		simde_mm_store_ps(ctx.v0.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v0.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v10.f32), 78), 2));
		// rlwinm r11,r11,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// vrlimi128 v13,v11,4,3
		simde_mm_store_ps(ctx.v13.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v13.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v11.f32), 57), 4));
		// addi r9,r1,160
		ctx.r9.s64 = ctx.r1.s64 + 160;
		// lvlx v8,r8,r31
		temp.u32 = ctx.r8.u32 + var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v8.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// vrlimi128 v0,v8,1,1
		simde_mm_store_ps(ctx.v0.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v0.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v8.f32), 147), 1));
		// lvlx v9,r7,r31
		temp.u32 = ctx.r7.u32 + var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v9.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// vrlimi128 v13,v9,2,2
		simde_mm_store_ps(ctx.v13.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v13.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v9.f32), 78), 2));
		// lvlx v7,r11,r31
		temp.u32 = ctx.r11.u32 + var_r31;
		simde_mm_store_si128((simde__m128i*)ctx.v7.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
		// addi r7,r1,176
		ctx.r7.s64 = ctx.r1.s64 + 176;
		// vexptefp v0,v0
		ctx.fpscr.enableFlushMode();
		ctx.v0.f32[0] = exp2f(ctx.v0.f32[0]);
		ctx.v0.f32[1] = exp2f(ctx.v0.f32[1]);
		ctx.v0.f32[2] = exp2f(ctx.v0.f32[2]);
		ctx.v0.f32[3] = exp2f(ctx.v0.f32[3]);
		// vrlimi128 v13,v7,1,1
		simde_mm_store_ps(ctx.v13.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v13.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v7.f32), 147), 1));
		// vexptefp v13,v13
		ctx.v13.f32[0] = exp2f(ctx.v13.f32[0]);
		ctx.v13.f32[1] = exp2f(ctx.v13.f32[1]);
		ctx.v13.f32[2] = exp2f(ctx.v13.f32[2]);
		ctx.v13.f32[3] = exp2f(ctx.v13.f32[3]);
		// stvx128 v0,r10,r9
		ea = (ctx.r10.u32 + ctx.r9.u32) & ~0xF;
		simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v0.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// rlwinm r11,r11,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// stvx128 v13,r11,r7
		ea = (ctx.r11.u32 + ctx.r7.u32) & ~0xF;
		simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v13.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
		// lwz r11,84(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
		// lwz r10,80(r1)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// addi r11,r11,32
		ctx.r11.s64 = ctx.r11.s64 + 32;
		// addi r10,r10,8
		ctx.r10.s64 = ctx.r10.s64 + 8;
		// cmpwi cr6,r11,256
		// stw r11,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
		// stw r10,80(r1)
		PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
		// blt cr6,0x825776e4
		} while (ctx.r11.s32 < 256);
	// lis r11,-32161
	// li r5,260
	ctx.r5.s64 = 260;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,432
	ctx.r3.s64 = ctx.r1.s64 + 432;
	// lwz r11,-22264(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22264);
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// li r5,128
	ctx.r5.s64 = 128;
	// addi r4,r1,432
	ctx.r4.s64 = ctx.r1.s64 + 432;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82576808
	phBoundCapsule_6808(ctx, base);
	// lis r11,-32256
	// lwz r4,748(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 748);
	// lis r10,-32254
	// lfs f13,160(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// srawi r9,r4,1
	ctx.xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r4.s32 >> 1;
	// lfs f0,27868(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27868);
	ctx.f0.f64 = double(temp.f32);
	// addi r7,r9,-1
	ctx.r7.s64 = ctx.r9.s64 + -1;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f0,17776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17776);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r1,164
	ctx.r11.s64 = ctx.r1.s64 + 164;
	// lfs f13,432(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 432);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// addi r9,r1,436
	ctx.r9.s64 = ctx.r1.s64 + 436;
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// cmpwi cr6,r7,1
	// blt cr6,0x82577848
	if (ctx.r7.s32 >= 1) {
		// mr r8,r7
		ctx.r8.u64 = ctx.r7.u64;
	loc_82577818:
		// lfs f13,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addic. r8,r8,-1
		ctx.xer.ca = ctx.r8.u32 > 0;
		ctx.r8.s64 = ctx.r8.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
		// fmuls f13,f13,f0
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// stfs f13,0(r10)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// lfs f12,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fmuls f13,f12,f0
		ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// stfs f13,0(r10)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bne 0x82577818
		if (!ctx.cr0.eq) goto loc_82577818;
	}
loc_82577848:
	// rlwinm r9,r7,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r9,r4
	// beq cr6,0x82577860
	if (ctx.r9.s32 != ctx.r4.s32) {
		// lfs f13,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// stfs f0,0(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	}
loc_82577860:
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// lwz r6,772(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 772);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r5,764(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 764);
	// bl 0x825778f0
	phBoundCapsule_78F0_w(ctx, base);
	// lfs f1,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82576ef0
	phBoundCapsule_6EF0(ctx, base);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,27200(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,756(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 756);
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_78A8_g"))) PPC_WEAK_FUNC(phBoundCapsule_78A8_g);
PPC_FUNC_IMPL(__imp__phBoundCapsule_78A8_g) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	PPCRegister temp{};
	// FRAME: size=112, savegprlr_29
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// cmpwi cr6,r31,0
	// beq cr6,0x825778e8
while (!ctx.cr0.eq) {
	loc_825778C8:
		// lfs f1,0(r30)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f1.f64 = double(temp.f32);
		// bl 0x82430e88
		phBoundCapsule_0E88_g(ctx, base);
		// frsp f0,f1
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f1.f64));
		// stfs f0,0(r29)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
		// addic. r31,r31,-1
		ctx.xer.ca = var_r31 > 0;
		var_r31 = (uint32_t)(var_r31 + -1);
		ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// addi r29,r29,4
		var_r29 = (uint32_t)(var_r29 + 4);
		// bne 0x825778c8
}
loc_825778E8:
	return;
}

__attribute__((alias("__imp__phBoundCapsule_78F0_w"))) PPC_WEAK_FUNC(phBoundCapsule_78F0_w);
PPC_FUNC_IMPL(__imp__phBoundCapsule_78F0_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f89c
	ctx.lr = 0x825778F8;
	__savegprlr_29(ctx, base);
	// lis r11,-32256
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f13.f64 = double(temp.f32);
	// lfs f9,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f9.f64 = double(temp.f32);
	// fcmpu cr6,f13,f9
	// bne cr6,0x82577914
	if (ctx.f13.f64 == ctx.f9.f64) {
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f13,17784(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17784);  /* glob:lbl_82024578 @ 0x82024578 */
		ctx.f13.f64 = double(temp.f32);
	}
loc_82577914:
	// clrlwi. r11,r4,31
	ctx.r11.u64 = ctx.r4.u32 & 0x1;
	// beq 0x82577928
	if (ctx.r11.s32 != 0) {
		// addi r11,r1,-112
		ctx.r11.s64 = ctx.r1.s64 + -112;
		// mr r29,r5
		var_r29 = ctx.r5.u32;
		// b 0x82577930
	} else {
	loc_82577928:
		// mr r11,r5
		ctx.r11.u64 = ctx.r5.u64;
		// addi r29,r1,-112
		var_r29 = (uint32_t)(ctx.r1.s64 + -112);
	}
loc_82577930:
	// lis r10,-32256
	// li r9,0
	ctx.r9.s64 = 0;
	// cmpwi cr6,r4,0
	// lfs f10,15788(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15788);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,0(r29)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// stfs f10,0(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// ble cr6,0x82577a28
	if (ctx.r4.s32 > 0) {
		// lis r8,-32254
		// lis r10,-32248
		// li r31,0
		var_r31 = 0;
		// addi r30,r3,4
		var_r30 = (uint32_t)(ctx.r3.s64 + 4);
		// lfs f11,17780(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 17780);
		ctx.f11.f64 = double(temp.f32);
		// lfs f12,-24880(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -24880);
		ctx.f12.f64 = double(temp.f32);
	loc_82577964:
		// fmr f0,f9
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = ctx.f9.f64;
		// cmpwi cr6,r9,0
		// blt cr6,0x82577998
		if (ctx.r9.s32 >= 0) {
			// mr r8,r11
			ctx.r8.u64 = ctx.r11.u64;
			// mr r5,r30
			ctx.r5.u64 = var_r30;
			// addi r10,r9,1
			ctx.r10.s64 = ctx.r9.s64 + 1;
		loc_8257797C:
			// lfs f8,0(r8)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
			ctx.f8.f64 = double(temp.f32);
			// addic. r10,r10,-1
			ctx.xer.ca = ctx.r10.u32 > 0;
			ctx.r10.s64 = ctx.r10.s64 + -1;
			// lfs f7,0(r5)
			temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
			ctx.f7.f64 = double(temp.f32);
			// addi r8,r8,4
			ctx.r8.s64 = ctx.r8.s64 + 4;
			// fmadds f0,f8,f7,f0
			ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f7.f64 + ctx.f0.f64));
			// addi r5,r5,-4
			ctx.r5.s64 = ctx.r5.s64 + -4;
			// bne 0x8257797c
			if (ctx.r10.s32 != 0) goto loc_8257797C;
		}
	loc_82577998:
		// fdivs f0,f0,f13
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
		// fcmpu cr6,f0,f12
		// ble cr6,0x825779a8
		if (ctx.f0.f64 > ctx.f12.f64) {
			// fmr f0,f12
			ctx.f0.f64 = ctx.f12.f64;
		}
	loc_825779A8:
		// fcmpu cr6,f0,f11
		ctx.fpscr.disableFlushMode();
		// bge cr6,0x825779b4
		if (ctx.f0.f64 < ctx.f11.f64) {
			// fmr f0,f11
			ctx.f0.f64 = ctx.f11.f64;
		}
	loc_825779B4:
		// mr r10,r11
		ctx.r10.u64 = ctx.r11.u64;
		// stfs f0,0(r6)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
		// mr r11,r29
		ctx.r11.u64 = var_r29;
		// fneg f8,f0
		ctx.f8.u64 = ctx.f0.u64 ^ 0x8000000000000000;
		// addi r6,r6,4
		ctx.r6.s64 = ctx.r6.s64 + 4;
		// add r8,r31,r11
		ctx.r8.u64 = var_r31 + ctx.r11.u64;
		// cmpwi cr6,r9,1
		// mr r29,r10
		var_r29 = ctx.r10.u32;
		// stfs f8,4(r8)
		temp.f32 = float(ctx.f8.f64);
		PPC_STORE_U32(ctx.r8.u32 + 4, temp.u32);
		// blt cr6,0x82577a0c
		if (ctx.r9.s32 >= 1) {
			// add r5,r31,r10
			ctx.r5.u64 = var_r31 + ctx.r10.u64;
			// subf r3,r11,r10
			ctx.r3.s64 = ctx.r10.s64 - ctx.r11.s64;
			// addi r8,r11,4
			ctx.r8.s64 = ctx.r11.s64 + 4;
			// mr r10,r9
			ctx.r10.u64 = ctx.r9.u64;
		loc_825779EC:
			// lfs f8,0(r5)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
			ctx.f8.f64 = double(temp.f32);
			// addic. r10,r10,-1
			ctx.xer.ca = ctx.r10.u32 > 0;
			ctx.r10.s64 = ctx.r10.s64 + -1;
			// lfsx f7,r3,r8
			temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r8.u32);
			ctx.f7.f64 = double(temp.f32);
			// addi r5,r5,-4
			ctx.r5.s64 = ctx.r5.s64 + -4;
			// fnmsubs f8,f8,f0,f7
			ctx.f8.f64 = double(float(-(ctx.f8.f64 * ctx.f0.f64 - ctx.f7.f64)));
			// stfs f8,0(r8)
			temp.f32 = float(ctx.f8.f64);
			PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
			// addi r8,r8,4
			ctx.r8.s64 = ctx.r8.s64 + 4;
			// bne 0x825779ec
			if (ctx.r10.s32 != 0) goto loc_825779EC;
		}
	loc_82577A0C:
		// fnmsubs f0,f0,f0,f10
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f0.f64 - ctx.f10.f64)));
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// addi r30,r30,4
		var_r30 = (uint32_t)(var_r30 + 4);
		// cmpw cr6,r9,r4
		// fmuls f13,f0,f13
		ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
		// blt cr6,0x82577964
		if (ctx.r9.s32 < ctx.r4.s32) goto loc_82577964;
	}
loc_82577A28:
	// stfs f13,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// b 0x8242f8ec
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__SinglesNetworkClient_7A30_2hr"))) PPC_WEAK_FUNC(SinglesNetworkClient_7A30_2hr);
PPC_FUNC_IMPL(__imp__SinglesNetworkClient_7A30_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f89c
	ctx.lr = 0x82577A38;
	__savegprlr_29(ctx, base);
	// lis r11,-32256
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mr r29,r3
	var_r29 = ctx.r3.u32;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f8,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
	ctx.f8.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// fmuls f0,f1,f8
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmr f10,f0
	ctx.f10.f64 = ctx.f0.f64;
	// fadds f11,f0,f1
	ctx.f11.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
	// fcmpu cr6,f13,f0
	// bge cr6,0x82577a84
	if (ctx.f13.f64 < ctx.f0.f64) {
		// mr r7,r5
		ctx.r7.u64 = ctx.r5.u64;
	loc_82577A68:
		// cmpw cr6,r11,r6
		// bge cr6,0x82577a84
		if (ctx.r11.s32 >= ctx.r6.s32) goto loc_82577A84;
		// addi r7,r7,4
		ctx.r7.s64 = ctx.r7.s64 + 4;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// lfs f13,0(r7)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f13,f0
		// blt cr6,0x82577a68
		if (ctx.f13.f64 < ctx.f0.f64) goto loc_82577A68;
	}
loc_82577A84:
	// lis r7,-32254
	ctx.r7.s64 = -2113798144;
	// lfs f9,17788(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 17788);  /* glob:lbl_8202457C @ 0x8202457c */
	ctx.f9.f64 = double(temp.f32);
	// fsubs f5,f9,f0
	ctx.f5.f64 = double(float(ctx.f9.f64 - ctx.f0.f64));
	// fcmpu cr6,f0,f5
	// bge cr6,0x82577bbc
	if (ctx.f0.f64 < ctx.f5.f64) {
		// subf r30,r9,r8
		var_r30 = (uint32_t)(ctx.r8.s64 - ctx.r9.s64);
		// mr r7,r9
		ctx.r7.u64 = ctx.r9.u64;
		// lis r8,-32248
		// lis r9,-32256
		// lfs f6,-25840(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -25840);
		ctx.f6.f64 = double(temp.f32);
		// lfs f7,15784(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15784);
		ctx.f7.f64 = double(temp.f32);
	loc_82577AB0:
		// cmpw cr6,r3,r10
		// bge cr6,0x82577bbc
		if (ctx.r3.s32 >= ctx.r10.s32) {
			// b 0x8242f8ec
			__restgprlr_29(ctx, base);
			return;
		}
		// fmr f13,f7
		ctx.fpscr.disableFlushMode();
		ctx.f13.f64 = ctx.f7.f64;
		// cmpw cr6,r11,r6
		// bge cr6,0x82577b30
		if (ctx.r11.s32 < ctx.r6.s32) {
			// rlwinm r9,r11,2,0,29
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// mr r8,r11
			ctx.r8.u64 = ctx.r11.u64;
			// lfsx f12,r9,r5
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
			ctx.f12.f64 = double(temp.f32);
			// stw r8,-48(r1)
			PPC_STORE_U32(ctx.r1.u32 + -48, ctx.r8.u32);
			// fcmpu cr6,f12,f11
			// bge cr6,0x82577b30
			if (ctx.f12.f64 < ctx.f11.f64) {
				// add r9,r9,r4
				ctx.r9.u64 = ctx.r9.u64 + ctx.r4.u64;
				// subf r31,r4,r5
				var_r31 = (uint32_t)(ctx.r5.s64 - ctx.r4.s64);
				loc_82577AE4:
				// cmpw cr6,r8,r6
				// bge cr6,0x82577b18
				if (ctx.r8.s32 >= ctx.r6.s32) goto loc_82577B18;
				// lfs f12,0(r9)
				ctx.fpscr.disableFlushMode();
				temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
				ctx.f12.f64 = double(temp.f32);
				// fcmpu cr6,f13,f12
				// bge cr6,0x82577b00
				if (ctx.f13.f64 < ctx.f12.f64) {
				// fmr f13,f12
				ctx.f13.f64 = ctx.f12.f64;
				// mr r11,r8
				ctx.r11.u64 = ctx.r8.u64;
				}
				loc_82577B00:
				// addi r9,r9,4
				ctx.r9.s64 = ctx.r9.s64 + 4;
				// addi r8,r8,1
				ctx.r8.s64 = ctx.r8.s64 + 1;
				// lfsx f12,r31,r9
				ctx.fpscr.disableFlushMode();
				temp.u32 = PPC_LOAD_U32(var_r31 + ctx.r9.u32);
				ctx.f12.f64 = double(temp.f32);
				// stw r8,-48(r1)
				PPC_STORE_U32(ctx.r1.u32 + -48, ctx.r8.u32);
				// fcmpu cr6,f12,f11
				// blt cr6,0x82577ae4
				if (ctx.f12.f64 < ctx.f11.f64) goto loc_82577AE4;
				loc_82577B18:
				// fcmpu cr6,f13,f7
				ctx.fpscr.disableFlushMode();
			} else {
				if (ctx.f13.f64 > ctx.f7.f64) {
					// rlwinm r9,r11,2,0,29
					ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
					// stfsx f13,r30,r7
					temp.f32 = float(ctx.f13.f64);
					PPC_STORE_U32(var_r30 + ctx.r7.u32, temp.u32);
					// lfsx f13,r9,r5
					temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
					ctx.f13.f64 = double(temp.f32);
					// b 0x82577b6c
					} else {
				}
			}
		loc_82577B30:
			// fadds f13,f11,f10
			ctx.fpscr.disableFlushMode();
			ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
			// addi r9,r1,-48
			ctx.r9.s64 = ctx.r1.s64 + -48;
			// fmadds f13,f13,f8,f8
			ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f8.f64));
			// fctiwz f13,f13
			ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
			// stfiwx f13,0,r9
			PPC_STORE_U32(ctx.r9.u32, ctx.f13.u32);
			// lwz r9,-48(r1)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -48);
			// extsw r8,r9
			ctx.r8.s64 = ctx.r9.s32;
			// rlwinm r9,r9,2,0,29
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
			// std r8,-40(r1)
			PPC_STORE_U64(ctx.r1.u32 + -40, ctx.r8.u64);
			// lfsx f13,r9,r29
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + var_r29);
			ctx.f13.f64 = double(temp.f32);
			// fadds f13,f13,f6
			ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f6.f64));
			// stfsx f13,r30,r7
			temp.f32 = float(ctx.f13.f64);
			PPC_STORE_U32(var_r30 + ctx.r7.u32, temp.u32);
			// lfd f13,-40(r1)
			ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
			// fcfid f13,f13
			ctx.f13.f64 = double(ctx.f13.s64);
			// frsp f13,f13
			ctx.f13.f64 = double(float(ctx.f13.f64));
		}
	loc_82577B6C:
		// fadds f10,f0,f13
		ctx.fpscr.disableFlushMode();
		ctx.f10.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// stfs f13,0(r7)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
		// fadds f11,f10,f1
		ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f1.f64));
		// fcmpu cr6,f11,f9
		// ble cr6,0x82577b84
		if (ctx.f11.f64 > ctx.f9.f64) {
			// fmr f11,f9
			ctx.f11.f64 = ctx.f9.f64;
		}
	loc_82577B84:
		// rlwinm r9,r11,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r3,r3,1
		ctx.r3.s64 = ctx.r3.s64 + 1;
		// add r9,r9,r5
		ctx.r9.u64 = ctx.r9.u64 + ctx.r5.u64;
		// addi r7,r7,4
		ctx.r7.s64 = ctx.r7.s64 + 4;
		// b 0x82577ba8
		goto loc_82577BA8;
		do {
			// cmpw cr6,r11,r6
			// bge cr6,0x82577bb4
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// lfs f13,0(r9)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
			ctx.f13.f64 = double(temp.f32);
			// fcmpu cr6,f13,f10
			// blt cr6,0x82577b98
			} while (ctx.f13.f64 < ctx.f10.f64);
	loc_82577BB4:
		// fcmpu cr6,f10,f5
		ctx.fpscr.disableFlushMode();
		// blt cr6,0x82577ab0
		if (ctx.f10.f64 < ctx.f5.f64) goto loc_82577AB0;
	}
loc_82577BBC:
	// b 0x8242f8ec
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__SinglesNetworkClient_7BC0"))) PPC_WEAK_FUNC(SinglesNetworkClient_7BC0);
PPC_FUNC_IMPL(__imp__SinglesNetworkClient_7BC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r29 = 0;
	double var_f29 = 0.0;
	double var_f30 = 0.0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// FRAME: size=1632, savegprlr_26
	// lis r11,-32256
	// fmr f29,f1
	var_f29 = ctx.f1.f64;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// addi r9,r1,528
	ctx.r9.s64 = ctx.r1.s64 + 528;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// mr r28,r7
	var_r28 = ctx.r7.u32;
	// lfs f0,15788(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f0,100(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f0,104(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f0,17792(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17792);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f0,120(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// bl 0x82577a30
	SinglesNetworkClient_7A30_2hr(ctx, base);
	// li r30,0
	var_r30 = 0;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// li r31,0
	var_r31 = 0;
	// cmpwi r3,0
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, var_r30);
	// lvx128 v0,r0,r10
	ea = (ctx.r10.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lvlx v13,0,r11
	temp.u32 = ctx.r11.u32;
	simde_mm_store_si128((simde__m128i*)ctx.v13.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(temp.u32 & ~0xF)), simde_mm_load_si128((simde__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lis r11,-32256
	// vrlimi128 v0,v13,8,0
	simde_mm_store_ps(ctx.v0.f32, simde_mm_blend_ps(simde_mm_load_ps(ctx.v0.f32), simde_mm_permute_ps(simde_mm_load_ps(ctx.v13.f32), 228), 8));
	// lvx128 v12,r0,r10
	ea = (ctx.r10.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v12.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// vlogefp v0,v0
	ctx.fpscr.enableFlushMode();
	ctx.v0.f32[0] = log2f(ctx.v0.f32[0]);
	ctx.v0.f32[1] = log2f(ctx.v0.f32[1]);
	ctx.v0.f32[2] = log2f(ctx.v0.f32[2]);
	ctx.v0.f32[3] = log2f(ctx.v0.f32[3]);
	// lfs f0,15784(r11)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// vaddfp v0,v0,v12
	ctx.fpscr.enableFlushModeUnconditional();
	simde_mm_store_ps(ctx.v0.f32, simde_mm_add_ps(simde_mm_load_ps(ctx.v0.f32), simde_mm_load_ps(ctx.v12.f32)));
	// stvx v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v0.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// vexptefp v0,v0
	ctx.v0.f32[0] = exp2f(ctx.v0.f32[0]);
	ctx.v0.f32[1] = exp2f(ctx.v0.f32[1]);
	ctx.v0.f32[2] = exp2f(ctx.v0.f32[2]);
	ctx.v0.f32[3] = exp2f(ctx.v0.f32[3]);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// stvx v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v0.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// lfs f13,96(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// ble 0x82577cf8
	if (ctx.cr0.gt) {
		// lis r11,-32256
		// li r27,0
		var_r27 = 0;
		// mr r26,r3
		var_r26 = ctx.r3.u32;
		// lfs f30,27200(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
		var_f30 = double(temp.f32);
	loc_82577C88:
		// addi r11,r1,528
		ctx.r11.s64 = ctx.r1.s64 + 528;
		// addi r10,r1,80
		ctx.r10.s64 = ctx.r1.s64 + 80;
		// mr r31,r30
		var_r31 = (uint32_t)(var_r30);
		// lfsx f31,r27,r11
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r27 + ctx.r11.u32);
		var_f31 = double(temp.f32);
		// fadds f0,f31,f0
		ctx.f0.f64 = double(float(var_f31 + ctx.f0.f64));
		// fmuls f0,f0,f30
		ctx.f0.f64 = double(float(ctx.f0.f64 * var_f30));
		// fadds f0,f0,f30
		ctx.f0.f64 = double(float(ctx.f0.f64 + var_f30));
		// fctiwz f0,f0
		ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
		// stfiwx f0,0,r10
		PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
		// lwz r30,80(r1)
		var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 80));
		// cmpw cr6,r31,r30
		// bge cr6,0x82577ce0
		if ((int32_t)var_r31 < (int32_t)var_r30) {
			// rlwinm r11,r31,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
			// subf r29,r31,r30
			var_r29 = var_r30 - var_r31;
			// add r4,r11,r28
			ctx.r4.u64 = ctx.r11.u64 + var_r28;
			// rlwinm r11,r29,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(var_r29 | (var_r29 << 32), 2) & 0xFFFFFFFC;
			// addi r3,r4,4
			ctx.r3.s64 = ctx.r4.s64 + 4;
			// addi r11,r11,-1
			ctx.r11.s64 = ctx.r11.s64 + -1;
			// rlwinm r5,r11,0,0,29
			ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
			// stfs f13,0(r4)
			temp.f32 = float(ctx.f13.f64);
			PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
			// bl 0x82434520
			SinglesNetworkClient_4520_g(ctx, base);
			// add r31,r29,r31
			var_r31 = (uint32_t)(var_r29 + var_r31);
		}
	loc_82577CE0:
		// addi r11,r1,128
		ctx.r11.s64 = ctx.r1.s64 + 128;
		// fmr f0,f31
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = var_f31;
		// addic. r26,r26,-1
		ctx.xer.ca = var_r26 > 0;
		var_r26 = (uint32_t)(var_r26 + -1);
		// lfsx f13,r27,r11
		temp.u32 = PPC_LOAD_U32(var_r27 + ctx.r11.u32);
		ctx.f13.f64 = double(temp.f32);
		// addi r27,r27,4
		var_r27 = (uint32_t)(var_r27 + 4);
		// bne 0x82577c88
		if ((int32_t)var_r26 != 0) goto loc_82577C88;
	}
loc_82577CF8:
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// fctiwz f0,f29
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (var_f29 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&var_f29));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r30,r11,r30
	var_r30 = (uint32_t)(ctx.r11.u64 + var_r30);
	// cmpwi cr6,r30,256
	// ble cr6,0x82577d18
	if ((int32_t)var_r30 > 256) {
		// li r30,256
		var_r30 = 256;
	}
loc_82577D18:
	// cmpw cr6,r31,r30
	// bge cr6,0x82577d44
	if ((int32_t)var_r31 < (int32_t)var_r30) {
		// rlwinm r11,r31,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
		// subf r10,r31,r30
		ctx.r10.s64 = (int64_t)(int32_t)var_r30 - (int64_t)(int32_t)var_r31;
		// add r4,r11,r28
		ctx.r4.u64 = ctx.r11.u64 + var_r28;
		// rlwinm r11,r10,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r3,r4,4
		ctx.r3.s64 = ctx.r4.s64 + 4;
		// addi r11,r11,-1
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// rlwinm r5,r11,0,0,29
		ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
		// stfs f13,0(r4)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
		// bl 0x82434520
		SinglesNetworkClient_4520_g(ctx, base);
	}
loc_82577D44:
	// cmpwi cr6,r30,256
	// bge cr6,0x82577d78
	if ((int32_t)var_r30 < 256) {
		// lis r9,-32248
		// rlwinm r11,r30,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
		// subfic r10,r30,256
		ctx.xer.ca = var_r30 <= 256;
		ctx.r10.s64 = 256 - (int64_t)(int32_t)var_r30;
		// add r11,r11,r28
		ctx.r11.u64 = ctx.r11.u64 + var_r28;
		// lfs f0,-25528(r9)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -25528);
		ctx.f0.f64 = double(temp.f32);
	loc_82577D60:
		// lfs f13,-4(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
		ctx.f13.f64 = double(temp.f32);
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// fmuls f13,f13,f0
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// stfs f13,0(r11)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x82577d60
		if (ctx.r10.s32 != 0) goto loc_82577D60;
	}
loc_82577D78:
	return;
}

__attribute__((alias("__imp__phBoundCapsule_7D90_w"))) PPC_WEAK_FUNC(phBoundCapsule_7D90_w);
PPC_FUNC_IMPL(__imp__phBoundCapsule_7D90_w) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// addi r5,r5,-1
	ctx.r5.s64 = ctx.r5.s64 + -1;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmpw cr6,r11,r5
	// bge cr6,0x82577dfc
	if (ctx.r11.s32 < ctx.r5.s32) {
		// rlwinm r10,r11,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// add r10,r10,r3
		ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	loc_82577DAC:
		// lfs f0,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// lfs f13,-4(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f0,f13
		// blt cr6,0x82577dec
		if (ctx.f0.f64 >= ctx.f13.f64) {
			// bso cr6,0x82577dec
			// UNIMPLEMENTED: bso
			PPC_UNIMPLEMENTED(0x82577DBC, "bso");
			// lfs f13,4(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
			ctx.f13.f64 = double(temp.f32);
			// fcmpu cr6,f0,f13
			// ble cr6,0x82577dec
			if (ctx.f0.f64 <= ctx.f13.f64) goto loc_82577DEC;
			// mr r4,r11
			ctx.r4.u64 = ctx.r11.u64;
			// addi r9,r9,1
			ctx.r9.s64 = ctx.r9.s64 + 1;
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// addi r10,r10,4
			ctx.r10.s64 = ctx.r10.s64 + 4;
			// cmpw cr6,r9,r6
			// stw r4,0(r7)
			PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r4.u32);
			// addi r7,r7,4
			ctx.r7.s64 = ctx.r7.s64 + 4;
			// beq cr6,0x82577dfc
			if (ctx.r9.s32 == ctx.r6.s32) {
				// stw r9,0(r8)
				PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r9.u32);
				// blr
				return;
			}
		}
	loc_82577DEC:
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// cmpw cr6,r11,r5
		// blt cr6,0x82577dac
		if (ctx.r11.s32 < ctx.r5.s32) goto loc_82577DAC;
	}
loc_82577DFC:
	// stw r9,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_7E08_2h"))) PPC_WEAK_FUNC(phBoundCapsule_7E08_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_7E08_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// fadds f13,f1,f3
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// lis r11,-32256
	// fsubs f12,f3,f1
	ctx.f12.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lfs f0,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	// fmsubs f13,f13,f0,f2
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 - ctx.f2.f64));
	// lfs f1,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fcmpu cr6,f13,f1
	// beq cr6,0x82577e44
	if (ctx.f13.f64 != ctx.f1.f64) {
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f12,16056(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16056);  /* glob:lbl_82003EB8 @ 0x82003eb8 */
		ctx.f12.f64 = double(temp.f32);
		// fmuls f12,f13,f12
		ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
		// fdivs f12,f0,f12
		ctx.f12.f64 = double(float(ctx.f0.f64 / ctx.f12.f64));
		// fneg f1,f12
		ctx.f1.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	}
loc_82577E44:
	// fmadds f0,f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f13.f64 + ctx.f0.f64));
	// fmadds f0,f0,f1,f2
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f1.f64 + ctx.f2.f64));
	// stfs f0,0(r6)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_7E58_2h"))) PPC_WEAK_FUNC(phBoundCapsule_7E58_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_7E58_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	PPCRegister temp{};
	// FRAME: size=544, savegprlr_27
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// mr r31,r6
	var_r31 = ctx.r6.u32;
	// mr r6,r30
	ctx.r6.u64 = var_r30;
	// li r5,256
	ctx.r5.s64 = 256;
	// mr r28,r7
	var_r28 = ctx.r7.u32;
	// mr r27,r8
	var_r27 = ctx.r8.u32;
	// mr r29,r9
	var_r29 = ctx.r9.u32;
	// bl 0x825769d0
	phBoundCapsule_69D0_w(ctx, base);
	// mr r8,r27
	ctx.r8.u64 = var_r27;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// mr r6,r29
	ctx.r6.u64 = var_r29;
	// li r5,256
	ctx.r5.s64 = 256;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bl 0x82577d90
	phBoundCapsule_7D90_w(ctx, base);
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(var_r27 + 0);
	// cmpwi r4,0
	// ble 0x82577f50
	if (ctx.r4.s32 > 0) {
		// addi r10,r1,96
		ctx.r10.s64 = ctx.r1.s64 + 96;
		// lis r6,-32256
		// subf r7,r31,r10
		ctx.r7.s64 = ctx.r10.s64 - (int64_t)(int32_t)var_r31;
		// lis r9,-32256
		// lis r10,-32256
		// rotlwi r8,r4,0
		ctx.r8.u64 = ctx.r4.u32;
		// lfs f8,16056(r6)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 16056);
		ctx.f8.f64 = double(temp.f32);
		// mr r11,r31
		ctx.r11.u64 = var_r31;
		// subf r5,r31,r28
		ctx.r5.s64 = (int64_t)(int32_t)var_r28 - (int64_t)(int32_t)var_r31;
		// lfs f9,15784(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15784);
		ctx.f9.f64 = double(temp.f32);
		// lfs f10,27200(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27200);
		ctx.f10.f64 = double(temp.f32);
	loc_82577ED8:
		// lwzx r9,r7,r11
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r11.u32);
		// rlwinm r10,r9,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// add r10,r10,r30
		ctx.r10.u64 = ctx.r10.u64 + var_r30;
		// lfs f0,4(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
		ctx.f0.f64 = double(temp.f32);
		// lfs f13,-4(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
		ctx.f13.f64 = double(temp.f32);
		// fadds f12,f13,f0
		ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
		// lfs f11,0(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// fsubs f13,f0,f13
		ctx.f13.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
		// fmsubs f0,f12,f10,f11
		ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 - ctx.f11.f64));
		// fmuls f12,f13,f10
		ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
		// fcmpu cr6,f0,f9
		// beq cr6,0x82577f18
		if (ctx.f0.f64 != ctx.f9.f64) {
			// fmuls f13,f0,f8
			ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
			// fdivs f13,f12,f13
			ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
			// fneg f13,f13
			ctx.f13.u64 = ctx.f13.u64 ^ 0x8000000000000000;
			// b 0x82577f1c
		} else {
		loc_82577F18:
			// fmr f13,f9
			ctx.fpscr.disableFlushMode();
			ctx.f13.f64 = ctx.f9.f64;
		}
	loc_82577F1C:
		// extsw r10,r9
		ctx.r10.s64 = ctx.r9.s32;
		// fmadds f0,f13,f0,f12
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f12.f64));
		// addic. r8,r8,-1
		ctx.xer.ca = ctx.r8.u32 > 0;
		ctx.r8.s64 = ctx.r8.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
		// std r10,80(r1)
		PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
		// fmadds f0,f0,f13,f11
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f11.f64));
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// lfd f0,80(r1)
		ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
		// fcfid f0,f0
		ctx.f0.f64 = double(ctx.f0.s64);
		// frsp f0,f0
		ctx.f0.f64 = double(float(ctx.f0.f64));
		// fadds f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// stfsx f0,r5,r11
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r5.u32 + ctx.r11.u32, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x82577ed8
		if (!ctx.cr0.eq) goto loc_82577ED8;
	}
loc_82577F50:
	// cmpwi cr6,r4,3
	// bgt cr6,0x82577f9c
	if (ctx.r4.s32 <= 3) {
		// lis r11,-32254
		// addi r9,r30,28
		ctx.r9.s64 = (int64_t)(int32_t)var_r30 + 28;
		// subf r8,r31,r28
		ctx.r8.s64 = (int64_t)(int32_t)var_r28 - (int64_t)(int32_t)var_r31;
		// li r10,36
		ctx.r10.s64 = 36;
		// lfs f13,17796(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17796);
		ctx.f13.f64 = double(temp.f32);
		// mr r11,r31
		ctx.r11.u64 = var_r31;
		// fmr f0,f13
		ctx.f0.f64 = ctx.f13.f64;
	loc_82577F74:
		// lfs f12,0(r9)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// stfsx f0,r11,r8
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + ctx.r8.u32, temp.u32);
		// addi r9,r9,28
		ctx.r9.s64 = ctx.r9.s64 + 28;
		// stfs f12,0(r11)
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// fadds f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x82577f74
		if (ctx.r10.s32 != 0) goto loc_82577F74;
		// li r11,36
		ctx.r11.s64 = 36;
		// stw r11,0(r27)
		PPC_STORE_U32(var_r27 + 0, ctx.r11.u32);
	}
loc_82577F9C:
	return;
}

__attribute__((alias("__imp__phBoundCapsule_7FA8_2h"))) PPC_WEAK_FUNC(phBoundCapsule_7FA8_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_7FA8_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32256
	// cmpwi cr6,r5,0
	// lfs f0,15788(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
	ctx.f0.f64 = double(temp.f32);
	// bltlr cr6
	if (ctx.r5.s32 < 0) return;
	// addi r11,r5,1
	ctx.r11.s64 = ctx.r5.s64 + 1;
loc_82577FBC:
	// lfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f13.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f13,0(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// fmuls f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// bne 0x82577fbc
	if (ctx.r11.s32 != 0) goto loc_82577FBC;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_7FE0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_7FE0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_7FE0_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f894
	ctx.lr = 0x82577FE8;
	__savegprlr_27(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpw cr6,r5,r10
	// mr r31,r10
	var_r31 = ctx.r10.u32;
	// bgt cr6,0x82577ffc
	if (ctx.r5.s32 <= ctx.r10.s32) {
		// mr r31,r5
		var_r31 = ctx.r5.u32;
	}
loc_82577FFC:
	// cmpwi cr6,r31,0
	// ble cr6,0x82578034
	if ((int32_t)var_r31 > 0) {
		// mr r6,r7
		ctx.r6.u64 = ctx.r7.u64;
		// subf r30,r7,r3
		var_r30 = (uint32_t)(ctx.r3.s64 - ctx.r7.s64);
		// subf r29,r7,r4
		var_r29 = (uint32_t)(ctx.r4.s64 - ctx.r7.s64);
		// subf r28,r7,r8
		var_r28 = (uint32_t)(ctx.r8.s64 - ctx.r7.s64);
		// mr r11,r31
		ctx.r11.u64 = var_r31;
	loc_82578018:
		// lfsx f0,r30,r6
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r30 + ctx.r6.u32);
		ctx.f0.f64 = double(temp.f32);
		// addic. r31,r31,-1
		ctx.xer.ca = var_r31 > 0;
		var_r31 = (uint32_t)(var_r31 + -1);
		// stfs f0,0(r6)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
		// lfsx f0,r29,r6
		temp.u32 = PPC_LOAD_U32(var_r29 + ctx.r6.u32);
		ctx.f0.f64 = double(temp.f32);
		// stfsx f0,r28,r6
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r28 + ctx.r6.u32, temp.u32);
		// addi r6,r6,4
		ctx.r6.s64 = ctx.r6.s64 + 4;
		// bne 0x82578018
		if ((int32_t)var_r31 != 0) goto loc_82578018;
	}
loc_82578034:
	// subf r6,r11,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r11.s64;
	// addi r30,r5,-1
	var_r30 = (uint32_t)(ctx.r5.s64 + -1);
	// cmpw cr6,r30,r6
	// ble cr6,0x82578048
	if ((int32_t)var_r30 > ctx.r6.s32) {
		// mr r30,r6
		var_r30 = ctx.r6.u32;
	}
loc_82578048:
	// cmpwi cr6,r30,0
	// ble cr6,0x825780a0
	if ((int32_t)var_r30 > 0) {
		// rlwinm r6,r11,2,0,29
		ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// mr r29,r3
		var_r29 = ctx.r3.u32;
		// add r31,r6,r8
		var_r31 = (uint32_t)(ctx.r6.u64 + ctx.r8.u64);
		// addi r6,r4,4
		ctx.r6.s64 = ctx.r4.s64 + 4;
		// subf r28,r4,r3
		var_r28 = (uint32_t)(ctx.r3.s64 - ctx.r4.s64);
		// subf r27,r8,r7
		var_r27 = (uint32_t)(ctx.r7.s64 - ctx.r8.s64);
		// add r11,r30,r11
		ctx.r11.u64 = var_r30 + ctx.r11.u64;
	loc_8257806C:
		// lfs f13,0(r29)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r29 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f13.f64 = double(temp.f32);
		// addic. r30,r30,-1
		ctx.xer.ca = var_r30 > 0;
		var_r30 = (uint32_t)(var_r30 + -1);
		ctx.cr0.compare<int32_t>((int32_t)var_r30, 0, ctx.xer);
		// lfsx f0,r28,r6
		temp.u32 = PPC_LOAD_U32(var_r28 + ctx.r6.u32);
		ctx.f0.f64 = double(temp.f32);
		// addi r29,r29,4
		var_r29 = (uint32_t)(var_r29 + 4);
		// fmuls f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
		// stfsx f0,r27,r31
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r27 + var_r31, temp.u32);
		// lfs f0,0(r6)
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// lfs f13,-4(r6)
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -4);
		ctx.f13.f64 = double(temp.f32);
		// addi r6,r6,4
		ctx.r6.s64 = ctx.r6.s64 + 4;
		// fsubs f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
		// stfs f0,0(r31)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
		// addi r31,r31,4
		var_r31 = (uint32_t)(var_r31 + 4);
		// bne 0x8257806c
		if (!ctx.cr0.eq) goto loc_8257806C;
	}
loc_825780A0:
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// addi r5,r5,-2
	ctx.r5.s64 = ctx.r5.s64 + -2;
	// cmpw cr6,r5,r10
	// ble cr6,0x825780b4
	if (ctx.r5.s32 > ctx.r10.s32) {
		// mr r5,r10
		ctx.r5.u64 = ctx.r10.u64;
	}
loc_825780B4:
	// cmpwi cr6,r5,0
	// ble cr6,0x82578108
	if (ctx.r5.s32 > 0) {
		// rlwinm r10,r11,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// subf r31,r8,r7
		var_r31 = (uint32_t)(ctx.r7.s64 - ctx.r8.s64);
		// add r6,r10,r8
		ctx.r6.u64 = ctx.r10.u64 + ctx.r8.u64;
		// addi r10,r4,8
		ctx.r10.s64 = ctx.r4.s64 + 8;
		// subf r4,r4,r3
		ctx.r4.s64 = ctx.r3.s64 - ctx.r4.s64;
		// add r11,r5,r11
		ctx.r11.u64 = ctx.r5.u64 + ctx.r11.u64;
	loc_825780D4:
		// lfs f13,0(r3)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f13.f64 = double(temp.f32);
		// addic. r5,r5,-1
		ctx.xer.ca = ctx.r5.u32 > 0;
		ctx.r5.s64 = ctx.r5.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
		// lfsx f0,r10,r4
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
		ctx.f0.f64 = double(temp.f32);
		// addi r3,r3,4
		ctx.r3.s64 = ctx.r3.s64 + 4;
		// fmuls f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
		// stfsx f0,r6,r31
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r6.u32 + var_r31, temp.u32);
		// lfs f0,0(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// lfs f13,-8(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8);
		ctx.f13.f64 = double(temp.f32);
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// fsubs f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
		// stfs f0,0(r6)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
		// addi r6,r6,4
		ctx.r6.s64 = ctx.r6.s64 + 4;
		// bne 0x825780d4
		if (!ctx.cr0.eq) goto loc_825780D4;
	}
loc_82578108:
	// cmpwi cr6,r11,10
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r11.u32);
	// blt cr6,0x82578164
	if (ctx.r11.s32 >= 10) {
		// li r5,0
		ctx.r5.s64 = 0;
		// cmpwi cr6,r11,0
		// ble cr6,0x82578160
		if (ctx.r11.s32 > 0) {
			// lis r4,-32256
			// mr r10,r8
			ctx.r10.u64 = ctx.r8.u64;
			// subf r6,r7,r8
			ctx.r6.s64 = ctx.r8.s64 - ctx.r7.s64;
			// subf r8,r8,r7
			ctx.r8.s64 = ctx.r7.s64 - ctx.r8.s64;
			// lfs f13,27204(r4)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 27204);
			ctx.f13.f64 = double(temp.f32);
		loc_82578134:
			// lfs f0,0(r7)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
			ctx.f0.f64 = double(temp.f32);
			// fcmpu cr6,f0,f13
			// ble cr6,0x82578154
			if (ctx.f0.f64 > ctx.f13.f64) {
				// stfsx f0,r10,r8
				temp.f32 = float(ctx.f0.f64);
				PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, temp.u32);
				// addi r5,r5,1
				ctx.r5.s64 = ctx.r5.s64 + 1;
				// lfsx f0,r7,r6
				temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
				ctx.f0.f64 = double(temp.f32);
				// stfs f0,0(r10)
				temp.f32 = float(ctx.f0.f64);
				PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
				// addi r10,r10,4
				ctx.r10.s64 = ctx.r10.s64 + 4;
			}
		loc_82578154:
			// addic. r11,r11,-1
			ctx.xer.ca = ctx.r11.u32 > 0;
			ctx.r11.s64 = ctx.r11.s64 + -1;
			// addi r7,r7,4
			ctx.r7.s64 = ctx.r7.s64 + 4;
			// bne 0x82578134
			if (ctx.r11.s32 != 0) goto loc_82578134;
		}
	loc_82578160:
		// stw r5,0(r9)
		PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r5.u32);
	}
loc_82578164:
	// b 0x8242f8e4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__atSingleton_8168"))) PPC_WEAK_FUNC(atSingleton_8168);
PPC_FUNC_IMPL(__imp__atSingleton_8168) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	double var_f31 = 0.0;
	double var_f29 = 0.0;
	double var_f28 = 0.0;
	double var_f30 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, var_r30);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, var_r31);
	// addi r12,r1,-24
	ctx.r12.s64 = ctx.r1.s64 + -24;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	var_f31 = ctx.f1.f64;
	// fmr f29,f2
	var_f29 = ctx.f2.f64;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
	// stfs f31,12(r31)
	temp.f32 = float(var_f31);
	PPC_STORE_U32(var_r31 + 12, temp.u32);
	// stfs f29,16(r31)
	temp.f32 = float(var_f29);
	PPC_STORE_U32(var_r31 + 16, temp.u32);
	// bl 0x8257a5e0
	atSingleton_A5E0_2h(ctx, base);
	// lhz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U16(var_r31 + 24);
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	var_f28 = ctx.f1.f64;
	// cmplwi r10,0
	// lha r11,22(r31)
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(var_r31 + 22));
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// cntlzw r11,r11
	ctx.r11.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 ^ 1;
	// extsh r30,r11
	var_r30 = (uint32_t)(ctx.r11.s16);
	// bne 0x825781d0
	if (ctx.r10.u32 == 0) {
		// li r11,1
		ctx.r11.s64 = 1;
		// sth r11,24(r31)
		PPC_STORE_U16(var_r31 + 24, ctx.r11.u16);
	}
loc_825781D0:
	// lhz r11,26(r31)
	ctx.r11.u64 = PPC_LOAD_U16(var_r31 + 26);
	// cmplwi r11,0
	// bne 0x825781e4
	if (ctx.r11.u32 == 0) {
		// li r11,90
		ctx.r11.s64 = 90;
		// sth r11,26(r31)
		PPC_STORE_U16(var_r31 + 26, ctx.r11.u16);
	}
loc_825781E4:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,15788(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
	ctx.f0.f64 = double(temp.f32);
	// fadds f1,f31,f0
	ctx.f1.f64 = double(float(var_f31 + ctx.f0.f64));
	// bl 0x82432450
	jumptable_2450(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f1.f64;
	// lis r11,-32254
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 4)/* atSingleton::flags@+0x4 */;
	// fmr f1,f31
	ctx.f1.f64 = var_f31;
	// frsp f13,f0
	ctx.f13.f64 = double(float(ctx.f0.f64));
	// lfs f0,17800(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17800);  /* glob:0x82004588 */
	ctx.f0.f64 = double(temp.f32);
	// fmuls f30,f13,f0
	var_f30 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x8257a640
	atSingleton_A640_2h(ctx, base);
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(var_r31 + 4)/* atSingleton::flags@+0x4 */;
	// fmr f2,f28
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = var_f28;
	// lhz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U16(var_r31 + 24);
	// fmr f1,f30
	ctx.f1.f64 = var_f30;
	// bl 0x8257a6b0
	atSingleton_A6B0_2h(ctx, base);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 4)/* atSingleton::flags@+0x4 */;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = var_f31;
	// bl 0x8257a740
	atSingleton_A740_2h(ctx, base);
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(var_r31 + 4)/* atSingleton::flags@+0x4 */;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = var_f30;
	// lhz r5,26(r31)
	ctx.r5.u64 = PPC_LOAD_U16(var_r31 + 26);
	// lhz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U16(var_r31 + 24);
	// bl 0x8257a910
	atSingleton_A910_2h(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 4)/* atSingleton::flags@+0x4 */;
	// mr r4,r30
	ctx.r4.u64 = var_r30;
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = var_f29;
	// sth r11,28(r31)
	PPC_STORE_U16(var_r31 + 28, ctx.r11.u16);
	// bl 0x8257a9e0
	atSingleton_A9E0_2h(ctx, base);
	// cmpwi r3,0
	// beq 0x825782a8
	if (ctx.r3.s32 != 0) {
		// lis r11,-32256
		// lwz r4,8(r31)
		ctx.r4.u64 = PPC_LOAD_U32(var_r31 + 8);
		// lfs f0,27200(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
		ctx.f0.f64 = double(temp.f32);
		// fadds f0,f30,f0
		ctx.f0.f64 = double(float(var_f30 + ctx.f0.f64));
		// fctidz f0,f0
		ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simde_mm_cvttsd_si64(simde_mm_load_sd(&ctx.f0.f64));
		// stfd f0,80(r1)
		PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f0.u64);
		// lbz r3,87(r1)
		ctx.r3.u64 = PPC_LOAD_U8(ctx.r1.u32 + 87);
		// bl 0x8257a4d0
		atSingleton_A4D0_2hr(ctx, base);
		// lbz r11,30(r31)
		ctx.r11.u64 = PPC_LOAD_U8(var_r31 + 30);
		// cmplwi r11,0
		// beq 0x825782b0
		if (ctx.r11.u32 == 0) {
			// li r3,0
			ctx.r3.s64 = 0;
			// addi r1,r1,144
			ctx.r1.s64 = ctx.r1.s64 + 144;
			// addi r12,r1,-24
			ctx.r12.s64 = ctx.r1.s64 + -24;
			// bl 0x82436664
			__restfpr_28(ctx, base);
			// lwz r12,-8(r1)
			ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
			// mtlr r12
			ctx.lr = ctx.r12.u64;
			// ld r30,-24(r1)
			var_r30 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -24));
			// ld r31,-16(r1)
			var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -16));
			// blr
			return;
		}
		// lhz r4,22(r31)
		ctx.r4.u64 = PPC_LOAD_U16(var_r31 + 22);
		// lwz r3,8(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
		// bl 0x8257a380
		atSingleton_A380_fw(ctx, base);
		// sth r3,20(r31)
		PPC_STORE_U16(var_r31 + 20, ctx.r3.u16);
		// b 0x825782b0
	} else {
	loc_825782A8:
		// lwz r3,8(r31)
		ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 8);
		// bl 0x8257a5e8
		atSingleton_A5E8_2h(ctx, base);
	}
loc_825782B0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// addi r12,r1,-24
	ctx.r12.s64 = ctx.r1.s64 + -24;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	var_r30 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -24));
	// ld r31,-16(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -16));
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_82D8_2hr_82D8_1"))) PPC_WEAK_FUNC(phBoundCapsule_82D8_2hr_82D8_1);
PPC_FUNC_IMPL(__imp__phBoundCapsule_82D8_2hr_82D8_1) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	double var_f29 = 0.0;
	double var_f30 = 0.0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// FRAME: size=1232, savegprlr_25
	// mr r26,r4
	var_r26 = ctx.r4.u32;
	// fmr f29,f1
	var_f29 = ctx.f1.f64;
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// addi r25,r26,8
	var_r25 = (uint32_t)(var_r26 + 8);
	// mr r27,r5
	var_r27 = ctx.r5.u32;
	// mr r29,r8
	var_r29 = ctx.r8.u32;
	// lfs f1,52(r30)
	temp.u32 = PPC_LOAD_U32(var_r30 + 52);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,0(r25)
	temp.u32 = PPC_LOAD_U32(var_r25 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f3,48(r30)
	temp.u32 = PPC_LOAD_U32(var_r30 + 48);
	ctx.f3.f64 = double(temp.f32);
	// lfs f4,4(r25)
	temp.u32 = PPC_LOAD_U32(var_r25 + 4);
	ctx.f4.f64 = double(temp.f32);
	// bl 0x82577408
	phBoundCapsule_7408_2h(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	var_f30 = ctx.f1.f64;
	// cmpwi cr6,r29,1
	// bne cr6,0x82578334
	if ((int32_t)var_r29 == 1) {
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f0,16056(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16056);  /* glob:lbl_82003EB8 @ 0x82003eb8 */
		ctx.f0.f64 = double(temp.f32);
		// fmuls f30,f30,f0
		var_f30 = double(float(var_f30 * ctx.f0.f64));
	}
loc_82578334:
	// lwz r28,0(r30)
	var_r28 = (uint32_t)(PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */);
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = var_f30;
	// bl 0x82576e48
	phBoundCapsule_6E48_2h(ctx, base);
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r4,r27
	ctx.r4.u64 = var_r27;
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	// mr r5,r31
	ctx.r5.u64 = var_r31;
	// bl 0x825766e8
	phBoundCapsule_66E8_2h(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82576c38
	phBoundCapsule_6C38_2h(ctx, base);
	// lis r11,-32256
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = var_f30;
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f31,19100(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 19100);  /* glob:lbl_82004A9C @ 0x82004a9c */
	var_f31 = double(temp.f32);
	// fmr f2,f31
	ctx.f2.f64 = var_f31;
	// bl 0x825774b8
	phBoundCapsule_74B8(ctx, base);
	// lis r11,-32256
	// stfs f1,0(r26)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(var_r26 + 0, temp.u32);
	// cmpwi cr6,r29,1
	// lfs f10,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f10.f64 = double(temp.f32);
	// bne cr6,0x825783a0
	if ((int32_t)var_r29 == 1) {
		// fmuls f0,f1,f10
		ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
		// stfs f0,0(r26)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(var_r26 + 0, temp.u32);
	}
loc_825783A0:
	// lfs f12,28(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r30 + 28);
	ctx.f12.f64 = double(temp.f32);
	// fmr f9,f29
	ctx.f9.f64 = var_f29;
	// lfs f0,4(r25)
	temp.u32 = PPC_LOAD_U32(var_r25 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f12,f31
	// lfs f13,48(r30)
	temp.u32 = PPC_LOAD_U32(var_r30 + 48);
	ctx.f13.f64 = double(temp.f32);
	// bge cr6,0x825783bc
	if (ctx.f12.f64 < var_f31) {
		// stfs f31,28(r30)
		temp.f32 = float(var_f31);
		PPC_STORE_U32(var_r30 + 28, temp.u32);
	}
loc_825783BC:
	// fcmpu cr6,f29,f31
	ctx.fpscr.disableFlushMode();
	// bge cr6,0x825783c8
	if (var_f29 < var_f31) {
		// fmr f9,f31
		ctx.f9.f64 = var_f31;
	}
loc_825783C8:
	// fsubs f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f11,27348(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27348);  /* glob:lbl_82006AD4 @ 0x82006ad4 */
	ctx.f11.f64 = double(temp.f32);
	// fabs f12,f12
	ctx.f12.u64 = ctx.f12.u64 & ~0x8000000000000000;
	// fcmpu cr6,f12,f11
	// bge cr6,0x825783ec
	if (ctx.f12.f64 < ctx.f11.f64) {
		// fadds f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
		// fmuls f0,f0,f10
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
		// b 0x82578424
	} else {
	loc_825783EC:
		// lis r11,-32248
		// lfs f12,80(r1)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		ctx.f12.f64 = double(temp.f32);
		// lfs f11,-24540(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24540);
		ctx.f11.f64 = double(temp.f32);
		// fcmpu cr6,f12,f11
		// bge cr6,0x82578410
		if (ctx.f12.f64 < ctx.f11.f64) {
			// fcmpu cr6,f0,f13
			// bgt cr6,0x82578418
			if (ctx.f0.f64 > ctx.f13.f64) goto loc_82578418;
		loc_82578408:
			// fdivs f0,f0,f9
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f9.f64));
			// b 0x82578420
			goto loc_82578420;
		}
	loc_82578410:
		// fcmpu cr6,f0,f13
		ctx.fpscr.disableFlushMode();
		// bgt cr6,0x82578408
		if (ctx.f0.f64 > ctx.f13.f64) goto loc_82578408;
	loc_82578418:
		// lfs f0,28(r30)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r30 + 28);
		ctx.f0.f64 = double(temp.f32);
		// fdivs f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
	loc_82578420:
		// fmuls f0,f0,f12
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	}
loc_82578424:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,15784(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// bge cr6,0x82578438
	if (ctx.f0.f64 < ctx.f13.f64) {
		// fmr f0,f13
		ctx.f0.f64 = ctx.f13.f64;
	}
loc_82578438:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,15788(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// ble cr6,0x8257844c
	if (ctx.f0.f64 > ctx.f13.f64) {
		// fmr f0,f13
		ctx.f0.f64 = ctx.f13.f64;
	}
loc_8257844C:
	// stfs f9,28(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(var_r30 + 28, temp.u32);
	// stfs f0,4(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r26 + 4, temp.u32);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_8468_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_8468_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_8468_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r21 = 0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f87c
	ctx.lr = 0x82578470;
	__savegprlr_21(ctx, base);
	// lis r11,-32255
	// lis r9,-32164
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// addi r25,r7,320
	var_r25 = (uint32_t)(ctx.r7.s64 + 320);  // addr:0x82020140
	// addi r24,r7,368
	var_r24 = (uint32_t)(ctx.r7.s64 + 368);  // addr:0x82020170
	// lfs f0,21604(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21604);  /* glob:0x82005464 */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	// fcmpu cr6,f1,f0
	// addi r28,r9,10016
	var_r28 = (uint32_t)(ctx.r9.s64 + 10016);  // lbl_825C2720 @ 0x825c2720
	// addi r11,r11,17808
	ctx.r11.s64 = ctx.r11.s64 + 17808;
	// ble cr6,0x825784ac
	if (ctx.f1.f64 > ctx.f0.f64) {
		// addi r9,r11,1644
		ctx.r9.s64 = ctx.r11.s64 + 1644;
		// mr r22,r11
		var_r22 = ctx.r11.u32;
		// mr r8,r28
		ctx.r8.u64 = var_r28;
		// b 0x825784b8
	} else {
	loc_825784AC:
		// addi r22,r11,48
		var_r22 = (uint32_t)(ctx.r11.s64 + 48);  // addr:0x82020030
		// addi r8,r28,24
		ctx.r8.s64 = (int64_t)(int32_t)var_r28 + 24;
		// addi r9,r11,2744
		ctx.r9.s64 = ctx.r11.s64 + 2744;
	}
loc_825784B8:
	// stw r9,-112(r1)
	PPC_STORE_U32(ctx.r1.u32 + -112, ctx.r9.u32);
	// addi r9,r28,48
	ctx.r9.s64 = (int64_t)(int32_t)var_r28 + 48;
	// addi r3,r1,-112
	ctx.r3.s64 = ctx.r1.s64 + -112;
	// addi r6,r11,4324
	ctx.r6.s64 = ctx.r11.s64 + 4324;
	// addi r7,r11,3600
	ctx.r7.s64 = ctx.r11.s64 + 3600;
	// addi r11,r11,4984
	ctx.r11.s64 = ctx.r11.s64 + 4984;
	// addi r30,r9,-16
	var_r30 = (uint32_t)(ctx.r9.s64 + -16);  // addr:0x825bfff0
	// subf r23,r3,r8
	var_r23 = (uint32_t)(ctx.r8.s64 - ctx.r3.s64);
	// lis r8,-32256
	// stw r6,-104(r1)
	PPC_STORE_U32(ctx.r1.u32 + -104, ctx.r6.u32);
	// lis r9,-32256
	// stw r7,-108(r1)
	PPC_STORE_U32(ctx.r1.u32 + -108, ctx.r7.u32);
	// stw r11,-100(r1)
	PPC_STORE_U32(ctx.r1.u32 + -100, ctx.r11.u32);
	// li r27,0
	var_r27 = 0;
	// li r26,0
	var_r26 = 0;
	// li r29,0
	var_r29 = 0;
	// lfs f9,15784(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 15784);
	ctx.f9.f64 = double(temp.f32);
	// mr r11,r25
	ctx.r11.u64 = var_r25;
	// lfs f10,15788(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15788);
	ctx.f10.f64 = double(temp.f32);
	// addi r6,r1,-112
	ctx.r6.s64 = ctx.r1.s64 + -112;
loc_82578508:
	// cmpwi cr6,r26,4
	// bge cr6,0x825785dc
	if ((int32_t)var_r26 < 4) {
		// lwz r9,0(r6)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		// li r3,0
		ctx.r3.s64 = 0;
		// lwz r8,0(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// rlwinm r7,r8,3,0,28
		ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
		// lwz r8,4(r9)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
		// add r8,r8,r7
		ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
		// lfs f0,0(r8)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// lfs f0,4(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 4);
		ctx.f0.f64 = double(temp.f32);
		// stfs f0,4(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
		// lwz r8,24(r9)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
		// cmpwi r8,0
		// ble 0x82578568
		if (ctx.r8.s32 > 0) {
			// lwz r31,0(r10)
			var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r10.u32 + 0));
			// lwz r7,28(r9)
			ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
		loc_8257854C:
			// lwz r21,0(r7)
			var_r21 = (uint32_t)(PPC_LOAD_U32(ctx.r7.u32 + 0));
			// cmpw cr6,r21,r31
			// beq cr6,0x825785d4
			if ((int32_t)var_r21 == (int32_t)var_r31) goto loc_825785D4;
			// addi r3,r3,1
			ctx.r3.s64 = ctx.r3.s64 + 1;
			// addi r7,r7,4
			ctx.r7.s64 = ctx.r7.s64 + 4;
			// cmpw cr6,r3,r8
			// blt cr6,0x8257854c
			if (ctx.r3.s32 < ctx.r8.s32) goto loc_8257854C;
		}
	loc_82578568:
		// lwz r7,16(r9)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	loc_8257856C:
		// lwz r8,0(r10)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// lfs f8,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f8.f64 = double(temp.f32);
		// lwz r9,8(r9)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
		// lfs f7,4(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		ctx.f7.f64 = double(temp.f32);
		// rlwinm r8,r8,3,0,28
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
		// lwz r3,4(r10)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
		// add r9,r9,r8
		ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
		// rlwinm r8,r3,3,0,28
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 3) & 0xFFFFFFF8;
		// add r8,r8,r7
		ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
		// lfs f13,4(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
		ctx.f13.f64 = double(temp.f32);
		// fmuls f6,f13,f13
		ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
		// lfs f0,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// lfs f11,4(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 4);
		ctx.f11.f64 = double(temp.f32);
		// fmuls f13,f13,f11
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
		// lfs f12,0(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fmadds f6,f0,f0,f6
		ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f6.f64));
		// fmsubs f13,f0,f12,f13
		ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f12.f64 - ctx.f13.f64));
		// fdivs f0,f10,f6
		ctx.f0.f64 = double(float(ctx.f10.f64 / ctx.f6.f64));
		// fmadds f13,f13,f0,f8
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f8.f64));
		// stfs f13,0(r11)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// lfs f13,4(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
		ctx.f13.f64 = double(temp.f32);
		// fmuls f13,f13,f12
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
		// lfs f12,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fmadds f13,f12,f11,f13
		ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f13.f64));
		// fmadds f0,f13,f0,f7
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f7.f64));
		// b 0x825785fc
		goto loc_825785FC;
	loc_825785D4:
		// lwz r7,20(r9)
		ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
		// b 0x8257856c
		goto loc_8257856C;
	}
loc_825785DC:
	// lwz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U32(var_r30 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r9,r9,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// lfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// lfs f0,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
loc_825785FC:
	// lwzx r9,r23,r6
	ctx.r9.u64 = PPC_LOAD_U32(var_r23 + ctx.r6.u32);
	// stfs f0,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// mr r31,r24
	var_r31 = (uint32_t)(var_r24);
	// li r3,2
	ctx.r3.s64 = 2;
	// subf r8,r25,r9
	ctx.r8.s64 = ctx.r9.s64 - (int64_t)(int32_t)var_r25;
loc_82578610:
	// fmr f0,f9
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f9.f64;
	// cmpwi cr6,r29,0
	// ble cr6,0x8257863c
	if ((int32_t)var_r29 > 0) {
		// mr r9,r25
		ctx.r9.u64 = var_r25;
		// mr r7,r27
		ctx.r7.u64 = var_r27;
	loc_82578624:
		// lfsx f13,r8,r9
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
		ctx.f13.f64 = double(temp.f32);
		// addic. r7,r7,-1
		ctx.xer.ca = ctx.r7.u32 > 0;
		ctx.r7.s64 = ctx.r7.s64 + -1;
		// lfs f12,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// fmadds f0,f13,f12,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f0.f64));
		// bne 0x82578624
		if (ctx.r7.s32 != 0) goto loc_82578624;
	}
loc_8257863C:
	// stfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// addic. r3,r3,-1
	ctx.xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	// add r8,r29,r8
	ctx.r8.u64 = var_r29 + ctx.r8.u64;
	// addi r31,r31,4
	var_r31 = (uint32_t)(var_r31 + 4);
	// bne 0x82578610
	if (ctx.r3.s32 != 0) goto loc_82578610;
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r7,r28,48
	ctx.r7.s64 = (int64_t)(int32_t)var_r28 + 48;
	// lfs f13,0(r24)
	temp.u32 = PPC_LOAD_U32(var_r24 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r9,r27,1
	ctx.r9.s64 = (int64_t)(int32_t)var_r27 + 1;
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lfs f0,4(r24)
	temp.u32 = PPC_LOAD_U32(var_r24 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addi r8,r29,4
	ctx.r8.s64 = (int64_t)(int32_t)var_r29 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r30,r30,4
	var_r30 = (uint32_t)(var_r30 + 4);
	// addi r7,r7,8
	ctx.r7.s64 = ctx.r7.s64 + 8;
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r26,r26,1
	var_r26 = (uint32_t)(var_r26 + 1);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// addi r27,r9,1
	var_r27 = (uint32_t)(ctx.r9.s64 + 1);  // addr:0x82000001
	// addi r29,r8,4
	var_r29 = (uint32_t)(ctx.r8.s64 + 4);  // addr:0x82000004
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmpw cr6,r30,r7
	// blt cr6,0x82578508
	if ((int32_t)var_r30 < ctx.r7.s32) goto loc_82578508;
	// cmpwi cr6,r5,0
	// ble cr6,0x825786e0
	if (ctx.r5.s32 > 0) {
		// mr r11,r25
		ctx.r11.u64 = var_r25;
		// subf r9,r25,r22
		ctx.r9.s64 = (int64_t)(int32_t)var_r22 - (int64_t)(int32_t)var_r25;
		// subf r8,r25,r4
		ctx.r8.s64 = ctx.r4.s64 - (int64_t)(int32_t)var_r25;
		// mr r10,r5
		ctx.r10.u64 = ctx.r5.u64;
	loc_825786C4:
		// lfsx f0,r11,r9
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
		ctx.f0.f64 = double(temp.f32);
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// lfs f13,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fadds f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// stfsx f0,r11,r8
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + ctx.r8.u32, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x825786c4
		if (ctx.r10.s32 != 0) goto loc_825786C4;
	}
loc_825786E0:
	// b 0x8242f8cc
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_86E8_fw"))) PPC_WEAK_FUNC(phBoundCapsule_86E8_fw);
PPC_FUNC_IMPL(__imp__phBoundCapsule_86E8_fw) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// FRAME: size=160, manual
	// lhz r10,92(r3)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r3.u32 + 92);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r31,r6
	var_r31 = ctx.r6.u32;
	// cmplwi cr6,r10,1
	// bne cr6,0x8257871c
	if (ctx.r10.u32 == 1) {
		// lis r10,-32256
		ctx.r10.s64 = -2113929216;
		// lfs f5,27200(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
		ctx.f5.f64 = double(temp.f32);
		// b 0x82578728
	} else {
	loc_8257871C:
		// lis r10,-32256
		// addi r11,r11,8
		ctx.r11.s64 = ctx.r11.s64 + 8;
		// lfs f5,15788(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
		ctx.f5.f64 = double(temp.f32);
	}
loc_82578728:
	// lwz r8,24(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// addi r7,r3,104
	ctx.r7.s64 = ctx.r3.s64 + 104;
	// lwz r30,20(r3)
	var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r3.u32 + 20));
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// lfs f4,32(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f4.f64 = double(temp.f32);
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lfs f3,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f3.f64 = double(temp.f32);
	// lwz r9,12(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r6,8(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lfs f2,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// lwz r5,4(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4)/* phBoundCapsule::flags@+0x4 */;
	// lfs f1,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// stw r7,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r7.u32);
	// stw r8,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r8.u32);
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, var_r30);
	// bl 0x82578db8
	phBoundCapsule_8DB8_2h(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// addi r11,r11,80
	ctx.r11.s64 = ctx.r11.s64 + 80;
	// stw r11,0(r31)
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_8790_h"))) PPC_WEAK_FUNC(phBoundCapsule_8790_h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_8790_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r26 = 0;
	double var_f29 = 0.0;
	double var_f28 = 0.0;
	double var_f30 = 0.0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f884
	ctx.lr = 0x82578798;
	__savegprlr_23(ctx, base);
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-816(r1)
	ea = -816 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r27,-32161
	var_r27 = (uint32_t)(-2107703296);
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	var_f29 = ctx.f1.f64;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// fmr f28,f2
	var_f28 = ctx.f2.f64;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r23,r7
	var_r23 = ctx.r7.u32;
	// mr r24,r8
	var_r24 = ctx.r8.u32;
	// lwz r11,-22264(r27)
	ctx.r11.u64 = PPC_LOAD_U32(var_r27 + -22264);
	// mr r28,r9
	var_r28 = ctx.r9.u32;
	// mr r29,r10
	var_r29 = ctx.r10.u32;
	// addi r25,r30,2316
	var_r25 = (uint32_t)(var_r30 + 2316);
	// addi r26,r30,2056
	var_r26 = (uint32_t)(var_r30 + 2056);
	// li r5,2316
	ctx.r5.s64 = 2316;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// lis r9,-32256
	// mr r10,r30
	ctx.r10.u64 = var_r30;
	// li r11,12
	ctx.r11.s64 = 12;
	// lis r7,-32164
	// lis r8,-32254
	// lfs f13,27200(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27200);
	ctx.f13.f64 = double(temp.f32);
loc_82578800:
	// lfs f12,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lfs f0,24912(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 24912);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// fmadds f0,f0,f12,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64 + ctx.f13.f64));
	// addi r31,r31,4
	var_r31 = (uint32_t)(var_r31 + 4);
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r6,r9,2,22,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0x3FC;
	// lwz r9,10072(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10072);
	// lfsx f0,r6,r9
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r9.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bne 0x82578800
	if (!ctx.cr0.eq) goto loc_82578800;
	// lis r11,-32256
	// addi r5,r30,224
	ctx.r5.s64 = (int64_t)(int32_t)var_r30 + 224;
	// addi r3,r1,368
	ctx.r3.s64 = ctx.r1.s64 + 368;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// lfs f30,15788(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
	var_f30 = double(temp.f32);
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// stfs f30,0(r5)
	temp.f32 = float(var_f30);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
loc_8257885C:
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lfsx f0,r10,r30
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + var_r30);
	ctx.f0.f64 = double(temp.f32);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// fneg f13,f0
	ctx.f13.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// cmpwi cr6,r7,1
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// stfs f13,4(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4, temp.u32);
	// blt cr6,0x825788b0
	if (ctx.r7.s32 >= 1) {
		// add r6,r10,r9
		ctx.r6.u64 = ctx.r10.u64 + ctx.r9.u64;
		// subf r4,r11,r9
		ctx.r4.s64 = ctx.r9.s64 - ctx.r11.s64;
		// addi r8,r11,4
		ctx.r8.s64 = ctx.r11.s64 + 4;
		// mr r9,r7
		ctx.r9.u64 = ctx.r7.u64;
	loc_82578890:
		// lfs f13,0(r6)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addic. r9,r9,-1
		ctx.xer.ca = ctx.r9.u32 > 0;
		ctx.r9.s64 = ctx.r9.s64 + -1;
		// lfsx f12,r4,r8
		temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r8.u32);
		ctx.f12.f64 = double(temp.f32);
		// addi r6,r6,-4
		ctx.r6.s64 = ctx.r6.s64 + -4;
		// fnmsubs f13,f13,f0,f12
		ctx.f13.f64 = double(float(-(ctx.f13.f64 * ctx.f0.f64 - ctx.f12.f64)));
		// stfs f13,0(r8)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// bne 0x82578890
		if (ctx.r9.s32 != 0) goto loc_82578890;
	}
loc_825788B0:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmpwi cr6,r10,48
	// blt cr6,0x8257885c
	if (ctx.r10.s32 < 48) goto loc_8257885C;
	// mr r11,r29
	ctx.r11.u64 = var_r29;
	// subf r9,r29,r5
	ctx.r9.s64 = ctx.r5.s64 - (int64_t)(int32_t)var_r29;
	// subf r8,r29,r30
	ctx.r8.s64 = (int64_t)(int32_t)var_r30 - (int64_t)(int32_t)var_r29;
	// subf r7,r29,r28
	ctx.r7.s64 = (int64_t)(int32_t)var_r28 - (int64_t)(int32_t)var_r29;
	// li r10,12
	ctx.r10.s64 = 12;
loc_825788D4:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// lfsx f0,r8,r11
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfsx f0,r7,r11
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + ctx.r11.u32, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x825788d4
	if (ctx.r10.s32 != 0) goto loc_825788D4;
	// addi r31,r30,48
	var_r31 = (uint32_t)(var_r30 + 48);
	// li r11,1
	ctx.r11.s64 = 1;
	// addi r29,r31,4
	var_r29 = (uint32_t)(var_r31 + 4);
	// subf r6,r31,r5
	ctx.r6.s64 = ctx.r5.s64 - (int64_t)(int32_t)var_r31;
	// mr r10,r29
	ctx.r10.u64 = var_r29;
	// stfs f29,0(r31)
	temp.f32 = float(var_f29);
	PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
loc_82578908:
	// extsw r9,r11
	ctx.r9.s64 = ctx.r11.s32;
	// lfsx f0,r10,r6
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f0.f64 = double(temp.f32);
	// cmpwi cr6,r11,1
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// ble cr6,0x82578958
	if (ctx.r11.s32 > 1) {
		// addi r8,r5,4
		ctx.r8.s64 = ctx.r5.s64 + 4;
		// addi r7,r10,-4
		ctx.r7.s64 = ctx.r10.s64 + -4;
		// addi r9,r11,-1
		ctx.r9.s64 = ctx.r11.s64 + -1;
	loc_8257893C:
		// lfs f13,0(r8)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addic. r9,r9,-1
		ctx.xer.ca = ctx.r9.u32 > 0;
		ctx.r9.s64 = ctx.r9.s64 + -1;
		// lfs f12,0(r7)
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// fnmsubs f0,f13,f12,f0
		ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f12.f64 - ctx.f0.f64)));
		// addi r7,r7,-4
		ctx.r7.s64 = ctx.r7.s64 + -4;
		// bne 0x8257893c
		if (ctx.r9.s32 != 0) goto loc_8257893C;
	}
loc_82578958:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,12
	// ble cr6,0x82578908
	if (ctx.r11.s32 <= 12) goto loc_82578908;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmpwi cr6,r11,43
	// lfs f31,15784(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
	var_f31 = double(temp.f32);
	// bgt cr6,0x825789c8
	if (ctx.r11.s32 <= 43) {
		// rlwinm r10,r11,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r7,r5,4
		ctx.r7.s64 = ctx.r5.s64 + 4;
		// add r10,r10,r31
		ctx.r10.u64 = ctx.r10.u64 + var_r31;
		// subfic r6,r11,44
		ctx.xer.ca = ctx.r11.u32 <= 44;
		ctx.r6.s64 = 44 - ctx.r11.s64;
	loc_8257898C:
		// fmr f0,f31
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = var_f31;
		// mr r9,r7
		ctx.r9.u64 = ctx.r7.u64;
		// addi r8,r10,-4
		ctx.r8.s64 = ctx.r10.s64 + -4;
		// li r11,12
		ctx.r11.s64 = 12;
	loc_8257899C:
		// lfs f13,0(r9)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// lfs f12,0(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// fnmsubs f0,f13,f12,f0
		ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f12.f64 - ctx.f0.f64)));
		// addi r8,r8,-4
		ctx.r8.s64 = ctx.r8.s64 + -4;
		// bne 0x8257899c
		if (ctx.r11.s32 != 0) goto loc_8257899C;
		// stfs f0,0(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addic. r6,r6,-1
		ctx.xer.ca = ctx.r6.u32 > 0;
		ctx.r6.s64 = ctx.r6.s64 + -1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bne 0x8257898c
		if (ctx.r6.s32 != 0) goto loc_8257898C;
	}
loc_825789C8:
	// lis r10,-32164
	// mr r11,r29
	ctx.r11.u64 = var_r29;
	// lwz r10,10084(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 10084);
	// subf r9,r31,r10
	ctx.r9.s64 = ctx.r10.s64 - (int64_t)(int32_t)var_r31;
	// li r10,43
	ctx.r10.s64 = 43;
loc_825789DC:
	// lfsx f0,r9,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x825789dc
	if (ctx.r10.s32 != 0) goto loc_825789DC;
	// lwz r11,-22264(r27)
	ctx.r11.u64 = PPC_LOAD_U32(var_r27 + -22264);
	// li r5,260
	ctx.r5.s64 = 260;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// lwz r11,-22264(r27)
	ctx.r11.u64 = PPC_LOAD_U32(var_r27 + -22264);
	// li r5,260
	ctx.r5.s64 = 260;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,432
	ctx.r3.s64 = ctx.r1.s64 + 432;
	// bctrl
	PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
	// lis r4,-32254
	// lis r5,-32254
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r11,r1,432
	ctx.r11.s64 = ctx.r1.s64 + 432;
	// addi r6,r1,348
	ctx.r6.s64 = ctx.r1.s64 + 348;
	// addi r10,r1,684
	ctx.r10.s64 = ctx.r1.s64 + 684;
	// lfs f13,23360(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 23360);
	ctx.f13.f64 = double(temp.f32);
	// addi r7,r1,100
	ctx.r7.s64 = ctx.r1.s64 + 100;
	// lfs f0,23356(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 23356);
	ctx.f0.f64 = double(temp.f32);
	// mr r9,r29
	ctx.r9.u64 = var_r29;
	// li r8,21
	ctx.r8.s64 = 21;
loc_82578A58:
	// lfs f12,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// fmuls f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f11,0(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// fmuls f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f11,0(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// fmuls f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f11,0(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f12,0(r6)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// addi r6,r6,-4
	ctx.r6.s64 = ctx.r6.s64 + -4;
	// bne 0x82578a58
	if (!ctx.cr0.eq) goto loc_82578A58;
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// li r5,128
	ctx.r5.s64 = 128;
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r4,r1,432
	ctx.r4.s64 = ctx.r1.s64 + 432;
	// fmuls f0,f12,f13
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// bl 0x825767c8
	phBoundCapsule_67C8(ctx, base);
	// subf r11,r30,r25
	ctx.r11.s64 = (int64_t)(int32_t)var_r25 - (int64_t)(int32_t)var_r30;
	// li r10,65
	ctx.r10.s64 = 65;
	// addi r11,r11,-2316
	ctx.r11.s64 = ctx.r11.s64 + -2316;
	// subf r9,r25,r26
	ctx.r9.s64 = (int64_t)(int32_t)var_r26 - (int64_t)(int32_t)var_r25;
loc_82578AD4:
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// addi r7,r1,432
	ctx.r7.s64 = ctx.r1.s64 + 432;
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// lfsx f0,r11,r8
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	ctx.f0.f64 = double(temp.f32);
	// lfsx f13,r11,r7
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r7.u32);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// stfsx f0,r9,r25
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + var_r25, temp.u32);
	// stfs f13,0(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(var_r25 + 0, temp.u32);
	// addi r25,r25,4
	var_r25 = (uint32_t)(var_r25 + 4);
	// bgt 0x82578ad4
	if (ctx.cr0.gt) goto loc_82578AD4;
	// mr r5,r30
	ctx.r5.u64 = var_r30;
	// fmr f1,f29
	ctx.f1.f64 = var_f29;
	// mr r3,r26
	ctx.r3.u64 = var_r26;
	// bl 0x8257aa28
	phBoundCapsule_AA28_2hr(ctx, base);
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = var_f31;
	// fmr f13,f31
	ctx.f13.f64 = var_f31;
	// fcmpu cr6,f28,f30
	// bne cr6,0x82578b2c
	if (var_f28 == var_f30) {
		// extsh. r11,r23
		ctx.r11.s64 = (int16_t)var_r23;
		// bne 0x82578b2c
		if (ctx.r11.s32 != 0) goto loc_82578B2C;
		// extsh. r11,r24
		ctx.r11.s64 = (int16_t)var_r24;
		// beq 0x82578bf4
		if (ctx.r11.s32 == 0) {
			// addi r1,r1,816
			ctx.r1.s64 = ctx.r1.s64 + 816;
			// addi r12,r1,-80
			ctx.r12.s64 = ctx.r1.s64 + -80;
			// bl 0x82436664
			__restfpr_28(ctx, base);
			// b 0x8242f8d4
			__restgprlr_23(ctx, base);
			return;
		}
	}
loc_82578B2C:
	// li r9,0
	ctx.r9.s64 = 0;
	// extsh r6,r24
	ctx.r6.s64 = (int16_t)var_r24;
	// mr r11,r30
	ctx.r11.u64 = var_r30;
	// subf r7,r30,r26
	ctx.r7.s64 = (int64_t)(int32_t)var_r26 - (int64_t)(int32_t)var_r30;
loc_82578B3C:
	// cmpw cr6,r9,r6
	// blt cr6,0x82578b98
	if (ctx.r9.s32 >= ctx.r6.s32) {
		// extsw r10,r9
		ctx.r10.s64 = ctx.r9.s32;
		// addi r5,r1,80
		ctx.r5.s64 = ctx.r1.s64 + 80;
		// extsh r8,r23
		ctx.r8.s64 = (int16_t)var_r23;
		// std r10,88(r1)
		PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
		// lfd f12,88(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
		// fcfid f12,f12
		ctx.f12.f64 = double(ctx.f12.s64);
		// frsp f12,f12
		ctx.f12.f64 = double(float(ctx.f12.f64));
		// fmuls f12,f12,f28
		ctx.f12.f64 = double(float(ctx.f12.f64 * var_f28));
		// fctiwz f12,f12
		ctx.f12.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f12.f64));
		// stfiwx f12,0,r5
		PPC_STORE_U32(ctx.r5.u32, ctx.f12.u32);
		// lwz r10,80(r1)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// add r10,r10,r8
		ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
		// rlwinm r8,r10,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// cmpwi cr6,r10,64
		// lfsx f12,r8,r26
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + var_r26);
		ctx.f12.f64 = double(temp.f32);
		// stfs f12,0(r11)
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// bgt cr6,0x82578b90
		if (ctx.r10.s32 <= 64) {
			// lfsx f12,r8,r26
			temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + var_r26);
			ctx.f12.f64 = double(temp.f32);
			// b 0x82578b9c
			goto loc_82578B9C;
		}
	loc_82578B90:
		// lfs f12,256(r26)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r26 + 256);
		ctx.f12.f64 = double(temp.f32);
		// b 0x82578b9c
	} else {
	loc_82578B98:
		// lfsx f12,r7,r11
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r11.u32);
		ctx.f12.f64 = double(temp.f32);
	}
loc_82578B9C:
	// stfs f12,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lfsx f12,r7,r11
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r11.u32);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmpwi cr6,r9,65
	// blt cr6,0x82578b3c
	if (ctx.r9.s32 < 65) goto loc_82578B3C;
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// lis r9,-32254
	// mr r11,r26
	ctx.r11.u64 = var_r26;
	// subf r8,r26,r30
	ctx.r8.s64 = (int64_t)(int32_t)var_r30 - (int64_t)(int32_t)var_r26;
	// li r10,65
	ctx.r10.s64 = 65;
	// lfs f0,23352(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 23352);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
loc_82578BDC:
	// lfsx f13,r8,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r11.u32);
	ctx.f13.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// fadds f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x82578bdc
	if (ctx.r10.s32 != 0) goto loc_82578BDC;
loc_82578BF4:
	// addi r1,r1,816
	ctx.r1.s64 = ctx.r1.s64 + 816;
	// addi r12,r1,-80
	ctx.r12.s64 = ctx.r1.s64 + -80;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// b 0x8242f8d4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_8C08_2h"))) PPC_WEAK_FUNC(phBoundCapsule_8C08_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_8C08_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, var_r30);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, var_r31);
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r30,12(r3)
	var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r3.u32 + 12));
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// lhz r6,4(r3)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r3.u32 + 4);
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// slw r10,r10,r5
	ctx.r10.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r5.u8 & 0x3F));
	// addi r31,r10,-1
	var_r31 = (uint32_t)(ctx.r10.s64 + -1);  // addr:0x825bffff
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(var_r30 + 0);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// add r7,r8,r5
	ctx.r7.u64 = ctx.r8.u64 + ctx.r5.u64;
	// rlwinm. r5,r7,0,0,28
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFF8;
	// beq 0x82578cb0
	if (ctx.r5.s32 != 0) {
		// lbz r5,0(r9)
		ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
		// clrlwi r6,r6,16
		ctx.r6.u64 = ctx.r6.u32 & 0xFFFF;
		// subfic r8,r8,8
		ctx.xer.ca = ctx.r8.u32 <= 8;
		ctx.r8.s64 = 8 - ctx.r8.s64;
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// srw r10,r5,r10
		ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r5.u32 >> (ctx.r10.u8 & 0x3F));
		// stb r10,0(r4)
		PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r10.u8);
		// lhz r10,0(r11)
		ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// clrlwi r10,r10,16
		ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
		// mr r5,r10
		ctx.r5.u64 = ctx.r10.u64;
		// cmplw cr6,r5,r6
		// sth r10,0(r11)
		PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
		// blt cr6,0x82578c8c
		if (ctx.r5.u32 >= ctx.r6.u32) {
			// li r10,0
			ctx.r10.s64 = 0;
			// sth r10,0(r11)
			PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
			// lwz r9,0(r3)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
		}
	loc_82578C8C:
		// lbz r11,0(r9)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
		// sraw r9,r31,r8
		temp.u32 = ctx.r8.u32 & 0x3F;
		if (temp.u32 > 0x1F) temp.u32 = 0x1F;
		ctx.xer.ca = ((int32_t)var_r31 < 0) & ((((int32_t)var_r31 >> temp.u32) << temp.u32) != (int32_t)var_r31);
		ctx.r9.s64 = (int32_t)var_r31 >> temp.u32;
		// lbz r10,0(r4)
		ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
		// addi r7,r7,-8
		ctx.r7.s64 = ctx.r7.s64 + -8;
		// and r11,r9,r11
		ctx.r11.u64 = ctx.r9.u64 & ctx.r11.u64;
		// slw r11,r11,r8
		ctx.r11.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r11.u32 << (ctx.r8.u8 & 0x3F));
		// or r11,r11,r10
		ctx.r11.u64 = ctx.r11.u64 | ctx.r10.u64;
		// stb r11,0(r4)
		PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r11.u8);
		// b 0x82578cf4
	} else {
	loc_82578CB0:
		// lbz r9,0(r9)
		ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
		// clrlwi r8,r31,24
		ctx.r8.u64 = var_r31 & 0xFF;
		// cmpwi cr6,r7,8
		// srw r10,r9,r10
		ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r10.u8 & 0x3F));
		// and r10,r10,r8
		ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
		// stb r10,0(r4)
		PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r10.u8);
		// bne cr6,0x82578cf4
		if (ctx.r7.s32 != 8) {
			// stb r7,0(r30)
			PPC_STORE_U8(var_r30 + 0, ctx.r7.u8);
			// ld r30,-16(r1)
			var_r30 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -16));
			// ld r31,-8(r1)
			var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
			// blr
			return;
		}
		// lhz r10,0(r11)
		ctx.r10.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
		// clrlwi r9,r6,16
		ctx.r9.u64 = ctx.r6.u32 & 0xFFFF;
		// li r7,0
		ctx.r7.s64 = 0;
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// clrlwi r10,r10,16
		ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
		// mr r8,r10
		ctx.r8.u64 = ctx.r10.u64;
		// cmplw cr6,r8,r9
		// sth r10,0(r11)
		PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
		// blt cr6,0x82578cf4
		if (ctx.r8.u32 < ctx.r9.u32) {
			// stb r7,0(r30)
			PPC_STORE_U8(var_r30 + 0, ctx.r7.u8);
			// ld r30,-16(r1)
			var_r30 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -16));
			// ld r31,-8(r1)
			var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
			// blr
			return;
		}
		// sth r7,0(r11)
		PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r7.u16);
	}
loc_82578CF4:
	// stb r7,0(r30)
	PPC_STORE_U8(var_r30 + 0, ctx.r7.u8);
	// ld r30,-16(r1)
	var_r30 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -16));
	// ld r31,-8(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_8D08_wrh"))) PPC_WEAK_FUNC(phBoundCapsule_8D08_wrh);
PPC_FUNC_IMPL(__imp__phBoundCapsule_8D08_wrh) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// lis r11,-32254
	// fmr f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f1.f64;
	// addi r8,r1,-16
	ctx.r8.s64 = ctx.r1.s64 + -16;
	// lis r9,-32248
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// cmpwi cr6,r4,0
	// lfs f0,23420(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 23420);
	ctx.f0.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// fmuls f12,f2,f0
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// lfs f0,-25800(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -25800);
	ctx.f0.f64 = double(temp.f32);
	// fctiwz f12,f12
	ctx.f12.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f12.f64));
	// stfiwx f12,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f12.u32);
	// ble cr6,0x82578d88
	if (ctx.r4.s32 > 0) {
		// lis r9,-32254
		ctx.r9.s64 = -2113798144;
		// lfs f12,23416(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 23416);  /* glob:lbl_82025B78 @ 0x82025b78 */
		ctx.f12.f64 = double(temp.f32);
	loc_82578D44:
		// lfs f11,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// lwz r9,-16(r1)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
		// fadds f11,f11,f13
		ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
		// stfs f11,0(r10)
		temp.f32 = float(ctx.f11.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// cmpw cr6,r11,r9
		// fadds f13,f13,f1
		ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
		// blt cr6,0x82578d64
		if (ctx.r11.s32 >= ctx.r9.s32) {
			// fadds f0,f0,f12
			ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f12.f64));
		}
	loc_82578D64:
		// clrlwi. r9,r11,31
		ctx.r9.u64 = ctx.r11.u32 & 0x1;
		// bne 0x82578d78
		if (ctx.r9.s32 == 0) {
			// lfs f11,0(r10)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			ctx.f11.f64 = double(temp.f32);
			// fadds f11,f11,f0
			ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
			// stfs f11,0(r10)
			temp.f32 = float(ctx.f11.f64);
			PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		}
	loc_82578D78:
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// cmpw cr6,r11,r4
		// blt cr6,0x82578d44
		if (ctx.r11.s32 < ctx.r4.s32) goto loc_82578D44;
	}
loc_82578D88:
	// addi r11,r4,3
	ctx.r11.s64 = ctx.r4.s64 + 3;
	// srawi. r10,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 2;
	// blelr
	if (ctx.r10.s32 <= 0) return;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_82578D98:
	// lvx128 v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// vexptefp v0,v0
	ctx.fpscr.enableFlushMode();
	ctx.v0.f32[0] = exp2f(ctx.v0.f32[0]);
	ctx.v0.f32[1] = exp2f(ctx.v0.f32[1]);
	ctx.v0.f32[2] = exp2f(ctx.v0.f32[2]);
	ctx.v0.f32[3] = exp2f(ctx.v0.f32[3]);
	// stvx v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v0.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// bne 0x82578d98
	if (ctx.r10.s32 != 0) goto loc_82578D98;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_8DB8_2h"))) PPC_WEAK_FUNC(phBoundCapsule_8DB8_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_8DB8_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r25 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r19 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r22 = 0;
	double var_f29 = 0.0;
	double var_f26 = 0.0;
	double var_f25 = 0.0;
	double var_f28 = 0.0;
	double var_f30 = 0.0;
	double var_f31 = 0.0;
	double var_f27 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f874
	ctx.lr = 0x82578DC0;
	__savegprlr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x8243660c
	__savefpr_25(ctx, base);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	var_f29 = ctx.f1.f64;
	// lis r11,-32256
	// mr r25,r10
	var_r25 = ctx.r10.u32;
	// fmr f26,f3
	var_f26 = ctx.f3.f64;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// fmr f25,f4
	var_f25 = ctx.f4.f64;
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// fmr f28,f5
	var_f28 = ctx.f5.f64;
	// mr r20,r4
	var_r20 = ctx.r4.u32;
	// lfs f30,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
	var_f30 = double(temp.f32);
	// lis r11,-32248
	// mr r21,r5
	var_r21 = ctx.r5.u32;
	// mr r19,r6
	var_r19 = ctx.r6.u32;
	// mr r26,r9
	var_r26 = ctx.r9.u32;
	// fmuls f13,f29,f30
	ctx.f13.f64 = double(float(var_f29 * var_f30));
	// lfs f0,-25804(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25804);
	ctx.f0.f64 = double(temp.f32);
	// fdivs f31,f0,f29
	var_f31 = double(float(ctx.f0.f64 / var_f29));
	// fctiwz f0,f13
	ctx.f0.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// lwz r31,112(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 112));
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// extsw r11,r31
	ctx.r11.s64 = (int32_t)var_r31;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r11.u64);
	// lfd f0,112(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmadds f0,f0,f31,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * var_f31 + var_f30));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmpwi cr6,r11,256
	// blt cr6,0x82578e50
	if (ctx.r11.s32 >= 256) {
		// addi r31,r31,-1
		var_r31 = (uint32_t)(var_r31 + -1);
	}
loc_82578E50:
	// cmpwi cr6,r31,100
	// ble cr6,0x82578e5c
	if ((int32_t)var_r31 > 100) {
		// li r31,100
		var_r31 = 100;
	}
loc_82578E5C:
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f13,17788(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 17788);  /* glob:lbl_8202457C @ 0x8202457c */
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f2,f13
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fcmpu cr6,f0,f13
	// bge cr6,0x82578e80
	if (ctx.f0.f64 < ctx.f13.f64) {
		// li r11,100
		ctx.r11.s64 = 100;
		// twllei r31,0
		if ((int32_t)var_r31 == 0 || var_r31 < 0u) __builtin_trap();
		// divw r27,r11,r31
		var_r27 = (uint32_t)(int32_t)((int32_t)var_r31 ? ctx.r11.s32 / (int32_t)var_r31 : 0);
		// b 0x82578e84
	} else {
	loc_82578E80:
		// li r27,1
		var_r27 = 1;
	}
loc_82578E84:
	// extsw r10,r27
	ctx.r10.s64 = (int32_t)var_r27;
	// fmuls f13,f0,f29
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f0.f64 * var_f29));
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// lis r11,-32254
	// mullw r23,r27,r31
	var_r23 = (uint32_t)(int64_t((int32_t)var_r27) * int64_t((int32_t)var_r31));
	// std r10,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r10.u64);
	// lis r10,-32248
	// addi r24,r11,23364
	var_r24 = (uint32_t)(ctx.r11.s64 + 23364);  // lbl_82025B44 @ 0x82025b44
	// li r30,0
	var_r30 = 0;
	// addi r11,r24,28
	ctx.r11.s64 = (int64_t)(int32_t)var_r24 + 28;
	// lfs f0,-25260(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -25260);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r29,112(r1)
	var_r29 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 112));
	// mullw r22,r29,r27
	var_r22 = (uint32_t)(int64_t((int32_t)var_r29) * int64_t((int32_t)var_r27));
	// lfd f0,120(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fdivs f27,f31,f0
	var_f27 = double(float(var_f31 / ctx.f0.f64));
loc_82578ED4:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f29,f0
	// bgt cr6,0x82578ef8
	if (var_f29 > ctx.f0.f64) goto loc_82578EF8;
	// addi r10,r24,28
	ctx.r10.s64 = (int64_t)(int32_t)var_r24 + 28;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r10,r10,20
	ctx.r10.s64 = ctx.r10.s64 + 20;
	// addi r30,r30,1
	var_r30 = (uint32_t)(var_r30 + 1);
	// cmpw cr6,r11,r10
	// blt cr6,0x82578ed4
	if (ctx.r11.s32 < ctx.r10.s32) goto loc_82578ED4;
loc_82578EF8:
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = var_f27;
	// bl 0x82576ef0
	phBoundCapsule_6EF0(ctx, base);
	// rlwinm r6,r30,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,388(r1)
	var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 388));
	// addi r11,r24,4
	ctx.r11.s64 = (int64_t)(int32_t)var_r24 + 4;
	// fmr f4,f28
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = var_f28;
	// mr r10,r26
	ctx.r10.u64 = var_r26;
	// lwz r26,396(r1)
	var_r26 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 396));
	// mr r8,r21
	ctx.r8.u64 = var_r21;
	// stw r25,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, var_r25);
	// mr r9,r26
	ctx.r9.u64 = var_r26;
	// fmr f3,f27
	ctx.f3.f64 = var_f27;
	// mr r7,r29
	ctx.r7.u64 = var_r29;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, var_r30);
	// lfsx f0,r6,r11
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	// fmadds f13,f1,f30,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 * var_f30 + ctx.f0.f64));
	// mr r6,r31
	ctx.r6.u64 = var_r31;
	// fmr f2,f31
	ctx.f2.f64 = var_f31;
	// lfs f0,23412(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 23412);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// bl 0x8257abe8
	phBoundCapsule_ABE8_wrh(ctx, base);
	// lfs f12,8(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r28 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32254
	// fadds f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 + var_f31));
	// lfs f13,0(r28)
	temp.u32 = PPC_LOAD_U32(var_r28 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,23424(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 23424);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	// fmadds f13,f12,f0,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// lfs f0,-25884(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25884);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f10,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
	ctx.f10.f64 = double(temp.f32);
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f0,f10
	// ble cr6,0x82578f90
	if (ctx.f0.f64 > ctx.f10.f64) {
		// fadds f0,f0,f30
		ctx.f0.f64 = double(float(ctx.f0.f64 + var_f30));
		// b 0x82578f94
	} else {
	loc_82578F90:
		// fsubs f0,f0,f30
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 - var_f30));
	}
loc_82578F94:
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f0.u32);
	// lwa r10,112(r1)
	ctx.r10.s64 = int32_t(PPC_LOAD_U32(ctx.r1.u32 + 112));
	// lis r11,-32255
	// mr r7,r26
	ctx.r7.u64 = var_r26;
	// stfs f31,8(r28)
	temp.f32 = float(var_f31);
	PPC_STORE_U32(var_r28 + 8, temp.u32);
	// mr r6,r30
	ctx.r6.u64 = var_r30;
	// fmr f2,f29
	ctx.f2.f64 = var_f29;
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// std r10,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r10.u64);
	// lfs f0,-32048(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32048);
	ctx.f0.f64 = double(temp.f32);
	// lfd f12,120(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fnmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64)));
	// stfs f1,0(r28)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(var_r28 + 0, temp.u32);
	// bl 0x82578d08
	phBoundCapsule_8D08_wrh(ctx, base);
	// addi r11,r31,-1
	ctx.r11.s64 = (int64_t)(int32_t)var_r31 + -1;
	// addi r10,r23,-1
	ctx.r10.s64 = (int64_t)(int32_t)var_r23 + -1;
	// cmpw cr6,r11,r29
	// blt cr6,0x8257904c
	if (ctx.r11.s32 >= (int32_t)var_r29) {
		// subf r9,r29,r11
		ctx.r9.s64 = ctx.r11.s64 - (int64_t)(int32_t)var_r29;
		// rlwinm r8,r11,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r7,r9,1
		ctx.r7.s64 = ctx.r9.s64 + 1;
		// rlwinm r9,r10,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// rlwinm r4,r27,2,0,29
		ctx.r4.u64 = __builtin_rotateleft64(var_r27 | (var_r27 << 32), 2) & 0xFFFFFFFC;
		// add r9,r9,r30
		ctx.r9.u64 = ctx.r9.u64 + var_r30;
		// add r6,r8,r30
		ctx.r6.u64 = ctx.r8.u64 + var_r30;
		// subf r3,r30,r26
		ctx.r3.s64 = (int64_t)(int32_t)var_r26 - (int64_t)(int32_t)var_r30;
		// subf r11,r7,r11
		ctx.r11.s64 = ctx.r11.s64 - ctx.r7.s64;
	loc_8257900C:
		// cmpwi cr6,r27,0
		// ble cr6,0x82579040
		if ((int32_t)var_r27 > 0) {
			// mr r8,r9
			ctx.r8.u64 = ctx.r9.u64;
			// mr r5,r27
			ctx.r5.u64 = var_r27;
			// subf r10,r27,r10
			ctx.r10.s64 = ctx.r10.s64 - (int64_t)(int32_t)var_r27;
			// subf r9,r4,r9
			ctx.r9.s64 = ctx.r9.s64 - ctx.r4.s64;
		loc_82579024:
			// lfsx f0,r6,r3
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r3.u32);
			ctx.f0.f64 = double(temp.f32);
			// addic. r5,r5,-1
			ctx.xer.ca = ctx.r5.u32 > 0;
			ctx.r5.s64 = ctx.r5.s64 + -1;
			// stfsx f0,r3,r8
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r3.u32 + ctx.r8.u32, temp.u32);
			// lfs f0,0(r6)
			temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
			ctx.f0.f64 = double(temp.f32);
			// stfs f0,0(r8)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
			// addi r8,r8,-4
			ctx.r8.s64 = ctx.r8.s64 + -4;
			// bne 0x82579024
			if (ctx.r5.s32 != 0) goto loc_82579024;
		}
	loc_82579040:
		// addic. r7,r7,-1
		ctx.xer.ca = ctx.r7.u32 > 0;
		ctx.r7.s64 = ctx.r7.s64 + -1;
		// addi r6,r6,-4
		ctx.r6.s64 = ctx.r6.s64 + -4;
		// bne 0x8257900c
		if (ctx.r7.s32 != 0) goto loc_8257900C;
	}
loc_8257904C:
	// cmpwi cr6,r11,0
	// blt cr6,0x825790b0
	if (ctx.r11.s32 >= 0) {
		// rlwinm r9,r11,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// subf r6,r30,r26
		ctx.r6.s64 = (int64_t)(int32_t)var_r26 - (int64_t)(int32_t)var_r30;
		// add r7,r9,r30
		ctx.r7.u64 = ctx.r9.u64 + var_r30;
	loc_82579060:
		// rlwinm r9,r10,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// lfsx f0,r7,r6
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
		ctx.f0.f64 = double(temp.f32);
		// addi r10,r10,-1
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// cmpwi cr6,r27,1
		// stfsx f0,r9,r26
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r9.u32 + var_r26, temp.u32);
		// lfs f0,0(r7)
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// stfsx f0,r9,r30
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r9.u32 + var_r30, temp.u32);
		// ble cr6,0x825790a4
		if ((int32_t)var_r27 > 1) {
			// rlwinm r8,r10,2,0,29
			ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
			// addi r9,r27,-1
			ctx.r9.s64 = (int64_t)(int32_t)var_r27 + -1;
			// add r8,r8,r30
			ctx.r8.u64 = ctx.r8.u64 + var_r30;
			// subf r10,r9,r10
			ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
		loc_82579090:
			// stfsx f10,r8,r6
			ctx.fpscr.disableFlushMode();
			temp.f32 = float(ctx.f10.f64);
			PPC_STORE_U32(ctx.r8.u32 + ctx.r6.u32, temp.u32);
			// addic. r9,r9,-1
			ctx.xer.ca = ctx.r9.u32 > 0;
			ctx.r9.s64 = ctx.r9.s64 + -1;
			// stfs f10,0(r8)
			temp.f32 = float(ctx.f10.f64);
			PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
			// addi r8,r8,-4
			ctx.r8.s64 = ctx.r8.s64 + -4;
			// bne 0x82579090
			if (ctx.r9.s32 != 0) goto loc_82579090;
		}
	loc_825790A4:
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// addi r7,r7,-4
		ctx.r7.s64 = ctx.r7.s64 + -4;
		// bge 0x82579060
		if (ctx.r11.s32 >= 0) goto loc_82579060;
	}
loc_825790B0:
	// cmpw cr6,r22,r23
	// bge cr6,0x82579134
	if ((int32_t)var_r22 < (int32_t)var_r23) {
		// rlwinm r10,r22,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(var_r22 | (var_r22 << 32), 2) & 0xFFFFFFFC;
		// lwz r8,428(r1)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 428);
		// lfs f0,0(r24)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(var_r24 + 0);
		ctx.f0.f64 = double(temp.f32);
		// subf r11,r22,r23
		ctx.r11.s64 = (int64_t)(int32_t)var_r23 - (int64_t)(int32_t)var_r22;
		// add r10,r10,r30
		ctx.r10.u64 = ctx.r10.u64 + var_r30;
	loc_825790CC:
		// lwz r9,0(r8)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
		// clrlwi r7,r9,16
		ctx.r7.u64 = ctx.r9.u32 & 0xFFFF;
		// srawi r9,r9,16
		ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0xFFFF) != 0);
		ctx.r9.s64 = ctx.r9.s32 >> 16;
		// mulli r7,r7,16807
		ctx.r7.s64 = static_cast<int64_t>(ctx.r7.u64 * static_cast<uint64_t>(16807));
		// mulli r9,r9,16807
		ctx.r9.s64 = static_cast<int64_t>(ctx.r9.u64 * static_cast<uint64_t>(16807));
		// rlwinm r5,r9,16,1,15
		ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0x7FFF0000;
		// rlwinm r6,r9,17,15,31
		ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 17) & 0x1FFFF;
		// add r9,r7,r5
		ctx.r9.u64 = ctx.r7.u64 + ctx.r5.u64;
		// rlwinm r5,r9,1,31,31
		ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
		// clrlwi r7,r9,1
		ctx.r7.u64 = ctx.r9.u32 & 0x7FFFFFFF;
		// add r9,r6,r5
		ctx.r9.u64 = ctx.r6.u64 + ctx.r5.u64;
		// add r9,r9,r7
		ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
		// rlwinm r7,r9,1,31,31
		ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
		// add r9,r7,r9
		ctx.r9.u64 = ctx.r7.u64 + ctx.r9.u64;
		// clrlwi r9,r9,1
		ctx.r9.u64 = ctx.r9.u32 & 0x7FFFFFFF;
		// extsw r7,r9
		ctx.r7.s64 = ctx.r9.s32;
		// stw r9,0(r8)
		PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r9.u32);
		// std r7,120(r1)
		PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r7.u64);
		// lfd f13,120(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
		// fcfid f13,f13
		ctx.f13.f64 = double(ctx.f13.s64);
		// frsp f13,f13
		ctx.f13.f64 = double(float(ctx.f13.f64));
		// fmuls f13,f13,f0
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// stfs f13,0(r10)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bne 0x825790cc
		if (!ctx.cr0.eq) goto loc_825790CC;
	}
loc_82579134:
	// mr r9,r26
	ctx.r9.u64 = var_r26;
	// mtctr r23
	ctx.ctr.u64 = var_r23;
	// lis r11,-32256
	// cmpwi cr6,r23,0
	// lfs f13,15788(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
	ctx.f13.f64 = double(temp.f32);
	// ble cr6,0x82579198
	if ((int32_t)var_r23 > 0) {
		// mr r10,r26
		ctx.r10.u64 = var_r26;
		// mr r11,r23
		ctx.r11.u64 = var_r23;
	loc_82579154:
		// lfs f0,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// fadds f10,f0,f10
		ctx.f10.f64 = double(float(ctx.f0.f64 + ctx.f10.f64));
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bne 0x82579154
		if (ctx.r11.s32 != 0) goto loc_82579154;
		// lis r11,-32255
		ctx.r11.s64 = -2113863680;
		// lfs f0,22448(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22448);  /* glob:lbl_820157B0 @ 0x820157b0 */
		ctx.f0.f64 = double(temp.f32);
		// fcmpu cr6,f10,f0
		// ble cr6,0x8257917c
		if (ctx.f10.f64 > ctx.f0.f64) {
			// fdivs f13,f0,f10
			ctx.f13.f64 = double(float(ctx.f0.f64 / ctx.f10.f64));
		}
	loc_8257917C:
		// cmpwi cr6,r23,0
		// ble cr6,0x82579198
	while (ctx.ctr.u32 != 0) {
		loc_82579184:
			// lfs f0,0(r9)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
			ctx.f0.f64 = double(temp.f32);
			// fmuls f0,f0,f13
			ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
			// stfs f0,0(r9)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// bdnz 0x82579184
			--ctx.ctr.u64;
	}
	}
loc_82579198:
	// mr r10,r26
	ctx.r10.u64 = var_r26;
	// fmr f3,f25
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = var_f25;
	// mr r9,r30
	ctx.r9.u64 = var_r30;
	// fmr f2,f26
	ctx.f2.f64 = var_f26;
	// mr r8,r19
	ctx.r8.u64 = var_r19;
	// fmr f1,f27
	ctx.f1.f64 = var_f27;
	// mr r7,r21
	ctx.r7.u64 = var_r21;
	// mr r6,r20
	ctx.r6.u64 = var_r20;
	// li r5,160
	ctx.r5.s64 = 160;
	// mr r4,r23
	ctx.r4.u64 = var_r23;
	// bl 0x82572d40
	phBoundCapsule_2D40_fw(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x82436658
	__restfpr_25(ctx, base);
	// b 0x8242f8c4
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_91D8_p33"))) PPC_WEAK_FUNC(phBoundCapsule_91D8_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_91D8_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	PPCRegister temp{};
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r30,0
	var_r30 = 0;
	// cmplwi cr6,r31,0
	// li r3,1
	ctx.r3.s64 = 1;
	// beq cr6,0x8257923c
	if (var_r31 != 0) {
		// lis r11,-32161
		// stw r30,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ var_r30);
		// li r4,12
		ctx.r4.s64 = 12;
		// lwz r11,-22272(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22272);
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// cmplwi r3,0
		// bne 0x82579228
		if (ctx.r3.u32 == 0) {
			// li r30,1
			var_r30 = 1;
			// b 0x82579238
		} else {
		loc_82579228:
			// lis r11,-32256
			// stw r3,0(r31)
			PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r3.u32);
			// lfs f0,19112(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 19112);
			ctx.f0.f64 = double(temp.f32);
			// stfs f0,8(r3)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
		}
	loc_82579238:
		// mr r3,r30
		ctx.r3.u64 = var_r30;
	}
loc_8257923C:
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_9258_p33"))) PPC_WEAK_FUNC(phBoundCapsule_9258_p33);
PPC_FUNC_IMPL(__imp__phBoundCapsule_9258_p33) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	// cmplwi r3,0
	// beq 0x82579290
	if (ctx.r3.u32 != 0) {
		// lis r11,-32161
		ctx.r11.s64 = -2107703296;
		// lwz r11,-22268(r11)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -22268);
		// bctrl
		PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
		// li r11,0
		ctx.r11.s64 = 0;
		// stw r11,0(r31)
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
	}
loc_82579290:
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_92A8_2h"))) PPC_WEAK_FUNC(phBoundCapsule_92A8_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_92A8_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r29 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f890
	ctx.lr = 0x825792B0;
	__savegprlr_26(ctx, base);
	// lis r11,-32248
	// extsw r10,r6
	ctx.r10.s64 = ctx.r6.s32;
	// addi r9,r1,-72
	ctx.r9.s64 = ctx.r1.s64 + -72;
	// addi r8,r1,-80
	ctx.r8.s64 = ctx.r1.s64 + -80;
	// lfs f0,-25804(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25804);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	// std r10,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.r10.u64);
	// lfd f12,-72(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// fdivs f0,f0,f1
	ctx.f0.f64 = double(float(ctx.f0.f64 / ctx.f1.f64));
	// fcfid f11,f12
	ctx.f11.f64 = double(ctx.f12.s64);
	// lfs f13,-23892(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -23892);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f7,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
	ctx.f7.f64 = double(temp.f32);
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f12,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f0,f13,f12
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// frsp f12,f11
	ctx.f12.f64 = double(float(ctx.f11.f64));
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f13.f64));
	// fdivs f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 / ctx.f0.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// stfiwx f13,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f13.u32);
	// lwz r29,-80(r1)
	var_r29 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + -80));
	// lwz r27,-72(r1)
	var_r27 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + -72));
	// srawi r30,r29,1
	ctx.xer.ca = ((int32_t)var_r29 < 0) & ((var_r29 & 0x1) != 0);
	var_r30 = (uint32_t)((int32_t)var_r29 >> 1);
	// cmpwi cr6,r27,1
	// addi r11,r30,16384
	ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 16384;
	// srawi r3,r11,15
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x7FFF) != 0);
	ctx.r3.s64 = ctx.r11.s32 >> 15;
	// blt cr6,0x8257946c
	if ((int32_t)var_r27 >= 1) {
		// lis r10,-32254
		// lis r11,-32254
		// li r7,16384
		ctx.r7.s64 = 16384;
		// mr r26,r27
		var_r26 = (uint32_t)(var_r27);
		// addi r28,r11,24920
		var_r28 = (uint32_t)(ctx.r11.s64 + 24920);  // lbl_82026158 @ 0x82026158
		// lfs f6,25816(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 25816);
		ctx.f6.f64 = double(temp.f32);
	loc_8257933C:
		// add r7,r7,r29
		ctx.r7.u64 = ctx.r7.u64 + var_r29;
		// fmr f0,f6
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = ctx.f6.f64;
		// mr r11,r3
		ctx.r11.u64 = ctx.r3.u64;
		// add r10,r7,r30
		ctx.r10.u64 = ctx.r7.u64 + var_r30;
		// rlwinm r6,r11,5,0,26
		ctx.r6.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
		// srawi r3,r10,15
		ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFF) != 0);
		ctx.r3.s64 = ctx.r10.s32 >> 15;
		// srawi r8,r7,15
		ctx.xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x7FFF) != 0);
		ctx.r8.s64 = ctx.r7.s32 >> 15;
		// addi r10,r7,-15872
		ctx.r10.s64 = ctx.r7.s64 + -15872;
		// rlwinm r8,r8,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
		// srawi r10,r10,10
		ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3FF) != 0);
		ctx.r10.s64 = ctx.r10.s32 >> 10;
		// rlwinm r9,r11,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// subf r10,r10,r6
		ctx.r10.s64 = ctx.r6.s64 - ctx.r10.s64;
		// add r6,r9,r4
		ctx.r6.u64 = ctx.r9.u64 + ctx.r4.u64;
		// lfsx f9,r8,r4
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
		ctx.f9.f64 = double(temp.f32);
		// add r9,r9,r5
		ctx.r9.u64 = ctx.r9.u64 + ctx.r5.u64;
		// lfsx f8,r8,r5
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r5.u32);
		ctx.f8.f64 = double(temp.f32);
		// cmpwi cr6,r10,-112
		// bgt cr6,0x825793c0
		if (ctx.r10.s32 <= -112) {
			// subfic r8,r10,-112
			ctx.xer.ca = ctx.r10.u32 <= 4294967184;
			ctx.r8.s64 = -112 - ctx.r10.s64;
			// rlwinm r8,r8,27,5,31
			ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
			// addi r8,r8,1
			ctx.r8.s64 = ctx.r8.s64 + 1;
			// rlwinm r31,r8,5,0,26
			var_r31 = (uint32_t)(__builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0);
			// add r11,r8,r11
			ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
			// add r10,r31,r10
			ctx.r10.u64 = var_r31 + ctx.r10.u64;
		loc_8257939C:
			// lfs f12,0(r6)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
			ctx.f12.f64 = double(temp.f32);
			// addic. r8,r8,-1
			ctx.xer.ca = ctx.r8.u32 > 0;
			ctx.r8.s64 = ctx.r8.s64 + -1;
			// fmuls f12,f12,f12
			ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
			// lfs f13,0(r9)
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
			ctx.f13.f64 = double(temp.f32);
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// addi r6,r6,4
			ctx.r6.s64 = ctx.r6.s64 + 4;
			// fmadds f13,f13,f13,f12
			ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f12.f64));
			// fadds f0,f13,f0
			ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
			// bne 0x8257939c
			if (ctx.r8.s32 != 0) goto loc_8257939C;
		}
	loc_825793C0:
		// fmr f11,f0
		ctx.fpscr.disableFlushMode();
		ctx.f11.f64 = ctx.f0.f64;
		// cmpwi cr6,r10,112
		// bge cr6,0x82579428
		if (ctx.r10.s32 < 112) {
			// rlwinm r10,r10,2,0,29
			ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
			// addi r8,r28,448
			ctx.r8.s64 = (int64_t)(int32_t)var_r28 + 448;
			// add r10,r10,r8
			ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
		loc_825793D8:
			// cmpw cr6,r11,r3
			// bge cr6,0x8257945c
			if (ctx.r11.s32 >= ctx.r3.s32) goto loc_8257945C;
			// lfs f12,0(r6)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
			ctx.f12.f64 = double(temp.f32);
			// addi r8,r28,896
			ctx.r8.s64 = (int64_t)(int32_t)var_r28 + 896;
			// fmuls f5,f12,f12
			ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
			// lfs f10,0(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			ctx.f10.f64 = double(temp.f32);
			// lfs f13,0(r9)
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
			ctx.f13.f64 = double(temp.f32);
			// fnmsubs f12,f10,f9,f12
			ctx.f12.f64 = double(float(-(ctx.f10.f64 * ctx.f9.f64 - ctx.f12.f64)));
			// fnmsubs f10,f10,f8,f13
			ctx.f10.f64 = double(float(-(ctx.f10.f64 * ctx.f8.f64 - ctx.f13.f64)));
			// addi r10,r10,128
			ctx.r10.s64 = ctx.r10.s64 + 128;
			// addi r6,r6,4
			ctx.r6.s64 = ctx.r6.s64 + 4;
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// addi r11,r11,1
			ctx.r11.s64 = ctx.r11.s64 + 1;
			// cmpw cr6,r10,r8
			// fmadds f13,f13,f13,f5
			ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f5.f64));
			// fadds f0,f13,f0
			ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
			// fmuls f13,f12,f12
			ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
			// fmadds f13,f10,f10,f13
			ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f10.f64 + ctx.f13.f64));
			// fadds f11,f13,f11
			ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
			// blt cr6,0x825793d8
			if (ctx.r10.s32 < ctx.r8.s32) goto loc_825793D8;
		}
	loc_82579428:
		// cmpw cr6,r11,r3
		// bge cr6,0x8257945c
		if (ctx.r11.s32 < ctx.r3.s32) {
			// subf r11,r11,r3
			ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
		loc_82579434:
			// lfs f12,0(r6)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
			ctx.f12.f64 = double(temp.f32);
			// addic. r11,r11,-1
			ctx.xer.ca = ctx.r11.u32 > 0;
			ctx.r11.s64 = ctx.r11.s64 + -1;
			// fmuls f12,f12,f12
			ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
			// lfs f13,0(r9)
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
			ctx.f13.f64 = double(temp.f32);
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// addi r6,r6,4
			ctx.r6.s64 = ctx.r6.s64 + 4;
			// fmadds f13,f13,f13,f12
			ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f12.f64));
			// fadds f0,f13,f0
			ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
			// fadds f11,f11,f13
			ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
			// bne 0x82579434
			if (ctx.r11.s32 != 0) goto loc_82579434;
		}
	loc_8257945C:
		// fdivs f0,f11,f0
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f11.f64 / ctx.f0.f64));
		// addic. r26,r26,-1
		ctx.xer.ca = var_r26 > 0;
		var_r26 = (uint32_t)(var_r26 + -1);
		// fadds f7,f0,f7
		ctx.f7.f64 = double(float(ctx.f0.f64 + ctx.f7.f64));
		// bne 0x8257933c
		if ((int32_t)var_r26 != 0) goto loc_8257933C;
	}
loc_8257946C:
	// extsw r11,r27
	ctx.r11.s64 = (int32_t)var_r27;
	// std r11,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.r11.u64);
	// lfd f0,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lis r11,-32256
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fdivs f13,f7,f0
	ctx.f13.f64 = double(float(ctx.f7.f64 / ctx.f0.f64));
	// lfs f0,15788(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f1,f0,f13
	ctx.f1.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// b 0x8242f8e0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_9498_2h"))) PPC_WEAK_FUNC(phBoundCapsule_9498_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_9498_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r10,-32248
	// addi r9,r1,-16
	ctx.r9.s64 = ctx.r1.s64 + -16;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lfs f0,-25804(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -25804);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32254
	// fdivs f12,f0,f1
	ctx.f12.f64 = double(float(ctx.f0.f64 / ctx.f1.f64));
	// lfs f0,25820(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 25820);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,27200(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f13
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f0.u32);
	// lwz r3,-16(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// cmpw cr6,r3,r11
	// blelr cr6
	if (ctx.r3.s32 <= ctx.r11.s32) return;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_94E0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_94E0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_94E0_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	double var_f31 = 0.0;
	double var_f30 = 0.0;
	double var_f28 = 0.0;
	double var_f29 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f890
	ctx.lr = 0x825794E8;
	__savegprlr_26(ctx, base);
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32255
	// lis r7,-32248
	// lis r8,-32248
	// lis r9,-32254
	// lis r10,-32254
	// lfs f31,21768(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21768);
	var_f31 = double(temp.f32);
	// mr r28,r3
	var_r28 = ctx.r3.u32;
	// lfs f30,-23944(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -23944);
	var_f30 = double(temp.f32);
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// lfs f28,-24764(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + -24764);
	var_f28 = double(temp.f32);
	// mr r26,r5
	var_r26 = ctx.r5.u32;
	// lfs f29,25828(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 25828);
	var_f29 = double(temp.f32);
	// li r27,0
	var_r27 = 0;
	// li r31,0
	var_r31 = 0;
	// li r11,73
	ctx.r11.s64 = 73;
	// addi r29,r10,17184
	var_r29 = (uint32_t)(ctx.r10.s64 + 17184);  // lbl_82024320 @ 0x82024320
loc_82579534:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r11,1
	ctx.r4.s64 = ctx.r11.s64 + 1;
	// mr r3,r28
	ctx.r3.u64 = var_r28;
	// bl 0x82576a30
	phBoundCapsule_6A30(ctx, base);
	// fmuls f13,f31,f29
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(var_f31 * var_f29));
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// blt cr6,0x825795f0
	if (ctx.f0.f64 < ctx.f13.f64) {
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// stw r27,0(r26)
		PPC_STORE_U32(var_r26 + 0, var_r27);
		// addi r1,r1,176
		ctx.r1.s64 = ctx.r1.s64 + 176;
		// addi r12,r1,-56
		ctx.r12.s64 = ctx.r1.s64 + -56;
		// bl 0x82436664
		__restfpr_28(ctx, base);
		// b 0x8242f8e0
		__restgprlr_26(ctx, base);
		return;
	}
	// fmuls f13,f31,f28
	ctx.f13.f64 = double(float(var_f31 * var_f28));
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,0(r30)
	PPC_STORE_U32(var_r30 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
	// fcmpu cr6,f0,f13
	// blt cr6,0x82579574
	if (ctx.f0.f64 >= ctx.f13.f64) {
		// bso cr6,0x82579574
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257956C, "bso");
		// mr r27,r31
		var_r27 = (uint32_t)(var_r31);
	}
loc_82579574:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// fmr f31,f0
	ctx.fpscr.disableFlushMode();
	var_f31 = ctx.f0.f64;
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(var_r29 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f12.f64 = double(temp.f32);
	// addi r31,r31,1
	var_r31 = (uint32_t)(var_r31 + 1);
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + var_r29;
	// addi r30,r30,4
	var_r30 = (uint32_t)(var_r30 + 4);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f30
	ctx.f0.f64 = double(float(ctx.f13.f64 * var_f30));
	// fcmpu cr6,f0,f12
	// blt cr6,0x825795f0
	if (ctx.f0.f64 < ctx.f12.f64) {
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// stw r27,0(r26)
		PPC_STORE_U32(var_r26 + 0, var_r27);
		// addi r1,r1,176
		ctx.r1.s64 = ctx.r1.s64 + 176;
		// addi r12,r1,-56
		ctx.r12.s64 = ctx.r1.s64 + -56;
		// bl 0x82436664
		__restfpr_28(ctx, base);
		// b 0x8242f8e0
		__restgprlr_26(ctx, base);
		return;
	}
	// b 0x825795ac
	goto loc_825795AC;
	do {
		// addi r10,r10,-4
		ctx.r10.s64 = ctx.r10.s64 + -4;
		// addi r11,r11,-1
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// lfs f13,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f13,f0
		ctx.fpscr.disableFlushMode();
		// bgt cr6,0x825795a0
		} while (ctx.f13.f64 > ctx.f0.f64);
	// cmpwi cr6,r11,0
	// blt cr6,0x825795f0
	if (ctx.r11.s32 < 0) {
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// stw r27,0(r26)
		PPC_STORE_U32(var_r26 + 0, var_r27);
		// addi r1,r1,176
		ctx.r1.s64 = ctx.r1.s64 + 176;
		// addi r12,r1,-56
		ctx.r12.s64 = ctx.r1.s64 + -56;
		// bl 0x82436664
		__restfpr_28(ctx, base);
		// b 0x8242f8e0
		__restgprlr_26(ctx, base);
		return;
	}
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + var_r28;
loc_825795C4:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// bge cr6,0x825795e0
	if (ctx.f0.f64 >= ctx.f13.f64) goto loc_825795E0;
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// bge 0x825795c4
	if (ctx.r11.s32 >= 0) goto loc_825795C4;
loc_825795E0:
	// cmpwi cr6,r11,0
	// blt cr6,0x825795f0
	if (ctx.r11.s32 < 0) {
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// stw r27,0(r26)
		PPC_STORE_U32(var_r26 + 0, var_r27);
		// addi r1,r1,176
		ctx.r1.s64 = ctx.r1.s64 + 176;
		// addi r12,r1,-56
		ctx.r12.s64 = ctx.r1.s64 + -56;
		// bl 0x82436664
		__restfpr_28(ctx, base);
		// b 0x8242f8e0
		__restgprlr_26(ctx, base);
		return;
	}
	// cmpwi cr6,r31,5
	// blt cr6,0x82579534
	if ((int32_t)var_r31 < 5) goto loc_82579534;
loc_825795F0:
	// mr r3,r31
	ctx.r3.u64 = var_r31;
	// stw r27,0(r26)
	PPC_STORE_U32(var_r26 + 0, var_r27);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// addi r12,r1,-56
	ctx.r12.s64 = ctx.r1.s64 + -56;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// b 0x8242f8e0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_9608_2h"))) PPC_WEAK_FUNC(phBoundCapsule_9608_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_9608_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=144, savegprlr_26
	// mr r28,r5
	var_r28 = ctx.r5.u32;
	// lis r11,-32254
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// addi r8,r11,17184
	ctx.r8.s64 = ctx.r11.s64 + 17184;
	// lis r9,-32248
	// lwz r30,0(r28)
	var_r30 = (uint32_t)(PPC_LOAD_U32(var_r28 + 0));
	// mr r27,r6
	var_r27 = ctx.r6.u32;
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + var_r29;
	// lfs f0,-25668(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -25668);
	ctx.f0.f64 = double(temp.f32);
	// lwz r26,0(r27)
	var_r26 = (uint32_t)(PPC_LOAD_U32(var_r27 + 0));
	// lwz r31,-4(r11)
	var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r11.u32 + -4));
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
	// add r10,r11,r8
	ctx.r10.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	// bgt cr6,0x8257973c
	if (ctx.f13.f64 <= ctx.f0.f64) {
		// bso cr6,0x8257973c
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x82579658, "bso");
		// lfsx f12,r11,r3
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
		ctx.f12.f64 = double(temp.f32);
		// lis r11,-32255
		// li r9,0
		ctx.r9.s64 = 0;
		// lfs f0,-27004(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -27004);
		ctx.f0.f64 = double(temp.f32);
		// lis r11,-32256
		// fmuls f12,f12,f0
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
		// lfs f0,16056(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16056);
		ctx.f0.f64 = double(temp.f32);
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	loc_8257967C:
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// addi r31,r31,1
		var_r31 = (uint32_t)(var_r31 + 1);
		// lfs f11,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// fcmpu cr6,f11,f0
		// blt cr6,0x8257967c
		if (ctx.f11.f64 < ctx.f0.f64) goto loc_8257967C;
		// rlwinm r11,r31,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
		// add r10,r11,r3
		ctx.r10.u64 = ctx.r11.u64 + ctx.r3.u64;
		// lfs f0,-4(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
		ctx.f0.f64 = double(temp.f32);
		// fcmpu cr6,f0,f12
		// bge cr6,0x825796b4
		if (ctx.f0.f64 < ctx.f12.f64) {
			// lfs f0,0(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			ctx.f0.f64 = double(temp.f32);
			// fcmpu cr6,f0,f12
			// bge cr6,0x825796b4
			if (ctx.f0.f64 >= ctx.f12.f64) goto loc_825796B4;
			// li r9,1
			ctx.r9.s64 = 1;
		}
	loc_825796B4:
		// lis r10,-32256
		// add r11,r11,r8
		ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
		// lfs f0,22776(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 22776);
		ctx.f0.f64 = double(temp.f32);
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	loc_825796C4:
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// addi r31,r31,1
		var_r31 = (uint32_t)(var_r31 + 1);
		// lfs f13,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f13,f0
		// blt cr6,0x825796c4
		if (ctx.f13.f64 < ctx.f0.f64) goto loc_825796C4;
		// rlwinm r11,r31,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 2) & 0xFFFFFFFC;
		// add r3,r11,r3
		ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
		// lfs f0,-4(r3)
		temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + -4);
		ctx.f0.f64 = double(temp.f32);
		// fcmpu cr6,f0,f12
		// bge cr6,0x825796fc
		if (ctx.f0.f64 < ctx.f12.f64) {
			// lfs f0,0(r3)
			temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
			ctx.f0.f64 = double(temp.f32);
			// fcmpu cr6,f0,f12
			// bge cr6,0x825796fc
			if (ctx.f0.f64 >= ctx.f12.f64) goto loc_825796FC;
			// li r9,1
			ctx.r9.s64 = 1;
		}
	loc_825796FC:
		// cmpwi cr6,r9,1
		// bne cr6,0x8257973c
		if (ctx.r9.s32 != 1) {
			// stw r26,0(r27)
			PPC_STORE_U32(var_r27 + 0, var_r26);
			// stw r30,0(r28)
			PPC_STORE_U32(var_r28 + 0, var_r30);
			return;
		}
		// cmpwi cr6,r30,1
		// bne cr6,0x8257972c
		if ((int32_t)var_r30 == 1) {
			// addi r6,r1,84
			ctx.r6.s64 = ctx.r1.s64 + 84;
			// addi r5,r1,80
			ctx.r5.s64 = ctx.r1.s64 + 80;
			// subfic r4,r31,74
			ctx.xer.ca = var_r31 <= 74;
			ctx.r4.s64 = 74 - (int64_t)(int32_t)var_r31;
			// bl 0x82576a30
			phBoundCapsule_6A30(ctx, base);
			// lwz r11,80(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
			// add r11,r11,r31
			ctx.r11.u64 = ctx.r11.u64 + var_r31;
			// stw r11,0(r29)
			PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ ctx.r11.u32);
			// b 0x8257973c
		} else {
		loc_8257972C:
			// addi r30,r30,-1
			var_r30 = (uint32_t)(var_r30 + -1);
			// cmpw cr6,r26,r30
			// bne cr6,0x8257973c
			if ((int32_t)var_r26 != (int32_t)var_r30) {
				// stw r26,0(r27)
				PPC_STORE_U32(var_r27 + 0, var_r26);
				// stw r30,0(r28)
				PPC_STORE_U32(var_r28 + 0, var_r30);
				return;
			}
			// li r26,0
			var_r26 = 0;
		}
	}
loc_8257973C:
	// stw r26,0(r27)
	PPC_STORE_U32(var_r27 + 0, var_r26);
	// stw r30,0(r28)
	PPC_STORE_U32(var_r28 + 0, var_r30);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_9750_2h"))) PPC_WEAK_FUNC(phBoundCapsule_9750_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_9750_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, var_r30);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, var_r31);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// li r31,0
	var_r31 = 0;
	// lwz r30,0(r7)
	var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r7.u32 + 0));
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi r11,0
	// ble 0x8257979c
	if (ctx.r11.s32 > 0) {
		// mr r9,r5
		ctx.r9.u64 = ctx.r5.u64;
	loc_82579774:
		// lwz r8,0(r9)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		// cmpw cr6,r4,r8
		// bne cr6,0x82579788
		if (ctx.r4.s32 == ctx.r8.s32) {
			// li r31,1
			var_r31 = 1;
			// cmpw cr6,r4,r8
			ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r8.s32, ctx.xer);
		}
	loc_82579788:
		// bgt cr6,0x8257979c
		if (ctx.cr6.gt) goto loc_8257979C;
		// addi r10,r10,1
		ctx.r10.s64 = ctx.r10.s64 + 1;
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// cmpw cr6,r10,r11
		// blt cr6,0x82579774
		if (ctx.r10.s32 < ctx.r11.s32) goto loc_82579774;
	}
loc_8257979C:
	// cmpwi cr6,r31,0
	// bne cr6,0x82579850
	if ((int32_t)var_r31 == 0) {
		// rlwinm r9,r30,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
		// rlwinm r8,r4,2,0,29
		ctx.r8.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
		// cmpw cr6,r10,r11
		ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
		// lwzx r9,r9,r5
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
		// lfsx f0,r8,r3
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
		ctx.f0.f64 = double(temp.f32);
		// rlwinm r9,r9,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
		// lfsx f12,r9,r3
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
		ctx.f12.f64 = double(temp.f32);
		// lis r9,-32248
		ctx.r9.s64 = -2113404928;
		// lfs f13,-24764(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -24764);  /* glob:lbl_82079F44 @ 0x82079f44 */
		ctx.f13.f64 = double(temp.f32);
		// fmuls f13,f12,f13
		ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
		// bne cr6,0x825797f4
		if (ctx.cr6.eq) {
			// lwz r9,0(r5)
			ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
			// rlwinm r9,r9,2,0,29
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
			// lfsx f11,r9,r3
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
			ctx.f11.f64 = double(temp.f32);
			// lis r9,-32255
			ctx.r9.s64 = -2113863680;
			// lfs f12,-26584(r9)
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -26584);  /* glob:lbl_82009828 @ 0x82009828 */
			ctx.f12.f64 = double(temp.f32);
			// fmuls f12,f11,f12
			ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
			// fcmpu cr6,f0,f12
			// bso cr6,0x825797f4
			// UNIMPLEMENTED: bso
			PPC_UNIMPLEMENTED(0x825797EC, "bso");
			// bge cr6,0x82579808
			if (ctx.f0.f64 >= ctx.f12.f64) goto loc_82579808;
		}
	loc_825797F4:
		// cmpw cr6,r10,r30
		// ble cr6,0x82579850
		if (ctx.r10.s32 <= (int32_t)var_r30) {
			// stw r30,0(r7)
			PPC_STORE_U32(ctx.r7.u32 + 0, var_r30);
			// stw r11,0(r6)
			PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
			// ld r30,-16(r1)
			var_r30 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -16));
			// ld r31,-8(r1)
			var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
			// blr
			return;
		}
		// fcmpu cr6,f0,f13
		ctx.fpscr.disableFlushMode();
		// blt cr6,0x82579850
		if (ctx.f0.f64 < ctx.f13.f64) {
			// stw r30,0(r7)
			PPC_STORE_U32(ctx.r7.u32 + 0, var_r30);
			// stw r11,0(r6)
			PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
			// ld r30,-16(r1)
			var_r30 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -16));
			// ld r31,-8(r1)
			var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
			// blr
			return;
		}
		// bso cr6,0x82579850
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x82579804, "bso");
	loc_82579808:
		// cmpw cr6,r11,r10
		// ble cr6,0x82579834
		if (ctx.r11.s32 > ctx.r10.s32) {
			// rlwinm r8,r11,2,0,29
			ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// subf r9,r10,r11
			ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
			// add r8,r8,r5
			ctx.r8.u64 = ctx.r8.u64 + ctx.r5.u64;
		loc_8257981C:
			// addi r3,r8,-4
			ctx.r3.s64 = ctx.r8.s64 + -4;
			// addic. r9,r9,-1
			ctx.xer.ca = ctx.r9.u32 > 0;
			ctx.r9.s64 = ctx.r9.s64 + -1;
			// lwz r31,0(r3)
			var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */);
			// stw r31,0(r8)
			PPC_STORE_U32(ctx.r8.u32 + 0, var_r31);
			// mr r8,r3
			ctx.r8.u64 = ctx.r3.u64;
			// bne 0x8257981c
			if (ctx.r9.s32 != 0) goto loc_8257981C;
		}
	loc_82579834:
		// rlwinm r9,r10,2,0,29
		ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// fcmpu cr6,f0,f13
		ctx.fpscr.disableFlushMode();
		// stwx r4,r9,r5
		PPC_STORE_U32(ctx.r9.u32 + ctx.r5.u32, ctx.r4.u32);
		// blt cr6,0x8257984c
		if (ctx.f0.f64 >= ctx.f13.f64) {
			// bso cr6,0x8257984c
			// UNIMPLEMENTED: bso
			PPC_UNIMPLEMENTED(0x82579844, "bso");
			// mr r30,r10
			var_r30 = ctx.r10.u32;
		}
	loc_8257984C:
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
	}
loc_82579850:
	// stw r30,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, var_r30);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// ld r30,-16(r1)
	var_r30 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -16));
	// ld r31,-8(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_9868_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_9868_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_9868_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r17 = 0;
	uint32_t var_r18 = 0;
	uint32_t var_r16 = 0;
	uint32_t var_r15 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r19 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r27 = 0;
	double var_f31 = 0.0;
	double var_f27 = 0.0;
	double var_f26 = 0.0;
	double var_f28 = 0.0;
	double var_f29 = 0.0;
	double var_f30 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f864
	ctx.lr = 0x82579870;
	__savegprlr_15(ctx, base);
	// addi r12,r1,-144
	ctx.r12.s64 = ctx.r1.s64 + -144;
	// bl 0x82436610
	__savefpr_26(ctx, base);
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r17,r4
	var_r17 = ctx.r4.u32;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	var_f31 = ctx.f1.f64;
	// mr r18,r3
	var_r18 = ctx.r3.u32;
	// fmr f27,f2
	var_f27 = ctx.f2.f64;
	// mr r16,r5
	var_r16 = ctx.r5.u32;
	// mr r5,r17
	ctx.r5.u64 = var_r17;
	// mr r4,r18
	ctx.r4.u64 = var_r18;
	// mr r15,r6
	var_r15 = ctx.r6.u32;
	// mr r24,r7
	var_r24 = ctx.r7.u32;
	// mr r29,r8
	var_r29 = ctx.r8.u32;
	// bl 0x825769a0
	phBoundCapsule_69A0_2h(ctx, base);
	// lis r11,-32248
	// li r31,0
	var_r31 = 0;
	// lfs f0,-25840(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25840);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32255
	// fadds f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f0.f64));
	// lfs f0,-26560(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -26560);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// addi r20,r11,17184
	var_r20 = (uint32_t)(ctx.r11.s64 + 17184);  // lbl_82024320 @ 0x82024320
	// fdivs f26,f0,f13
	var_f26 = double(float(ctx.f0.f64 / ctx.f13.f64));
loc_825798CC:
	// mr r7,r17
	ctx.r7.u64 = var_r17;
	// lfsx f1,r31,r20
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + var_r20);
	ctx.f1.f64 = double(temp.f32);
	// mr r6,r18
	ctx.r6.u64 = var_r18;
	// fmr f2,f26
	ctx.f2.f64 = var_f26;
	// mr r5,r15
	ctx.r5.u64 = var_r15;
	// mr r4,r16
	ctx.r4.u64 = var_r16;
	// bl 0x8257ad50
	phBoundCapsule_AD50_2hr(ctx, base);
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// stfsx f1,r31,r11
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(var_r31 + ctx.r11.u32, temp.u32);
	// addi r31,r31,8
	var_r31 = (uint32_t)(var_r31 + 8);
	// cmpwi cr6,r31,296
	// blt cr6,0x825798cc
	if ((int32_t)var_r31 < 296) goto loc_825798CC;
	// addi r11,r1,132
	ctx.r11.s64 = ctx.r1.s64 + 132;
	// li r10,37
	ctx.r10.s64 = 37;
loc_82579904:
	// lfs f0,-4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f0.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// bne 0x82579904
	if (ctx.r10.s32 != 0) goto loc_82579904;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,21612(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21612);  /* glob:lbl_8201546C @ 0x8201546c */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	// fmuls f0,f31,f0
	ctx.f0.f64 = double(float(var_f31 * ctx.f0.f64));
	// lfs f13,25824(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 25824);  /* glob:0x820164e0 */
	ctx.f13.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// fmuls f12,f31,f13
	ctx.f12.f64 = double(float(var_f31 * ctx.f13.f64));
	// lfs f13,0(r20)
	temp.u32 = PPC_LOAD_U32(var_r20 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	// bge cr6,0x82579958
	if (ctx.f13.f64 < ctx.f0.f64) {
		// mr r10,r20
		ctx.r10.u64 = var_r20;
	loc_82579944:
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// lfs f13,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fcmpu cr6,f13,f0
		// blt cr6,0x82579944
		if (ctx.f13.f64 < ctx.f0.f64) goto loc_82579944;
	}
loc_82579958:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// mr r25,r11
	var_r25 = ctx.r11.u32;
	// lfsx f0,r10,r9
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	ctx.f0.f64 = double(temp.f32);
loc_82579968:
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// lfsx f13,r10,r9
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// bge cr6,0x82579980
	if (ctx.f0.f64 < ctx.f13.f64) {
		// fmr f0,f13
		ctx.f0.f64 = ctx.f13.f64;
		// mr r25,r11
		var_r25 = ctx.r11.u32;
	}
loc_82579980:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpwi cr6,r10,296
	// bge cr6,0x825799a0
	if (ctx.r10.s32 >= 296) goto loc_825799A0;
	// lfsx f13,r10,r20
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + var_r20);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	// bso cr6,0x825799a0
	// UNIMPLEMENTED: bso
	PPC_UNIMPLEMENTED(0x82579998, "bso");
	// ble cr6,0x82579968
	if (ctx.f13.f64 <= ctx.f12.f64) goto loc_82579968;
loc_825799A0:
	// lis r11,-32256
	// fcmpu cr6,f27,f0
	ctx.fpscr.disableFlushMode();
	// lfs f28,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
	var_f28 = double(temp.f32);
	// ble cr6,0x825799b8
	if (var_f27 > ctx.f0.f64) {
		// fadds f0,f0,f27
		ctx.f0.f64 = double(float(ctx.f0.f64 + var_f27));
		// fmuls f0,f0,f28
		ctx.f0.f64 = double(float(ctx.f0.f64 * var_f28));
	}
loc_825799B8:
	// rlwinm r31,r25,2,0,29
	var_r31 = (uint32_t)(__builtin_rotateleft64(var_r25 | (var_r25 << 32), 2) & 0xFFFFFFFC);
	// addi r30,r1,128
	var_r30 = (uint32_t)(ctx.r1.s64 + 128);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lfsx f31,r31,r30
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + var_r30);
	var_f31 = double(temp.f32);
	// stfsx f0,r31,r30
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r31 + var_r30, temp.u32);
	// bl 0x825794e0
	phBoundCapsule_94E0_2h(ctx, base);
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82579608
	phBoundCapsule_9608_2h(ctx, base);
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r25
	ctx.r4.u64 = var_r25;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82579750
	phBoundCapsule_9750_2h(ctx, base);
	// lwz r23,80(r1)
	var_r23 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 80));
	// stfsx f31,r31,r30
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(var_f31);
	PPC_STORE_U32(var_r31 + var_r30, temp.u32);
	// li r22,0
	var_r22 = 0;
	// addi r19,r23,-1
	var_r19 = (uint32_t)(var_r23 + -1);
	// li r28,0
	var_r28 = 0;
	// cmpwi cr6,r23,0
	// ble cr6,0x82579b44
	if ((int32_t)var_r23 > 0) {
		// lwz r21,88(r1)
		var_r21 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + 88));
		// mr r26,r29
		var_r26 = (uint32_t)(var_r29);
		// addi r27,r1,96
		var_r27 = (uint32_t)(ctx.r1.s64 + 96);
		// subf r24,r29,r24
		var_r24 = var_r24 - var_r29;
	loc_82579A34:
		// cmpwi cr6,r28,0
		// beq cr6,0x82579a4c
		if ((int32_t)var_r28 != 0) {
			// cmpw cr6,r28,r19
			// beq cr6,0x82579a4c
			if ((int32_t)var_r28 == (int32_t)var_r19) goto loc_82579A4C;
			// cmpw cr6,r28,r21
			// bne cr6,0x82579b34
			if ((int32_t)var_r28 != (int32_t)var_r21) goto loc_82579B34;
		}
	loc_82579A4C:
		// cmpw cr6,r28,r21
		// bne cr6,0x82579a5c
		if ((int32_t)var_r28 == (int32_t)var_r21) {
			// lwz r11,708(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 708);
			// stw r22,0(r11)
			PPC_STORE_U32(ctx.r11.u32 + 0, var_r22);
		}
	loc_82579A5C:
		// lwz r30,0(r27)
		var_r30 = (uint32_t)(PPC_LOAD_U32(var_r27 + 0));
		// addi r8,r1,128
		ctx.r8.s64 = ctx.r1.s64 + 128;
		// li r10,0
		ctx.r10.s64 = 0;
		// rlwinm r11,r30,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(var_r30 | (var_r30 << 32), 2) & 0xFFFFFFFC;
		// cmpwi r30,0
		// add r9,r11,r20
		ctx.r9.u64 = ctx.r11.u64 + var_r20;
		// lfsx f31,r11,r8
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
		var_f31 = double(temp.f32);
		// lfs f29,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		var_f29 = double(temp.f32);
		// ble 0x82579a94
		if ((int32_t)var_r30 > 0) {
			// lfs f0,-4(r9)
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -4);
			ctx.f0.f64 = double(temp.f32);
			// li r10,1
			ctx.r10.s64 = 1;
			// fadds f0,f0,f29
			ctx.f0.f64 = double(float(ctx.f0.f64 + var_f29));
			// fmuls f0,f0,f28
			ctx.f0.f64 = double(float(ctx.f0.f64 * var_f28));
			// stfs f0,88(r1)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
		}
	loc_82579A94:
		// addi r11,r30,1
		ctx.r11.s64 = (int64_t)(int32_t)var_r30 + 1;
		// cmpwi cr6,r11,74
		// bge cr6,0x82579ac0
		if (ctx.r11.s32 < 74) {
			// rlwinm r11,r11,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
			// rlwinm r9,r10,2,0,29
			ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
			// addi r8,r1,88
			ctx.r8.s64 = ctx.r1.s64 + 88;
			// addi r10,r10,1
			ctx.r10.s64 = ctx.r10.s64 + 1;
			// lfsx f0,r11,r20
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r20);
			ctx.f0.f64 = double(temp.f32);
			// fadds f0,f0,f29
			ctx.f0.f64 = double(float(ctx.f0.f64 + var_f29));
			// fmuls f0,f0,f28
			ctx.f0.f64 = double(float(ctx.f0.f64 * var_f28));
			// stfsx f0,r9,r8
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, temp.u32);
		}
	loc_82579AC0:
		// cmpwi cr6,r10,0
		// ble cr6,0x82579b0c
		if (ctx.r10.s32 > 0) {
			// addi r31,r1,88
			var_r31 = (uint32_t)(ctx.r1.s64 + 88);
			// mr r29,r10
			var_r29 = ctx.r10.u32;
		loc_82579AD0:
			// lfs f30,0(r31)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
			var_f30 = double(temp.f32);
			// mr r7,r17
			ctx.r7.u64 = var_r17;
			// mr r6,r18
			ctx.r6.u64 = var_r18;
			// fmr f2,f26
			ctx.f2.f64 = var_f26;
			// mr r5,r15
			ctx.r5.u64 = var_r15;
			// fmr f1,f30
			ctx.f1.f64 = var_f30;
			// mr r4,r16
			ctx.r4.u64 = var_r16;
			// bl 0x8257ad50
			phBoundCapsule_AD50_2hr(ctx, base);
			// fcmpu cr6,f1,f31
			ctx.fpscr.disableFlushMode();
			// ble cr6,0x82579b00
			if (ctx.f1.f64 > var_f31) {
				// fmr f29,f30
				var_f29 = var_f30;
				// fmr f31,f1
				var_f31 = ctx.f1.f64;
			}
		loc_82579B00:
			// addic. r29,r29,-1
			ctx.xer.ca = var_r29 > 0;
			var_r29 = (uint32_t)(var_r29 + -1);
			// addi r31,r31,4
			var_r31 = (uint32_t)(var_r31 + 4);
			// bne 0x82579ad0
			if ((int32_t)var_r29 != 0) goto loc_82579AD0;
		}
	loc_82579B0C:
		// stfsx f29,r24,r26
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(var_f29);
		PPC_STORE_U32(var_r24 + var_r26, temp.u32);
		// cmpw cr6,r30,r25
		// bne cr6,0x82579b28
		if ((int32_t)var_r30 == (int32_t)var_r25) {
			// fcmpu cr6,f27,f31
			// ble cr6,0x82579b28
			if (var_f27 <= var_f31) goto loc_82579B28;
			// fadds f0,f31,f27
			ctx.f0.f64 = double(float(var_f31 + var_f27));
			// fmuls f31,f0,f28
			var_f31 = double(float(ctx.f0.f64 * var_f28));
		}
	loc_82579B28:
		// stfs f31,0(r26)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(var_f31);
		PPC_STORE_U32(var_r26 + 0, temp.u32);
		// addi r22,r22,1
		var_r22 = (uint32_t)(var_r22 + 1);
		// addi r26,r26,4
		var_r26 = (uint32_t)(var_r26 + 4);
	loc_82579B34:
		// addi r28,r28,1
		var_r28 = (uint32_t)(var_r28 + 1);
		// addi r27,r27,4
		var_r27 = (uint32_t)(var_r27 + 4);
		// cmpw cr6,r28,r23
		// blt cr6,0x82579a34
		if ((int32_t)var_r28 < (int32_t)var_r23) goto loc_82579A34;
	}
loc_82579B44:
	// mr r3,r22
	ctx.r3.u64 = var_r22;
	// addi r1,r1,624
	ctx.r1.s64 = ctx.r1.s64 + 624;
	// addi r12,r1,-144
	ctx.r12.s64 = ctx.r1.s64 + -144;
	// bl 0x8243665c
	__restfpr_26(ctx, base);
	// b 0x8242f8b4
	__restgprlr_15(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_9B58_w"))) PPC_WEAK_FUNC(phBoundCapsule_9B58_w);
PPC_FUNC_IMPL(__imp__phBoundCapsule_9B58_w) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r10,-32256
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fadds f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// addi r9,r3,4
	ctx.r9.s64 = ctx.r3.s64 + 4;
	// addi r8,r4,4
	ctx.r8.s64 = ctx.r4.s64 + 4;
	// lfs f12,15784(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15784);
	ctx.f12.f64 = double(temp.f32);
	// add r10,r11,r3
	ctx.r10.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// stfs f12,0(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// cmpwi cr6,r5,256
	// lis r7,-32254
	// stfs f0,0(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// stfs f12,0(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// bne cr6,0x82579bb0
	if (ctx.r5.s32 == 256) {
		// addi r6,r7,25832
		ctx.r6.s64 = ctx.r7.s64 + 25832;
		// b 0x82579bb8
	} else {
	loc_82579BB0:
		// addi r7,r7,25832
		ctx.r7.s64 = ctx.r7.s64 + 25832;
		// addi r6,r7,1016
		ctx.r6.s64 = ctx.r7.s64 + 1016;
	}
loc_82579BB8:
	// srawi r7,r5,1
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x1) != 0);
	ctx.r7.s64 = ctx.r5.s32 >> 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// cmpwi cr6,r7,1
	// ble cr6,0x82579c64
	if (ctx.r7.s32 > 1) {
		// lis r5,-32256
		// addi r7,r7,-1
		ctx.r7.s64 = ctx.r7.s64 + -1;
		// addi r3,r7,1
		ctx.r3.s64 = ctx.r7.s64 + 1;
		// lfs f0,27200(r5)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 27200);
		ctx.f0.f64 = double(temp.f32);
	loc_82579BD8:
		// lfs f12,0(r8)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// addic. r7,r7,-1
		ctx.xer.ca = ctx.r7.u32 > 0;
		ctx.r7.s64 = ctx.r7.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
		// lfs f10,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f10.f64 = double(temp.f32);
		// fadds f6,f10,f12
		ctx.f6.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
		// lfs f13,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// lfs f11,0(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// fsubs f10,f12,f10
		ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
		// fsubs f7,f13,f11
		ctx.f7.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
		// lfs f9,0(r6)
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		ctx.f9.f64 = double(temp.f32);
		// addi r6,r6,4
		ctx.r6.s64 = ctx.r6.s64 + 4;
		// fadds f5,f11,f13
		ctx.f5.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
		// lfs f8,0(r6)
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		ctx.f8.f64 = double(temp.f32);
		// addi r6,r6,4
		ctx.r6.s64 = ctx.r6.s64 + 4;
		// fmuls f12,f6,f0
		ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
		// fmuls f11,f10,f0
		ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
		// fmuls f13,f7,f0
		ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
		// fmuls f10,f5,f0
		ctx.f10.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
		// fmuls f7,f12,f8
		ctx.f7.f64 = double(float(ctx.f12.f64 * ctx.f8.f64));
		// fmuls f8,f13,f8
		ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
		// fmsubs f13,f13,f9,f7
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 - ctx.f7.f64));
		// fmadds f12,f12,f9,f8
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + ctx.f8.f64));
		// fadds f9,f13,f11
		ctx.f9.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
		// fsubs f13,f11,f13
		ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
		// stfs f13,0(r8)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
		// fadds f13,f12,f10
		ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
		// stfs f13,0(r9)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
		// fsubs f13,f10,f12
		ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
		// stfs f13,0(r10)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// addi r10,r10,-4
		ctx.r10.s64 = ctx.r10.s64 + -4;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// fneg f13,f9
		ctx.f13.u64 = ctx.f9.u64 ^ 0x8000000000000000;
		// stfs f13,0(r11)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// addi r11,r11,-4
		ctx.r11.s64 = ctx.r11.s64 + -4;
		// bne 0x82579bd8
		if (!ctx.cr0.eq) goto loc_82579BD8;
	}
loc_82579C64:
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f0,r11,r4
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f0.f64 = double(temp.f32);
	// fneg f0,f0
	ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// stfsx f0,r11,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_9C78_2hr_9C78_1"))) PPC_WEAK_FUNC(phBoundCapsule_9C78_2hr_9C78_1);
PPC_FUNC_IMPL(__imp__phBoundCapsule_9C78_2hr_9C78_1) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, var_r31);
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r9,r3,4
	ctx.r9.s64 = ctx.r3.s64 + 4;
	// add r10,r11,r3
	ctx.r10.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// addi r8,r4,4
	ctx.r8.s64 = ctx.r4.s64 + 4;
	// addi r7,r11,-4
	ctx.r7.s64 = ctx.r11.s64 + -4;
	// cmpwi cr6,r5,256
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 256, ctx.xer);
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f12,f0
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// lis r11,-32254
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// fsubs f12,f10,f9
	ctx.f12.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// fadds f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// bne cr6,0x82579cdc
	if (ctx.cr6.eq) {
		// addi r31,r11,25832
		var_r31 = (uint32_t)(ctx.r11.s64 + 25832);  // lbl_820264E8 @ 0x820264e8
		// b 0x82579ce4
	} else {
	loc_82579CDC:
		// addi r11,r11,25832
		ctx.r11.s64 = ctx.r11.s64 + 25832;
		// addi r31,r11,1016
		var_r31 = (uint32_t)(ctx.r11.s64 + 1016);  // addr:0x820203f8
	}
loc_82579CE4:
	// srawi r6,r5,1
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x1) != 0);
	ctx.r6.s64 = ctx.r5.s32 >> 1;
	// lis r5,-32256
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpwi cr6,r6,1
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 1, ctx.xer);
	// lfs f0,16056(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 16056);
	ctx.f0.f64 = double(temp.f32);
	// lfsx f13,r11,r3
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f12,r11,r4
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fmuls f0,f12,f0
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfsx f13,r11,r3
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
	// stfsx f0,r11,r4
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
	// ble cr6,0x82579d94
	if (ctx.cr6.gt) {
		// addi r11,r6,-1
		ctx.r11.s64 = ctx.r6.s64 + -1;
	loc_82579D18:
		// lfs f11,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// addi r6,r31,4
		ctx.r6.s64 = (int64_t)(int32_t)var_r31 + 4;
		// lfs f13,0(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
		// fsubs f8,f13,f11
		ctx.f8.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
		// lfs f10,0(r7)
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
		ctx.f10.f64 = double(temp.f32);
		// lfs f12,0(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fadds f13,f11,f13
		ctx.f13.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
		// lfs f0,0(r31)
		temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f0.f64 = double(temp.f32);
		// fadds f7,f10,f12
		ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
		// lfs f9,0(r6)
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		ctx.f9.f64 = double(temp.f32);
		// fsubs f12,f12,f10
		ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
		// addi r31,r6,4
		var_r31 = (uint32_t)(ctx.r6.s64 + 4);  // addr:0x82000004
		// fmuls f11,f0,f8
		ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
		// fmuls f10,f9,f8
		ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
		// fmadds f11,f9,f7,f11
		ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 + ctx.f11.f64));
		// fmsubs f0,f0,f7,f10
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f7.f64 - ctx.f10.f64));
		// fsubs f10,f12,f11
		ctx.f10.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
		// fadds f12,f11,f12
		ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
		// stfs f12,0(r8)
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
		// fsubs f12,f13,f0
		ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
		// stfs f12,0(r9)
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
		// fadds f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// stfs f0,0(r10)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// addi r9,r9,4
		ctx.r9.s64 = ctx.r9.s64 + 4;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// addi r10,r10,-4
		ctx.r10.s64 = ctx.r10.s64 + -4;
		// fneg f0,f10
		ctx.f0.u64 = ctx.f10.u64 ^ 0x8000000000000000;
		// stfs f0,0(r7)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
		// addi r7,r7,-4
		ctx.r7.s64 = ctx.r7.s64 + -4;
		// bne 0x82579d18
		if (!ctx.cr0.eq) goto loc_82579D18;
	}
loc_82579D94:
	// ld r31,-8(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_9DA0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_9DA0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_9DA0_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r25 = 0;
	uint32_t var_r17 = 0;
	uint32_t var_r24 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r18 = 0;
	uint32_t var_r21 = 0;
	uint32_t var_r19 = 0;
	uint32_t var_r23 = 0;
	uint32_t var_r22 = 0;
	uint32_t var_r20 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	double var_f30 = 0.0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f86c
	ctx.lr = 0x82579DA8;
	__savegprlr_17(ctx, base);
	// stfd f30,-144(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -144, ctx.f30.u64);
	// stfd f31,-136(r1)
	PPC_STORE_U64(ctx.r1.u32 + -136, ctx.f31.u64);
	// lis r11,-32254
	// li r25,1
	var_r25 = 1;
	// addi r11,r11,27096
	ctx.r11.s64 = ctx.r11.s64 + 27096;
	// cmpwi cr6,r5,256
	// addi r10,r11,1536
	ctx.r10.s64 = ctx.r11.s64 + 1536;
	// beq cr6,0x82579dcc
	if (ctx.r5.s32 != 256) {
		// addi r10,r11,1920
		ctx.r10.s64 = ctx.r11.s64 + 1920;
	}
loc_82579DCC:
	// srawi r11,r5,4
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0xF) != 0);
	ctx.r11.s64 = ctx.r5.s32 >> 4;
	// mulli r17,r11,96
	var_r17 = (uint32_t)(static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(96)));
loc_82579DD4:
	// rlwinm r11,r25,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(var_r25 | (var_r25 << 32), 4) & 0xFFFFFFF0;
	// srawi r24,r5,2
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x3) != 0);
	var_r24 = (uint32_t)(ctx.r5.s32 >> 2);
	// addi r11,r11,-12
	ctx.r11.s64 = ctx.r11.s64 + -12;
	// cmpwi cr6,r25,0
	// mullw r11,r11,r24
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t((int32_t)var_r24);
	// add r9,r11,r3
	ctx.r9.u64 = ctx.r11.u64 + ctx.r3.u64;
	// add r11,r11,r4
	ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
	// addi r26,r9,-16
	var_r26 = (uint32_t)(ctx.r9.s64 + -16);  // addr:0x8200fff0
	// addi r31,r11,-16
	var_r31 = (uint32_t)(ctx.r11.s64 + -16);  // addr:0x8201fff0
	// ble cr6,0x82579f50
	if ((int32_t)var_r25 > 0) {
		// addi r18,r24,-4
		var_r18 = (uint32_t)(var_r24 + -4);
		// mulli r21,r24,12
		var_r21 = (uint32_t)(static_cast<int64_t>(var_r24 * static_cast<uint64_t>(12)));
		// mr r19,r25
		var_r19 = (uint32_t)(var_r25);
	loc_82579E08:
		// subf r10,r17,r10
		ctx.r10.s64 = ctx.r10.s64 - (int64_t)(int32_t)var_r17;
		// cmpwi cr6,r18,0
		// blt cr6,0x82579f40
		if ((int32_t)var_r18 >= 0) {
			// addi r11,r18,4
			ctx.r11.s64 = (int64_t)(int32_t)var_r18 + 4;
			// rlwinm r23,r24,3,0,28
			var_r23 = (uint32_t)(__builtin_rotateleft64(var_r24 | (var_r24 << 32), 3) & 0xFFFFFFF8);
			// rlwinm r22,r24,2,0,29
			var_r22 = (uint32_t)(__builtin_rotateleft64(var_r24 | (var_r24 << 32), 2) & 0xFFFFFFFC);
			// rlwinm r20,r11,30,2,31
			var_r20 = (uint32_t)(__builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF);
		loc_82579E24:
			// mr r9,r31
			ctx.r9.u64 = var_r31;
			// add r7,r21,r31
			ctx.r7.u64 = var_r21 + var_r31;
			// add r8,r23,r31
			ctx.r8.u64 = var_r23 + var_r31;
			// add r11,r22,r31
			ctx.r11.u64 = var_r22 + var_r31;
			// subf r6,r31,r26
			ctx.r6.s64 = (int64_t)(int32_t)var_r26 - (int64_t)(int32_t)var_r31;
			// li r30,4
			var_r30 = 4;
		loc_82579E3C:
			// add r27,r6,r7
			var_r27 = (uint32_t)(ctx.r6.u64 + ctx.r7.u64);
			// lfs f11,0(r7)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
			ctx.f11.f64 = double(temp.f32);
			// lfs f13,0(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			ctx.f13.f64 = double(temp.f32);
			// add r29,r6,r9
			var_r29 = (uint32_t)(ctx.r6.u64 + ctx.r9.u64);
			// lfs f12,0(r8)
			temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
			ctx.f12.f64 = double(temp.f32);
			// fadds f30,f11,f13
			var_f30 = double(float(ctx.f11.f64 + ctx.f13.f64));
			// lfs f0,0(r9)
			temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
			ctx.f0.f64 = double(temp.f32);
			// fsubs f13,f13,f11
			ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
			// lfsx f3,r6,r11
			temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r11.u32);
			ctx.f3.f64 = double(temp.f32);
			// fadds f1,f12,f0
			ctx.f1.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
			// lfs f31,0(r27)
			temp.u32 = PPC_LOAD_U32(var_r27 + 0);
			var_f31 = double(temp.f32);
			// add r28,r6,r8
			var_r28 = (uint32_t)(ctx.r6.u64 + ctx.r8.u64);
			// fadds f11,f31,f3
			ctx.f11.f64 = double(float(var_f31 + ctx.f3.f64));
			// lfs f4,0(r29)
			temp.u32 = PPC_LOAD_U32(var_r29 + 0)/* phBoundCapsule::vtable@+0x0 */;
			ctx.f4.f64 = double(temp.f32);
			// fsubs f0,f0,f12
			ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
			// lfs f10,0(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			ctx.f10.f64 = double(temp.f32);
			// fsubs f3,f3,f31
			ctx.f3.f64 = double(float(ctx.f3.f64 - var_f31));
			// lfs f8,32(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 32);
			ctx.f8.f64 = double(temp.f32);
			// lfs f9,16(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
			ctx.f9.f64 = double(temp.f32);
			// addic. r30,r30,-1
			ctx.xer.ca = var_r30 > 0;
			var_r30 = (uint32_t)(var_r30 + -1);
			ctx.cr0.compare<int32_t>((int32_t)var_r30, 0, ctx.xer);
			// lfs f2,0(r28)
			temp.u32 = PPC_LOAD_U32(var_r28 + 0);
			ctx.f2.f64 = double(temp.f32);
			// fadds f12,f2,f4
			ctx.f12.f64 = double(float(ctx.f2.f64 + ctx.f4.f64));
			// lfs f7,48(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
			ctx.f7.f64 = double(temp.f32);
			// fsubs f4,f4,f2
			ctx.f4.f64 = double(float(ctx.f4.f64 - ctx.f2.f64));
			// lfs f6,64(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 64);
			ctx.f6.f64 = double(temp.f32);
			// lfs f5,80(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
			ctx.f5.f64 = double(temp.f32);
			// addi r10,r10,4
			ctx.r10.s64 = ctx.r10.s64 + 4;
			// fsubs f2,f1,f30
			ctx.f2.f64 = double(float(ctx.f1.f64 - var_f30));
			// fadds f1,f30,f1
			ctx.f1.f64 = double(float(var_f30 + ctx.f1.f64));
			// stfs f1,0(r9)
			temp.f32 = float(ctx.f1.f64);
			PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
			// addi r9,r9,4
			ctx.r9.s64 = ctx.r9.s64 + 4;
			// fsubs f30,f0,f3
			var_f30 = double(float(ctx.f0.f64 - ctx.f3.f64));
			// fadds f0,f0,f3
			ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f3.f64));
			// fsubs f1,f12,f11
			ctx.f1.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
			// fadds f31,f13,f4
			var_f31 = double(float(ctx.f13.f64 + ctx.f4.f64));
			// fadds f12,f11,f12
			ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
			// stfs f12,0(r29)
			temp.f32 = float(ctx.f12.f64);
			PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
			// fsubs f13,f4,f13
			ctx.f13.f64 = double(float(ctx.f4.f64 - ctx.f13.f64));
			// fmuls f4,f2,f10
			ctx.f4.f64 = double(float(ctx.f2.f64 * ctx.f10.f64));
			// fmuls f3,f2,f9
			ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
			// fmuls f12,f30,f8
			ctx.f12.f64 = double(float(var_f30 * ctx.f8.f64));
			// fmuls f11,f30,f7
			ctx.f11.f64 = double(float(var_f30 * ctx.f7.f64));
			// fmuls f2,f0,f6
			ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
			// fmuls f0,f0,f5
			ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
			// fmadds f9,f1,f9,f4
			ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f9.f64 + ctx.f4.f64));
			// stfs f9,0(r11)
			temp.f32 = float(ctx.f9.f64);
			PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
			// fmsubs f10,f1,f10,f3
			ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f10.f64 - ctx.f3.f64));
			// stfsx f10,r6,r11
			temp.f32 = float(ctx.f10.f64);
			PPC_STORE_U32(ctx.r6.u32 + ctx.r11.u32, temp.u32);
			// addi r11,r11,4
			ctx.r11.s64 = ctx.r11.s64 + 4;
			// fmadds f12,f31,f7,f12
			ctx.f12.f64 = double(float(var_f31 * ctx.f7.f64 + ctx.f12.f64));
			// stfs f12,0(r8)
			temp.f32 = float(ctx.f12.f64);
			PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
			// fmsubs f12,f31,f8,f11
			ctx.f12.f64 = double(float(var_f31 * ctx.f8.f64 - ctx.f11.f64));
			// stfs f12,0(r28)
			temp.f32 = float(ctx.f12.f64);
			PPC_STORE_U32(var_r28 + 0, temp.u32);
			// fmadds f12,f13,f5,f2
			ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f5.f64 + ctx.f2.f64));
			// stfs f12,0(r7)
			temp.f32 = float(ctx.f12.f64);
			PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
			// fmsubs f0,f13,f6,f0
			ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 - ctx.f0.f64));
			// addi r8,r8,4
			ctx.r8.s64 = ctx.r8.s64 + 4;
			// stfs f0,0(r27)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(var_r27 + 0, temp.u32);
			// addi r7,r7,4
			ctx.r7.s64 = ctx.r7.s64 + 4;
			// bne 0x82579e3c
			if (!ctx.cr0.eq) goto loc_82579E3C;
			// addic. r20,r20,-1
			ctx.xer.ca = var_r20 > 0;
			var_r20 = (uint32_t)(var_r20 + -1);
			// addi r26,r26,-16
			var_r26 = (uint32_t)(var_r26 + -16);
			// addi r31,r31,-16
			var_r31 = (uint32_t)(var_r31 + -16);
			// addi r10,r10,80
			ctx.r10.s64 = ctx.r10.s64 + 80;
			// bne 0x82579e24
			if ((int32_t)var_r20 != 0) goto loc_82579E24;
		}
	loc_82579F40:
		// addic. r19,r19,-1
		ctx.xer.ca = var_r19 > 0;
		var_r19 = (uint32_t)(var_r19 + -1);
		// subf r26,r21,r26
		var_r26 = var_r26 - var_r21;
		// subf r31,r21,r31
		var_r31 = var_r31 - var_r21;
		// bne 0x82579e08
		if ((int32_t)var_r19 != 0) goto loc_82579E08;
	}
loc_82579F50:
	// srawi r11,r5,2
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x3) != 0);
	ctx.r11.s64 = ctx.r5.s32 >> 2;
	// rlwinm r25,r25,2,0,29
	var_r25 = (uint32_t)(__builtin_rotateleft64(var_r25 | (var_r25 << 32), 2) & 0xFFFFFFFC);
	// addze r5,r11
	temp.s64 = ctx.r11.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r11.u32;
	ctx.r5.s64 = temp.s64;
	// srawi r11,r5,4
	ctx.xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0xF) != 0);
	ctx.r11.s64 = ctx.r5.s32 >> 4;
	// cmpwi cr6,r5,4
	// mulli r17,r11,96
	var_r17 = (uint32_t)(static_cast<int64_t>(ctx.r11.u64 * static_cast<uint64_t>(96)));
	// add r10,r17,r10
	ctx.r10.u64 = var_r17 + ctx.r10.u64;
	// bgt cr6,0x82579dd4
	if (ctx.r5.s32 > 4) goto loc_82579DD4;
	// rlwinm r11,r25,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(var_r25 | (var_r25 << 32), 4) & 0xFFFFFFF0;
	// cmpwi cr6,r25,0
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// addi r10,r11,-16
	ctx.r10.s64 = ctx.r11.s64 + -16;
	// ble cr6,0x8257a03c
	if ((int32_t)var_r25 > 0) {
		// subf r11,r3,r10
		ctx.r11.s64 = ctx.r10.s64 - ctx.r3.s64;
		// subf r30,r4,r3
		var_r30 = (uint32_t)(ctx.r3.s64 - ctx.r4.s64);
		// add r11,r11,r4
		ctx.r11.u64 = ctx.r11.u64 + ctx.r4.u64;
		// mr r9,r25
		ctx.r9.u64 = var_r25;
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
	loc_82579F98:
		// addi r8,r10,8
		ctx.r8.s64 = ctx.r10.s64 + 8;
		// lfs f0,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addi r7,r10,12
		ctx.r7.s64 = ctx.r10.s64 + 12;
		// lfsx f12,r30,r11
		temp.u32 = PPC_LOAD_U32(var_r30 + ctx.r11.u32);
		ctx.f12.f64 = double(temp.f32);
		// addi r6,r11,-4
		ctx.r6.s64 = ctx.r11.s64 + -4;
		// lfs f13,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// addi r5,r11,4
		ctx.r5.s64 = ctx.r11.s64 + 4;
		// addi r31,r11,8
		var_r31 = (uint32_t)(ctx.r11.s64 + 8);  // addr:0x82020008
		// lfs f11,0(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// addic. r9,r9,-1
		ctx.xer.ca = ctx.r9.u32 > 0;
		ctx.r9.s64 = ctx.r9.s64 + -1;
		ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
		// lfs f10,0(r7)
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
		ctx.f10.f64 = double(temp.f32);
		// fadds f6,f11,f0
		ctx.f6.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
		// fadds f5,f10,f12
		ctx.f5.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
		// lfs f9,0(r6)
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		ctx.f9.f64 = double(temp.f32);
		// lfs f8,0(r5)
		temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
		ctx.f8.f64 = double(temp.f32);
		// fsubs f0,f0,f11
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f11.f64));
		// lfs f7,0(r31)
		temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f7.f64 = double(temp.f32);
		// fadds f11,f8,f9
		ctx.f11.f64 = double(float(ctx.f8.f64 + ctx.f9.f64));
		// fadds f4,f7,f13
		ctx.f4.f64 = double(float(ctx.f7.f64 + ctx.f13.f64));
		// fsubs f13,f13,f7
		ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f7.f64));
		// fsubs f12,f12,f10
		ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
		// fsubs f9,f9,f8
		ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f8.f64));
		// fadds f10,f5,f6
		ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
		// stfs f10,0(r10)
		temp.f32 = float(ctx.f10.f64);
		PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
		// fsubs f10,f6,f5
		ctx.f10.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
		// stfsx f10,r30,r11
		temp.f32 = float(ctx.f10.f64);
		PPC_STORE_U32(var_r30 + ctx.r11.u32, temp.u32);
		// addi r10,r10,-16
		ctx.r10.s64 = ctx.r10.s64 + -16;
		// fsubs f10,f11,f4
		ctx.f10.f64 = double(float(ctx.f11.f64 - ctx.f4.f64));
		// stfs f10,0(r11)
		temp.f32 = float(ctx.f10.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// fadds f11,f4,f11
		ctx.f11.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
		// stfs f11,0(r6)
		temp.f32 = float(ctx.f11.f64);
		PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
		// fadds f11,f13,f0
		ctx.f11.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
		// addi r11,r11,-16
		ctx.r11.s64 = ctx.r11.s64 + -16;
		// fsubs f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
		// stfs f11,0(r8)
		temp.f32 = float(ctx.f11.f64);
		PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
		// fsubs f10,f9,f12
		ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
		// stfs f0,0(r7)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
		// fadds f13,f9,f12
		ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f12.f64));
		// stfs f10,0(r5)
		temp.f32 = float(ctx.f10.f64);
		PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
		// stfs f13,0(r31)
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(var_r31 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
		// bne 0x82579f98
		if (!ctx.cr0.eq) goto loc_82579F98;
	}
loc_8257A03C:
	// rlwinm r6,r25,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(var_r25 | (var_r25 << 32), 2) & 0xFFFFFFFC;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r6,-1
	ctx.r5.s64 = ctx.r6.s64 + -1;
	// srawi r9,r6,1
	ctx.xer.ca = (ctx.r6.s32 < 0) & ((ctx.r6.u32 & 0x1) != 0);
	ctx.r9.s64 = ctx.r6.s32 >> 1;
	// cmpwi cr6,r5,1
	// ble cr6,0x8257a0ac
	if (ctx.r5.s32 > 1) {
		// addi r10,r4,4
		ctx.r10.s64 = ctx.r4.s64 + 4;
		// subf r8,r4,r3
		ctx.r8.s64 = ctx.r3.s64 - ctx.r4.s64;
	loc_8257A05C:
		// cmpw cr6,r7,r9
		// ble cr6,0x8257a088
		if (ctx.r7.s32 > ctx.r9.s32) {
			// rlwinm r11,r9,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
			// lfsx f13,r10,r8
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
			ctx.f13.f64 = double(temp.f32);
			// lfs f0,0(r10)
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
			ctx.f0.f64 = double(temp.f32);
			// lfsx f12,r11,r3
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r3.u32);
			ctx.f12.f64 = double(temp.f32);
			// lfsx f11,r11,r4
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
			ctx.f11.f64 = double(temp.f32);
			// stfsx f12,r10,r8
			temp.f32 = float(ctx.f12.f64);
			PPC_STORE_U32(ctx.r10.u32 + ctx.r8.u32, temp.u32);
			// stfs f11,0(r10)
			temp.f32 = float(ctx.f11.f64);
			PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
			// stfsx f13,r11,r3
			temp.f32 = float(ctx.f13.f64);
			PPC_STORE_U32(ctx.r11.u32 + ctx.r3.u32, temp.u32);
			// stfsx f0,r11,r4
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r11.u32 + ctx.r4.u32, temp.u32);
		}
	loc_8257A088:
		// mr r11,r6
		ctx.r11.u64 = ctx.r6.u64;
	loc_8257A08C:
		// srawi r11,r11,1
		ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
		ctx.r11.s64 = ctx.r11.s32 >> 1;
		// xor r9,r11,r9
		ctx.r9.u64 = ctx.r11.u64 ^ ctx.r9.u64;
		// cmpw cr6,r9,r11
		// blt cr6,0x8257a08c
		if (ctx.r9.s32 < ctx.r11.s32) goto loc_8257A08C;
		// addi r7,r7,1
		ctx.r7.s64 = ctx.r7.s64 + 1;
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// cmpw cr6,r7,r5
		// blt cr6,0x8257a05c
		if (ctx.r7.s32 < ctx.r5.s32) goto loc_8257A05C;
	}
loc_8257A0AC:
	// lfd f30,-144(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// lfd f31,-136(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// b 0x8242f8bc
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_A0B8_2h"))) PPC_WEAK_FUNC(phBoundCapsule_A0B8_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_A0B8_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	double var_f28 = 0.0;
	double var_f27 = 0.0;
	double var_f31 = 0.0;
	double var_f29 = 0.0;
	double var_f30 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f894
	ctx.lr = 0x8257A0C0;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82436614
	__savefpr_27(ctx, base);
	// stwu r1,-608(r1)
	ea = -608 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	var_f28 = ctx.f1.f64;
	// mr r31,r6
	var_r31 = ctx.r6.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r7
	var_r29 = ctx.r7.u32;
	// mr r28,r8
	var_r28 = ctx.r8.u32;
	// lfs f27,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
	var_f27 = double(temp.f32);
	// mr r27,r9
	var_r27 = ctx.r9.u32;
	// cmpwi cr6,r31,0
	// ble cr6,0x8257a134
	if ((int32_t)var_r31 > 0) {
		// lis r7,-32256
		// lis r8,-32254
		// addi r10,r1,112
		ctx.r10.s64 = ctx.r1.s64 + 112;
		// addi r11,r1,112
		ctx.r11.s64 = ctx.r1.s64 + 112;
		// subf r9,r10,r5
		ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
		// lfs f13,27216(r7)
		temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 27216);
		ctx.f13.f64 = double(temp.f32);
		// mr r10,r31
		ctx.r10.u64 = var_r31;
		// lfs f0,29116(r8)
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 29116);
		ctx.f0.f64 = double(temp.f32);
	loc_8257A114:
		// lfsx f12,r9,r11
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
		ctx.f12.f64 = double(temp.f32);
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// fmadds f12,f12,f0,f13
		ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
		// fadds f12,f12,f27
		ctx.f12.f64 = double(float(ctx.f12.f64 + var_f27));
		// fctiwz f12,f12
		ctx.f12.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f12.f64));
		// stfiwx f12,0,r11
		PPC_STORE_U32(ctx.r11.u32, ctx.f12.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x8257a114
		if (ctx.r10.s32 != 0) goto loc_8257A114;
	}
loc_8257A134:
	// addi r4,r1,108
	ctx.r4.s64 = ctx.r1.s64 + 108;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x825764c8
	phBoundCapsule_64C8_2hr(ctx, base);
	// lwz r9,104(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// stfs f28,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(var_f28);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lwz r7,108(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r11,1
	ctx.r11.s64 = 1;
	// cmpwi cr6,r7,1
	// lfs f0,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f28,f0
	ctx.f0.f64 = double(float(var_f28 - ctx.f0.f64));
	// fmuls f13,f0,f0
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// ble cr6,0x8257a1d0
	if (ctx.r7.s32 > 1) {
		// addi r8,r9,4
		ctx.r8.s64 = ctx.r9.s64 + 4;
	loc_8257A16C:
		// lfs f0,0(r8)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// fsubs f0,f28,f0
		ctx.f0.f64 = double(float(var_f28 - ctx.f0.f64));
		// fmuls f0,f0,f0
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
		// fcmpu cr6,f0,f13
		// bge cr6,0x8257a188
		if (ctx.f0.f64 < ctx.f13.f64) {
			// fmr f13,f0
			ctx.f13.f64 = ctx.f0.f64;
			// mr r10,r11
			ctx.r10.u64 = ctx.r11.u64;
		}
	loc_8257A188:
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// cmpw cr6,r11,r7
		// blt cr6,0x8257a16c
		if (ctx.r11.s32 < ctx.r7.s32) goto loc_8257A16C;
		// cmplwi cr6,r10,1
		// blt cr6,0x8257a1d0
		if (ctx.r10.u32 < 1) goto loc_8257A1D0;
		// rlwinm r11,r10,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r8,r7,-1
		ctx.r8.s64 = ctx.r7.s64 + -1;
		// add r11,r11,r9
		ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
		// cmplw cr6,r10,r8
		// lfs f0,-4(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
		ctx.f0.f64 = double(temp.f32);
		// lfs f13,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fsubs f31,f13,f0
		var_f31 = double(float(ctx.f13.f64 - ctx.f0.f64));
		// bge cr6,0x8257a1e4
		if (ctx.r10.u32 >= ctx.r8.u32) goto loc_8257A1E4;
		// lfs f13,4(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		ctx.f13.f64 = double(temp.f32);
		// fsubs f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
		// fmuls f31,f0,f27
		var_f31 = double(float(ctx.f0.f64 * var_f27));
		// b 0x8257a1e4
	} else {
	loc_8257A1D0:
		// rlwinm r11,r10,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
		// add r11,r11,r9
		ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
		// lfs f0,4(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		ctx.f0.f64 = double(temp.f32);
		// lfs f13,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f13.f64 = double(temp.f32);
		// fsubs f31,f0,f13
		var_f31 = double(float(ctx.f0.f64 - ctx.f13.f64));
	}
loc_8257A1E4:
	// lis r11,-32254
	// cmpwi cr6,r31,0
	// lfs f29,29112(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29112);
	var_f29 = double(temp.f32);
	// ble cr6,0x8257a210
	if ((int32_t)var_r31 > 0) {
		// mr r10,r30
		ctx.r10.u64 = var_r30;
		// mr r11,r31
		ctx.r11.u64 = var_r31;
	loc_8257A1FC:
		// lfs f0,0(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addic. r11,r11,-1
		ctx.xer.ca = ctx.r11.u32 > 0;
		ctx.r11.s64 = ctx.r11.s64 + -1;
		// fadds f29,f29,f0
		var_f29 = double(float(var_f29 + ctx.f0.f64));
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// bne 0x8257a1fc
		if (ctx.r11.s32 != 0) goto loc_8257A1FC;
	}
loc_8257A210:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,21612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21612);  /* glob:lbl_8201546C @ 0x8201546c */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32256
	// fmuls f0,f31,f0
	ctx.f0.f64 = double(float(var_f31 * ctx.f0.f64));
	// lfs f13,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:0x82013da8 */
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32248
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f13,-24968(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24968);  /* glob:0x82009e78 */
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	// fsubs f2,f28,f0
	ctx.f2.f64 = double(float(var_f28 - ctx.f0.f64));
	// fmuls f1,f31,f13
	ctx.f1.f64 = double(float(var_f31 * ctx.f13.f64));
	// lfs f30,22700(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22700);  /* glob:0x820158ac */
	var_f30 = double(temp.f32);
	// fcmpu cr6,f2,f30
	// bge cr6,0x8257a24c
	if (ctx.f2.f64 < var_f30) {
		// fmr f2,f30
		ctx.f2.f64 = var_f30;
	}
loc_8257A24C:
	// fadds f3,f0,f28
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = double(float(ctx.f0.f64 + var_f28));
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f28,11192(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 11192);  /* glob:lbl_82022BB8 @ 0x82022bb8 */
	var_f28 = double(temp.f32);
	// fcmpu cr6,f3,f28
	// ble cr6,0x8257a264
	if (ctx.f3.f64 > var_f28) {
		// fmr f3,f28
		ctx.f3.f64 = var_f28;
	}
loc_8257A264:
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fmr f4,f29
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = var_f29;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// mr r8,r30
	ctx.r8.u64 = var_r30;
	// mr r7,r31
	ctx.r7.u64 = var_r31;
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x8257aeb0
	phBoundCapsule_AEB0_2h(ctx, base);
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lfs f0,-32044(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32044);  /* glob:lbl_820082D4 @ 0x820082d4 */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	// fmuls f0,f31,f0
	ctx.f0.f64 = double(float(var_f31 * ctx.f0.f64));
	// lfs f13,-25600(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25600);  /* glob:0x82009c00 */
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f31,f13
	ctx.f1.f64 = double(float(var_f31 * ctx.f13.f64));
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fcmpu cr6,f2,f30
	// bge cr6,0x8257a2b0
	if (ctx.f2.f64 < var_f30) {
		// fmr f2,f30
		ctx.f2.f64 = var_f30;
	}
loc_8257A2B0:
	// fadds f3,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// fcmpu cr6,f3,f28
	// ble cr6,0x8257a2c0
	if (ctx.f3.f64 > var_f28) {
		// fmr f3,f28
		ctx.f3.f64 = var_f28;
	}
loc_8257A2C0:
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// fmr f4,f29
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = var_f29;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// mr r8,r30
	ctx.r8.u64 = var_r30;
	// mr r7,r31
	ctx.r7.u64 = var_r31;
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x8257aeb0
	phBoundCapsule_AEB0_2h(ctx, base);
	// lfs f0,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f0,f0,f27
	ctx.f0.f64 = double(float(ctx.f0.f64 * var_f27));
	// stfs f29,0(r29)
	temp.f32 = float(var_f29);
	PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// fdivs f0,f0,f29
	ctx.f0.f64 = double(float(ctx.f0.f64 / var_f29));
	// stfs f0,0(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r27 + 0, temp.u32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r28)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r28 + 0, temp.u32);
	// addi r1,r1,608
	ctx.r1.s64 = ctx.r1.s64 + 608;
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82436660
	__restfpr_27(ctx, base);
	// b 0x8242f8e4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_A310_wrh"))) PPC_WEAK_FUNC(phBoundCapsule_A310_wrh);
PPC_FUNC_IMPL(__imp__phBoundCapsule_A310_wrh) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r9,0
	ctx.r9.s64 = 0;
	// addi r11,r4,1020
	ctx.r11.s64 = ctx.r4.s64 + 1020;
	// ori r9,r9,41600
	ctx.r9.u64 = ctx.r9.u64 | 41600;
	// li r10,255
	ctx.r10.s64 = 255;
loc_8257A320:
	// addi r9,r9,-162
	ctx.r9.s64 = ctx.r9.s64 + -162;
	// rlwinm r8,r9,24,8,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFFFFFF;
	// addi r8,r8,65
	ctx.r8.s64 = ctx.r8.s64 + 65;
	// mullw r8,r8,r10
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// addi r8,r8,209
	ctx.r8.s64 = ctx.r8.s64 + 209;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r8,r8,24,8,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 24) & 0xFFFFFF;
	// cmplwi cr6,r10,86
	// addi r8,r8,29
	ctx.r8.s64 = ctx.r8.s64 + 29;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f0,r8,r3
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// bgt cr6,0x8257a320
	if (ctx.r10.u32 > 86) goto loc_8257A320;
	// li r10,17789
	ctx.r10.s64 = 17789;
	// li r9,87
	ctx.r9.s64 = 87;
loc_8257A360:
	// addi r10,r10,-203
	ctx.r10.s64 = ctx.r10.s64 + -203;
	// addic. r9,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// rlwinm r8,r10,26,6,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x3FFFFFC;
	// lfsx f0,r8,r3
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// bne 0x8257a360
	if (ctx.r9.s32 != 0) goto loc_8257A360;
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A380_fw"))) PPC_WEAK_FUNC(atSingleton_A380_fw);
PPC_FUNC_IMPL(__imp__atSingleton_A380_fw) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// FRAME: size=96, manual
	// extsh. r11,r4
	ctx.r11.s64 = ctx.r4.s16;
	// bgt 0x8257a398
	if (ctx.r11.s32 <= 0) {
		// li r4,176
		ctx.r4.s64 = 176;
	}
loc_8257A398:
	// extsh r11,r4
	ctx.r11.s64 = ctx.r4.s16;
	// lfs f0,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4)/* atSingleton::flags@+0x4 */;
	ctx.f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lis r11,-32256
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// lfs f13,28080(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28080);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f12,29140(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29140);  /* glob:lbl_820271D4 @ 0x820271d4 */
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// bgt cr6,0x8257a3dc
	if (ctx.f0.f64 <= ctx.f13.f64) {
		// bso cr6,0x8257a3dc
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257A3CC, "bso");
		// fcmpu cr6,f0,f12
		// bso cr6,0x8257a3dc
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257A3D4, "bso");
		// bge cr6,0x8257a400
		if (ctx.f0.f64 >= ctx.f12.f64) goto loc_8257A400;
	}
loc_8257A3DC:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	// bge cr6,0x8257a3ec
	if (ctx.f0.f64 < ctx.f12.f64) {
		// fadds f0,f0,f13
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
		// b 0x8257a3f0
	} else {
	loc_8257A3EC:
		// fsubs f0,f0,f13
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	}
loc_8257A3F0:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f13,15784(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);  /* glob:lbl_82003DA8 @ 0x82003da8 */
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// bne cr6,0x8257a408
	if (ctx.f0.f64 == ctx.f13.f64) {
	loc_8257A400:
		// li r3,0
		ctx.r3.s64 = 0;
		// b 0x8257a4c0
	} else {
	loc_8257A408:
		// fcmpu cr6,f0,f13
		ctx.fpscr.disableFlushMode();
		// bge cr6,0x8257a46c
		if (ctx.f0.f64 < ctx.f13.f64) {
			// lis r11,-32254
			ctx.r11.s64 = -2113798144;
			// lfs f13,29136(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29136);  /* glob:lbl_820271D0 @ 0x820271d0 */
			ctx.f13.f64 = double(temp.f32);
			// lis r11,-32248
			// fmuls f2,f0,f13
			ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
			// lfd f1,-25752(r11)
			ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -25752);  /* glob:0x82019b68 */
			// bl 0x82431308
			atSingleton_1308_g(ctx, base);
			// frsp f0,f1
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = double(float(ctx.f1.f64));
			// lis r11,-32254
			ctx.r11.s64 = -2113798144;
			// lfs f13,29132(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29132);  /* glob:lbl_820271CC @ 0x820271cc */
			ctx.f13.f64 = double(temp.f32);
			// fneg f0,f0
			ctx.f0.u64 = ctx.f0.u64 ^ 0x8000000000000000;
			// fcmpu cr6,f0,f13
			// bge cr6,0x8257a444
			if (ctx.f0.f64 < ctx.f13.f64) {
				// fmr f0,f13
				ctx.f0.f64 = ctx.f13.f64;
			}
		loc_8257A444:
			// lis r11,-32256
			ctx.r11.s64 = -2113929216;
			// lfs f13,15788(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
			ctx.f13.f64 = double(temp.f32);
			// lis r11,-32254
			// fadds f13,f0,f13
			ctx.f13.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
			// lfs f0,29128(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29128);  /* glob:0x820071c8 */
			ctx.f0.f64 = double(temp.f32);
			// fmuls f0,f13,f0
			ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
			// fctiwz f0,f0
			ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
			// stfd f0,80(r1)
			PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f0.u64);
			// lhz r3,86(r1)
			ctx.r3.u64 = PPC_LOAD_U16(ctx.r1.u32 + 86);
			// b 0x8257a4c0
		} else {
		loc_8257A46C:
			// lis r11,-32254
			ctx.r11.s64 = -2113798144;
			// lfs f13,29124(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29124);  /* glob:lbl_820271C4 @ 0x820271c4 */
			ctx.f13.f64 = double(temp.f32);
			// lis r11,-32248
			// fmuls f2,f0,f13
			ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
			// lfd f1,-25752(r11)
			ctx.f1.u64 = PPC_LOAD_U64(ctx.r11.u32 + -25752);  /* glob:0x82019b68 */
			// bl 0x82431308
			atSingleton_1308_g(ctx, base);
			// frsp f0,f1
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = double(float(ctx.f1.f64));
			// lis r11,-32254
			ctx.r11.s64 = -2113798144;
			// lfs f13,29120(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29120);  /* glob:lbl_820271C0 @ 0x820271c0 */
			ctx.f13.f64 = double(temp.f32);
			// fcmpu cr6,f0,f13
			// ble cr6,0x8257a49c
			if (ctx.f0.f64 > ctx.f13.f64) {
				// fmr f0,f13
				ctx.f0.f64 = ctx.f13.f64;
			}
		loc_8257A49C:
			// lis r11,-32256
			ctx.r11.s64 = -2113929216;
			// lfs f13,15788(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
			ctx.f13.f64 = double(temp.f32);
			// lis r11,-32254
			// fsubs f13,f0,f13
			ctx.f13.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
			// lfs f0,29128(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29128);  /* glob:0x820071c8 */
			ctx.f0.f64 = double(temp.f32);
			// fmuls f0,f13,f0
			ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
			// fctiwz f0,f0
			ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
			// stfd f0,80(r1)
			PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f0.u64);
			// lhz r3,86(r1)
			ctx.r3.u64 = PPC_LOAD_U16(ctx.r1.u32 + 86);
		}
	}
loc_8257A4C0:
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A4D0_2hr"))) PPC_WEAK_FUNC(atSingleton_A4D0_2hr);
PPC_FUNC_IMPL(__imp__atSingleton_A4D0_2hr) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// rlwinm r11,r3,29,27,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 29) & 0x1F;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lis r9,-32254
	// lis r8,-32256
	// lfs f13,29144(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 29144);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,15788(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 15788);
	ctx.f12.f64 = double(temp.f32);
	// mr. r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f0,r11,r10
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
	// fmadds f0,f0,f13,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfsx f0,r11,r10
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, temp.u32);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lfsx f0,r10,r11
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// ble 0x8257a538
	if (ctx.r9.s32 > 0) {
		// li r11,0
		ctx.r11.s64 = 0;
		// mr r8,r9
		ctx.r8.u64 = ctx.r9.u64;
	loc_8257A514:
		// lfsx f11,r11,r10
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
		ctx.f11.f64 = double(temp.f32);
		// addic. r8,r8,-1
		ctx.xer.ca = ctx.r8.u32 > 0;
		ctx.r8.s64 = ctx.r8.s64 + -1;
		// fmuls f11,f11,f13
		ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
		// stfsx f11,r11,r10
		temp.f32 = float(ctx.f11.f64);
		PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, temp.u32);
		// lwz r10,0(r4)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// lfsx f11,r11,r10
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
		ctx.f11.f64 = double(temp.f32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fadds f0,f11,f0
		ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
		// bne 0x8257a514
		if (ctx.r8.s32 != 0) goto loc_8257A514;
	}
loc_8257A538:
	// addi r11,r9,1
	ctx.r11.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r11,32
	// bgt cr6,0x8257a570
	if (ctx.r11.s32 <= 32) {
		// lwz r10,0(r4)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// rlwinm r11,r11,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	loc_8257A54C:
		// lfsx f11,r11,r10
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
		ctx.f11.f64 = double(temp.f32);
		// fmuls f11,f11,f13
		ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
		// stfsx f11,r11,r10
		temp.f32 = float(ctx.f11.f64);
		PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, temp.u32);
		// lwz r10,0(r4)
		ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		// lfsx f11,r11,r10
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
		ctx.f11.f64 = double(temp.f32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// fadds f0,f11,f0
		ctx.f0.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
		// cmpwi cr6,r11,128
		// ble cr6,0x8257a54c
		if (ctx.r11.s32 <= 128) goto loc_8257A54C;
	}
loc_8257A570:
	// lis r11,-32256
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// fdivs f0,f12,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f12.f64 / ctx.f0.f64));
	// lfs f13,15784(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15784);
	ctx.f13.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// stfs f13,4(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
loc_8257A588:
	// extsw r9,r11
	ctx.r9.s64 = ctx.r11.s32;
	// lfs f13,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,32
	// std r9,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r9.u64);
	// lfd f11,-16(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// fmuls f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64 + ctx.f12.f64));
	// stfs f13,4(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// ble cr6,0x8257a588
	if (ctx.r11.s32 <= 32) goto loc_8257A588;
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,22700(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 22700);  /* glob:lbl_820058AC @ 0x820058ac */
	ctx.f0.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// stfs f0,4(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// sth r11,8(r4)
	PPC_STORE_U16(ctx.r4.u32 + 8, ctx.r11.u16);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A5E0_2h"))) PPC_WEAK_FUNC(atSingleton_A5E0_2h);
PPC_FUNC_IMPL(__imp__atSingleton_A5E0_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4)/* atSingleton::flags@+0x4 */;
	ctx.f1.f64 = double(temp.f32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A5E8_2h"))) PPC_WEAK_FUNC(atSingleton_A5E8_2h);
PPC_FUNC_IMPL(__imp__atSingleton_A5E8_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lha r11,8(r3)
	ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r3.u32 + 8));
	// cmpwi cr6,r11,84
	// bgt cr6,0x8257a628
	if (ctx.r11.s32 <= 84) {
		// lis r10,-32254
		// li r11,0
		ctx.r11.s64 = 0;
		// lfs f0,29148(r10)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 29148);
		ctx.f0.f64 = double(temp.f32);
	loc_8257A600:
		// lwz r9,0(r3)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* atSingleton::vtable@+0x0 */;
		// rlwinm r10,r11,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
		// addi r8,r11,1
		ctx.r8.s64 = ctx.r11.s64 + 1;
		// extsh r11,r8
		ctx.r11.s64 = ctx.r8.s16;
		// lfsx f13,r10,r9
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
		ctx.f13.f64 = double(temp.f32);
		// cmpwi cr6,r11,32
		// fmuls f13,f13,f0
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// stfsx f13,r10,r9
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, temp.u32);
		// ble cr6,0x8257a600
		if (ctx.r11.s32 <= 32) goto loc_8257A600;
		// b 0x8257a630
	} else {
	loc_8257A628:
		// li r11,84
		ctx.r11.s64 = 84;
		// sth r11,8(r3)
		PPC_STORE_U16(ctx.r3.u32 + 8, ctx.r11.u16);
	}
loc_8257A630:
	// lhz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// sth r11,8(r3)
	PPC_STORE_U16(ctx.r3.u32 + 8, ctx.r11.u16);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A640_2h"))) PPC_WEAK_FUNC(atSingleton_A640_2h);
PPC_FUNC_IMPL(__imp__atSingleton_A640_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32254
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,29176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29176);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// ble cr6,0x8257a674
	if (ctx.f0.f64 > ctx.f13.f64) {
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f13,29172(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29172);  /* glob:lbl_820271F4 @ 0x820271f4 */
		ctx.f13.f64 = double(temp.f32);
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f12,29168(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29168);  /* glob:lbl_820271F0 @ 0x820271f0 */
		ctx.f12.f64 = double(temp.f32);
		// lis r11,-32254
		// fnmsubs f12,f0,f13,f12
		ctx.f12.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f12.f64)));
		// lfs f13,29164(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29164);  /* glob:lbl_820271EC @ 0x820271ec */
		ctx.f13.f64 = double(temp.f32);
		// b 0x8257a690
	} else {
	loc_8257A674:
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f13,29160(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29160);  /* glob:lbl_820271E8 @ 0x820271e8 */
		ctx.f13.f64 = double(temp.f32);
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f12,29156(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29156);  /* glob:lbl_820271E4 @ 0x820271e4 */
		ctx.f12.f64 = double(temp.f32);
		// lis r11,-32254
		// fnmsubs f12,f0,f13,f12
		ctx.f12.f64 = double(float(-(ctx.f0.f64 * ctx.f13.f64 - ctx.f12.f64)));
		// lfs f13,29152(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29152);  /* glob:lbl_820271E0 @ 0x820271e0 */
		ctx.f13.f64 = double(temp.f32);
	}
loc_8257A690:
	// fmadds f0,f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 + ctx.f13.f64));
	// li r11,1
	ctx.r11.s64 = 1;
	// stfs f0,4(r4)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// fcmpu cr6,f1,f0
	// bgt cr6,0x8257a6a8
	if (ctx.f1.f64 <= ctx.f0.f64) {
		// li r11,0
		ctx.r11.s64 = 0;
	}
loc_8257A6A8:
	// stb r11,19(r4)
	PPC_STORE_U8(ctx.r4.u32 + 19, ctx.r11.u8);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A6B0_2h"))) PPC_WEAK_FUNC(atSingleton_A6B0_2h);
PPC_FUNC_IMPL(__imp__atSingleton_A6B0_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lbz r11,19(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 19);
	// cmplwi cr6,r11,0
	// beq cr6,0x8257a72c
	if (ctx.r11.u32 != 0) {
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f0,29184(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29184);  /* glob:lbl_82027200 @ 0x82027200 */
		ctx.f0.f64 = double(temp.f32);
		// extsh r11,r5
		ctx.r11.s64 = ctx.r5.s16;
		// fsubs f0,f2,f0
		ctx.f0.f64 = double(float(ctx.f2.f64 - ctx.f0.f64));
		// std r11,-16(r1)
		PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r11.u64);
		// lis r11,-32254
		// lfd f13,-16(r1)
		ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
		// fcfid f13,f13
		ctx.f13.f64 = double(ctx.f13.s64);
		// frsp f12,f13
		ctx.f12.f64 = double(float(ctx.f13.f64));
		// lfs f13,29180(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29180);
		ctx.f13.f64 = double(temp.f32);
		// fsubs f13,f12,f13
		ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
		// fcmpu cr6,f0,f13
		// bso cr6,0x8257a6f4
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257A6EC, "bso");
		// bge cr6,0x8257a6f8
		if (ctx.f0.f64 < ctx.f13.f64) {
		loc_8257A6F4:
			// fmr f0,f13
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = ctx.f13.f64;
		}
	loc_8257A6F8:
		// fcmpu cr6,f1,f0
		ctx.fpscr.disableFlushMode();
		// blt cr6,0x8257a72c
		if (ctx.f1.f64 < ctx.f0.f64) goto loc_8257A72C;
		// bso cr6,0x8257a72c
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257A700, "bso");
		// lhz r11,14(r6)
		ctx.r11.u64 = PPC_LOAD_U16(ctx.r6.u32 + 14);
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// extsh r11,r11
		ctx.r11.s64 = ctx.r11.s16;
		// cmpwi cr6,r11,1
		// sth r11,14(r6)
		PPC_STORE_U16(ctx.r6.u32 + 14, ctx.r11.u16);
		// ble cr6,0x8257a724
		if (ctx.r11.s32 > 1) {
			// li r11,1
			ctx.r11.s64 = 1;
			// b 0x8257a730
			goto loc_8257A730;
		}
	loc_8257A724:
		// li r11,0
		ctx.r11.s64 = 0;
		// b 0x8257a734
	} else {
	loc_8257A72C:
		// li r11,0
		ctx.r11.s64 = 0;
	loc_8257A730:
		// sth r11,14(r6)
		PPC_STORE_U16(ctx.r6.u32 + 14, ctx.r11.u16);
	}
loc_8257A734:
	// stb r11,20(r6)
	PPC_STORE_U8(ctx.r6.u32 + 20, ctx.r11.u8);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A740_2h"))) PPC_WEAK_FUNC(atSingleton_A740_2h);
PPC_FUNC_IMPL(__imp__atSingleton_A740_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32254
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,29176(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29176);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	// bge cr6,0x8257a780
	if (ctx.f13.f64 < ctx.f0.f64) {
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f0,29208(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29208);  /* glob:lbl_82027218 @ 0x82027218 */
		ctx.f0.f64 = double(temp.f32);
		// lis r11,-32254
		// fmuls f0,f13,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
		// lfs f12,29204(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29204);  /* glob:lbl_82027214 @ 0x82027214 */
		ctx.f12.f64 = double(temp.f32);
		// fadds f12,f13,f12
		ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
		// fcmpu cr6,f0,f12
		// bso cr6,0x8257a778
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257A770, "bso");
		// bge cr6,0x8257a7a8
		if (ctx.f0.f64 >= ctx.f12.f64) goto loc_8257A7A8;
	loc_8257A778:
		// fmr f0,f12
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = ctx.f12.f64;
		// b 0x8257a7a8
	} else {
	loc_8257A780:
		// lis r11,-32254
		ctx.r11.s64 = -2113798144;
		// lfs f0,29200(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29200);  /* glob:lbl_82027210 @ 0x82027210 */
		ctx.f0.f64 = double(temp.f32);
		// fcmpu cr6,f13,f0
		// bge cr6,0x8257a79c
		if (ctx.f13.f64 < ctx.f0.f64) {
			// lis r11,-32254
			ctx.r11.s64 = -2113798144;
			// lfs f0,29196(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29196);  /* glob:lbl_8202720C @ 0x8202720c */
			ctx.f0.f64 = double(temp.f32);
			// b 0x8257a7a4
		} else {
		loc_8257A79C:
			// lis r11,-32254
			ctx.r11.s64 = -2113798144;
			// lfs f0,29192(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29192);  /* glob:lbl_82027208 @ 0x82027208 */
			ctx.f0.f64 = double(temp.f32);
		}
	loc_8257A7A4:
		// fmuls f0,f13,f0
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	}
loc_8257A7A8:
	// fcmpu cr6,f1,f13
	ctx.fpscr.disableFlushMode();
	// bge cr6,0x8257a8ac
	if (ctx.f1.f64 < ctx.f13.f64) {
		// lbz r11,18(r4)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 18);
		// extsb. r11,r11
		ctx.r11.s64 = ctx.r11.s8;
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f9,15788(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:lbl_82003DAC @ 0x82003dac */
		ctx.f9.f64 = double(temp.f32);
		// bgt 0x8257a7f0
		if (ctx.r11.s32 <= 0) {
			// lis r11,-32256
			// fadds f12,f1,f9
			ctx.f12.f64 = double(float(ctx.f1.f64 + ctx.f9.f64));
			// lfs f11,19100(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 19100);
			ctx.f11.f64 = double(temp.f32);
			// lis r11,-32256
			// fmuls f11,f13,f11
			ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
			// lfs f10,27220(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27220);
			ctx.f10.f64 = double(temp.f32);
			// fmadds f8,f12,f10,f11
			ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 + ctx.f11.f64));
			// fcmpu cr6,f8,f0
			// bgt cr6,0x8257a7f0
			if (ctx.f8.f64 > ctx.f0.f64) goto loc_8257A7F0;
			// bso cr6,0x8257a7f0
			// UNIMPLEMENTED: bso
			PPC_UNIMPLEMENTED(0x8257A7E8, "bso");
			// fmadds f0,f12,f10,f11
			ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f10.f64 + ctx.f11.f64));
		}
	loc_8257A7F0:
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f12,27216(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27216);  /* glob:lbl_82006A50 @ 0x82006a50 */
		ctx.f12.f64 = double(temp.f32);
		// fmuls f12,f13,f12
		ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
		// fcmpu cr6,f1,f12
		// bgt cr6,0x8257a864
		if (ctx.f1.f64 <= ctx.f12.f64) {
			// bso cr6,0x8257a864
			// UNIMPLEMENTED: bso
			PPC_UNIMPLEMENTED(0x8257A804, "bso");
			// fcmpu cr6,f1,f9
			// bge cr6,0x8257a840
			if (ctx.f1.f64 < ctx.f9.f64) {
				// lis r11,-32255
				// fadds f12,f1,f9
				ctx.f12.f64 = double(float(ctx.f1.f64 + ctx.f9.f64));
				// lfs f11,21608(r11)
				temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21608);  /* glob:0x82005468 */
				ctx.f11.f64 = double(temp.f32);
				// lis r11,-32248
				// fmuls f13,f13,f11
				ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
				// lfs f11,-24540(r11)
				temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24540);
				ctx.f11.f64 = double(temp.f32);
				// fmadds f10,f12,f11,f13
				ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f13.f64));
				// fcmpu cr6,f10,f0
				// bgt cr6,0x8257a8e0
				if (ctx.f10.f64 > ctx.f0.f64) goto loc_8257A8E0;
				// bso cr6,0x8257a8e0
				// UNIMPLEMENTED: bso
				PPC_UNIMPLEMENTED(0x8257A834, "bso");
				// fmadds f0,f12,f11,f13
				ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f13.f64));
				// b 0x8257a8e0
				goto loc_8257A8E0;
			}
		loc_8257A840:
			// lis r11,-32248
			ctx.r11.s64 = -2113404928;
			// lfs f12,-25732(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25732);  /* glob:lbl_82079B7C @ 0x82079b7c */
			ctx.f12.f64 = double(temp.f32);
			// lis r11,-32255
			ctx.r11.s64 = -2113863680;
			// lfs f11,21620(r11)
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21620);  /* glob:lbl_82015474 @ 0x82015474 */
			ctx.f11.f64 = double(temp.f32);
		loc_8257A850:
			// fmuls f13,f13,f11
			ctx.fpscr.disableFlushMode();
			ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
			// fmadds f13,f1,f12,f13
			ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f13.f64));
		loc_8257A858:
			// fcmpu cr6,f13,f0
			ctx.fpscr.disableFlushMode();
			// bgt cr6,0x8257a8e0
			if (ctx.f13.f64 > ctx.f0.f64) goto loc_8257A8E0;
			// b 0x8257a8d8
			goto loc_8257A8D8;
		}
	loc_8257A864:
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f12,18992(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 18992);  /* glob:lbl_82004A30 @ 0x82004a30 */
		ctx.f12.f64 = double(temp.f32);
		// fmuls f12,f13,f12
		ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
		// fcmpu cr6,f1,f12
		// bgt cr6,0x8257a890
		if (ctx.f1.f64 > ctx.f12.f64) goto loc_8257A890;
		// bso cr6,0x8257a890
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257A878, "bso");
		// lis r11,-32255
		ctx.r11.s64 = -2113863680;
		// lfs f12,21628(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21628);  /* glob:lbl_8201547C @ 0x8201547c */
		ctx.f12.f64 = double(temp.f32);
		// lis r11,-32256
		ctx.r11.s64 = -2113929216;
		// lfs f11,27324(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27324);  /* glob:lbl_82006ABC @ 0x82006abc */
		ctx.f11.f64 = double(temp.f32);
		// b 0x8257a850
		goto loc_8257A850;
	loc_8257A890:
		// lis r11,-32255
		ctx.r11.s64 = -2113863680;
		// lfs f12,-27004(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -27004);  /* glob:lbl_82009684 @ 0x82009684 */
		ctx.f12.f64 = double(temp.f32);
		// lis r11,-32255
		ctx.r11.s64 = -2113863680;
		// lfs f11,21604(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21604);  /* glob:lbl_82015464 @ 0x82015464 */
		ctx.f11.f64 = double(temp.f32);
		// fmuls f11,f1,f11
		ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
		// fmadds f13,f13,f12,f11
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
		// b 0x8257a858
		goto loc_8257A858;
	}
loc_8257A8AC:
	// lbz r11,19(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 19);
	// cmplwi cr6,r11,0
	// bne cr6,0x8257a8e0
	if (ctx.r11.u32 == 0) {
		// lis r11,-32255
		ctx.r11.s64 = -2113863680;
		// lfs f12,21612(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 21612);  /* glob:lbl_8201546C @ 0x8201546c */
		ctx.f12.f64 = double(temp.f32);
		// lis r11,-32255
		ctx.r11.s64 = -2113863680;
		// lfs f11,-32044(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -32044);  /* glob:lbl_820082D4 @ 0x820082d4 */
		ctx.f11.f64 = double(temp.f32);
		// fmuls f11,f1,f11
		ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
		// fmadds f13,f13,f12,f11
		ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
		// fcmpu cr6,f13,f0
		// blt cr6,0x8257a8e0
		if (ctx.f13.f64 < ctx.f0.f64) goto loc_8257A8E0;
	loc_8257A8D8:
		// bso cr6,0x8257a8e0
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257A8D8, "bso");
		// fmr f0,f13
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = ctx.f13.f64;
	}
loc_8257A8E0:
	// lis r11,-32254
	ctx.r11.s64 = -2113798144;
	// lfs f13,29188(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29188);  /* glob:lbl_82027204 @ 0x82027204 */
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	// ble cr6,0x8257a8f4
	if (ctx.f0.f64 > ctx.f13.f64) {
		// fmr f0,f13
		ctx.f0.f64 = ctx.f13.f64;
	}
loc_8257A8F4:
	// lbz r11,18(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 18);
	// extsb. r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// bgt 0x8257a908
	if (ctx.r11.s32 <= 0) {
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// stb r11,18(r4)
		PPC_STORE_U8(ctx.r4.u32 + 18, ctx.r11.u8);
	}
loc_8257A908:
	// stfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A910_2h"))) PPC_WEAK_FUNC(atSingleton_A910_2h);
PPC_FUNC_IMPL(__imp__atSingleton_A910_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// extsh r11,r4
	ctx.r11.s64 = ctx.r4.s16;
	// cmpwi cr6,r11,255
	// blt cr6,0x8257a920
	if (ctx.r11.s32 >= 255) {
		// li r4,255
		ctx.r4.s64 = 255;
	}
loc_8257A920:
	// lbz r11,20(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 20);
	// cmplwi cr6,r11,1
	// bne cr6,0x8257a96c
	if (ctx.r11.u32 == 1) {
		// li r11,0
		ctx.r11.s64 = 0;
		// sth r11,16(r6)
		PPC_STORE_U16(ctx.r6.u32 + 16, ctx.r11.u16);
		// lbz r11,21(r6)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 21);
		// cmplwi cr6,r11,0
		// bne cr6,0x8257a9d4
		if (ctx.r11.u32 != 0) {
			// lbz r11,21(r6)
			ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 21);
			// extsb r3,r11
			ctx.r3.s64 = ctx.r11.s8;
			// blr
			return;
		}
		// extsh r11,r4
		ctx.r11.s64 = ctx.r4.s16;
		// std r11,-16(r1)
		PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r11.u64);
		// lfd f0,-16(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
		// fcfid f0,f0
		ctx.f0.f64 = double(ctx.f0.s64);
		// frsp f0,f0
		ctx.f0.f64 = double(float(ctx.f0.f64));
		// fcmpu cr6,f1,f0
		// blt cr6,0x8257a9d4
		if (ctx.f1.f64 < ctx.f0.f64) {
			// lbz r11,21(r6)
			ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 21);
			// extsb r3,r11
			ctx.r3.s64 = ctx.r11.s8;
			// blr
			return;
		}
		// bso cr6,0x8257a9d4
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257A95C, "bso");
		// li r11,1
		ctx.r11.s64 = 1;
		// stb r11,21(r6)
		PPC_STORE_U8(ctx.r6.u32 + 21, ctx.r11.u8);
		// b 0x8257a9d4
	} else {
	loc_8257A96C:
		// clrlwi r11,r5,16
		ctx.r11.u64 = ctx.r5.u32 & 0xFFFF;
		// lfs f13,8(r6)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
		ctx.f13.f64 = double(temp.f32);
		// lis r10,-32256
		// std r11,-16(r1)
		PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r11.u64);
		// lhz r11,16(r6)
		ctx.r11.u64 = PPC_LOAD_U16(ctx.r6.u32 + 16);
		// addi r11,r11,1
		ctx.r11.s64 = ctx.r11.s64 + 1;
		// extsh r11,r11
		ctx.r11.s64 = ctx.r11.s16;
		// sth r11,16(r6)
		PPC_STORE_U16(ctx.r6.u32 + 16, ctx.r11.u16);
		// lfd f0,-16(r1)
		ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
		// fcfid f0,f0
		ctx.f0.f64 = double(ctx.f0.s64);
		// frsp f12,f0
		ctx.f12.f64 = double(float(ctx.f0.f64));
		// lfs f0,27200(r10)
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27200);
		ctx.f0.f64 = double(temp.f32);
		// mr r10,r11
		ctx.r10.u64 = ctx.r11.u64;
		// fmadds f0,f13,f12,f0
		ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f0.f64));
		// fctidz f0,f0
		ctx.f0.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simde_mm_cvttsd_si64(simde_mm_load_sd(&ctx.f0.f64));
		// stfd f0,-16(r1)
		PPC_STORE_U64(ctx.r1.u32 + -16, ctx.f0.u64);
		// lha r11,-10(r1)
		ctx.r11.s64 = int16_t(PPC_LOAD_U16(ctx.r1.u32 + -10));
		// cmpw cr6,r10,r11
		// ble cr6,0x8257a9d4
		if (ctx.r10.s32 <= ctx.r11.s32) {
			// lbz r11,21(r6)
			ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 21);
			// extsb r3,r11
			ctx.r3.s64 = ctx.r11.s8;
			// blr
			return;
		}
		// extsh r11,r10
		ctx.r11.s64 = ctx.r10.s16;
		// li r10,0
		ctx.r10.s64 = 0;
		// cmpwi cr6,r11,32700
		// stb r10,21(r6)
		PPC_STORE_U8(ctx.r6.u32 + 21, ctx.r10.u8);
		// ble cr6,0x8257a9d4
		if (ctx.r11.s32 <= 32700) {
			// lbz r11,21(r6)
			ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 21);
			// extsb r3,r11
			ctx.r3.s64 = ctx.r11.s8;
			// blr
			return;
		}
		// li r11,32700
		ctx.r11.s64 = 32700;
		// sth r11,16(r6)
		PPC_STORE_U16(ctx.r6.u32 + 16, ctx.r11.u16);
	}
loc_8257A9D4:
	// lbz r11,21(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 21);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_A9E0_2h"))) PPC_WEAK_FUNC(atSingleton_A9E0_2h);
PPC_FUNC_IMPL(__imp__atSingleton_A9E0_2h) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lbz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 20);
	// cmplwi cr6,r11,1
	// bne cr6,0x8257aa1c
	if (ctx.r11.u32 == 1) {
		// extsh r11,r4
		ctx.r11.s64 = ctx.r4.s16;
		// cmpwi cr6,r11,1
		// bne cr6,0x8257aa1c
		if (ctx.r11.s32 != 1) {
			// li r3,0
			ctx.r3.s64 = 0;
			// blr
			return;
		}
		// lbz r11,21(r3)
		ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 21);
		// cmplwi cr6,r11,1
		// bne cr6,0x8257aa1c
		if (ctx.r11.u32 != 1) {
			// li r3,0
			ctx.r3.s64 = 0;
			// blr
			return;
		}
		// lis r11,-32248
		ctx.r11.s64 = -2113404928;
		// lfs f0,-25384(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25384);  /* glob:lbl_82079CD8 @ 0x82079cd8 */
		ctx.f0.f64 = double(temp.f32);
		// fcmpu cr6,f1,f0
		// blt cr6,0x8257aa1c
		if (ctx.f1.f64 < ctx.f0.f64) {
			// li r3,0
			ctx.r3.s64 = 0;
			// blr
			return;
		}
		// li r3,1
		ctx.r3.s64 = 1;
		// bnslr cr6
		// UNIMPLEMENTED: bnslr
		PPC_UNIMPLEMENTED(0x8257AA18, "bnslr");
	}
loc_8257AA1C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__phBoundCapsule_AA28_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_AA28_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_AA28_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	double var_f28 = 0.0;
	double var_f30 = 0.0;
	double var_f31 = 0.0;
	double var_f29 = 0.0;
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f894
	ctx.lr = 0x8257AA30;
	__savegprlr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82436618
	__savefpr_28(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	var_r31 = ctx.r5.u32;
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	var_f28 = ctx.f1.f64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// li r4,64
	ctx.r4.s64 = 64;
	// mr r27,r3
	var_r27 = ctx.r3.u32;
	// bl 0x82576a30
	phBoundCapsule_6A30(ctx, base);
	// lis r11,-32256
	// addi r10,r31,4
	ctx.r10.s64 = (int64_t)(int32_t)var_r31 + 4;
	// lfs f30,15788(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 15788);  /* glob:0x82083dac */
	var_f30 = double(temp.f32);
	// li r11,11
	ctx.r11.s64 = 11;
	// fmr f1,f30
	ctx.f1.f64 = var_f30;
loc_8257AA6C:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// fnmsubs f0,f0,f0,f30
	ctx.f0.f64 = double(float(-(ctx.f0.f64 * ctx.f0.f64 - var_f30)));
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// fmuls f1,f0,f1
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// bne 0x8257aa6c
	if (ctx.r11.s32 != 0) goto loc_8257AA6C;
	// bl 0x82576ef0
	phBoundCapsule_6EF0(ctx, base);
	// lis r11,-32256
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + 0)/* phBoundCapsule::vtable@+0x0 */;
	ctx.f0.f64 = double(temp.f32);
	// addi r29,r1,112
	var_r29 = (uint32_t)(ctx.r1.s64 + 112);
	// li r31,0
	var_r31 = 0;
	// fmadds f30,f0,f0,f30
	var_f30 = double(float(ctx.f0.f64 * ctx.f0.f64 + var_f30));
	// li r30,5
	var_r30 = 5;
	// lis r28,-32164
	var_r28 = (uint32_t)(-2107899904);
	// lfs f31,27200(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);
	var_f31 = double(temp.f32);
	// lis r11,-32248
	// fnmsubs f28,f1,f31,f28
	var_f28 = double(float(-(ctx.f1.f64 * var_f31 - var_f28)));
	// lfs f13,-25416(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25416);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f29,f0,f13
	var_f29 = double(float(ctx.f0.f64 * ctx.f13.f64));
loc_8257AAB8:
	// lwz r11,10080(r28)
	ctx.r11.u64 = PPC_LOAD_U32(var_r28 + 10080);
	// lfsx f0,r31,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(var_r31 + ctx.r11.u32);
	ctx.f0.f64 = double(temp.f32);
	// addi r31,r31,128
	var_r31 = (uint32_t)(var_r31 + 128);
	// fmadds f1,f0,f29,f30
	ctx.f1.f64 = double(float(ctx.f0.f64 * var_f29 + var_f30));
	// bl 0x82576ef0
	phBoundCapsule_6EF0(ctx, base);
	// fnmsubs f0,f1,f31,f28
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(-(ctx.f1.f64 * var_f31 - var_f28)));
	// stfs f0,0(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r29 + 0,/* phBoundCapsule::vtable@+0x0 */ temp.u32);
	// addic. r30,r30,-1
	ctx.xer.ca = var_r30 > 0;
	var_r30 = (uint32_t)(var_r30 + -1);
	// addi r29,r29,4
	var_r29 = (uint32_t)(var_r29 + 4);
	// bne 0x8257aab8
	if ((int32_t)var_r30 != 0) goto loc_8257AAB8;
	// lis r10,-32254
	// li r11,1
	ctx.r11.s64 = 1;
	// addi r10,r10,29212
	ctx.r10.s64 = ctx.r10.s64 + 29212;
	// addi r9,r27,4
	ctx.r9.s64 = (int64_t)(int32_t)var_r27 + 4;
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
loc_8257AAFC:
	// clrlwi r8,r11,28
	ctx.r8.u64 = ctx.r11.u32 & 0xF;
	// lfs f13,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// srawi r10,r11,4
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0xF) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 4;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r1,116
	ctx.r6.s64 = ctx.r1.s64 + 116;
	// std r8,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r8.u64);
	// lfsx f8,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfd f0,96(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// fmuls f9,f0,f11
	ctx.f9.f64 = double(float(ctx.f0.f64 * ctx.f11.f64));
	// lfsx f0,r10,r7
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f0.f64));
	// fmadds f0,f8,f9,f0
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f9.f64 + ctx.f0.f64));
	// fsubs f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 - ctx.f0.f64));
	// fmuls f0,f0,f31
	ctx.f0.f64 = double(float(ctx.f0.f64 * var_f31));
	// fcmpu cr6,f0,f12
	// ble cr6,0x8257ab4c
	if (ctx.f0.f64 > ctx.f12.f64) {
		// fmr f0,f12
		ctx.f0.f64 = ctx.f12.f64;
	}
loc_8257AB4C:
	// fcmpu cr6,f0,f10
	ctx.fpscr.disableFlushMode();
	// bgt cr6,0x8257ab58
	if (ctx.f0.f64 <= ctx.f10.f64) {
		// fmr f0,f10
		ctx.f0.f64 = ctx.f10.f64;
	}
loc_8257AB58:
	// cmpwi cr6,r11,16
	// bge cr6,0x8257ab7c
	if (ctx.r11.s32 < 16) {
		// extsw r10,r11
		ctx.r10.s64 = ctx.r11.s32;
		// std r10,104(r1)
		PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
		// lfd f9,104(r1)
		ctx.fpscr.disableFlushMode();
		ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
		// fcfid f9,f9
		ctx.f9.f64 = double(ctx.f9.s64);
		// frsp f9,f9
		ctx.f9.f64 = double(float(ctx.f9.f64));
		// fmuls f9,f9,f11
		ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f11.f64));
		// fmuls f0,f9,f0
		ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
	}
loc_8257AB7C:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// fadds f0,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f0,0(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmpwi cr6,r11,64
	// blt cr6,0x8257aafc
	if (ctx.r11.s32 < 64) goto loc_8257AAFC;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// li r4,64
	ctx.r4.s64 = 64;
	// mr r3,r27
	ctx.r3.u64 = var_r27;
	// bl 0x82576a30
	phBoundCapsule_6A30(ctx, base);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// mr r11,r27
	ctx.r11.u64 = var_r27;
	// fsubs f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f13.f64));
	// li r10,64
	ctx.r10.s64 = 64;
loc_8257ABBC:
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// fadds f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bne 0x8257abbc
	if (ctx.r10.s32 != 0) goto loc_8257ABBC;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x82436664
	__restfpr_28(ctx, base);
	// b 0x8242f8e4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_ABE8_wrh"))) PPC_WEAK_FUNC(phBoundCapsule_ABE8_wrh);
PPC_FUNC_IMPL(__imp__phBoundCapsule_ABE8_wrh) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r31 = 0;
	double var_f31 = 0.0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f890
	ctx.lr = 0x8257ABF0;
	__savegprlr_26(ctx, base);
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// addi r30,r8,2056
	var_r30 = (uint32_t)(ctx.r8.s64 + 2056);  // __imp_XAudioGetVoiceCategoryVolume @ 0x82000808
	// fmr f13,f2
	ctx.f13.f64 = ctx.f2.f64;
	// addi r29,r8,2316
	var_r29 = (uint32_t)(ctx.r8.s64 + 2316);  // __imp_ObLookupThreadByThreadId @ 0x8200090c
	// cmpwi cr6,r6,0
	// lfs f0,252(r30)
	temp.u32 = PPC_LOAD_U32(var_r30 + 252);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,256(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r30 + 256, temp.u32);
	// lfs f0,252(r29)
	temp.u32 = PPC_LOAD_U32(var_r29 + 252);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,256(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(var_r29 + 256, temp.u32);
	// ble cr6,0x8257ad18
	if (ctx.r6.s32 > 0) {
		// lis r27,-32255
		var_r27 = (uint32_t)(-2113863680);
		// lwz r8,84(r1)
		ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
		// lis r28,-32254
		var_r28 = (uint32_t)(-2113798144);
		// lis r3,-32254
		// lis r4,-32254
		// lis r5,-32254
		// lis r11,-32256
		// lfs f10,-32044(r27)
		temp.u32 = PPC_LOAD_U32(var_r27 + -32044);
		ctx.f10.f64 = double(temp.f32);
		// lfs f6,29232(r28)
		temp.u32 = PPC_LOAD_U32(var_r28 + 29232);
		ctx.f6.f64 = double(temp.f32);
		// subf r26,r8,r9
		var_r26 = (uint32_t)(ctx.r9.s64 - ctx.r8.s64);
		// lfs f7,29236(r3)
		temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 29236);
		ctx.f7.f64 = double(temp.f32);
		// mr r31,r6
		var_r31 = ctx.r6.u32;
		// lfs f8,29240(r4)
		temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 29240);
		ctx.f8.f64 = double(temp.f32);
		// lfs f9,29244(r5)
		temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 29244);
		ctx.f9.f64 = double(temp.f32);
		// lfs f5,27332(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27332);
		ctx.f5.f64 = double(temp.f32);
	loc_8257AC54:
		// fcmpu cr6,f13,f5
		ctx.fpscr.disableFlushMode();
		// ble cr6,0x8257ac68
		if (ctx.f13.f64 > ctx.f5.f64) {
			// fnmsubs f0,f13,f9,f8
			ctx.f0.f64 = double(float(-(ctx.f13.f64 * ctx.f9.f64 - ctx.f8.f64)));
			// fmadds f0,f0,f13,f7
			ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64 + ctx.f7.f64));
			// b 0x8257ac6c
		} else {
		loc_8257AC68:
			// fmuls f0,f13,f6
			ctx.fpscr.disableFlushMode();
			ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f6.f64));
		}
	loc_8257AC6C:
		// fmuls f0,f0,f10
		ctx.fpscr.disableFlushMode();
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
		// addi r11,r1,-80
		ctx.r11.s64 = ctx.r1.s64 + -80;
		// lwz r3,92(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
		// addic. r31,r31,-1
		ctx.xer.ca = var_r31 > 0;
		var_r31 = (uint32_t)(var_r31 + -1);
		ctx.cr0.compare<int32_t>((int32_t)var_r31, 0, ctx.xer);
		// fadds f13,f13,f2
		ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f2.f64));
		// fctiwz f12,f0
		ctx.f12.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
		// stfiwx f12,0,r11
		PPC_STORE_U32(ctx.r11.u32, ctx.f12.u32);
		// lwz r5,-80(r1)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + -80);
		// rlwinm r11,r5,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
		// extsw r5,r5
		ctx.r5.s64 = ctx.r5.s32;
		// add r4,r11,r30
		ctx.r4.u64 = ctx.r11.u64 + var_r30;
		// add r3,r11,r3
		ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
		// std r5,-72(r1)
		PPC_STORE_U64(ctx.r1.u32 + -72, ctx.r5.u64);
		// add r5,r11,r10
		ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
		// lfs f11,0(r4)
		temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// add r11,r11,r29
		ctx.r11.u64 = ctx.r11.u64 + var_r29;
		// lfs f31,4(r4)
		temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
		var_f31 = double(temp.f32);
		// fsubs f31,f31,f11
		var_f31 = double(float(var_f31 - ctx.f11.f64));
		// lfs f3,4(r5)
		temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
		ctx.f3.f64 = double(temp.f32);
		// lfd f12,-72(r1)
		ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
		// fcfid f12,f12
		ctx.f12.f64 = double(ctx.f12.s64);
		// frsp f12,f12
		ctx.f12.f64 = double(float(ctx.f12.f64));
		// fsubs f0,f0,f12
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
		// lfs f12,0(r5)
		temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
		ctx.f12.f64 = double(temp.f32);
		// fsubs f3,f3,f12
		ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f12.f64));
		// fmadds f11,f31,f0,f11
		ctx.f11.f64 = double(float(var_f31 * ctx.f0.f64 + ctx.f11.f64));
		// fmadds f12,f3,f0,f12
		ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f12.f64));
		// fsubs f11,f11,f12
		ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
		// fmadds f12,f11,f4,f12
		ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f4.f64 + ctx.f12.f64));
		// stfsx f12,r26,r8
		temp.f32 = float(ctx.f12.f64);
		PPC_STORE_U32(var_r26 + ctx.r8.u32, temp.u32);
		// lfs f12,0(r3)
		temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0)/* phBoundCapsule::vtable@+0x0 */;
		ctx.f12.f64 = double(temp.f32);
		// lfs f3,4(r3)
		temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4)/* phBoundCapsule::flags@+0x4 */;
		ctx.f3.f64 = double(temp.f32);
		// lfs f11,0(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// fsubs f3,f3,f12
		ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f12.f64));
		// lfs f31,4(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
		var_f31 = double(temp.f32);
		// fsubs f31,f31,f11
		var_f31 = double(float(var_f31 - ctx.f11.f64));
		// fmadds f12,f3,f0,f12
		ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f0.f64 + ctx.f12.f64));
		// fmadds f0,f31,f0,f11
		ctx.f0.f64 = double(float(var_f31 * ctx.f0.f64 + ctx.f11.f64));
		// fsubs f0,f0,f12
		ctx.f0.f64 = double(float(ctx.f0.f64 - ctx.f12.f64));
		// fmadds f0,f0,f4,f12
		ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f4.f64 + ctx.f12.f64));
		// stfs f0,0(r8)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
		// addi r8,r8,4
		ctx.r8.s64 = ctx.r8.s64 + 4;
		// bne 0x8257ac54
		if (!ctx.cr0.eq) goto loc_8257AC54;
	}
loc_8257AD18:
	// cmpw cr6,r7,r6
	// bge cr6,0x8257ad44
	if (ctx.r7.s32 < ctx.r6.s32) {
		// rlwinm r11,r7,2,0,29
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
		// subf r10,r7,r6
		ctx.r10.s64 = ctx.r6.s64 - ctx.r7.s64;
		// add r11,r11,r9
		ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	loc_8257AD2C:
		// lfs f0,0(r11)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
		ctx.f0.f64 = double(temp.f32);
		// addic. r10,r10,-1
		ctx.xer.ca = ctx.r10.u32 > 0;
		ctx.r10.s64 = ctx.r10.s64 + -1;
		// fadds f0,f0,f1
		ctx.f0.f64 = double(float(ctx.f0.f64 + ctx.f1.f64));
		// stfs f0,0(r11)
		temp.f32 = float(ctx.f0.f64);
		PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		// addi r11,r11,4
		ctx.r11.s64 = ctx.r11.s64 + 4;
		// bne 0x8257ad2c
		if (ctx.r10.s32 != 0) goto loc_8257AD2C;
	}
loc_8257AD44:
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8242f8e0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_AD50_2hr"))) PPC_WEAK_FUNC(phBoundCapsule_AD50_2hr);
PPC_FUNC_IMPL(__imp__phBoundCapsule_AD50_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8242f898
	ctx.lr = 0x8257AD58;
	__savegprlr_28(ctx, base);
	// lis r11,-32248
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r10,r1,-48
	ctx.r10.s64 = ctx.r1.s64 + -48;
	// lis r5,4096
	ctx.r5.s64 = 268435456;
	// li r31,16384
	var_r31 = 16384;
	// li r9,0
	ctx.r9.s64 = 0;
	// lfs f0,-24420(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24420);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	// fmuls f10,f1,f0
	ctx.f10.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f0,-25388(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -25388);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32254
	// fmuls f0,f1,f0
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// lfs f13,25816(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 25816);
	ctx.f13.f64 = double(temp.f32);
	// fctiwz f10,f10
	ctx.f10.s64 = (ctx.f10.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f10.f64));
	// stfiwx f10,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f10.u32);
	// addi r10,r1,-48
	ctx.r10.s64 = ctx.r1.s64 + -48;
	// lwz r30,-48(r1)
	var_r30 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + -48));
	// fmr f12,f13
	ctx.f12.f64 = ctx.f13.f64;
	// mullw r11,r8,r30
	ctx.r11.s64 = int64_t(ctx.r8.s32) * int64_t((int32_t)var_r30);
	// fmr f11,f13
	ctx.f11.f64 = ctx.f13.f64;
	// fctiwz f0,f0
	ctx.f0.s64 = (ctx.f0.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f0.u32);
	// lwz r10,-48(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	// cmpwi cr6,r11,16384
	// divw r28,r5,r10
	var_r28 = (uint32_t)(int32_t)(ctx.r10.s32 ? ctx.r5.s32 / ctx.r10.s32 : 0);
	// twllei r10,0
	if (ctx.r10.s32 == 0 || ctx.r10.u32 < 0u) __builtin_trap();
	// bge cr6,0x8257ade0
	if (ctx.r11.s32 < 16384) {
		// mr r10,r4
		ctx.r10.u64 = ctx.r4.u64;
	loc_8257ADC8:
		// addi r10,r10,4
		ctx.r10.s64 = ctx.r10.s64 + 4;
		// addi r9,r9,1
		ctx.r9.s64 = ctx.r9.s64 + 1;
		// lwz r11,0(r10)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
		// mullw r11,r11,r30
		ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t((int32_t)var_r30);
		// cmpwi cr6,r11,16384
		// blt cr6,0x8257adc8
		if (ctx.r11.s32 < 16384) goto loc_8257ADC8;
	}
loc_8257ADE0:
	// addi r10,r28,2048
	ctx.r10.s64 = (int64_t)(int32_t)var_r28 + 2048;
	// srawi r5,r10,12
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0xFFF) != 0);
	ctx.r5.s64 = ctx.r10.s32 >> 12;
	// cmpw cr6,r5,r7
	// bge cr6,0x8257ae90
	if (ctx.r5.s32 < ctx.r7.s32) {
		// mr r3,r10
		ctx.r3.u64 = ctx.r10.u64;
		// lis r8,-32256
		// lis r10,-32164
		// lfs f10,15788(r8)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 15788);
		ctx.f10.f64 = double(temp.f32);
		// lwz r29,10080(r10)
		var_r29 = (uint32_t)(PPC_LOAD_U32(ctx.r10.u32 + 10080));
	loc_8257AE04:
		// addis r31,r31,1
		var_r31 = (uint32_t)(var_r31 + 65536);
		// stfs f13,-48(r1)
		ctx.fpscr.disableFlushMode();
		temp.f32 = float(ctx.f13.f64);
		PPC_STORE_U32(ctx.r1.u32 + -48, temp.u32);
		// addi r31,r31,-32768
		var_r31 = (uint32_t)(var_r31 + -32768);
		// cmpw cr6,r11,r31
		// bge cr6,0x8257ae6c
		if (ctx.r11.s32 < (int32_t)var_r31) {
			// rlwinm r10,r9,2,0,29
			ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
			// lwzx r10,r10,r4
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
		loc_8257AE20:
			// srawi r11,r11,7
			ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x7F) != 0);
			ctx.r11.s64 = ctx.r11.s32 >> 7;
			// rlwinm r10,r10,2,0,29
			ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
			// rlwinm r11,r11,2,22,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0x3FC;
			// lfsx f0,r10,r6
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
			ctx.f0.f64 = double(temp.f32);
			// lwz r10,-48(r1)
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -48);
			// lfsx f9,r11,r29
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + var_r29);
			ctx.f9.f64 = double(temp.f32);
			// fadds f9,f9,f10
			ctx.f9.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
			// fmuls f0,f9,f0
			ctx.f0.f64 = double(float(ctx.f9.f64 * ctx.f0.f64));
			// stfs f0,-44(r1)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r1.u32 + -44, temp.u32);
			// lwz r11,-44(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -44);
			// cmpw cr6,r11,r10
			// ble cr6,0x8257ae54
			if (ctx.r11.s32 > ctx.r10.s32) {
				// stw r11,-48(r1)
				PPC_STORE_U32(ctx.r1.u32 + -48, ctx.r11.u32);
			}
		loc_8257AE54:
			// addi r9,r9,1
			ctx.r9.s64 = ctx.r9.s64 + 1;
			// rlwinm r11,r9,2,0,29
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
			// lwzx r10,r11,r4
			ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
			// mullw r11,r10,r30
			ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t((int32_t)var_r30);
			// cmpw cr6,r11,r31
			// blt cr6,0x8257ae20
			if (ctx.r11.s32 < (int32_t)var_r31) goto loc_8257AE20;
		}
	loc_8257AE6C:
		// rlwinm r10,r5,2,0,29
		ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
		// lfs f9,-48(r1)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -48);
		ctx.f9.f64 = double(temp.f32);
		// add r3,r3,r28
		ctx.r3.u64 = ctx.r3.u64 + var_r28;
		// srawi r5,r3,12
		ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFFF) != 0);
		ctx.r5.s64 = ctx.r3.s32 >> 12;
		// lfsx f0,r10,r6
		temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
		ctx.f0.f64 = double(temp.f32);
		// cmpw cr6,r5,r7
		// fmadds f12,f0,f9,f12
		ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f9.f64 + ctx.f12.f64));
		// fmadds f11,f0,f0,f11
		ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f0.f64 + ctx.f11.f64));
		// blt cr6,0x8257ae04
		if (ctx.r5.s32 < ctx.r7.s32) goto loc_8257AE04;
	}
loc_8257AE90:
	// lis r11,-32256
	ctx.r11.s64 = -2113929216;
	// lfs f0,27200(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 27200);  /* glob:lbl_82006A40 @ 0x82006a40 */
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32248
	ctx.r11.s64 = -2113404928;
	// lfs f13,-24968(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -24968);  /* glob:lbl_82079E78 @ 0x82079e78 */
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmsubs f0,f12,f0,f13
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f0.f64 - ctx.f13.f64));
	// fmuls f1,f0,f2
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// b 0x8242f8e8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__phBoundCapsule_AEB0_2h"))) PPC_WEAK_FUNC(phBoundCapsule_AEB0_2h);
PPC_FUNC_IMPL(__imp__phBoundCapsule_AEB0_2h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, var_r31);
	// fcmpu cr6,f2,f3
	ctx.fpscr.disableFlushMode();
	// bgt cr6,0x8257af54
	if (ctx.f2.f64 <= ctx.f3.f64) {
		// bso cr6,0x8257af54
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257AEBC, "bso");
		// lis r9,-32256
		// lis r11,-32254
		// lis r4,-32164
		// lfs f12,27200(r9)
		temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27200);
		ctx.f12.f64 = double(temp.f32);
		// lfs f13,29248(r11)
		temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 29248);  /* glob:0x82087240 */
		ctx.f13.f64 = double(temp.f32);
	loc_8257AED4:
		// fmadds f11,f2,f13,f12
		ctx.fpscr.disableFlushMode();
		ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f13.f64 + ctx.f12.f64));
		// addi r11,r1,-16
		ctx.r11.s64 = ctx.r1.s64 + -16;
		// cmpwi cr6,r7,0
		// fmr f0,f4
		ctx.f0.f64 = ctx.f4.f64;
		// fctiwz f11,f11
		ctx.f11.s64 = (ctx.f11.f64 > double(INT_MAX)) ? INT_MAX : simde_mm_cvttsd_si32(simde_mm_load_sd(&ctx.f11.f64));
		// stfiwx f11,0,r11
		PPC_STORE_U32(ctx.r11.u32, ctx.f11.u32);
		// ble cr6,0x8257af2c
		if (ctx.r7.s32 > 0) {
			// mr r11,r8
			ctx.r11.u64 = ctx.r8.u64;
			// subf r5,r8,r10
			ctx.r5.s64 = ctx.r10.s64 - ctx.r8.s64;
			// mr r9,r7
			ctx.r9.u64 = ctx.r7.u64;
		loc_8257AEFC:
			// lwzx r3,r5,r11
			ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r11.u32);
			// lfs f11,0(r11)
			ctx.fpscr.disableFlushMode();
			temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
			ctx.f11.f64 = double(temp.f32);
			// lwz r31,-16(r1)
			var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r1.u32 + -16));
			// addic. r9,r9,-1
			ctx.xer.ca = ctx.r9.u32 > 0;
			ctx.r9.s64 = ctx.r9.s64 + -1;
			// addi r11,r11,4
			ctx.r11.s64 = ctx.r11.s64 + 4;
			// mullw r3,r3,r31
			ctx.r3.s64 = int64_t(ctx.r3.s32) * int64_t((int32_t)var_r31);
			// lwz r31,10080(r4)
			var_r31 = (uint32_t)(PPC_LOAD_U32(ctx.r4.u32 + 10080));
			// addis r3,r3,128
			ctx.r3.s64 = ctx.r3.s64 + 8388608;
			// rlwinm r3,r3,10,22,29
			ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 10) & 0x3FC;
			// lfsx f10,r3,r31
			temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + var_r31);
			ctx.f10.f64 = double(temp.f32);
			// fmadds f0,f10,f11,f0
			ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 + ctx.f0.f64));
			// bne 0x8257aefc
			if (ctx.r9.s32 != 0) goto loc_8257AEFC;
		}
	loc_8257AF2C:
		// lfs f11,0(r6)
		ctx.fpscr.disableFlushMode();
		temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		ctx.f11.f64 = double(temp.f32);
		// fcmpu cr6,f0,f11
		// ble cr6,0x8257af44
		if (ctx.f0.f64 > ctx.f11.f64) {
			// lwz r11,84(r1)
			ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
			// stfs f0,0(r6)
			temp.f32 = float(ctx.f0.f64);
			PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
			// stfs f2,0(r11)
			temp.f32 = float(ctx.f2.f64);
			PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
		}
	loc_8257AF44:
		// fadds f2,f1,f2
		ctx.fpscr.disableFlushMode();
		ctx.f2.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
		// fcmpu cr6,f2,f3
		// bso cr6,0x8257af54
		// UNIMPLEMENTED: bso
		PPC_UNIMPLEMENTED(0x8257AF4C, "bso");
		// ble cr6,0x8257aed4
		if (ctx.f2.f64 <= ctx.f3.f64) goto loc_8257AED4;
	}
loc_8257AF54:
	// ld r31,-8(r1)
	var_r31 = (uint32_t)(PPC_LOAD_U64(ctx.r1.u32 + -8));
	// blr
	return;
}

__attribute__((alias("__imp__fiAsciiTokenizer_AF60_fw"))) PPC_WEAK_FUNC(fiAsciiTokenizer_AF60_fw);
PPC_FUNC_IMPL(__imp__fiAsciiTokenizer_AF60_fw) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// cmplwi cr6,r31,0
	// beq cr6,0x8257b008
	if (var_r31 != 0) {
		// cmpwi cr6,r31,-1
		// beq cr6,0x8257b008
		if ((int32_t)var_r31 == -1) goto loc_8257B008;
		// lis r11,-32161
		ctx.r11.s64 = -2107703296;
		// addi r30,r11,-21728
		var_r30 = (uint32_t)(ctx.r11.s64 + -21728);  // lbl_825EAB20 @ 0x825eab20
		// lwz r11,0(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 0)/* fiAsciiTokenizer::vtable@+0x0 */;
		// cmplwi cr6,r11,0
		// beq cr6,0x8257afc4
		if (ctx.r11.u32 != 0) {
			// addi r3,r31,64
			ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 64;
			// rotlwi r11,r11,0
			ctx.r11.u64 = ctx.r11.u32;
			// bctrl
			PPC_CALL_INDIRECT_FUNC(ctx.r11.u32);
			// cmplwi cr6,r3,0
			// beq cr6,0x8257afc4
			if (ctx.r3.u32 == 0) goto loc_8257AFC4;
			// cmpwi cr6,r3,-1
			// beq cr6,0x8257b008
			if (ctx.r3.s32 == -1) goto loc_8257B008;
			// li r10,3
			ctx.r10.s64 = 3;
			// b 0x8257afd8
		} else {
		loc_8257AFC4:
			// addi r3,r31,64
			ctx.r3.s64 = (int64_t)(int32_t)var_r31 + 64;
			// bl 0x82433370
			fiAsciiTokenizer_3370_g(ctx, base);
			// cmplwi cr6,r3,0
			// beq cr6,0x8257b008
			if (ctx.r3.u32 == 0) goto loc_8257B008;
			// li r10,0
			ctx.r10.s64 = 0;
		}
	loc_8257AFD8:
		// clrlwi r9,r3,27
		ctx.r9.u64 = ctx.r3.u32 & 0x1F;
		// clrlwi r7,r10,24
		ctx.r7.u64 = ctx.r10.u32 & 0xFF;
		// subfic r8,r9,64
		ctx.xer.ca = ctx.r9.u32 <= 64;
		ctx.r8.s64 = 64 - ctx.r9.s64;
		// cmplwi cr6,r7,3
		// clrlwi r11,r8,24
		ctx.r11.u64 = ctx.r8.u32 & 0xFF;
		// add r3,r11,r3
		ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
		// stb r11,-1(r3)
		PPC_STORE_U8(ctx.r3.u32 + -1, ctx.r11.u8);
		// stb r10,-2(r3)
		PPC_STORE_U8(ctx.r3.u32 + -2, ctx.r10.u8);
		// bne cr6,0x8257b00c
		if (ctx.r7.u32 != 3) {
			// blr
			return;
		}
		// lwz r11,4(r30)
		ctx.r11.u64 = PPC_LOAD_U32(var_r30 + 4)/* fiAsciiTokenizer::flags@+0x4 */;
		// stw r11,-8(r3)
		PPC_STORE_U32(ctx.r3.u32 + -8, ctx.r11.u32);
		// b 0x8257b00c
	} else {
	loc_8257B008:
		// li r3,0
		ctx.r3.s64 = 0;
	}
loc_8257B00C:
	// blr
	return;
}

__attribute__((alias("__imp__xam_B028_sp"))) PPC_WEAK_FUNC(xam_B028_sp);
PPC_FUNC_IMPL(__imp__xam_B028_sp) {
	PPC_FUNC_PROLOGUE();
	// cmplwi cr6,r3,0
	// beqlr cr6
	if (ctx.r3.u32 == 0) return;
	// lbz r11,-2(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + -2);
	// cmplwi cr6,r11,3
	// bne cr6,0x8257b050
	if (ctx.r11.u32 == 3) {
		// lbz r10,-1(r3)
		ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + -1);
		// lwz r9,-8(r3)
		ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + -8);
		// subf r3,r10,r3
		ctx.r3.s64 = ctx.r3.s64 - ctx.r10.s64;
		// mtctr r9
		ctx.ctr.u64 = ctx.r9.u64;
		// bctr
		PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
		return;
	}
loc_8257B050:
	// lbz r8,-1(r3)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r3.u32 + -1);
	// subf r3,r8,r3
	ctx.r3.s64 = ctx.r3.s64 - ctx.r8.s64;
	// b 0x82433310
	fiAsciiTokenizer_3310_g(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8257B05C"))) PPC_WEAK_FUNC(sub_8257B05C);
PPC_FUNC_IMPL(__imp__sub_8257B05C) {
	PPC_FUNC_PROLOGUE();
	// blr
	return;
}

__attribute__((alias("__imp__xam_B060_w"))) PPC_WEAK_FUNC(xam_B060_w);
PPC_FUNC_IMPL(__imp__xam_B060_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	PPCRegister temp{};
	// FRAME: size=112, manual
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r4,11
	ctx.r4.s64 = 720896;
	// li r7,8
	ctx.r7.s64 = 8;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// ori r4,r4,8
	ctx.r4.u64 = ctx.r4.u64 | 8;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// li r3,251
	ctx.r3.s64 = 251;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// mr r31,r5
	var_r31 = ctx.r5.u32;
	// bl 0x825860ec
	__imp__XMsgStartIORequest(ctx, base);
	// cmpwi r3,0
	// bge 0x8257b0ac
	if (ctx.r3.s32 < 0) {
		// li r3,1627
		ctx.r3.s64 = 1627;
		// b 0x8257b0cc
	} else {
	loc_8257B0AC:
		// cmplwi cr6,r31,0
		// bne cr6,0x8257b0c8
		if (var_r31 == 0) {
			// bl 0x8242c368
			xam_C368(ctx, base);
			// subfic r11,r3,0
			ctx.xer.ca = ctx.r3.u32 <= 0;
			ctx.r11.s64 = 0 - ctx.r3.s64;
			// subfe r11,r11,r11
			temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
			ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
			ctx.xer.ca = temp.u8;
			// andi. r3,r11,1627
			ctx.r3.u64 = ctx.r11.u64 & 1627;
			ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
			// b 0x8257b0cc
		} else {
		loc_8257B0C8:
			// li r3,997
			ctx.r3.s64 = 997;
		}
	}
loc_8257B0CC:
	// blr
	return;
}

__attribute__((alias("__imp__xam_B0E0_g"))) PPC_WEAK_FUNC(xam_B0E0_g);
PPC_FUNC_IMPL(__imp__xam_B0E0_g) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=112, manual
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// lis r4,11
	ctx.r4.s64 = 720896;
	// li r7,24
	ctx.r7.s64 = 24;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// ori r4,r4,6
	ctx.r4.u64 = ctx.r4.u64 | 6;
	// li r3,251
	ctx.r3.s64 = 251;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// bl 0x825860ec
	__imp__XMsgStartIORequest(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__game_B138_h"))) PPC_WEAK_FUNC(game_B138_h);
PPC_FUNC_IMPL(__imp__game_B138_h) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=128, manual
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// lis r4,11
	ctx.r4.s64 = 720896;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r7,32
	ctx.r7.s64 = 32;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r8,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r8.u32);
	// ori r4,r4,7
	ctx.r4.u64 = ctx.r4.u64 | 7;
	// li r3,251
	ctx.r3.s64 = 251;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// bl 0x825860ec
	__imp__XMsgStartIORequest(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__thunk_XamUserGetName"))) PPC_WEAK_FUNC(thunk_XamUserGetName);
PPC_FUNC_IMPL(__imp__thunk_XamUserGetName) {
	PPC_FUNC_PROLOGUE();
	// b 0x8258682c
	__imp__XamUserGetName(ctx, base);
	return;
}

__attribute__((alias("__imp__thunk_XamUserGetSigninState"))) PPC_WEAK_FUNC(thunk_XamUserGetSigninState);
PPC_FUNC_IMPL(__imp__thunk_XamUserGetSigninState) {
	PPC_FUNC_PROLOGUE();
	// b 0x825867cc
	__imp__XamUserGetSigninState(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_B1A8"))) PPC_WEAK_FUNC(xam_B1A8);
PPC_FUNC_IMPL(__imp__xam_B1A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r30,r3
	var_r30 = ctx.r3.u32;
	// mr r28,r4
	var_r28 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// bl 0x825860cc
	__imp__XamGetSystemVersion(ctx, base);
	// lis r11,8201
	ctx.r11.s64 = 537460736;
	// ori r11,r11,27392
	ctx.r11.u64 = ctx.r11.u64 | 27392;
	// cmplw cr6,r3,r11
	// bge cr6,0x8257b220
	if (ctx.r3.u32 < ctx.r11.u32) {
		// cmplwi cr6,r30,255
		// bne cr6,0x8257b210
		if (var_r30 == 255) {
			// li r31,0
			var_r31 = 0;
		loc_8257B1E0:
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bl 0x825867cc
			__imp__XamUserGetSigninState(ctx, base);
			// cmpwi cr6,r3,1
			// beq cr6,0x8257b200
			if (ctx.r3.s32 == 1) {
				// li r11,0
				ctx.r11.s64 = 0;
				// li r3,1245
				ctx.r3.s64 = 1245;
				// stw r11,0(r29)
				PPC_STORE_U32(var_r29 + 0, ctx.r11.u32);
				// b 0x8257b230
				return;
			}
			// addi r31,r31,1
			var_r31 = (uint32_t)(var_r31 + 1);
			// cmplwi cr6,r31,4
			// blt cr6,0x8257b1e0
			if (var_r31 < 4) goto loc_8257B1E0;
			// b 0x8257b220
			goto loc_8257B220;
		loc_8257B200:
			// li r11,0
			ctx.r11.s64 = 0;
			// li r3,1245
			ctx.r3.s64 = 1245;
			// stw r11,0(r29)
			PPC_STORE_U32(var_r29 + 0, ctx.r11.u32);
			// b 0x8257b230
			return;
		}
	loc_8257B210:
		// mr r3,r30
		ctx.r3.u64 = var_r30;
		// bl 0x825867cc
		__imp__XamUserGetSigninState(ctx, base);
		// cmpwi cr6,r3,1
		// beq cr6,0x8257b200
		if (ctx.r3.s32 == 1) {
			// li r11,0
			ctx.r11.s64 = 0;
			// li r3,1245
			ctx.r3.s64 = 1245;
			// stw r11,0(r29)
			PPC_STORE_U32(var_r29 + 0, ctx.r11.u32);
			// b 0x8257b230
			return;
		}
	}
loc_8257B220:
	// mr r5,r29
	ctx.r5.u64 = var_r29;
	// mr r4,r28
	ctx.r4.u64 = var_r28;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bl 0x825867ac
	__imp__XamUserCheckPrivilege(ctx, base);
loc_8257B230:
	return;
}

__attribute__((alias("__imp__xam_B238_h"))) PPC_WEAK_FUNC(xam_B238_h);
PPC_FUNC_IMPL(__imp__xam_B238_h) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	PPCRegister temp{};
	// FRAME: size=176, savegprlr_26
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// mr r28,r10
	var_r28 = ctx.r10.u32;
	// mulli r10,r31,52
	ctx.r10.s64 = static_cast<int64_t>(var_r31 * static_cast<uint64_t>(52));
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// mr r27,r3
	var_r27 = ctx.r3.u32;
	// mullw r10,r10,r11
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// mr r26,r5
	var_r26 = ctx.r5.u32;
	// mr r30,r7
	var_r30 = ctx.r7.u32;
	// cmplwi cr6,r11,0
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// beq cr6,0x8257b298
	if (ctx.r11.u32 != 0) {
		// addi r6,r30,4
		ctx.r6.s64 = (int64_t)(int32_t)var_r30 + 4;
		// mr r7,r11
		ctx.r7.u64 = ctx.r11.u64;
	loc_8257B27C:
		// lwz r5,0(r6)
		ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
		// addic. r7,r7,-1
		ctx.xer.ca = ctx.r7.u32 > 0;
		ctx.r7.s64 = ctx.r7.s64 + -1;
		// addi r6,r6,136
		ctx.r6.s64 = ctx.r6.s64 + 136;
		// mullw r5,r5,r31
		ctx.r5.s64 = int64_t(ctx.r5.s32) * int64_t((int32_t)var_r31);
		// mulli r5,r5,28
		ctx.r5.s64 = static_cast<int64_t>(ctx.r5.u64 * static_cast<uint64_t>(28));
		// add r10,r5,r10
		ctx.r10.u64 = ctx.r5.u64 + ctx.r10.u64;
		// bne 0x8257b27c
		if (ctx.r7.s32 != 0) goto loc_8257B27C;
	}
loc_8257B298:
	// lwz r29,0(r8)
	var_r29 = (uint32_t)(PPC_LOAD_U32(ctx.r8.u32 + 0));
	// cmplw cr6,r10,r29
	// ble cr6,0x8257b2b0
	if (ctx.r10.u32 > var_r29) {
		// li r3,122
		ctx.r3.s64 = 122;
		// stw r10,0(r8)
		PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
		// b 0x8257b318
	} else {
	loc_8257B2B0:
		// lis r4,11
		ctx.r4.s64 = 720896;
		// stw r27,80(r1)
		PPC_STORE_U32(ctx.r1.u32 + 80, var_r27);
		// li r7,28
		ctx.r7.s64 = 28;
		// stw r31,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, var_r31);
		// addi r6,r1,80
		ctx.r6.s64 = ctx.r1.s64 + 80;
		// stw r26,88(r1)
		PPC_STORE_U32(ctx.r1.u32 + 88, var_r26);
		// mr r5,r28
		ctx.r5.u64 = var_r28;
		// stw r11,92(r1)
		PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
		// ori r4,r4,33
		ctx.r4.u64 = ctx.r4.u64 | 33;
		// stw r30,96(r1)
		PPC_STORE_U32(ctx.r1.u32 + 96, var_r30);
		// li r3,251
		ctx.r3.s64 = 251;
		// stw r29,100(r1)
		PPC_STORE_U32(ctx.r1.u32 + 100, var_r29);
		// stw r9,104(r1)
		PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
		// bl 0x825860ec
		__imp__XMsgStartIORequest(ctx, base);
		// cmpwi r3,0
		// bge 0x8257b2f8
		if (ctx.r3.s32 < 0) {
			// li r3,1627
			ctx.r3.s64 = 1627;
			// b 0x8257b318
		} else {
		loc_8257B2F8:
			// cmplwi cr6,r28,0
			// bne cr6,0x8257b314
			if (var_r28 == 0) {
				// bl 0x8242c368
				xam_C368(ctx, base);
				// subfic r11,r3,0
				ctx.xer.ca = ctx.r3.u32 <= 0;
				ctx.r11.s64 = 0 - ctx.r3.s64;
				// subfe r11,r11,r11
				temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
				ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
				ctx.xer.ca = temp.u8;
				// andi. r3,r11,1627
				ctx.r3.u64 = ctx.r11.u64 & 1627;
				ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
				// b 0x8257b318
			} else {
			loc_8257B314:
				// li r3,997
				ctx.r3.s64 = 997;
			}
		}
	}
loc_8257B318:
	return;
}

__attribute__((alias("__imp__xam_B320"))) PPC_WEAK_FUNC(xam_B320);
PPC_FUNC_IMPL(__imp__xam_B320) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	// FRAME: size=144, savegprlr_25
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r27,r7
	var_r27 = ctx.r7.u32;
	// mr r26,r8
	var_r26 = ctx.r8.u32;
	// mr r25,r9
	var_r25 = ctx.r9.u32;
	// bl 0x8257b738
	xam_B738(ctx, base);
	// cmplwi r3,0
	// bne 0x8257b378
	if (ctx.r3.u32 == 0) {
		// mr r10,r25
		ctx.r10.u64 = var_r25;
		// mr r9,r26
		ctx.r9.u64 = var_r26;
		// mr r8,r27
		ctx.r8.u64 = var_r27;
		// mr r7,r28
		ctx.r7.u64 = var_r28;
		// mr r6,r29
		ctx.r6.u64 = var_r29;
		// clrldi r5,r30,32
		ctx.r5.u64 = var_r30 & 0xFFFFFFFF;
		// li r4,1
		ctx.r4.s64 = 1;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8258683c
		__imp__XamUserCreateStatsEnumerator(ctx, base);
	}
loc_8257B378:
	return;
}

__attribute__((alias("__imp__xam_B380"))) PPC_WEAK_FUNC(xam_B380);
PPC_FUNC_IMPL(__imp__xam_B380) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	// FRAME: size=144, savegprlr_25
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r27,r7
	var_r27 = ctx.r7.u32;
	// mr r26,r8
	var_r26 = ctx.r8.u32;
	// mr r25,r9
	var_r25 = ctx.r9.u32;
	// bl 0x8257b738
	xam_B738(ctx, base);
	// cmplwi r3,0
	// bne 0x8257b3d8
	if (ctx.r3.u32 == 0) {
		// mr r10,r25
		ctx.r10.u64 = var_r25;
		// mr r9,r26
		ctx.r9.u64 = var_r26;
		// mr r8,r27
		ctx.r8.u64 = var_r27;
		// mr r7,r28
		ctx.r7.u64 = var_r28;
		// mr r6,r29
		ctx.r6.u64 = var_r29;
		// mr r5,r30
		ctx.r5.u64 = var_r30;
		// li r4,0
		ctx.r4.s64 = 0;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x8258683c
		__imp__XamUserCreateStatsEnumerator(ctx, base);
	}
loc_8257B3D8:
	return;
}

__attribute__((alias("__imp__game_B3E0_h"))) PPC_WEAK_FUNC(game_B3E0_h);
PPC_FUNC_IMPL(__imp__game_B3E0_h) {
	PPC_FUNC_PROLOGUE();
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// oris r6,r4,1
	ctx.r6.u64 = ctx.r4.u64 | 65536;
	// oris r5,r4,2
	ctx.r5.u64 = ctx.r4.u64 | 131072;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8258684c
	__imp__XamWriteGamerTile(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_B3F8"))) PPC_WEAK_FUNC(xam_B3F8);
PPC_FUNC_IMPL(__imp__xam_B3F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	// FRAME: size=160, savegprlr_24
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r29,r4
	var_r29 = ctx.r4.u32;
	// mr r30,r5
	var_r30 = ctx.r5.u32;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r27,r7
	var_r27 = ctx.r7.u32;
	// mr r26,r8
	var_r26 = ctx.r8.u32;
	// mr r25,r9
	var_r25 = ctx.r9.u32;
	// mr r24,r10
	var_r24 = ctx.r10.u32;
	// bl 0x8257b738
	xam_B738(ctx, base);
	// cmplwi r3,0
	// bne 0x8257b478
	if (ctx.r3.u32 == 0) {
		// rldicl r11,r30,16,48
		ctx.r11.u64 = __builtin_rotateleft64(var_r30, 16) & 0xFFFF;
		// rotlwi r11,r11,0
		ctx.r11.u64 = ctx.r11.u32;
		// clrlwi r10,r11,28
		ctx.r10.u64 = ctx.r11.u32 & 0xF;
		// cmplwi cr6,r10,9
		// bne cr6,0x8257b454
		if (ctx.r10.u32 == 9) {
			// rlwinm. r11,r11,0,24,25
			ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC0;
			// beq 0x8257b454
			if (ctx.r11.s32 == 0) goto loc_8257B454;
			// li r3,87
			ctx.r3.s64 = 87;
			// b 0x8257b478
		} else {
		loc_8257B454:
			// mr r10,r24
			ctx.r10.u64 = var_r24;
			// mr r9,r25
			ctx.r9.u64 = var_r25;
			// mr r8,r26
			ctx.r8.u64 = var_r26;
			// mr r7,r27
			ctx.r7.u64 = var_r27;
			// mr r6,r28
			ctx.r6.u64 = var_r28;
			// mr r5,r30
			ctx.r5.u64 = var_r30;
			// mr r4,r29
			ctx.r4.u64 = var_r29;
			// mr r3,r31
			ctx.r3.u64 = var_r31;
			// bl 0x8258685c
			__imp__XamUserCreateAchievementEnumerator(ctx, base);
		}
	}
loc_8257B478:
	return;
}

__attribute__((alias("__imp__xam_B480"))) PPC_WEAK_FUNC(xam_B480);
PPC_FUNC_IMPL(__imp__xam_B480) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,7
	ctx.r4.s64 = 7;
	// bl 0x8258686c
	__imp__XamUserGetXUID(ctx, base);
	// cmpwi r3,0
	// blt 0x8257b4a8
	if (ctx.r3.s32 >= 0) {
		// li r3,0
		ctx.r3.s64 = 0;
		// b 0x8257b4c0
	} else {
	loc_8257B4A8:
		// rlwinm r11,r3,0,3,15
		ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x1FFF0000;
		// lis r10,7
		ctx.r10.s64 = 458752;
		// clrlwi r3,r3,16
		ctx.r3.u64 = ctx.r3.u32 & 0xFFFF;
		// cmpw cr6,r11,r10
		// beq cr6,0x8257b4c0
		if (ctx.r11.s32 == ctx.r10.s32) {
			// blr
			return;
		}
		// li r3,1627
		ctx.r3.s64 = 1627;
	}
loc_8257B4C0:
	// blr
	return;
}

__attribute__((alias("__imp__XMsgCancelIORequest_B4D0_fw"))) PPC_WEAK_FUNC(XMsgCancelIORequest_B4D0_fw);
PPC_FUNC_IMPL(__imp__XMsgCancelIORequest_B4D0_fw) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x825867fc
	__imp__XMsgCancelIORequest(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr
	return;
}

__attribute__((alias("__imp__nt_B4F8"))) PPC_WEAK_FUNC(nt_B4F8);
PPC_FUNC_IMPL(__imp__nt_B4F8) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8258688c
	__imp__NtCancelTimer(ctx, base);
	// cmpwi r3,0
	// bge 0x8257b520
	if (ctx.r3.s32 < 0) {
		// bl 0x8242c330
		pg_C330_g(ctx, base);
		// li r3,0
		ctx.r3.s64 = 0;
		// b 0x8257b524
	} else {
	loc_8257B520:
		// li r3,1
		ctx.r3.s64 = 1;
	}
loc_8257B524:
	// blr
	return;
}

__attribute__((alias("__imp__nt_B538"))) PPC_WEAK_FUNC(nt_B538);
PPC_FUNC_IMPL(__imp__nt_B538) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// li r6,1
	ctx.r6.s64 = 1;
	// bl 0x8258689c
	__imp__NtSetTimerEx(ctx, base);
	// cmpwi r3,0
	// bge 0x8257b570
	if (ctx.r3.s32 < 0) {
		// bl 0x8242c330
		pg_C330_g(ctx, base);
		// li r3,0
		ctx.r3.s64 = 0;
		// b 0x8257b590
	} else {
	loc_8257B570:
		// lis r11,16384
		ctx.r11.s64 = 1073741824;
		// ori r11,r11,37
		ctx.r11.u64 = ctx.r11.u64 | 37;
		// cmpw cr6,r3,r11
		// li r3,50
		ctx.r3.s64 = 50;
		// beq cr6,0x8257b588
		if (ctx.r3.s32 != ctx.r11.s32) {
			// li r3,0
			ctx.r3.s64 = 0;
		}
	loc_8257B588:
		// bl 0x8242c388
		thunk_game_C318(ctx, base);
		// li r3,1
		ctx.r3.s64 = 1;
	}
loc_8257B590:
	// blr
	return;
}

__attribute__((alias("__imp__nt_B5A0"))) PPC_WEAK_FUNC(nt_B5A0);
PPC_FUNC_IMPL(__imp__nt_B5A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=128, manual
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// cmplwi cr6,r5,0
	// beq cr6,0x8257b5d0
	if (ctx.r5.u32 != 0) {
		// addi r4,r1,88
		ctx.r4.s64 = ctx.r1.s64 + 88;
		// addi r3,r1,96
		ctx.r3.s64 = ctx.r1.s64 + 96;
		// bl 0x82568d48
		xam_8D48_g(ctx, base);
		// mr r4,r3
		ctx.r4.u64 = ctx.r3.u64;
		// b 0x8257b5d4
	} else {
	loc_8257B5D0:
		// li r4,0
		ctx.r4.s64 = 0;
	}
loc_8257B5D4:
	// cntlzw r11,r31
	ctx.r11.u64 = var_r31 == 0 ? 32 : __builtin_clz(var_r31);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// bl 0x825868ac
	__imp__NtCreateTimer(ctx, base);
	// cmpwi r3,0
	// blt 0x8257b60c
	if (ctx.r3.s32 >= 0) {
		// lis r11,16384
		ctx.r11.s64 = 1073741824;
		// cmpw cr6,r3,r11
		// li r3,183
		ctx.r3.s64 = 183;
		// beq cr6,0x8257b600
		if (ctx.r3.s32 != ctx.r11.s32) {
			// li r3,0
			ctx.r3.s64 = 0;
		}
	loc_8257B600:
		// bl 0x8242c388
		thunk_game_C318(ctx, base);
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// b 0x8257b614
	} else {
	loc_8257B60C:
		// bl 0x8242c330
		pg_C330_g(ctx, base);
		// li r3,0
		ctx.r3.s64 = 0;
	}
loc_8257B614:
	// blr
	return;
}

__attribute__((alias("__imp__nt_B628"))) PPC_WEAK_FUNC(nt_B628);
PPC_FUNC_IMPL(__imp__nt_B628) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// bl 0x825868bc
	__imp__NtDuplicateObject(ctx, base);
	// cmpwi r3,0
	// blt 0x8257b654
	if (ctx.r3.s32 >= 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x8257b65c
	} else {
	loc_8257B654:
		// bl 0x8242c330
		pg_C330_g(ctx, base);
		// li r3,0
		ctx.r3.s64 = 0;
	}
loc_8257B65C:
	// blr
	return;
}

__attribute__((alias("__imp__nt_B670"))) PPC_WEAK_FUNC(nt_B670);
PPC_FUNC_IMPL(__imp__nt_B670) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x825868cc
	__imp__NtReleaseMutant(ctx, base);
	// cmpwi r3,0
	// blt 0x8257b694
	if (ctx.r3.s32 >= 0) {
		// li r3,1
		ctx.r3.s64 = 1;
		// b 0x8257b69c
	} else {
	loc_8257B694:
		// bl 0x8242c330
		pg_C330_g(ctx, base);
		// li r3,0
		ctx.r3.s64 = 0;
	}
loc_8257B69C:
	// blr
	return;
}

__attribute__((alias("__imp__nt_B6B0"))) PPC_WEAK_FUNC(nt_B6B0);
PPC_FUNC_IMPL(__imp__nt_B6B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=128, manual
	// mr r31,r4
	var_r31 = ctx.r4.u32;
	// cmplwi cr6,r5,0
	// beq cr6,0x8257b6e0
	if (ctx.r5.u32 != 0) {
		// addi r4,r1,88
		ctx.r4.s64 = ctx.r1.s64 + 88;
		// addi r3,r1,96
		ctx.r3.s64 = ctx.r1.s64 + 96;
		// bl 0x82568d48
		xam_8D48_g(ctx, base);
		// mr r4,r3
		ctx.r4.u64 = ctx.r3.u64;
		// b 0x8257b6e4
	} else {
	loc_8257B6E0:
		// li r4,0
		ctx.r4.s64 = 0;
	}
loc_8257B6E4:
	// clrlwi r5,r31,24
	ctx.r5.u64 = var_r31 & 0xFF;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x825868dc
	__imp__NtCreateMutant(ctx, base);
	// cmpwi r3,0
	// blt 0x8257b718
	if (ctx.r3.s32 >= 0) {
		// lis r11,16384
		ctx.r11.s64 = 1073741824;
		// cmpw cr6,r3,r11
		// li r3,183
		ctx.r3.s64 = 183;
		// beq cr6,0x8257b70c
		if (ctx.r3.s32 != ctx.r11.s32) {
			// li r3,0
			ctx.r3.s64 = 0;
		}
	loc_8257B70C:
		// bl 0x8242c388
		thunk_game_C318(ctx, base);
		// lwz r3,80(r1)
		ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// b 0x8257b720
	} else {
	loc_8257B718:
		// bl 0x8242c330
		pg_C330_g(ctx, base);
		// li r3,0
		ctx.r3.s64 = 0;
	}
loc_8257B720:
	// blr
	return;
}

__attribute__((alias("__imp__xam_B738"))) PPC_WEAK_FUNC(xam_B738);
PPC_FUNC_IMPL(__imp__xam_B738) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	// FRAME: size=112, manual
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// li r30,1627
	var_r30 = 1627;
	// cmplwi cr6,r31,0
	// beq cr6,0x8257b780
	if (var_r31 != 0) {
		// addi r3,r1,80
		ctx.r3.s64 = ctx.r1.s64 + 80;
		// bl 0x8258687c
		__imp__XamGetExecutionId(ctx, base);
		// cmpwi r3,0
		// blt 0x8257b784
		if (ctx.r3.s32 < 0) {
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			// blr
			return;
		}
		// lwz r11,80(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
		// rlwinm r10,r31,16,16,31
		ctx.r10.u64 = __builtin_rotateleft64(var_r31 | (var_r31 << 32), 16) & 0xFFFF;
		// lhz r11,12(r11)
		ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 12);
		// cmplw cr6,r11,r10
		// bne cr6,0x8257b784
		if (ctx.r11.u32 != ctx.r10.u32) {
			// mr r3,r30
			ctx.r3.u64 = var_r30;
			// blr
			return;
		}
	}
loc_8257B780:
	// li r30,0
	var_r30 = 0;
loc_8257B784:
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// blr
	return;
}

__attribute__((alias("__imp__xam_B7A0"))) PPC_WEAK_FUNC(xam_B7A0);
PPC_FUNC_IMPL(__imp__xam_B7A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	// FRAME: size=160, savegprlr_25
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r27,r7
	var_r27 = ctx.r7.u32;
	// mr r26,r8
	var_r26 = ctx.r8.u32;
	// mr r25,r9
	var_r25 = ctx.r9.u32;
	// bl 0x8257b738
	xam_B738(ctx, base);
	// cmplwi r3,0
	// bne 0x8257b7fc
	if (ctx.r3.u32 == 0) {
		// mr r10,r26
		ctx.r10.u64 = var_r26;
		// stw r25,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, var_r25);
		// mr r9,r27
		ctx.r9.u64 = var_r27;
		// mr r8,r28
		ctx.r8.u64 = var_r28;
		// mr r7,r29
		ctx.r7.u64 = var_r29;
		// li r6,0
		ctx.r6.s64 = 0;
		// li r5,0
		ctx.r5.s64 = 0;
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x825867bc
		__imp__XamUserReadProfileSettings(ctx, base);
	}
loc_8257B7FC:
	return;
}

__attribute__((alias("__imp__xam_B808"))) PPC_WEAK_FUNC(xam_B808);
PPC_FUNC_IMPL(__imp__xam_B808) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r28 = 0;
	uint32_t var_r27 = 0;
	uint32_t var_r26 = 0;
	uint32_t var_r25 = 0;
	uint32_t var_r24 = 0;
	// FRAME: size=160, savegprlr_24
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// mr r27,r7
	var_r27 = ctx.r7.u32;
	// mr r26,r8
	var_r26 = ctx.r8.u32;
	// mr r25,r9
	var_r25 = ctx.r9.u32;
	// mr r24,r10
	var_r24 = ctx.r10.u32;
	// bl 0x8257b738
	xam_B738(ctx, base);
	// cmplwi r3,0
	// bne 0x8257b86c
	if (ctx.r3.u32 == 0) {
		// lwz r11,244(r1)
		ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
		// mr r10,r24
		ctx.r10.u64 = var_r24;
		// mr r9,r25
		ctx.r9.u64 = var_r25;
		// mr r8,r26
		ctx.r8.u64 = var_r26;
		// mr r7,r27
		ctx.r7.u64 = var_r27;
		// mr r6,r28
		ctx.r6.u64 = var_r28;
		// mr r5,r29
		ctx.r5.u64 = var_r29;
		// stw r11,84(r1)
		PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
		// mr r4,r30
		ctx.r4.u64 = var_r30;
		// mr r3,r31
		ctx.r3.u64 = var_r31;
		// bl 0x825867bc
		__imp__XamUserReadProfileSettings(ctx, base);
	}
loc_8257B86C:
	return;
}

__attribute__((alias("__imp__xam_B878"))) PPC_WEAK_FUNC(xam_B878);
PPC_FUNC_IMPL(__imp__xam_B878) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r29 = 0;
	uint32_t var_r31 = 0;
	uint32_t var_r28 = 0;
	// FRAME: size=128, savegprlr_28
	// mr r30,r4
	var_r30 = ctx.r4.u32;
	// mr r29,r5
	var_r29 = ctx.r5.u32;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,3
	ctx.r4.s64 = 3;
	// mr r31,r3
	var_r31 = ctx.r3.u32;
	// mr r28,r6
	var_r28 = ctx.r6.u32;
	// bl 0x8258686c
	__imp__XamUserGetXUID(ctx, base);
	// mr r7,r28
	ctx.r7.u64 = var_r28;
	// mr r6,r29
	ctx.r6.u64 = var_r29;
	// mr r5,r30
	ctx.r5.u64 = var_r30;
	// mr r4,r31
	ctx.r4.u64 = var_r31;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x825868ec
	__imp__XamUserWriteProfileSettings(ctx, base);
	return;
}

__attribute__((alias("__imp__xe_B8C0_w"))) PPC_WEAK_FUNC(xe_B8C0_w);
PPC_FUNC_IMPL(__imp__xe_B8C0_w) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// lis r11,-32160
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r11,26496
	ctx.r3.s64 = ctx.r11.s64 + 26496;
	// lis r4,80
	ctx.r4.s64 = 5242880;
	// bl 0x82186ca8
	xe_alloc_thread_ctx_6CA8(ctx, base);
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14072
	ctx.r3.s64 = ctx.r11.s64 + 14072;
	// bl 0x8242f7d0
	atexit(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__xe_B900_w"))) PPC_WEAK_FUNC(xe_B900_w);
PPC_FUNC_IMPL(__imp__xe_B900_w) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// lis r11,-32160
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r11,26692
	ctx.r3.s64 = ctx.r11.s64 + 26692;
	// lis r4,16
	ctx.r4.s64 = 1048576;
	// bl 0x82186ca8
	xe_alloc_thread_ctx_6CA8(ctx, base);
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14088
	ctx.r3.s64 = ctx.r11.s64 + 14088;
	// bl 0x8242f7d0
	atexit(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__xam_B940_sp"))) PPC_WEAK_FUNC(xam_B940_sp);
PPC_FUNC_IMPL(__imp__xam_B940_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-25132
	ctx.r11.s64 = ctx.r11.s64 + -25132;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_B960_sp"))) PPC_WEAK_FUNC(xam_B960_sp);
PPC_FUNC_IMPL(__imp__xam_B960_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-25112
	ctx.r11.s64 = ctx.r11.s64 + -25112;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_B980_sp"))) PPC_WEAK_FUNC(xam_B980_sp);
PPC_FUNC_IMPL(__imp__xam_B980_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-25092
	ctx.r11.s64 = ctx.r11.s64 + -25092;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_B9A0_sp"))) PPC_WEAK_FUNC(xam_B9A0_sp);
PPC_FUNC_IMPL(__imp__xam_B9A0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-25072
	ctx.r11.s64 = ctx.r11.s64 + -25072;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_B9C0_sp"))) PPC_WEAK_FUNC(xam_B9C0_sp);
PPC_FUNC_IMPL(__imp__xam_B9C0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-25052
	ctx.r11.s64 = ctx.r11.s64 + -25052;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_B9E0_sp"))) PPC_WEAK_FUNC(xam_B9E0_sp);
PPC_FUNC_IMPL(__imp__xam_B9E0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-25032
	ctx.r11.s64 = ctx.r11.s64 + -25032;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BA00_sp"))) PPC_WEAK_FUNC(xam_BA00_sp);
PPC_FUNC_IMPL(__imp__xam_BA00_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-25012
	ctx.r11.s64 = ctx.r11.s64 + -25012;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BA20_sp"))) PPC_WEAK_FUNC(xam_BA20_sp);
PPC_FUNC_IMPL(__imp__xam_BA20_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24992
	ctx.r11.s64 = ctx.r11.s64 + -24992;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BA40_sp"))) PPC_WEAK_FUNC(xam_BA40_sp);
PPC_FUNC_IMPL(__imp__xam_BA40_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24972
	ctx.r11.s64 = ctx.r11.s64 + -24972;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BA60_sp"))) PPC_WEAK_FUNC(xam_BA60_sp);
PPC_FUNC_IMPL(__imp__xam_BA60_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24952
	ctx.r11.s64 = ctx.r11.s64 + -24952;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BA80_sp"))) PPC_WEAK_FUNC(xam_BA80_sp);
PPC_FUNC_IMPL(__imp__xam_BA80_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24932
	ctx.r11.s64 = ctx.r11.s64 + -24932;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BAA0_sp"))) PPC_WEAK_FUNC(xam_BAA0_sp);
PPC_FUNC_IMPL(__imp__xam_BAA0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24912
	ctx.r11.s64 = ctx.r11.s64 + -24912;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BAC0_sp"))) PPC_WEAK_FUNC(xam_BAC0_sp);
PPC_FUNC_IMPL(__imp__xam_BAC0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24892
	ctx.r11.s64 = ctx.r11.s64 + -24892;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BAE0_sp"))) PPC_WEAK_FUNC(xam_BAE0_sp);
PPC_FUNC_IMPL(__imp__xam_BAE0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24872
	ctx.r11.s64 = ctx.r11.s64 + -24872;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BB00_sp"))) PPC_WEAK_FUNC(xam_BB00_sp);
PPC_FUNC_IMPL(__imp__xam_BB00_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24852
	ctx.r11.s64 = ctx.r11.s64 + -24852;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BB20_sp"))) PPC_WEAK_FUNC(xam_BB20_sp);
PPC_FUNC_IMPL(__imp__xam_BB20_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24832
	ctx.r11.s64 = ctx.r11.s64 + -24832;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BB40_sp"))) PPC_WEAK_FUNC(xam_BB40_sp);
PPC_FUNC_IMPL(__imp__xam_BB40_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24812
	ctx.r11.s64 = ctx.r11.s64 + -24812;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BB60_sp"))) PPC_WEAK_FUNC(xam_BB60_sp);
PPC_FUNC_IMPL(__imp__xam_BB60_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24792
	ctx.r11.s64 = ctx.r11.s64 + -24792;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BB80_sp"))) PPC_WEAK_FUNC(xam_BB80_sp);
PPC_FUNC_IMPL(__imp__xam_BB80_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24772
	ctx.r11.s64 = ctx.r11.s64 + -24772;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BBA0_sp"))) PPC_WEAK_FUNC(xam_BBA0_sp);
PPC_FUNC_IMPL(__imp__xam_BBA0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24752
	ctx.r11.s64 = ctx.r11.s64 + -24752;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BBC0_sp"))) PPC_WEAK_FUNC(xam_BBC0_sp);
PPC_FUNC_IMPL(__imp__xam_BBC0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24732
	ctx.r11.s64 = ctx.r11.s64 + -24732;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BBE0"))) PPC_WEAK_FUNC(xam_static_dtor_BBE0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BBE0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14104
	ctx.r3.s64 = ctx.r11.s64 + 14104;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BBF0"))) PPC_WEAK_FUNC(xam_static_dtor_BBF0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BBF0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14128
	ctx.r3.s64 = ctx.r11.s64 + 14128;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_BC00_sp"))) PPC_WEAK_FUNC(xam_BC00_sp);
PPC_FUNC_IMPL(__imp__xam_BC00_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24664
	ctx.r11.s64 = ctx.r11.s64 + -24664;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BC20_sp"))) PPC_WEAK_FUNC(xam_BC20_sp);
PPC_FUNC_IMPL(__imp__xam_BC20_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24644
	ctx.r11.s64 = ctx.r11.s64 + -24644;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BC40_sp"))) PPC_WEAK_FUNC(xam_BC40_sp);
PPC_FUNC_IMPL(__imp__xam_BC40_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24624
	ctx.r11.s64 = ctx.r11.s64 + -24624;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BC60"))) PPC_WEAK_FUNC(xam_static_dtor_BC60);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BC60) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14152
	ctx.r3.s64 = ctx.r11.s64 + 14152;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BC70"))) PPC_WEAK_FUNC(xam_static_dtor_BC70);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BC70) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// lis r11,-32160
	ctx.r11.s64 = -2107637760;
	// addi r3,r11,26992
	ctx.r3.s64 = ctx.r11.s64 + 26992;
	// bl 0x820e8830
	xam_8830_wrh(ctx, base);
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14176
	ctx.r3.s64 = ctx.r11.s64 + 14176;
	// bl 0x8242f7d0
	atexit(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BCA8"))) PPC_WEAK_FUNC(xam_static_dtor_BCA8);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BCA8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14184
	ctx.r3.s64 = ctx.r11.s64 + 14184;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_BCB8_sp"))) PPC_WEAK_FUNC(xam_BCB8_sp);
PPC_FUNC_IMPL(__imp__xam_BCB8_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24588
	ctx.r11.s64 = ctx.r11.s64 + -24588;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BCD8"))) PPC_WEAK_FUNC(xam_static_dtor_BCD8);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BCD8) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14232
	ctx.r3.s64 = ctx.r11.s64 + 14232;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_BCE8_sp"))) PPC_WEAK_FUNC(xam_BCE8_sp);
PPC_FUNC_IMPL(__imp__xam_BCE8_sp) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// lis r11,-32160
	// addi r11,r11,26432
	ctx.r11.s64 = ctx.r11.s64 + 26432;
	// lvx128 v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// lis r11,-32160
	// addi r11,r11,29248
	ctx.r11.s64 = ctx.r11.s64 + 29248;
	// stvx v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v0.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp__xam_BD08_sp"))) PPC_WEAK_FUNC(xam_BD08_sp);
PPC_FUNC_IMPL(__imp__xam_BD08_sp) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// lis r11,-32160
	// addi r11,r11,26432
	ctx.r11.s64 = ctx.r11.s64 + 26432;
	// lvx128 v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// lis r11,-32160
	// addi r11,r11,29232
	ctx.r11.s64 = ctx.r11.s64 + 29232;
	// stvx v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v0.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp__xam_BD28_sp"))) PPC_WEAK_FUNC(xam_BD28_sp);
PPC_FUNC_IMPL(__imp__xam_BD28_sp) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// lis r11,-32160
	// addi r11,r11,26432
	ctx.r11.s64 = ctx.r11.s64 + 26432;
	// lvx128 v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// lis r11,-32160
	// addi r11,r11,29200
	ctx.r11.s64 = ctx.r11.s64 + 29200;
	// stvx v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v0.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp__xam_BD48_sp"))) PPC_WEAK_FUNC(xam_BD48_sp);
PPC_FUNC_IMPL(__imp__xam_BD48_sp) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// lis r11,-32160
	// addi r11,r11,26432
	ctx.r11.s64 = ctx.r11.s64 + 26432;
	// lvx128 v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)ctx.v0.u8, simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)PPC_RAW_ADDR(ea)), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// lis r11,-32160
	// addi r11,r11,29216
	ctx.r11.s64 = ctx.r11.s64 + 29216;
	// stvx v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simde_mm_store_si128((simde__m128i*)PPC_RAW_ADDR(ea), simde_mm_shuffle_epi8(simde_mm_load_si128((simde__m128i*)ctx.v0.u8), simde_mm_load_si128((simde__m128i*)VectorMaskL)));
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BD68"))) PPC_WEAK_FUNC(xam_static_dtor_BD68);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BD68) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14256
	ctx.r3.s64 = ctx.r11.s64 + 14256;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BD78"))) PPC_WEAK_FUNC(xam_static_dtor_BD78);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BD78) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14280
	ctx.r3.s64 = ctx.r11.s64 + 14280;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BD88"))) PPC_WEAK_FUNC(xam_static_dtor_BD88);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BD88) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14304
	ctx.r3.s64 = ctx.r11.s64 + 14304;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_BD98_sp"))) PPC_WEAK_FUNC(xam_BD98_sp);
PPC_FUNC_IMPL(__imp__xam_BD98_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24556
	ctx.r11.s64 = ctx.r11.s64 + -24556;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BDB8_sp"))) PPC_WEAK_FUNC(xam_BDB8_sp);
PPC_FUNC_IMPL(__imp__xam_BDB8_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24536
	ctx.r11.s64 = ctx.r11.s64 + -24536;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BDD8"))) PPC_WEAK_FUNC(xam_static_dtor_BDD8);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BDD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r30 = 0;
	uint32_t var_r31 = 0;
	// FRAME: size=112, manual
	// lis r11,-32160
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r30,r11,31332
	var_r30 = (uint32_t)(ctx.r11.s64 + 31332);  // lbl_82607A64 @ 0x82607a64
	// li r10,8
	ctx.r10.s64 = 8;
	// mr r11,r30
	ctx.r11.u64 = var_r30;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_8257BE04:
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x8257be04
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8257BE04;
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
loc_8257BE14:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmpwi cr6,r11,8
	// stwx r9,r10,r30
	PPC_STORE_U32(ctx.r10.u32 + var_r30, ctx.r9.u32);
	// blt cr6,0x8257be14
	if (ctx.r11.s32 < 8) goto loc_8257BE14;
	// mr r31,r9
	var_r31 = ctx.r9.u32;
loc_8257BE2C:
	// li r7,-1
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = var_r31;
	// li r4,19
	ctx.r4.s64 = 19;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bl 0x820f3ab0
	xam_3AB0_wrh(ctx, base);
	// addi r31,r31,1
	var_r31 = (uint32_t)(var_r31 + 1);
	// cmpwi cr6,r31,8
	// blt cr6,0x8257be2c
	if ((int32_t)var_r31 < 8) goto loc_8257BE2C;
	// li r7,-1
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = var_r30;
	// bl 0x820f3ab0
	xam_3AB0_wrh(ctx, base);
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14312
	ctx.r3.s64 = ctx.r11.s64 + 14312;
	// bl 0x8242f7d0
	atexit(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BE90"))) PPC_WEAK_FUNC(xam_static_dtor_BE90);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BE90) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14320
	ctx.r3.s64 = ctx.r11.s64 + 14320;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_BEA0_sp"))) PPC_WEAK_FUNC(xam_BEA0_sp);
PPC_FUNC_IMPL(__imp__xam_BEA0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24480
	ctx.r11.s64 = ctx.r11.s64 + -24480;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BEC0_sp"))) PPC_WEAK_FUNC(xam_BEC0_sp);
PPC_FUNC_IMPL(__imp__xam_BEC0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24460
	ctx.r11.s64 = ctx.r11.s64 + -24460;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BEE0_sp"))) PPC_WEAK_FUNC(xam_BEE0_sp);
PPC_FUNC_IMPL(__imp__xam_BEE0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24440
	ctx.r11.s64 = ctx.r11.s64 + -24440;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BF00_w"))) PPC_WEAK_FUNC(xam_BF00_w);
PPC_FUNC_IMPL(__imp__xam_BF00_w) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82566d28
	xam_6D28_g(ctx, base);
	// lis r11,-32160
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r31,r11,31400
	var_r31 = (uint32_t)(ctx.r11.s64 + 31400);  // lbl_82607AA8 @ 0x82607aa8
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r3,396(r31)
	PPC_STORE_U32(var_r31 + 396, ctx.r3.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82566d28
	xam_6D28_g(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// lis r10,-32168
	// stw r3,400(r31)
	PPC_STORE_U32(var_r31 + 400, ctx.r3.u32);
	// addi r3,r10,14336
	ctx.r3.s64 = ctx.r10.s64 + 14336;
	// stw r11,392(r31)
	PPC_STORE_U32(var_r31 + 392, ctx.r11.u32);
	// stw r11,388(r31)
	PPC_STORE_U32(var_r31 + 388, ctx.r11.u32);
	// stw r11,384(r31)
	PPC_STORE_U32(var_r31 + 384, ctx.r11.u32);
	// bl 0x8242f7d0
	atexit(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__RtlInitializeCriticalSection_BF78_w"))) PPC_WEAK_FUNC(RtlInitializeCriticalSection_BF78_w);
PPC_FUNC_IMPL(__imp__RtlInitializeCriticalSection_BF78_w) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// lis r11,-32160
	ctx.r11.s64 = -2107637760;
	// addi r3,r11,31364
	ctx.r3.s64 = ctx.r11.s64 + 31364;
	// bl 0x82585ecc
	__imp__RtlInitializeCriticalSection(ctx, base);
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14400
	ctx.r3.s64 = ctx.r11.s64 + 14400;
	// bl 0x8242f7d0
	atexit(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_BFB0"))) PPC_WEAK_FUNC(xam_static_dtor_BFB0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_BFB0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14408
	ctx.r3.s64 = ctx.r11.s64 + 14408;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_BFC0_sp"))) PPC_WEAK_FUNC(xam_BFC0_sp);
PPC_FUNC_IMPL(__imp__xam_BFC0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24420
	ctx.r11.s64 = ctx.r11.s64 + -24420;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_BFE0_sp"))) PPC_WEAK_FUNC(xam_BFE0_sp);
PPC_FUNC_IMPL(__imp__xam_BFE0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24400
	ctx.r11.s64 = ctx.r11.s64 + -24400;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C000_sp"))) PPC_WEAK_FUNC(xam_C000_sp);
PPC_FUNC_IMPL(__imp__xam_C000_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24380
	ctx.r11.s64 = ctx.r11.s64 + -24380;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C020_sp"))) PPC_WEAK_FUNC(xam_C020_sp);
PPC_FUNC_IMPL(__imp__xam_C020_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24336
	ctx.r11.s64 = ctx.r11.s64 + -24336;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C040_sp"))) PPC_WEAK_FUNC(xam_C040_sp);
PPC_FUNC_IMPL(__imp__xam_C040_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24272
	ctx.r11.s64 = ctx.r11.s64 + -24272;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C060_sp"))) PPC_WEAK_FUNC(xam_C060_sp);
PPC_FUNC_IMPL(__imp__xam_C060_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24252
	ctx.r11.s64 = ctx.r11.s64 + -24252;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C080_sp"))) PPC_WEAK_FUNC(xam_C080_sp);
PPC_FUNC_IMPL(__imp__xam_C080_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24232
	ctx.r11.s64 = ctx.r11.s64 + -24232;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C0A0_sp"))) PPC_WEAK_FUNC(xam_C0A0_sp);
PPC_FUNC_IMPL(__imp__xam_C0A0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24212
	ctx.r11.s64 = ctx.r11.s64 + -24212;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C0C0_sp"))) PPC_WEAK_FUNC(xam_C0C0_sp);
PPC_FUNC_IMPL(__imp__xam_C0C0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24192
	ctx.r11.s64 = ctx.r11.s64 + -24192;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C0E0_sp"))) PPC_WEAK_FUNC(xam_C0E0_sp);
PPC_FUNC_IMPL(__imp__xam_C0E0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24160
	ctx.r11.s64 = ctx.r11.s64 + -24160;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C100_sp"))) PPC_WEAK_FUNC(xam_C100_sp);
PPC_FUNC_IMPL(__imp__xam_C100_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24140
	ctx.r11.s64 = ctx.r11.s64 + -24140;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C120_sp"))) PPC_WEAK_FUNC(xam_C120_sp);
PPC_FUNC_IMPL(__imp__xam_C120_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24080
	ctx.r11.s64 = ctx.r11.s64 + -24080;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C140_sp"))) PPC_WEAK_FUNC(xam_C140_sp);
PPC_FUNC_IMPL(__imp__xam_C140_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24060
	ctx.r11.s64 = ctx.r11.s64 + -24060;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C160_sp"))) PPC_WEAK_FUNC(xam_C160_sp);
PPC_FUNC_IMPL(__imp__xam_C160_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24040
	ctx.r11.s64 = ctx.r11.s64 + -24040;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C180_sp"))) PPC_WEAK_FUNC(xam_C180_sp);
PPC_FUNC_IMPL(__imp__xam_C180_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24020
	ctx.r11.s64 = ctx.r11.s64 + -24020;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C1A0_sp"))) PPC_WEAK_FUNC(xam_C1A0_sp);
PPC_FUNC_IMPL(__imp__xam_C1A0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-24000
	ctx.r11.s64 = ctx.r11.s64 + -24000;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C1C0"))) PPC_WEAK_FUNC(xam_static_dtor_C1C0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C1C0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14416
	ctx.r3.s64 = ctx.r11.s64 + 14416;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C1D0"))) PPC_WEAK_FUNC(xam_static_dtor_C1D0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C1D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14432
	ctx.r3.s64 = ctx.r11.s64 + 14432;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_C1E0_sp"))) PPC_WEAK_FUNC(xam_C1E0_sp);
PPC_FUNC_IMPL(__imp__xam_C1E0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23980
	ctx.r11.s64 = ctx.r11.s64 + -23980;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C200_sp"))) PPC_WEAK_FUNC(xam_C200_sp);
PPC_FUNC_IMPL(__imp__xam_C200_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32160
	// lis r11,-32163
	// addi r11,r11,-23960
	ctx.r11.s64 = ctx.r11.s64 + -23960;
	// lwz r9,8316(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8316);
	// stw r11,8316(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8316, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C220_sp"))) PPC_WEAK_FUNC(xam_C220_sp);
PPC_FUNC_IMPL(__imp__xam_C220_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23904
	ctx.r11.s64 = ctx.r11.s64 + -23904;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C240"))) PPC_WEAK_FUNC(xam_static_dtor_C240);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C240) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14496
	ctx.r3.s64 = ctx.r11.s64 + 14496;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_C250_sp"))) PPC_WEAK_FUNC(xam_C250_sp);
PPC_FUNC_IMPL(__imp__xam_C250_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23760
	ctx.r11.s64 = ctx.r11.s64 + -23760;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C270_sp"))) PPC_WEAK_FUNC(xam_C270_sp);
PPC_FUNC_IMPL(__imp__xam_C270_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23712
	ctx.r11.s64 = ctx.r11.s64 + -23712;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C290_sp"))) PPC_WEAK_FUNC(xam_C290_sp);
PPC_FUNC_IMPL(__imp__xam_C290_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23692
	ctx.r11.s64 = ctx.r11.s64 + -23692;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C2B0_sp"))) PPC_WEAK_FUNC(xam_C2B0_sp);
PPC_FUNC_IMPL(__imp__xam_C2B0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23672
	ctx.r11.s64 = ctx.r11.s64 + -23672;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C2D0_sp"))) PPC_WEAK_FUNC(xam_C2D0_sp);
PPC_FUNC_IMPL(__imp__xam_C2D0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23652
	ctx.r11.s64 = ctx.r11.s64 + -23652;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C2F0_sp"))) PPC_WEAK_FUNC(xam_C2F0_sp);
PPC_FUNC_IMPL(__imp__xam_C2F0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23632
	ctx.r11.s64 = ctx.r11.s64 + -23632;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C310_sp"))) PPC_WEAK_FUNC(xam_C310_sp);
PPC_FUNC_IMPL(__imp__xam_C310_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23612
	ctx.r11.s64 = ctx.r11.s64 + -23612;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C330_sp"))) PPC_WEAK_FUNC(xam_C330_sp);
PPC_FUNC_IMPL(__imp__xam_C330_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23592
	ctx.r11.s64 = ctx.r11.s64 + -23592;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C350_sp"))) PPC_WEAK_FUNC(xam_C350_sp);
PPC_FUNC_IMPL(__imp__xam_C350_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23572
	ctx.r11.s64 = ctx.r11.s64 + -23572;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C370_sp"))) PPC_WEAK_FUNC(xam_C370_sp);
PPC_FUNC_IMPL(__imp__xam_C370_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23552
	ctx.r11.s64 = ctx.r11.s64 + -23552;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C390_sp"))) PPC_WEAK_FUNC(xam_C390_sp);
PPC_FUNC_IMPL(__imp__xam_C390_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23232
	ctx.r11.s64 = ctx.r11.s64 + -23232;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C3B0_sp"))) PPC_WEAK_FUNC(xam_C3B0_sp);
PPC_FUNC_IMPL(__imp__xam_C3B0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23212
	ctx.r11.s64 = ctx.r11.s64 + -23212;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C3D0_sp"))) PPC_WEAK_FUNC(xam_C3D0_sp);
PPC_FUNC_IMPL(__imp__xam_C3D0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23192
	ctx.r11.s64 = ctx.r11.s64 + -23192;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C3F0_sp"))) PPC_WEAK_FUNC(xam_C3F0_sp);
PPC_FUNC_IMPL(__imp__xam_C3F0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23172
	ctx.r11.s64 = ctx.r11.s64 + -23172;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C410_sp"))) PPC_WEAK_FUNC(xam_C410_sp);
PPC_FUNC_IMPL(__imp__xam_C410_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23152
	ctx.r11.s64 = ctx.r11.s64 + -23152;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C430_sp"))) PPC_WEAK_FUNC(xam_C430_sp);
PPC_FUNC_IMPL(__imp__xam_C430_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23132
	ctx.r11.s64 = ctx.r11.s64 + -23132;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C450_sp"))) PPC_WEAK_FUNC(xam_C450_sp);
PPC_FUNC_IMPL(__imp__xam_C450_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23112
	ctx.r11.s64 = ctx.r11.s64 + -23112;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C470_sp"))) PPC_WEAK_FUNC(xam_C470_sp);
PPC_FUNC_IMPL(__imp__xam_C470_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23092
	ctx.r11.s64 = ctx.r11.s64 + -23092;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C490_sp"))) PPC_WEAK_FUNC(xam_C490_sp);
PPC_FUNC_IMPL(__imp__xam_C490_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-23072
	ctx.r11.s64 = ctx.r11.s64 + -23072;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C4B0"))) PPC_WEAK_FUNC(xam_static_dtor_C4B0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C4B0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14520
	ctx.r3.s64 = ctx.r11.s64 + 14520;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C4C0"))) PPC_WEAK_FUNC(xam_static_dtor_C4C0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C4C0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14536
	ctx.r3.s64 = ctx.r11.s64 + 14536;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C4D0"))) PPC_WEAK_FUNC(xam_static_dtor_C4D0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C4D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14552
	ctx.r3.s64 = ctx.r11.s64 + 14552;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C4E0"))) PPC_WEAK_FUNC(xam_static_dtor_C4E0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C4E0) {
	PPC_FUNC_PROLOGUE();
	// FRAME: size=96, manual
	// lis r11,-32163
	// li r4,-1
	// addi r3,r11,-23024
	ctx.r3.s64 = ctx.r11.s64 + -23024;
	// bl 0x82154628
	util_4628(ctx, base);
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14568
	ctx.r3.s64 = ctx.r11.s64 + 14568;
	// bl 0x8242f7d0
	atexit(ctx, base);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C518_sp"))) PPC_WEAK_FUNC(xam_C518_sp);
PPC_FUNC_IMPL(__imp__xam_C518_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22464
	ctx.r11.s64 = ctx.r11.s64 + -22464;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C538_sp"))) PPC_WEAK_FUNC(xam_C538_sp);
PPC_FUNC_IMPL(__imp__xam_C538_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22444
	ctx.r11.s64 = ctx.r11.s64 + -22444;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C558_sp"))) PPC_WEAK_FUNC(xam_C558_sp);
PPC_FUNC_IMPL(__imp__xam_C558_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22424
	ctx.r11.s64 = ctx.r11.s64 + -22424;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C578_sp"))) PPC_WEAK_FUNC(xam_C578_sp);
PPC_FUNC_IMPL(__imp__xam_C578_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22404
	ctx.r11.s64 = ctx.r11.s64 + -22404;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C598_sp"))) PPC_WEAK_FUNC(xam_C598_sp);
PPC_FUNC_IMPL(__imp__xam_C598_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22384
	ctx.r11.s64 = ctx.r11.s64 + -22384;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C5B8_sp"))) PPC_WEAK_FUNC(xam_C5B8_sp);
PPC_FUNC_IMPL(__imp__xam_C5B8_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22364
	ctx.r11.s64 = ctx.r11.s64 + -22364;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C5D8_sp"))) PPC_WEAK_FUNC(xam_C5D8_sp);
PPC_FUNC_IMPL(__imp__xam_C5D8_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22344
	ctx.r11.s64 = ctx.r11.s64 + -22344;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C5F8_sp"))) PPC_WEAK_FUNC(xam_C5F8_sp);
PPC_FUNC_IMPL(__imp__xam_C5F8_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22324
	ctx.r11.s64 = ctx.r11.s64 + -22324;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C618_sp"))) PPC_WEAK_FUNC(xam_C618_sp);
PPC_FUNC_IMPL(__imp__xam_C618_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22304
	ctx.r11.s64 = ctx.r11.s64 + -22304;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C638_sp"))) PPC_WEAK_FUNC(xam_C638_sp);
PPC_FUNC_IMPL(__imp__xam_C638_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22284
	ctx.r11.s64 = ctx.r11.s64 + -22284;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__xam_C658_sp"))) PPC_WEAK_FUNC(xam_C658_sp);
PPC_FUNC_IMPL(__imp__xam_C658_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22264
	ctx.r11.s64 = ctx.r11.s64 + -22264;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__audControl3d_C678_2hr"))) PPC_WEAK_FUNC(audControl3d_C678_2hr);
PPC_FUNC_IMPL(__imp__audControl3d_C678_2hr) {
	PPC_FUNC_PROLOGUE();
	uint32_t var_r31 = 0;
	// FRAME: size=96, manual
	// lis r11,-32158
	// li r31,3
	var_r31 = 3;
	// addi r3,r11,-32112
	ctx.r3.s64 = ctx.r11.s64 + -32112;
loc_8257C694:
	// bl 0x821613c8
	audControl3d_13C8_w(ctx, base);
	// addi r31,r31,-1
	var_r31 = (uint32_t)(var_r31 + -1);
	// addi r3,r3,176
	ctx.r3.s64 = ctx.r3.s64 + 176;
	// cmpwi cr6,r31,0
	// bge cr6,0x8257c694
	if ((int32_t)var_r31 >= 0) goto loc_8257C694;
	// blr
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C6C0"))) PPC_WEAK_FUNC(xam_static_dtor_C6C0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C6C0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14576
	ctx.r3.s64 = ctx.r11.s64 + 14576;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C6D0"))) PPC_WEAK_FUNC(xam_static_dtor_C6D0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C6D0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14640
	ctx.r3.s64 = ctx.r11.s64 + 14640;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C6E0"))) PPC_WEAK_FUNC(xam_static_dtor_C6E0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C6E0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14704
	ctx.r3.s64 = ctx.r11.s64 + 14704;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__xam_static_dtor_C6F0"))) PPC_WEAK_FUNC(xam_static_dtor_C6F0);
PPC_FUNC_IMPL(__imp__xam_static_dtor_C6F0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32168
	ctx.r11.s64 = -2108162048;
	// addi r3,r11,14768
	ctx.r3.s64 = ctx.r11.s64 + 14768;
	// b 0x8242f7d0
	atexit(ctx, base);
	return;
}

__attribute__((alias("__imp__atSingleton_C700_sp"))) PPC_WEAK_FUNC(atSingleton_C700_sp);
PPC_FUNC_IMPL(__imp__atSingleton_C700_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22192
	ctx.r11.s64 = ctx.r11.s64 + -22192;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_C720_sp"))) PPC_WEAK_FUNC(atSingleton_C720_sp);
PPC_FUNC_IMPL(__imp__atSingleton_C720_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22172
	ctx.r11.s64 = ctx.r11.s64 + -22172;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_C740_sp"))) PPC_WEAK_FUNC(atSingleton_C740_sp);
PPC_FUNC_IMPL(__imp__atSingleton_C740_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22152
	ctx.r11.s64 = ctx.r11.s64 + -22152;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_C760_sp"))) PPC_WEAK_FUNC(atSingleton_C760_sp);
PPC_FUNC_IMPL(__imp__atSingleton_C760_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22132
	ctx.r11.s64 = ctx.r11.s64 + -22132;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_C780_sp"))) PPC_WEAK_FUNC(atSingleton_C780_sp);
PPC_FUNC_IMPL(__imp__atSingleton_C780_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22112
	ctx.r11.s64 = ctx.r11.s64 + -22112;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_C7A0_sp"))) PPC_WEAK_FUNC(atSingleton_C7A0_sp);
PPC_FUNC_IMPL(__imp__atSingleton_C7A0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22092
	ctx.r11.s64 = ctx.r11.s64 + -22092;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_C7C0_sp"))) PPC_WEAK_FUNC(atSingleton_C7C0_sp);
PPC_FUNC_IMPL(__imp__atSingleton_C7C0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22072
	ctx.r11.s64 = ctx.r11.s64 + -22072;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

__attribute__((alias("__imp__atSingleton_C7E0_sp"))) PPC_WEAK_FUNC(atSingleton_C7E0_sp);
PPC_FUNC_IMPL(__imp__atSingleton_C7E0_sp) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32161
	// lis r11,-32163
	// addi r11,r11,-22052
	ctx.r11.s64 = ctx.r11.s64 + -22052;
	// lwz r9,-17164(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -17164);
	// stw r11,-17164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -17164, ctx.r11.u32);
	// stw r9,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r9.u32);
	// blr
	return;
}

